{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from r2r import R2RClient\n",
    "from scraper import Scraper\n",
    "from splitter import Splitter\n",
    "from io_helper import IOHelper\n",
    "from server import ServerHelper\n",
    "from prompt import PromptHelper\n",
    "\n",
    "client = R2RClient(os.getenv(\"R2R_HOSTNAME\", \"http://localhost:7272\"))\n",
    "scraper = Scraper()\n",
    "splitter = Splitter()\n",
    "io_helper = IOHelper()\n",
    "server = ServerHelper(client)\n",
    "prompt = PromptHelper(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from r2r import R2RConfig\n",
    "\n",
    "config = R2RConfig.from_toml(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.schema_json of <class 'core.base.providers.base.AppConfig'>>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def load_prompt(directory_path):\n",
    "    if not directory_path:\n",
    "        raise ValueError(\"No directory path provided\")\n",
    "    \n",
    "    if not directory_path.is_dir():\n",
    "        error_msg = f\"The specified path is not a directory: {directory_path}\"\n",
    "        raise ValueError(error_msg)\n",
    "\n",
    "    for yaml_file in directory_path.glob(\"*.yaml\"):\n",
    "        try:\n",
    "            with open(yaml_file, \"r\") as file:\n",
    "                data = yaml.safe_load(file)\n",
    "                if not data:\n",
    "                    print(f\"Warning: YAML file {yaml_file} is empty\")\n",
    "                    continue\n",
    "                if not isinstance(data, dict):\n",
    "                    raise ValueError(f\"Invalid format in YAML file {yaml_file}\")\n",
    "                \n",
    "                for name, prompt_data in data.items():\n",
    "                    print(f'{name}, {prompt_data[\"template\"]}, {prompt_data.get(\"input_types\", {})}')\n",
    "                    \n",
    "        except yaml.YAMLError as e:\n",
    "            error_msg = f\"Error loading prompts from YAML file {yaml_file}: {e}\"\n",
    "            raise ValueError(error_msg)\n",
    "        except KeyError as e:\n",
    "            error_msg = f\"Missing key in YAML file {yaml_file}: {e}\"\n",
    "            raise ValueError(error_msg)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected error loading YAML file {yaml_file}: {e}\"\n",
    "            raise ValueError(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_rag_template, ## Task: You are an AI assistant specialized in providing accurate and context-based responses. Your task is to answer user queries using only the information from the provided context. Your responses should be factual, comprehensive, and directly reference the given context.\n",
      "## Context: {context}\n",
      "## Query: {query}\n",
      "## Instructions: 1. Analyze the query and the provided context carefully. 2. Formulate a response based solely on the information in the context. 3. Use specific references (e.g., [1], [2]) to cite relevant parts of the context in your response. 4. Ensure your answer is as comprehensive as possible within the constraints of the given context. 5. If the query cannot be fully answered from the context:\n",
      "  a. Provide partial information if available, clearly stating what aspects you can address.\n",
      "  b. Indicate which parts of the query cannot be answered based on the given context.\n",
      "6. If the query is entirely outside the scope of the provided context, state: \"The provided context does not contain relevant information to answer this query.\" 7. Avoid making assumptions or inferring information beyond what is explicitly stated in the context. 8. Pay attention to any metadata, titles, or structural information in the context to ensure relevance and consistency. 9. If the context contains conflicting information, highlight the discrepancy and provide both viewpoints. 10. Prioritize recent information if dates are provided in the context. 11. If asked for an opinion or subjective interpretation, clarify that you can only provide information based on the given context. 12. If the context includes numerical data, present it accurately and, where appropriate, provide context or comparisons to aid understanding.\n",
      "## Response Format: 1. Brief summary of the query (1-2 sentences) 2. Comprehensive answer with specific references to the context 3. (If applicable) Clear statement of any aspects of the query that could not be addressed 4. (Optional) Suggestions for further queries that could provide more complete information, based on the available context\n",
      "## Response:\n",
      ", {'query': 'str', 'context': 'str'}\n"
     ]
    }
   ],
   "source": [
    "load_prompt(Path(\"my_templates\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested: files\\03 Kubernetes.pdf ...\n"
     ]
    }
   ],
   "source": [
    "files = list(io_helper.iterate_over_files(\"files\"))\n",
    "ingestion_resp = server.ingest_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'c1d89317-1011-5618-8754-4eafb384bd83',\n",
       "  'title': '03 Kubernetes.pdf',\n",
       "  'user_id': '2acb499e-8428-543b-bd85-0d9098718220',\n",
       "  'type': 'pdf',\n",
       "  'created_at': '2024-10-20T21:52:51.967235Z',\n",
       "  'updated_at': '2024-10-20T21:52:51.967239Z',\n",
       "  'ingestion_status': 'success',\n",
       "  'kg_extraction_status': 'pending',\n",
       "  'version': 'v0',\n",
       "  'collection_ids': ['122fdf6a-e116-546b-a8f6-e4cb2e2c0a09'],\n",
       "  'metadata': {'version': 'v0'}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.documents_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = server.document_chunks('c1d89317-1011-5618-8754-4eafb384bd83')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_rsp = server.rag(\n",
    "    query=\"How to create a deployment with 5 replicas that is vertically and horizontally scalable and also create a LoadBalancer?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, here's how you can create a deployment with 5 replicas that is vertically and horizontally scalable and also create a LoadBalancer:\n",
      "\n",
      "**Step 1: Create a Deployment**\n",
      "\n",
      "To create a deployment with 5 replicas, you can use the following command:\n",
      "```bash\n",
      "docker service create --replicas=5 my-service\n",
      "```\n",
      "This will create a new service named `my-service` with 5 replicas.\n",
      "\n",
      "**Step 2: Make the Service Vertically and Horizontally Scalable**\n",
      "\n",
      "To make the service vertically scalable (i.e., increase resources for each replica), you can use the following command:\n",
      "```bash\n",
      "docker service update --resource=cpu=1000m my-service\n",
      "```\n",
      "This will set the CPU resource for each replica to 1 core.\n",
      "\n",
      "To make the service horizontally scalable, you can use a load balancer. In Docker Swarm, you can create a LoadBalancer using the following command:\n",
      "```bash\n",
      "docker service create --name my-load-balancer --publish=8080:80 my-service\n",
      "```\n",
      "This will create a new service named `my-load-balancer` that exposes port 8080 on each node and routes traffic to the `my-service` service.\n",
      "\n",
      "**Step 3: Verify the Deployment**\n",
      "\n",
      "To verify that the deployment was successful, you can use the following command:\n",
      "```bash\n",
      "docker ps -a\n",
      "```\n",
      "This will show you a list of all running containers, including the replicas of your service.\n",
      "\n",
      "You can also check the load balancer by accessing it through the node's IP address and port number (e.g., `<node-ip>:8080`).\n",
      "\n",
      "Note: The above commands are based on Docker Swarm 1.12 or later versions. If you're using an earlier version, please refer to the official documentation for more information.\n"
     ]
    }
   ],
   "source": [
    "print(rag_rsp['completion']['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "from prompt import PromptHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
