R2R_PORT=7272
R2R_HOST=0.0.0.0
R2R_LOG_LEVEL=DEBUG
# Since the `R2R` requires a configuration I use a bind mount inside the docker compose.
# This means that a config file available locally, will be available in the container under that path.
R2R_CONFIG_PATH=/app/custom_config_ollama.toml
R2R_PROJECT_NAME="Evaluation Approaches for RAG"

# These values have to match the ones specified in the `pgvector-db.env`.
R2R_POSTGRES_DBNAME=r2r
R2R_POSTGRES_USER=user
R2R_POSTGRES_PASSWORD=password

# When running docker compose we can use the name of the container.
# This will enable the `r2r` container to use the name of the `pgvector` service as hostname.
R2R_POSTGRES_HOST=pgvector-db
R2R_POSTGRES_PORT=5432
R2R_POSTGRES_MAX_CONNECTIONS=1024
R2R_POSTGRES_STATEMENT_CACHE_SIZE=100

# If not set, the embedding with LiteLLM doesn't work.
# Since `r2r` sends parameters that do not match the ones expected by `litellm` they have to be ignored.
LITELLM_DROP_PARAMS=true

# The communication will be initiated from inside the `r2r` container to `ollama`, which runs locally.
# That special hostname enables communication from inside any container with `localhost`. 
OLLAMA_API_BASE=http://host.docker.internal:11434

# This will be the hostname of the `unstructured` service used for file ingestion.
# `R2R` will send requests to it, and we would get be able to ingest various files.
UNSTRUCTURED_SERVICE_URL=http://unstructured:7275
UNSTRUCTURED_NUM_WORKERS=10

TELEMETRY_ENABLED=false
