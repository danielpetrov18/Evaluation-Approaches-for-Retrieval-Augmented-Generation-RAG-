{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a synthetic dataset using DeepEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesizer\n",
    "\n",
    "This object can be used to generate **Golden** instances, which consist out of **input**, **expected output** and **context**. It uses a LLM to come up with random input and thereafter tries to enhance those, by making them more complex and realistic.\n",
    "\n",
    "For a comprehensive guide on understanding how this object works please refer here: [Synthesizer](https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms)\n",
    "\n",
    "### Summary\n",
    "\n",
    "I will try to summarize the most important information:\n",
    "\n",
    "* It uses a **LLM to come-up with a comprehensive dataset** much faster than a human can\n",
    "* The process starts with the LLM generating **synthetic queries** based on context from a knowledge base - usually documents\n",
    "* Those initial queries are then **evolved** to reflect real-life complexity and then together with the context can be used to generate a **target/expected output**\n",
    "\n",
    "![Dataset generation workflow](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/670574639fc6b9d5c483d766_664050ef1eb43f5fb8f57ff8_diagram.png \"Synthetic generation\")\n",
    "\n",
    "* There exist two main methods:\n",
    "    - Self-improvement: Iteratively uses the LLMs output to generate more complex queries\n",
    "    - Distillation: A stronger model is being utilized \n",
    "\n",
    "* Constructing contexts:\n",
    "    - During this phase documents from the knowledge base are split using a token splitter\n",
    "    - A random chunk is selected\n",
    "    - Finally, additional chunks are retrieved based on **semantic similarity**, **knowledge graphs** or others\n",
    "    - Ensuring that **chunk size**, **chunk overlap** or other similar parameters here and in the **retrieval component** of the **RAG** application are identical will yield better results\n",
    "\n",
    "![Constructing contexts](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/672cb28e9f8f60aabd382788_672cb201dadd3fd2de4451d2_context_generation.png \"Context construction\")\n",
    "\n",
    "* Constructing synthetic queries:\n",
    "    - Using the contexts the **Synthesizer** can now generate synthetic input\n",
    "    - Doing so we ensure that the input corresponds with the context enhancing the **relevancy** and **accuracy**\n",
    "\n",
    "![Constructing synthetic queries](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/672cb28e9f8f60aabd382775_672cb23c502672c70e0372cd_asymmetry.png \"Synthetic queries creation\")\n",
    "\n",
    "* Data Filtering:\n",
    "    1. Context filtering: Removes low-quality chunks that may be unintelligible\n",
    "\n",
    "    ![Context filtering](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/672cb28e9f8f60aabd38278b_672cb26b461b45b0b5a6cd30_context_filtering.png \"Filtering context\")\n",
    "\n",
    "    2. Input filtering: Ensures generated inputs meet quality standards\n",
    "\n",
    "    ![Input filtering](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/672cb28e9f8f60aabd382772_672cb27b799642a337436c3f_input_filtering.png \"Filtering queries\")\n",
    "    \n",
    "* Customizing dataset generating:\n",
    "    - Depending on the scenario inputs and outputs can be tailored to specific use cases\n",
    "        - For example a medical chatbot would have a completely different behaviour than a scientific one. It would need to comfort patients.\n",
    "    \n",
    "* Data Evolution:\n",
    "    - **In-Depth Evolving**: Expands simple instructions into more detailed versions\n",
    "    - **In-Breadth Evolving**: Produces diverse instructions to enrich the dataset\n",
    "    - **Elimination Evolving**: Removes less effective instructions\n",
    "\n",
    "    ![Data evolution](https://cdn.prod.website-files.com/64bd90bdba579d6cce245aec/670574639fc6b9d5c483d763_6641a0d7ef709f365d888577_Screenshot%25202024-05-13%2520at%25201.10.30%2520PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies:\n",
    "\n",
    "* If you already have a **virtual environment** you **DON'T** need to execute the next function.\n",
    "* Make sure you select the correct kernel in your notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_venv(venv_exists: bool = False, name: str = \"venv\"):\n",
    "    if not venv_exists:\n",
    "        !python3 -m venv {name}\n",
    "    \n",
    "    # Install requirements into the venv directly\n",
    "    !{name}/bin/pip install -U deepeval ipykernel\n",
    "     \n",
    "    print(f\"Virtual environment '{name}' has been created and packages installed.\")\n",
    "    print(\"Important: You need to manually select this kernel in your notebook:\")\n",
    "    print(f\"1. Restart the kernel\")\n",
    "    print(f\"2. Select the '{name}' kernel from the kernel menu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_venv(venv_exists=False, name=\"venv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After installing dependencies and selecting the kernel you should be good to go.\n",
    "# Make sure the package is installed before continuing further.\n",
    "!pip3 show deepeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM provider\n",
    "\n",
    "**DeepEval** uses **OpenAI** by default as a LLM, however **Ollama** is also available. To use it execute the code cell below. This will generate a `.deepeval` file where key-value pairs will be stored about that particular LLM-provider like model name, base url and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙌 Congratulations! You're now using a local Ollama model for all evals that \n",
      "require an LLM.\n",
      "🙌 Congratulations! You're now using Ollama embeddings for all evals that \n",
      "require text embeddings.\n"
     ]
    }
   ],
   "source": [
    "!deepeval set-ollama llama3.1 --base-url=\"http://localhost:11434/\"\n",
    "!deepeval set-ollama-embeddings mxbai-embed-large --base-url=\"http://localhost:11434\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting chunks from knowledge base to be used as context in data generation\n",
    "\n",
    "**Before executing the next cell:**\n",
    "* Make sure Ollama is up and running.\n",
    "* Download the required models for generation and embedding.\n",
    "* Make sure docker is up and running.\n",
    "* Activate the compose file in the root of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory already exists. Skipping download.\n",
      "Virtual environment already exists. Skipping creation.\n",
      "Dependencies already installed. Skipping installation.\n",
      "Environment is set and ready to be used\n",
      "Error when creating document: {'message': 'Document 88fa13ca-5921-590f-8693-408b1ed047bf already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document bf55e614-3330-5283-a759-ea1bfa15a655 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document d7c24a75-99ba-5b84-8339-5a9188be0580 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document 2a9978ac-84fd-5644-8633-dcc90e19c123 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document a5ef7ed6-02c2-5a86-9299-fff661c1e7f7 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document 6530a034-daa1-5198-b340-563b5e45ca2b already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document db0faff8-f57f-5459-91f4-92f611106fa1 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "Error when creating document: {'message': 'Document 15bea571-fbd0-5ed6-a1c2-5bb70b6b7f36 already exists. Submit a DELETE request to `/documents/{document_id}` to delete this document and allow for re-ingestion.', 'error_type': 'R2RException'}\n",
      "INGESTION STEP COMPLETED...\n",
      "EXTRACTION STEP COMPLETED...\n",
      "SAVED TO JSON FILE...\n",
      "Data extracted and saved to chunks.json\n",
      "chunks.json\t       evaluate.ipynb\t  fill_dataset.py  r2r_venv\n",
      "data\t\t       extract_chunks.py  fill_dataset.sh  venv\n",
      "deepeval_dataset.json  extract_chunks.sh  generate.ipynb\n"
     ]
    }
   ],
   "source": [
    "!chmod u+x ./extract_chunks.sh\n",
    "!./extract_chunks.sh\n",
    "!ls # There should be a chunks.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtration config** serves as a way to configure the quality of the generated synthetic input queries. Having higher threshold would ensure that the input queries are of higher quality.\n",
    "\n",
    "If the **quality_score** is still lower than the **synthetic_input_quality_threshold** after **max_quality_retries**, the **golden with the highest quality_score** will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.synthesizer.config import FiltrationConfig\n",
    "\n",
    "# (This step is completely OPTIONAL)\n",
    "# https://www.deepeval.com/docs/synthesizer-introduction\n",
    "filtration_config = FiltrationConfig(\n",
    "    synthetic_input_quality_threshold=0.7,\n",
    "    max_quality_retries=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evolutions** are used to specify the type of approach to use when trying to complicate the synthetic queries. Since this is a **RAG** application I will only use the evolution types which use **context**. The `num_evolutions` parameter can be configured to specify the number of iterations for performing those evolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.synthesizer.config import (\n",
    "    Evolution,\n",
    "    EvolutionConfig,\n",
    ")\n",
    "\n",
    "# (This step is completely OPTIONAL)\n",
    "# https://www.deepeval.com/docs/synthesizer-introduction\n",
    "evolution_config = EvolutionConfig(\n",
    "    num_evolutions=1,\n",
    "    evolutions={\n",
    "        Evolution.MULTICONTEXT: 0.25,\n",
    "        Evolution.CONCRETIZING: 0.25,\n",
    "        Evolution.CONSTRAINED: 0.25,\n",
    "        Evolution.COMPARATIVE: 0.25,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.synthesizer import Synthesizer\n",
    "\n",
    "# https://www.deepeval.com/docs/synthesizer-introduction\n",
    "synthesizer = Synthesizer(\n",
    "    filtration_config=filtration_config,\n",
    "    evolution_config=evolution_config\n",
    ")\n",
    "\n",
    "from deepeval.synthesizer.config import ContextConstructionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(file=\"chunks.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    context_chunks = json.load(f)\n",
    "\n",
    "source_files = []\n",
    "for file in os.listdir(\"data\"):\n",
    "    if file.endswith(\".md\") and file != \"README.md\":  \n",
    "        source_files.append(f\"data/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✨ Generating up to 56 goldens using DeepEval (using llama3.1 (Ollama), method=default): 100%|██████████| 56/56 [1:29:59<00:00, 96.42s/it]  \n"
     ]
    }
   ],
   "source": [
    "from deepeval.dataset.golden import Golden\n",
    "\n",
    "goldens: list[Golden] = synthesizer.generate_goldens_from_contexts(\n",
    "    contexts=context_chunks,\n",
    "    include_expected_output=True,\n",
    "    max_goldens_per_context=7,\n",
    "    source_files=source_files\n",
    ")\n",
    "\n",
    "# Save locally (Optional)\n",
    "# goldens_dataframe = synthesizer.to_pandas()\n",
    "synthesizer.save_as(\n",
    "    # Type of file to save ('json' or 'csv')\n",
    "    file_type='json',\n",
    "    # Directory where the file will be saved\n",
    "    directory=\"./synthetic_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confident AI\n",
    "\n",
    "1. In short **Confident AI** is a cloud-based platform part of the **DeepEval** framework, which stores **datasets**, **evaluations** and **monitoring data**. \n",
    "\n",
    "2. If you want to use **Confident AI** platform create an account from here: [Confident AI](https://www.confident-ai.com/)\n",
    "\n",
    "3. After signing-up an **API key** will be generated, which can be used to interact with the platform from inside the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "Example of .env file:\n",
    "```bash\n",
    "DEEPEVAL_RESULTS_FOLDER=<folder> # Results of evaluations can be saved locally\n",
    "DEEPEVAL_API_KEY=<your api key>  # Relevant if you want to use Confident AI\n",
    "DEEPEVAL_TELEMETRY_OPT_OUT=\"YES\" # Remove telemetry\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🎉🥳 Congratulations! You've successfully logged in! 🙌 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "🎉🥳 Congratulations! You've successfully logged in! 🙌 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from deepeval import login_with_confident_api_key\n",
    "\n",
    "# Loads the environment variables from a `.env` file.\n",
    "# If you want to use Confident AI be sure to create one in this directory.\n",
    "load_dotenv()\n",
    "\n",
    "deepeval_api_key: str = os.getenv(\"DEEPEVAL_API_KEY\")\n",
    "\n",
    "# You should get a message letting you know you are logged-in.\n",
    "login_with_confident_api_key(deepeval_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Dataset successfully pushed to Confident AI! View at \n",
       "<a href=\"https://app.confident-ai.com/project/cm8yaugri01pu126xyl2ybbmz/datasets/cm9k8fxwr38bcozrwh2ejr2o9\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cm8yaugri01pu126xyl2ybbmz/datasets/cm9k8fxwr38bcozrwh2ejr2o9</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Dataset successfully pushed to Confident AI! View at \n",
       "\u001b]8;id=999592;https://app.confident-ai.com/project/cm8yaugri01pu126xyl2ybbmz/datasets/cm9k8fxwr38bcozrwh2ejr2o9\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cm8yaugri01pu126xyl2ybbmz/datasets/cm9k8fxwr38bcozrwh2ejr2o9\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 20:55:56.337: Failed to load module \"canberra-gtk-module\"\n",
      "Gtk-Message: 20:55:56.338: Failed to load module \"canberra-gtk-module\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "dataset = EvaluationDataset(goldens=goldens)\n",
    "dataset.push(alias=\"DeepEval Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "# I did some cleaning on the data since the input was not fully in the expected format on the ConfidentAI platform.\n",
    "final_dataset = EvaluationDataset()\n",
    "final_dataset.pull(alias=\"DeepEval Dataset\")\n",
    "\n",
    "# Saving the data locally so I can use it in a script.\n",
    "# Since R2R and DeepEval have conflicting dependencies a virtual environment with both of these \n",
    "# libraries doesn't work. They need to be separated.\n",
    "json_out: list[dict] = []\n",
    "for golden in final_dataset.goldens:\n",
    "    json_out.append(golden.model_dump())\n",
    "\n",
    "# Save json data\n",
    "with open(\"deepeval_dataset.json\", \"w\") as f:\n",
    "    json.dump(json_out, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of `actual response` and `retrieval context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual environment already exists. Skipping creation.\n",
      "Dependencies already installed. Skipping installation.\n",
      "Environment is set and ready to be used\n",
      "No template name provided. Using default template.\n",
      "Added data to sample: 1 out of 54\n",
      "Added data to sample: 2 out of 54\n",
      "Added data to sample: 3 out of 54\n",
      "Added data to sample: 4 out of 54\n",
      "Added data to sample: 5 out of 54\n",
      "Added data to sample: 6 out of 54\n",
      "Added data to sample: 7 out of 54\n",
      "Added data to sample: 8 out of 54\n",
      "Added data to sample: 9 out of 54\n",
      "Added data to sample: 10 out of 54\n",
      "Added data to sample: 11 out of 54\n",
      "Added data to sample: 12 out of 54\n",
      "Added data to sample: 13 out of 54\n",
      "Added data to sample: 14 out of 54\n",
      "Added data to sample: 15 out of 54\n",
      "Added data to sample: 16 out of 54\n",
      "Added data to sample: 17 out of 54\n",
      "Added data to sample: 18 out of 54\n",
      "Added data to sample: 19 out of 54\n",
      "Added data to sample: 20 out of 54\n",
      "Added data to sample: 21 out of 54\n",
      "Added data to sample: 22 out of 54\n",
      "Added data to sample: 23 out of 54\n",
      "Added data to sample: 24 out of 54\n",
      "Added data to sample: 25 out of 54\n",
      "Added data to sample: 26 out of 54\n",
      "Added data to sample: 27 out of 54\n",
      "Added data to sample: 28 out of 54\n",
      "Added data to sample: 29 out of 54\n",
      "Added data to sample: 30 out of 54\n",
      "Added data to sample: 31 out of 54\n",
      "Added data to sample: 32 out of 54\n",
      "Added data to sample: 33 out of 54\n",
      "Added data to sample: 34 out of 54\n",
      "Added data to sample: 35 out of 54\n",
      "Added data to sample: 36 out of 54\n",
      "Added data to sample: 37 out of 54\n",
      "Added data to sample: 38 out of 54\n",
      "Added data to sample: 39 out of 54\n",
      "Added data to sample: 40 out of 54\n",
      "Added data to sample: 41 out of 54\n",
      "Added data to sample: 42 out of 54\n",
      "Added data to sample: 43 out of 54\n",
      "Added data to sample: 44 out of 54\n",
      "Added data to sample: 45 out of 54\n",
      "Added data to sample: 46 out of 54\n",
      "Added data to sample: 47 out of 54\n",
      "Added data to sample: 48 out of 54\n",
      "Added data to sample: 49 out of 54\n",
      "Added data to sample: 50 out of 54\n",
      "Added data to sample: 51 out of 54\n",
      "Added data to sample: 52 out of 54\n",
      "Added data to sample: 53 out of 54\n",
      "Added data to sample: 54 out of 54\n",
      "Full dataset saved...\n",
      "{'input': \"Considering the necessity of advance notification and preparation for passengers requiring special assistance, how do Ragas Airlines' wheelchair assistance, priority boarding, and airport escort service cater to passengers with disabilities during various stages of their journey, such as check-in, security, boarding, and deplaning?\", 'actual_output': 'Ragas Airlines provides wheelchair assistance, priority boarding, and airport escort services for passengers with disabilities. These services are available at different stages of the journey:\\n\\n*   Wheelchair assistance is available at check-in, security, boarding, and deplaning.\\n*   Priority boarding allows passengers needing assistance to board before other passengers.\\n*   The airport escort service provides assistance from check-in to the boarding gate.\\n\\nThese services aim to ensure a smooth and comfortable experience for passengers with disabilities throughout their journey.', 'expected_output': 'Ragas Airlines provides comprehensive support for passengers with disabilities through its special assistance services. For wheelchair assistance, the airline offers support at check-in, security, boarding, and deplaning stages. Additionally, priority boarding allows passengers needing assistance to board before other passengers. The Airport Escort Service provides a dedicated assistant from check-in to the boarding gate.\\n\\nThese services are available upon advance request (at least 48 hours prior) through various channels such as \"Manage My Booking\" on the airline\\'s website, the customer support hotline, or through a travel agent. This ensures that Ragas Airlines can accommodate passengers\\' needs effectively and provide a smooth journey for all its customers.', 'context': ['# *\\n\\nSpecial Assistance**\\n\\nRagas Airlines provides **special assistance services** for passengers with disabilities, unaccompanied minors, and those requiring medical support. Below is a **detailed breakdown** of how to request and prepare for these services.\\n\\n---\\n\\n## *\\n\\nPassengers with Disabilities**\\n\\nRagas Airlines ensures accessibility for passengers requiring **wheelchair assistance, mobility aid support, or other special needs accommodations**.\\n\\n### **1: Requesting Assistance Before Travel** - Request assistance at least **48 hours before departure** through: - **“Manage My Booking”** on the airline’s website. - The **customer support hotline**. - Your **travel agent (if booked through an agent)**.\\n\\n### **2: Available Assistance Options** - **Wheelchair Assistance** → Available at check-in, security, boarding, and deplaning. - **Priority Boarding** → Passengers needing assistance can board before other passengers. - **Airport Escort Service** → Assistance from check-in to the boarding gate.', '### **3: Traveling with Medical Equipment or Service Animals** - **Medical Equipment** → Passengers may carry medical devices (e.g., portable oxygen concentrators) but must notify the airline **48 hours in advance**. - **Service Animals** → Allowed on board but require **advance notification and documentation**.\\n\\n---\\n\\n## *\\n\\nUnaccompanied Minors**\\n\\nChildren traveling alone are provided with **dedicated staff assistance** to ensure a safe journey.\\n\\n### **1: Age Restrictions for Unaccompanied Minors** - **5-12 years** → Must use the airline’s **Unaccompanied Minor (UM) service**. - **13-17 years** → Optional UM service available.\\n\\n### **2: Booking the UM Service** - **Step 1:** Contact **customer service** or your travel agent to book the UM service. - **Step 2:** Provide parent/guardian details, including: - **Full name and contact number** of the person dropping off the minor. - **Full name and contact number** of the person receiving the minor.', '### **3: Airport Assistance** - A **dedicated airline staff member** will: - Escort the child through **security and boarding**. - Supervise them during the flight. - Ensure a **safe handover** at the destination.\\n\\n---\\n\\n## *\\n\\nPassengers with Medical Conditions**\\n\\nPassengers requiring **medical assistance** or **special accommodations** must notify the airline at least **48 hours before departure**.\\n\\n### **1: Traveling with Medications** - Carry medications in **original packaging** with a **doctor’s prescription**. - If medication requires refrigeration, **notify the airline in advance**.\\n\\n### **2: Medical Clearance for Travel** Passengers may need a **doctor’s approval** if: - They recently had **surgery**. - They have a **contagious illness**. - They require **in-flight oxygen or other medical support**.\\n\\nTo obtain clearance: 1. Have your **doctor complete a Medical Information Form (MEDIF)**. 2. Submit the form to the airline’s **medical department** at least **48 hours before the flight**.\\n\\n---', '## **Potential Issues and Resolutions for Special Assistance**\\n\\n### **1. Late Requests for Special Assistance** If you did not request assistance in advance: - **Step 1:** Visit the airline’s check-in counter **as early as possible**. - **Step 2:** Inform the staff about your requirements. - **Step 3:** The airline will try to accommodate you, but some services may be unavailable on short notice.\\n\\n---\\n\\n### **2. Missing Documents for Medical Clearance** If a **medical clearance form (MEDIF) is missing**, the airline may deny boarding. - **Step 1:** Contact your **doctor immediately** to request the required paperwork. - **Step 2:** Submit the form via **email or fax** to the airline’s medical department. - **Step 3:** If clearance is delayed, request to **reschedule your flight** instead of canceling.\\n\\n---'], 'retrieval_context': ['# *\\n\\nSpecial Assistance**\\n\\nRagas Airlines provides **special assistance services** for passengers with disabilities, unaccompanied minors, and those requiring medical support. Below is a **detailed breakdown** of how to request and prepare for these services.\\n\\n---\\n\\n## *\\n\\nPassengers with Disabilities**\\n\\nRagas Airlines ensures accessibility for passengers requiring **wheelchair assistance, mobility aid support, or other special needs accommodations**.\\n\\n### **1: Requesting Assistance Before Travel** - Request assistance at least **48 hours before departure** through: - **“Manage My Booking”** on the airline’s website. - The **customer support hotline**. - Your **travel agent (if booked through an agent)**.\\n\\n### **2: Available Assistance Options** - **Wheelchair Assistance** → Available at check-in, security, boarding, and deplaning. - **Priority Boarding** → Passengers needing assistance can board before other passengers. - **Airport Escort Service** → Assistance from check-in to the boarding gate.', '### **Step 2: Assistance Provided by the Airline**\\n\\nDepending on the length of the delay, Ragas Airlines offers different levels of support:\\n\\n#### **Condition 1. Short Delays (Less than 2 Hours)** - Stay near the departure gate and monitor **updates** via screens or mobile notifications.\\n\\n#### **Condition 2. Moderate Delays (Between 2 to 6 Hours)** - Passengers will receive **complimentary refreshments or meal vouchers**. - Visit an airline representative at the airport to collect your meal voucher.\\n\\n#### **Condition 3. Extended Delays (More than 6 Hours)** - Passengers may receive: - **Compensation** (depending on airline policy). - **Hotel accommodation** (for overnight delays). - **Transportation to and from the hotel** (provided by Ragas Airlines). - To claim accommodation or transport, visit the airline’s **help desk at the airport**.\\n\\n---\\n\\n## *\\n\\nPassenger Responsibilities During Delays**\\n\\nStep 1: Stay Informed*\\n\\nRegularly check *\\n\\nflight status updates*\\n\\nthrough:\\n\\nThe *\\n\\nairline’s website*', '# *\\n\\nIn\\n\\nFlight Services**\\n\\nRagas Airlines provides a variety of **in-flight amenities and services** to ensure a comfortable and enjoyable journey for all passengers. This section outlines available **meals, entertainment options, seating arrangements, and customer support during the flight**.\\n\\n---\\n\\n## *\\n\\nMeals and Beverages**\\n\\n### **1. Standard Meal Service** - Complimentary meals and beverages are provided on **long-haul flights**. - On **short-haul or domestic flights**, snacks and drinks may be available for **purchase**.\\n\\n### **2. Special Dietary Meals** Passengers can **pre-order special meals** to accommodate dietary needs, including: - Vegetarian - Vegan - Gluten-Free - Diabetic - Kosher/Halal\\n\\nTo request a special meal: - **Step 1:** Log into **\"Manage My Booking\"** at least **24 hours before departure**. - **Step 2:** Select **“Meal Preferences”** and choose the appropriate meal type. - **Step 3:** Confirm and check your boarding pass for meal confirmation.\\n\\n---\\n\\n## *\\n\\nIn', 'Flight Customer Support**\\n\\n### **1. Cabin Crew Assistance** Passengers can request assistance for: - Medical emergencies. - Special needs (disabilities, elderly passengers, parents with infants). - Seat adjustments or issues.\\n\\n### **2. Handling Passenger Complaints or Issues** If you encounter **any problems during the flight** (e.g., seating disputes, malfunctioning entertainment systems, or meal service issues), follow these steps: - **Step 1:** Notify a **flight attendant** immediately. - **Step 2:** If the issue is unresolved, request to speak to the **chief flight attendant**. - **Step 3:** If needed, file a **formal complaint** after landing via: - The **Ragas Airlines website**. - The **customer service desk at the airport**.\\n\\n---', '# *\\n\\nFlight Delays**\\n\\nFlight delays can be caused by **weather conditions, air traffic control restrictions, technical issues, or operational constraints**. Ragas Airlines aims to keep passengers informed and provide assistance in case of significant delays. Below is a **step-by-step guide** on how to handle flight delays effectively.\\n\\n---\\n\\n## **Airline’s Responsibilities in Case of Delays**\\n\\nWhen a flight is delayed, Ragas Airlines will:\\n\\n### **Step 1: Notify Passengers** - You will receive delay notifications via: - **Email** (check spam/junk folders if necessary). - **SMS** (ensure your registered phone number is active). - **Airport Announcements** (stay near your boarding gate for updates). - **Mobile App Notification** (if using the airline’s app).\\n\\nThe notification will include:\\n\\nUpdated departure time*\\n\\n.\\n\\nReason for the delay*\\n\\n.\\n\\nCompensation details (if applicable)*\\n\\n.\\n\\n---'], 'additional_metadata': {'evolutions': ['Constrained'], 'synthetic_input_quality': 1}, 'comments': None, 'tools_called': None, 'expected_tools': None, 'source_file': None}\n"
     ]
    }
   ],
   "source": [
    "# If you already have a custom prompt which is ingested in R2R you can provide the name as an argument to the script.\n",
    "!chmod u+x ./fill_dataset.sh\n",
    "!./fill_dataset.sh # Optional argument: custom_prompt_name\n",
    "\n",
    "# Check for the first golden if everything looks fine\n",
    "with open(\"deepeval_dataset.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having all of the data push the full dataset to ConfidentAI\n",
    "from deepeval.dataset.golden import Golden\n",
    "\n",
    "final_dataset.goldens.clear()\n",
    "for golden in data:\n",
    "    final_dataset.goldens.append(Golden(**golden))\n",
    "    \n",
    "final_dataset.push(\n",
    "    alias=\"DeepEval Dataset\",\n",
    "    overwrite=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
