{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been used on [Kaggle](https://www.kaggle.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone my repository\n",
    "!git clone https://github.com/danielpetrov18/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:55:40.337578Z",
     "iopub.status.busy": "2025-05-13T12:55:40.337122Z",
     "iopub.status.idle": "2025-05-13T12:55:40.346139Z",
     "shell.execute_reply": "2025-05-13T12:55:40.345464Z",
     "shell.execute_reply.started": "2025-05-13T12:55:40.337552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Switch into the ragas folder\n",
    "%cd Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/ragas_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip3 install -U ragas==0.2.15 rapidfuzz==3.13.0 langchain-ollama==0.3.2 python-dotenv==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download and install Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:55:43.934153Z",
     "iopub.status.busy": "2025-05-13T12:55:43.933567Z",
     "iopub.status.idle": "2025-05-13T12:55:43.938515Z",
     "shell.execute_reply": "2025-05-13T12:55:43.937765Z",
     "shell.execute_reply.started": "2025-05-13T12:55:43.934131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../env/rag.env\")\n",
    "\n",
    "# Create environment variables dictionary\n",
    "env = os.environ.copy()  # Start with current environment\n",
    "env[\"OLLAMA_KEEP_ALIVE\"] = \"1h\"\n",
    "env[\"OLLAMA_CONTEXT_LENGTH\"] = os.environ.get(\"LLM_CONTEXT_WINDOW_TOKENS\", \"16000\")\n",
    "\n",
    "# Start Ollama server in the background\n",
    "ollama_process = subprocess.Popen(\n",
    "    [\"ollama\", \"serve\"],\n",
    "    env=env,\n",
    "    # Uncomment the following lines if you want to capture the output\n",
    "    # stdout=subprocess.PIPE,\n",
    "    # stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Give it a moment to start up\n",
    "time.sleep(2)\n",
    "\n",
    "# Check if the process is running\n",
    "if ollama_process.poll() is None:\n",
    "    print(\"Ollama server started successfully\")\n",
    "else:\n",
    "    print(\"Failed to start Ollama server\")\n",
    "    if hasattr(ollama_process, 'stderr'):\n",
    "        print(ollama_process.stderr.read().decode())\n",
    "\n",
    "# To stop the process if needed\n",
    "# ollama_process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_model: str = os.getenv(\"EMBEDDING_MODEL\")\n",
    "evaluation_model: str = os.getenv(\"EVALUATION_MODEL\")\n",
    "\n",
    "# Download models\n",
    "! ollama pull {embedding_model} && ollama pull {evaluation_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:55:47.028123Z",
     "iopub.status.busy": "2025-05-13T12:55:47.027520Z",
     "iopub.status.idle": "2025-05-13T12:55:47.151030Z",
     "shell.execute_reply": "2025-05-13T12:55:47.150273Z",
     "shell.execute_reply.started": "2025-05-13T12:55:47.028097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Retrieve sensitive data (OPTIONAL STEP)\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "ragas_app_token = user_secrets.get_secret(\"RAGAS_APP_TOKEN\")\n",
    "\n",
    "os.environ['RAGAS_APP_TOKEN'] = ragas_app_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:55:49.678394Z",
     "iopub.status.busy": "2025-05-13T12:55:49.677728Z",
     "iopub.status.idle": "2025-05-13T12:55:56.289841Z",
     "shell.execute_reply": "2025-05-13T12:55:56.289231Z",
     "shell.execute_reply.started": "2025-05-13T12:55:49.678362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify which dataset to evaluate (only the file name):  test_id_1-dataset\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from ragas import EvaluationDataset, SingleTurnSample\n",
    "\n",
    "# Load the dataset corresponding to the experiment you want to test\n",
    "\n",
    "# The are located under `./datasets`\n",
    "filepath: str = input(\"Please specify which dataset to evaluate (only the file name): \")\n",
    "\n",
    "goldens: List[Dict] = []\n",
    "try:\n",
    "    with open(file=f\"./datasets/{filepath}.jsonl\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                goldens.append(json.loads(line))\n",
    "\n",
    "    samples: List[SingleTurnSample] = []\n",
    "    for golden in goldens:\n",
    "        single_turn_sample = SingleTurnSample(**golden)\n",
    "        samples.append(single_turn_sample)\n",
    "        \n",
    "    evaluation_dataset = EvaluationDataset(samples)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File: `./datasets/{filepath}.jsonl` containing goldens not found!\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSONL file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:55:59.153911Z",
     "iopub.status.busy": "2025-05-13T12:55:59.153107Z",
     "iopub.status.idle": "2025-05-13T12:55:59.517833Z",
     "shell.execute_reply": "2025-05-13T12:55:59.517262Z",
     "shell.execute_reply.started": "2025-05-13T12:55:59.153885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "from ragas import RunConfig, DiskCacheBackend\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# Instantiating required objects\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=86400,    # 24 hours on waiting for a single operation\n",
    "    max_retries=20,   # Max retries before giving up\n",
    "    max_wait=600,     # Max wait between retries\n",
    "    max_workers=4,    # Concurrent requests\n",
    "    log_tenacity=True # Print retry attempts\n",
    ")\n",
    "\n",
    "# This stores data generation and evaluation results locally on disk\n",
    "# When using it for the first time, it will create a .cache folder\n",
    "# When using it again, it will read from that folder and finish almost instantly\n",
    "cacher = DiskCacheBackend(cache_dir=f\".cache-{filepath}\")\n",
    "\n",
    "ragas_llm = LangchainLLMWrapper(\n",
    "    langchain_llm=ChatOllama(\n",
    "        model=evaluation_model,\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        temperature=float(os.getenv(\"EVALUATION_TEMPERATURE\")),\n",
    "        num_ctx=int(os.getenv(\"LLM_CONTEXT_WINDOW_TOKENS\")),\n",
    "        format=\"json\"\n",
    "    ),\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(\n",
    "    embeddings=OllamaEmbeddings(\n",
    "        model=embedding_model,\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    ),\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:01.796361Z",
     "iopub.status.busy": "2025-05-13T12:56:01.795775Z",
     "iopub.status.idle": "2025-05-13T12:56:01.801574Z",
     "shell.execute_reply": "2025-05-13T12:56:01.800889Z",
     "shell.execute_reply.started": "2025-05-13T12:56:01.796325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from prompts.metrics.custom_context_precision_prompt import MyContextPrecisionPrompt\n",
    "\n",
    "context_precision = LLMContextPrecisionWithReference(\n",
    "    name=\"context_precision\",\n",
    "    context_precision_prompt=MyContextPrecisionPrompt(),\n",
    "    max_retries=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:04.511576Z",
     "iopub.status.busy": "2025-05-13T12:56:04.510915Z",
     "iopub.status.idle": "2025-05-13T12:56:04.516288Z",
     "shell.execute_reply": "2025-05-13T12:56:04.515600Z",
     "shell.execute_reply.started": "2025-05-13T12:56:04.511549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import LLMContextRecall   \n",
    "from prompts.metrics.custom_context_recall_prompt import MyContextRecallPrompt\n",
    "\n",
    "context_recall = LLMContextRecall(\n",
    "    name=\"context_recall\",\n",
    "    context_recall_prompt=MyContextRecallPrompt(),\n",
    "    max_retries=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:06.992768Z",
     "iopub.status.busy": "2025-05-13T12:56:06.991909Z",
     "iopub.status.idle": "2025-05-13T12:56:06.997701Z",
     "shell.execute_reply": "2025-05-13T12:56:06.996984Z",
     "shell.execute_reply.started": "2025-05-13T12:56:06.992734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import ContextEntityRecall\n",
    "from prompts.metrics.custom_context_entities_recall_prompt import MyContextEntitiesRecallPrompt\n",
    "\n",
    "context_entity_recall = ContextEntityRecall(\n",
    "    context_entity_recall_prompt=MyContextEntitiesRecallPrompt(),\n",
    "    max_retries=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:09.519099Z",
     "iopub.status.busy": "2025-05-13T12:56:09.518494Z",
     "iopub.status.idle": "2025-05-13T12:56:09.525142Z",
     "shell.execute_reply": "2025-05-13T12:56:09.524381Z",
     "shell.execute_reply.started": "2025-05-13T12:56:09.519077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import NoiseSensitivity\n",
    "from prompts.metrics.faithfulness.custom_nli_generator_prompt import MyNLIStatementPrompt\n",
    "from prompts.metrics.faithfulness.custom_statement_generator_prompt import MyStatementGeneratorPrompt\n",
    "\n",
    "noise_sensitivity = NoiseSensitivity(\n",
    "    nli_statements_prompt=MyNLIStatementPrompt(),\n",
    "    statement_generator_prompt=MyStatementGeneratorPrompt(),\n",
    "    max_retries=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:11.700789Z",
     "iopub.status.busy": "2025-05-13T12:56:11.700215Z",
     "iopub.status.idle": "2025-05-13T12:56:11.705324Z",
     "shell.execute_reply": "2025-05-13T12:56:11.704551Z",
     "shell.execute_reply.started": "2025-05-13T12:56:11.700766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import ResponseRelevancy\n",
    "from prompts.metrics.custom_response_relevance_prompt import MyResponseRelevancePrompt\n",
    "\n",
    "response_relevancy = ResponseRelevancy(\n",
    "    question_generation=MyResponseRelevancePrompt()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:14.011269Z",
     "iopub.status.busy": "2025-05-13T12:56:14.010585Z",
     "iopub.status.idle": "2025-05-13T12:56:14.015216Z",
     "shell.execute_reply": "2025-05-13T12:56:14.014680Z",
     "shell.execute_reply.started": "2025-05-13T12:56:14.011245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import Faithfulness\n",
    "from prompts.metrics.faithfulness.custom_nli_generator_prompt import MyNLIStatementPrompt\n",
    "from prompts.metrics.faithfulness.custom_statement_generator_prompt import MyStatementGeneratorPrompt\n",
    "\n",
    "faithfulness = Faithfulness(\n",
    "    nli_statements_prompt=MyNLIStatementPrompt(),\n",
    "    statement_generator_prompt=MyStatementGeneratorPrompt(),\n",
    "    max_retries=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:16.181100Z",
     "iopub.status.busy": "2025-05-13T12:56:16.180510Z",
     "iopub.status.idle": "2025-05-13T12:56:16.185787Z",
     "shell.execute_reply": "2025-05-13T12:56:16.185038Z",
     "shell.execute_reply.started": "2025-05-13T12:56:16.181076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "from prompts.metrics.faithfulness.custom_nli_generator_prompt import MyNLIStatementPrompt\n",
    "\n",
    "factual_correctness = FactualCorrectness(\n",
    "    nli_prompt=MyNLIStatementPrompt()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:18.103876Z",
     "iopub.status.busy": "2025-05-13T12:56:18.103106Z",
     "iopub.status.idle": "2025-05-13T12:56:18.107215Z",
     "shell.execute_reply": "2025-05-13T12:56:18.106678Z",
     "shell.execute_reply.started": "2025-05-13T12:56:18.103847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics import SemanticSimilarity\n",
    "\n",
    "semantic_similarity = SemanticSimilarity(\n",
    "    threshold=0.7, # Default is 0.5 = 50%\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:56:20.295826Z",
     "iopub.status.busy": "2025-05-13T12:56:20.295085Z",
     "iopub.status.idle": "2025-05-13T15:20:42.345894Z",
     "shell.execute_reply": "2025-05-13T15:20:42.345331Z",
     "shell.execute_reply.started": "2025-05-13T12:56:20.295799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ragas.evaluation import evaluate, EvaluationResult\n",
    "\n",
    "results: EvaluationResult = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[\n",
    "        context_precision,           # Metric 1\n",
    "        context_recall,              # Metric 2\n",
    "        context_entity_recall,       # Metric 3\n",
    "        noise_sensitivity,           # Metric 4\n",
    "        response_relevancy,          # Metric 5\n",
    "        faithfulness,                # Metric 6\n",
    "        factual_correctness,         # Metric 7\n",
    "        semantic_similarity          # Metric 8\n",
    "    ],\n",
    "    llm=ragas_llm,\n",
    "    embeddings=ragas_embeddings,\n",
    "    experiment_name=f\"{filepath}-evaluation\",\n",
    "    run_config=run_config,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T15:21:15.544804Z",
     "iopub.status.busy": "2025-05-13T15:21:15.544124Z",
     "iopub.status.idle": "2025-05-13T15:21:15.580404Z",
     "shell.execute_reply": "2025-05-13T15:21:15.579817Z",
     "shell.execute_reply.started": "2025-05-13T15:21:15.544779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save results locally (optional)\n",
    "result_df: pd.DataFrame = results.to_pandas()\n",
    "result_df.to_csv(f'./{filepath}-eval-results.csv', index=False)\n",
    "\n",
    "# Display metric scores\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T15:21:41.285095Z",
     "iopub.status.busy": "2025-05-13T15:21:41.284315Z",
     "iopub.status.idle": "2025-05-13T15:21:43.235773Z",
     "shell.execute_reply": "2025-05-13T15:21:43.235155Z",
     "shell.execute_reply.started": "2025-05-13T15:21:41.285069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T15:21:49.149890Z",
     "iopub.status.busy": "2025-05-13T15:21:49.149581Z",
     "iopub.status.idle": "2025-05-13T15:21:49.285308Z",
     "shell.execute_reply": "2025-05-13T15:21:49.284659Z",
     "shell.execute_reply.started": "2025-05-13T15:21:49.149870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
