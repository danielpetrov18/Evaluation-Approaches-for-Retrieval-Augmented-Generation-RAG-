{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of High-Quality Test Dataset for RAG Systems\n",
    "\n",
    "### Purpose\n",
    "Test sets are critical for:\n",
    "- Accurately measuring RAG system performance\n",
    "- Identifying system strengths and weaknesses\n",
    "- Guiding continuous improvement\n",
    "\n",
    "### Key Evaluation Dimensions\n",
    "1. **Retrieval Effectiveness**: Assess how well relevant context is retrieved\n",
    "2. **Generation Quality**: Evaluate the accuracy and coherence of generated responses\n",
    "3. **Contextual Relevance**: Measure how well the system understands and integrates retrieved information\n",
    "\n",
    "### Evaluation Goals\n",
    "- Benchmark system performance\n",
    "- Detect hallucinations\n",
    "- Validate generalization capabilities\n",
    "- Simulate real-world query complexity\n",
    "\n",
    "### Best Practices\n",
    "- Use diverse query types\n",
    "- Cover multiple domains\n",
    "- Include edge cases\n",
    "- Create reproducible test scenarios\n",
    "- Contains enough number of samples to derive statistically significant conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Configuration for generating the goldens\n",
    "\n",
    "Goldens are the samples containing the `reference`, `reference_contexts` and `user_input`. For filling out the rest of the fields: `response` and `retrieved_contexts`, I use various different configurations, which are to be found at the root of the project under *experiments.csv*.\n",
    "\n",
    "The goldens are going to be saved under `./goldens`.\n",
    "\n",
    "Configuration for the generation of *goldens*:\n",
    "\n",
    "* For the generation of the goldens for all experiments I will make use of the following parameters:\n",
    "    \n",
    "    * Generation model - `llama3.1:8b-instruct-q4_1`\n",
    "\n",
    "    * Temperature - `0.0`\n",
    "\n",
    "    * The rest of the parameters will vary depending on the experiments configuration\n",
    "\n",
    "* For filling out the rest of the fields:\n",
    "\n",
    "    * Generation model - depends on the experiment configuration\n",
    "\n",
    "    * Temperature - depends on the experiment configuration\n",
    "\n",
    "    * The rest of the parameters will vary depending on the experiment configuration\n",
    "\n",
    "* The goal is that I make use of the stronger instruction following capabilities of `llama3.1:8b-instruct-q4_1` to try to generate a synthetic dataset, which is *clean* and *error-free/logic-free* as possible and to then try the **RAG** application with various settings and compare the results.\n",
    "\n",
    "* I think that using the same `model` and `temperature` for the generation of *goldens* would make the experiments fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve data:\n",
    "* The data can be a dataset from `huggingface` or any other platform.\n",
    "\n",
    "* Alternatively, files available on disk - pdf, md, etc.\n",
    "\n",
    "* One can also use `AsyncHtmlLoader` from `langchain` to scrape from the internet.\n",
    "    - **Careful when performing web scraping to not violate any terms and conditions!**\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "* Make sure you install the requirements first if you want to test the notebook.\n",
    "\n",
    "    * To do so run the `setup.sh` in the parent folder.\n",
    "\n",
    "* Make sure you select the proper environment as your kernel: `eval`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data'...\n",
      "remote: Enumerating objects: 14, done.\u001b[K\n",
      "remote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 14 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (14/14), 16.16 KiB | 5.39 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# For this notebook I will use a dataset provided by RAGAs.\n",
    "# The dataset contains markdown files about a fictional airline company.\n",
    "! git clone https://huggingface.co/datasets/explodinggradients/ragas-airline-dataset data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data into document objects\n",
    "\n",
    "For extracting data from documents and splitting them into chunks one can make use of various frameworks:\n",
    "\n",
    "* `langchain` <- The one I use\n",
    "\n",
    "* `llamaindex` <- Another popular solution\n",
    "\n",
    "Both frameworks provide various abstractions to load documents, extract data and split into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Final\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv(\"../../env/rag.env\")\n",
    "\n",
    "# The path is the folder, where the documents are stored at.\n",
    "# Make sure you select the proper one.\n",
    "DIR_PATH: Final[str] = \"data/\"\n",
    "loader = DirectoryLoader(\n",
    "    DIR_PATH,\n",
    "    glob=\"**/*.md\",\n",
    "    exclude=\"README.md\"\n",
    ")\n",
    "\n",
    "# The R2R framework uses a recrusive character text splitter to split the documents.\n",
    "# For that purpose I use it to try to mimic the same behavior.\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=int(os.getenv(\"CHUNK_SIZE\")),\n",
    "    chunk_overlap=int(os.getenv(\"CHUNK_OVERLAP\")),\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs: list[Document] = loader.load_and_split(splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Construct knowledge graph\n",
    "\n",
    "- A **knowledge graph** is a fundamental concept when it comes to **RAGAs** and using its capabilities for **automatic synthetic data generation**.\n",
    "\n",
    "- A **knowledge graph** consists of **Node**s at first, which represent **documents/chunks** - their content and additionally metadata (optional).\n",
    "\n",
    "- Thereafter, one can enrich the graph by using various **extractors** and applying different **transformations**. Doing so additional attributes get added to the relevant nodes and **relationships can get built**, which express some kind of connection between Node objects. The transformations can be applied only through the use of **Extractor**s, **Splitter**s and or **RelationshipBuilder**s. They serve as a way to gather relevant data from the documents depending on the type of extractor and this way to logically connect 2 or more nodes together.\n",
    "\n",
    "- Finally, the graph is used to generate so called **Scenario**s and can also be used to generate **Persona**s.\n",
    "\n",
    "![Knowledge graph creation workflow RAGAs](../../img/kg_rag.webp \"Knowledge graph RAGAs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import (\n",
    "    Node,\n",
    "    NodeType,\n",
    "    KnowledgeGraph,\n",
    ")\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.add(\n",
    "        Node(\n",
    "            type=NodeType.CHUNK, # Since we already split the documents, we can use the chunk type.\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate required objects\n",
    "\n",
    "- **RAGAs** would require a **LLM** and an **Embedding model** depending on the type of **Transformation**s one would like to apply to the **Knowledge Graph**. For that purpose one must create *wrapper* objects for both of the models. `langchain` and `llama-index` are both supported. \n",
    "\n",
    "- Additionally, a **configuration** can be used to modify the default behaviour of the framework. For example timeout values can be modified, maximum retries for failed operations and so on can be configured from the **RunConfig**.\n",
    "    - **NOTE**: depending on the LLM model and GPU you may need to modify the `timeout` value, otherwise you will stumble upon `TimeoutException`\n",
    "\n",
    "- Lastly, there's a single implementation in **RAGAs** for caching intermediate steps onto disk. To use it the **DiskCacheBackend** class can come in play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "from ragas import RunConfig, DiskCacheBackend\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=86400,    # 24 hours on waiting for a single operation\n",
    "    max_retries=20,   # Max retries before giving up\n",
    "    max_wait=600,     # Max wait between retries\n",
    "    max_workers=4,    # Concurrent requests\n",
    "    log_tenacity=True # Print retry attempts\n",
    ")\n",
    "\n",
    "# This stores data generation and evaluation results locally on disk\n",
    "# When using it for the first time, it will create a .cache folder\n",
    "# When using it again, it will read from that folder and finish almost instantly\n",
    "cacher = DiskCacheBackend(cache_dir=\".cache\")\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(\n",
    "    langchain_llm=ChatOllama(\n",
    "        model=os.getenv(\"DATA_GENERATION_MODEL\"),\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        temperature=float(os.getenv(\"DATA_GENERATION_TEMPERATURE\")),\n",
    "        num_ctx=int(os.getenv(\"LLM_CONTEXT_WINDOW_TOKENS\")),\n",
    "        format=\"json\" # If some operations would require a JSON output for proper extraction\n",
    "    ),\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(\n",
    "    embeddings=OllamaEmbeddings(\n",
    "        model=os.getenv(\"EMBEDDING_MODEL\"),\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    ),\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create the transformation pipeline\n",
    "\n",
    "The sequence of transformations:\n",
    "\n",
    "1. Named Entity Recognition (NER) and Keyphrases extraction \n",
    "    - NERExtractor identifies and extracts named entities (e.g., people, organizations, locations).  \n",
    "\n",
    "    - KeyphrasesExtractor extracts the main keyphrases to be found in the text\n",
    "\n",
    "2. NEROverlapBuilder and KeyphraseOverlapBuilder\n",
    "    - Used to establish a relationship between nodes containing similar:\n",
    "        \n",
    "        - entities\n",
    "        - keyphrases\n",
    "\n",
    "3. Parallel Processing for Efficiency:\n",
    "    - Certain transformations can run in parallel to improve performance.\n",
    "\n",
    "- Final Outcome:\n",
    "    - A structured set of document transformations that extract valuable information\n",
    "    - Used to enrich the knowledge graph for further generation of scenarios and finally samples\n",
    "\n",
    "**NOTE:** Some of the extractors *(LLM-based ones)* do receive an optional `prompt`, which one can use to modify the workflow. For instance the `NERExtractor` can receive a custom prompt, which could contain instructions that differ from the original one and extracts entities in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import (\n",
    "    Parallel,\n",
    "    OverlapScoreBuilder,\n",
    "    KeyphrasesExtractor,\n",
    ")\n",
    "from ragas.testset.transforms.extractors import NERExtractor\n",
    "\n",
    "from prompts.extractors.custom_ner_prompt import MyNERPrompt\n",
    "from prompts.extractors.custom_keyphrases_prompt import MyKeyphrasesExtractorPrompt\n",
    "\n",
    "ner_extractor = NERExtractor(\n",
    "    llm=langchain_llm,\n",
    "    prompt=MyNERPrompt(\n",
    "        name=\"custom_ner_extractor_prompt\"\n",
    "    ),\n",
    "    max_num_entities=15\n",
    ")\n",
    "\n",
    "keyphrases_extractor = KeyphrasesExtractor(\n",
    "    llm=langchain_llm,\n",
    "    prompt=MyKeyphrasesExtractorPrompt(\n",
    "        name=\"custom_keyphrases_extractor_prompt\"\n",
    "    ),\n",
    "    max_num=15\n",
    ")\n",
    "\n",
    "ner_overlap_sim = OverlapScoreBuilder()\n",
    "\n",
    "keyphrases_overlap_sim = OverlapScoreBuilder(\n",
    "    property_name=\"keyphrases\",\n",
    ")\n",
    "\n",
    "transforms = [\n",
    "    Parallel(\n",
    "        ner_extractor,\n",
    "        keyphrases_extractor\n",
    "    ),\n",
    "    Parallel(\n",
    "        ner_overlap_sim,\n",
    "        keyphrases_overlap_sim\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Apply the transformations to the knowledge graph\n",
    "\n",
    "In the cell below the `apply_transforms` is going to apply all the previously defined transformations enriching the `knowledge graph` in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74d0a3658e74f5598474b83642cdf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [NERExtractor, KeyphrasesExtractor]:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a18a3c84944fcea0810330134964f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [OverlapScoreBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset.transforms import apply_transforms\n",
    "\n",
    "apply_transforms(\n",
    "    kg,\n",
    "    transforms,\n",
    "    run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generating personas\n",
    "\n",
    "- A **Persona** is an entity/role which interacts with the system. **Personas** provide context and perspective, ensuring that **generated queries are natural, user-specific, and diverse**.\n",
    "\n",
    "- Example: a Senior DevOps engineer, a Junior Data Scientist, a Marketing Manager in the context of an IT company\n",
    "\n",
    "- **Persona** object consists of a **name** and a **description**.\n",
    "    \n",
    "    - The name is used to identify the persona and the description is used to describe the role of the persona.\n",
    "\n",
    "- Do note that personas can also be generated by a **knowledge graph** if you have one available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "# This example is taken from `RAGAs`:\n",
    "# https://docs.ragas.io/en/latest/howtos/applications/singlehop_testset_gen/#configuring-personas-for-query-generation\n",
    "\n",
    "persona_first_time_flier = Persona(\n",
    "    name=\"First Time Flier\",\n",
    "    role_description=\"Is flying for the first time and may feel anxious. Needs clear guidance on flight procedures, safety protocols, and what to expect throughout the journey.\",\n",
    ")\n",
    "\n",
    "persona_frequent_flier = Persona(\n",
    "    name=\"Frequent Flier\",\n",
    "    role_description=\"Travels regularly and values efficiency and comfort. Interested in loyalty programs, express services, and a seamless travel experience.\",\n",
    ")\n",
    "\n",
    "persona_angry_business_flier = Persona(\n",
    "    name=\"Angry Business Class Flier\",\n",
    "    role_description=\"Demands top-tier service and is easily irritated by any delays or issues. Expects immediate resolutions and is quick to express frustration if standards are not met.\",\n",
    ")\n",
    "\n",
    "personas: list[Persona] = [\n",
    "    persona_first_time_flier,\n",
    "    persona_frequent_flier,\n",
    "    persona_angry_business_flier\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate query types \n",
    "\n",
    "- There are two main types of queries in **RAGAs**:\n",
    "    \n",
    "    - **SingleHopQuery** where the **context** relevant for answering a question lies in a **single document/chunk**\n",
    "\n",
    "    - **MultiHopQuery** where the **context** relevant for answering a question lies in **multiple documents/chunks**\n",
    "\n",
    "- Additionally, for each of those queries there's a **Specific** or **Abstract** query variant:\n",
    "    \n",
    "    - **Specific** one which pertains to a **fact**. \n",
    "\n",
    "        - Example: When did WW1 break out? (Can be precisely answered, there's no room for guessing/interpretation)\n",
    "    \n",
    "    - **Abstract** one which is more about testing the **reasoning** capabilities of the LLM. \n",
    "\n",
    "        - Example: Why did WW1 break out? (There's room for interpretation in this case)\n",
    "\n",
    "- **Specific** vs. **Abstract Queries** in a RAG\n",
    "    - Specific Query: Focuses on clear, fact-based retrieval. The goal in RAG is to retrieve highly relevant information from one or more documents that directly address the specific question.\n",
    "\n",
    "    - Abstract Query: Requires a broader, more interpretive response. In RAG, abstract queries challenge the retrieval system to pull from documents that contain higher-level reasoning, explanations, or opinions, rather than simple facts.\n",
    "\n",
    "![Query tpes in RAGAs](../../img/ragas_query_types.png  \"Queries\")\n",
    "\n",
    "**Synthesizers** are responsible for **converting enriched nodes and personas into queries**. They achieve this by **selecting a node property (e.g., \"entities\" or \"keyphrases\"), pairing it with a persona, style, and query length**, and then using a LLM to generate a query-answer pair based on the content of the node.\n",
    "\n",
    "* Query lengths may vary:\n",
    "    - short\n",
    "    - medium\n",
    "    - long\n",
    "\n",
    "* Query style:\n",
    "    - misspelled\n",
    "    - websearch-like\n",
    "    - perfect-grammar\n",
    "    - poor-grammar\n",
    "\n",
    "Note that **synthesizers** can additionally be extended/modified by specifying custom **prompts**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.multi_hop.specific import MultiHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "\n",
    "from prompts.synthesizers.custom_themes_matching import MyThemesPersonasMatchingPrompt\n",
    "from prompts.synthesizers.custom_multi_hop_qa_generation import MyMultiHopQAGenerationPrompt\n",
    "from prompts.synthesizers.custom_single_hop_qa_generation import MySingleHopQAGenerationPrompt\n",
    "\n",
    "single_hop_specific_entities = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    generate_query_reference_prompt=MySingleHopQAGenerationPrompt(),\n",
    "    theme_persona_matching_prompt=MyThemesPersonasMatchingPrompt(),\n",
    "    property_name=\"entities\"\n",
    ")\n",
    "\n",
    "single_hop_specific_keyphrases = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    generate_query_reference_prompt=MySingleHopQAGenerationPrompt(),\n",
    "    theme_persona_matching_prompt=MyThemesPersonasMatchingPrompt(),\n",
    "    property_name=\"keyphrases\"\n",
    ")\n",
    "\n",
    "multi_hop_specific_entities = MultiHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    generate_query_reference_prompt=MyMultiHopQAGenerationPrompt(),\n",
    "    theme_persona_matching_prompt=MyThemesPersonasMatchingPrompt()\n",
    ")\n",
    "\n",
    "multi_hop_specific_keyphrases = MultiHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    generate_query_reference_prompt=MyMultiHopQAGenerationPrompt(),\n",
    "    relation_type=\"keyphrases_overlap\",\n",
    "    property_name=\"keyphrases\",\n",
    "    theme_persona_matching_prompt=MyThemesPersonasMatchingPrompt()\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (single_hop_specific_entities, 0.25),\n",
    "    (single_hop_specific_keyphrases, 0.25),\n",
    "    (multi_hop_specific_entities, 0.25),\n",
    "    (multi_hop_specific_keyphrases, 0.25)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Generate the samples\n",
    "\n",
    "#### Definition of evaluation sample\n",
    "\n",
    "An evaluation sample is a single structured data instance that is used to assess and measure the performance of your LLM application in specific scenarios. It represents a single unit of interaction or a specific use case that the AI application is expected to handle. In Ragas, evaluation samples are represented using the `SingleTurnSample` and `MultiTurnSample` classes.\n",
    "\n",
    "#### SingleTurnSample\n",
    "\n",
    "`SingleTurnSample` represents a single-turn interaction between a user, LLM, and expected results for evaluation. It is suitable for evaluations that involve a single question and answer pair, possibly with additional context or reference information.\n",
    "\n",
    "This type of sample is ideal for straightforward question-answering scenarios where a user asks a single question and expects a direct response.\n",
    "\n",
    "#### MultiTurnSample\n",
    "\n",
    "`MultiTurnSample` represents a multi-turn interaction between Human, AI and optionally a Tool and expected results for evaluation. It is suitable for representing conversational agents in more complex interactions for evaluation.\n",
    "\n",
    "In `MultiTurnSample`, the `user_input` attribute represents a sequence of messages that collectively form a multi-turn conversation between a human user and an AI system. These messages are instances of the classes `HumanMessage`, `AIMessage`, and `ToolMessage`.\n",
    "\n",
    "This type of sample is designed for evaluating more complex conversational flows where multiple turns of dialogue occur, potentially involving tool usage for gathering additional information.\n",
    "\n",
    "![Scenario generation workflow RAGAs](../../img/scenario_rag.webp \"Scenarios RAGAs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator, Testset\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    langchain_llm,\n",
    "    langchain_embeddings,\n",
    "    kg,\n",
    "    personas\n",
    ")\n",
    "\n",
    "dataset: Testset = generator.generate(\n",
    "    testset_size=50,\n",
    "    query_distribution=query_distribution,\n",
    "    num_personas=len(personas),\n",
    "    run_config=run_config,\n",
    "    with_debugging_logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Save dataset containing goldens (no actual output and retrieval context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The id should match the experiment_id\n",
    "goldens_id: str = input(\"Enter goldens id (Ex. 1): \")\n",
    "\n",
    "dataset.to_jsonl(f\"./goldens/{goldens_id}_goldens.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Upload to the cloud (Optional)\n",
    "\n",
    "* To upload the data on **app.ragas.io** make sure you:\n",
    "    * First create an account\n",
    "    * Get an **API key**\n",
    "    * Finally, create a `.env` file in the parent folder like so and export it in your notebook:\n",
    "\n",
    "```bash\n",
    "RAGAS_APP_TOKEN=apt.1234a-......-9dfew\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset uploaded! View at https://app.ragas.io/dashboard/alignment/testset/2446e75e-efd3-41e8-aacd-bcafbe3ad280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/testset/2446e75e-efd3-41e8-aacd-bcafbe3ad280'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the token\n",
    "load_dotenv(\"../.env\") \n",
    "\n",
    "dataset.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Fill out the missing fields in the dataset to complete it.\n",
    "\n",
    "* This script will first create a virtual environment with all required dependencies.\n",
    "\n",
    "* Next the files that are currently ingested will be removed.\n",
    "\n",
    "* The files from the `data` folder will be re-ingested.\n",
    "\n",
    "* Then the dataset will be filled out with `response` and `retrieved contexts`.\n",
    "\n",
    "* Finally, the dataset will be persisted into `/datasets`.\n",
    "\n",
    "This is required since the experiments have varying `chunk_size` and `chunk_overlap` values. Because of that the application needs to be restarted each time and the data ingested newly, so we can carry out the data generation properly.\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "- Make sure you set the proper values under `/env/rag.env` relative to the experiment id you want to carry out.\n",
    "\n",
    "- For each experiment provide an intuitive name to distinguish between the experiments\n",
    "\n",
    "    - In my case I just use the experiment id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the script executable\n",
    "!chmod u+x ./fill_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] VIRTUAL ENVIRONMENT ALREADY EXISTS. SKIPPING CREATION. [+]\n",
      "[+] INSTALLING DEPENDENCIES... [+]\n",
      "Collecting r2r==3.5.11 (from r2r[core]==3.5.11)\n",
      "  Using cached r2r-3.5.11-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: langchain==0.3.25 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (0.3.25)\n",
      "Collecting langchain-community==0.3.23\n",
      "  Using cached langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: unstructured==0.17.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured[md]==0.17.2) (0.17.2)\n",
      "Requirement already satisfied: aiofiles<25.0.0,>=24.1.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (24.1.0)\n",
      "Collecting alembic<2.0.0,>=1.13.3 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting fastapi<0.116.0,>=0.115.11 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (0.28.1)\n",
      "Requirement already satisfied: openai>=1.61.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (1.75.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (1.1.0)\n",
      "Collecting psycopg-binary<4.0.0,>=3.2.3 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Downloading psycopg_binary-3.2.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (2.32.3)\n",
      "Collecting tiktoken<0.9.0,>=0.8.0 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting toml<0.11.0,>=0.10.2 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting types-requests<3.0.0,>=2.31.0 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting types-aiofiles<25.0.0,>=24.1.0.20240626 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Downloading types_aiofiles-24.1.0.20250516-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (2.11.4)\n",
      "Collecting python-json-logger>=3.2.1 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: filetype>=1.2.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r==3.5.11->r2r[core]==3.5.11) (1.2.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain==0.3.25) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain==0.3.25) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain==0.3.25) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain==0.3.25) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain==0.3.25) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-community==0.3.23) (2.2.5)\n",
      "Requirement already satisfied: chardet in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (5.2.0)\n",
      "Requirement already satisfied: python-magic in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (0.4.27)\n",
      "Requirement already satisfied: lxml in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (5.4.0)\n",
      "Requirement already satisfied: nltk in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (4.13.4)\n",
      "Requirement already satisfied: emoji in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (2.14.1)\n",
      "Requirement already satisfied: python-iso639 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (3.13.0)\n",
      "Requirement already satisfied: backoff in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (0.34.0)\n",
      "Requirement already satisfied: wrapt in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (1.17.2)\n",
      "Requirement already satisfied: tqdm in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured==0.17.2->unstructured[md]==0.17.2) (1.1)\n",
      "Collecting aioshutil<2.0,>=1.5 (from r2r[core]==3.5.11)\n",
      "  Using cached aioshutil-1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiosqlite<0.21.0,>=0.20.0 (from r2r[core]==3.5.11)\n",
      "  Using cached aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: anthropic>=0.49.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (0.49.0)\n",
      "Collecting apscheduler<4.0.0,>=3.10.4 (from r2r[core]==3.5.11)\n",
      "  Using cached APScheduler-3.11.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting asyncpg<0.30.0,>=0.29.0 (from r2r[core]==3.5.11)\n",
      "  Using cached asyncpg-0.29.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting azure-ai-inference<2.0.0,>=1.0.0b8 (from r2r[core]==3.5.11)\n",
      "  Using cached azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting azure-ai-ml<2.0.0,>=1.24.0 (from r2r[core]==3.5.11)\n",
      "  Downloading azure_ai_ml-1.27.1-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting bcrypt<5.0.0,>=4.1.3 (from r2r[core]==3.5.11)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting boto3<2.0.0,>=1.35.17 (from r2r[core]==3.5.11)\n",
      "  Downloading boto3-1.38.18-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting colorlog<7.0.0,>=6.9.0 (from r2r[core]==3.5.11)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: docutils<0.22.0,>=0.21.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (0.21.2)\n",
      "Collecting epub<0.6.0,>=0.5.2 (from r2r[core]==3.5.11)\n",
      "  Using cached epub-0.5.2-py3-none-any.whl\n",
      "Collecting firecrawl-py>=1.13.5 (from r2r[core]==3.5.11)\n",
      "  Downloading firecrawl_py-2.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<2025.0.0,>=2024.6.0 (from r2r[core]==3.5.11)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting future<2.0.0,>=1.0.0 (from r2r[core]==3.5.11)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.37.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (2.40.1)\n",
      "Collecting google-auth-oauthlib<2.0.0,>=1.2.1 (from r2r[core]==3.5.11)\n",
      "  Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-genai<0.7.0,>=0.6.0 (from r2r[core]==3.5.11)\n",
      "  Using cached google_genai-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting gunicorn<22.0.0,>=21.2.0 (from r2r[core]==3.5.11)\n",
      "  Using cached gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting hatchet-sdk==0.47.0 (from r2r[core]==3.5.11)\n",
      "  Using cached hatchet_sdk-0.47.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting litellm<1.65.0,>=1.63.14 (from r2r[core]==3.5.11)\n",
      "  Using cached litellm-1.64.1-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: markdown<4.0,>=3.6 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (3.8)\n",
      "Collecting mistralai>=1.5.2 (from r2r[core]==3.5.11)\n",
      "  Using cached mistralai-1.7.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting msg-parser>=1.2.0 (from r2r[core]==3.5.11)\n",
      "  Using cached msg_parser-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx<4.0,>=3.3 (from r2r[core]==3.5.11)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community==0.3.23)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: olefile<0.48,>=0.47 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (0.47)\n",
      "Collecting ollama<0.4.0,>=0.3.1 (from r2r[core]==3.5.11)\n",
      "  Using cached ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.1.2 (from r2r[core]==3.5.11)\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting orgparse<0.5.0,>=0.4.20231004 (from r2r[core]==3.5.11)\n",
      "  Using cached orgparse-0.4.20231004-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pdf2image>=1.17.0 (from r2r[core]==3.5.11)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pillow<12.0.0,>=11.1.0 (from r2r[core]==3.5.11)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pillow-heif<0.22.0,>=0.21.0 (from r2r[core]==3.5.11)\n",
      "  Using cached pillow_heif-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
      "Collecting psutil (from unstructured==0.17.2->unstructured[md]==0.17.2)\n",
      "  Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting pyjwt<3.0.0,>=2.8.0 (from r2r[core]==3.5.11)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pynacl<2.0.0,>=1.5.0 (from r2r[core]==3.5.11)\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting pypdf<5.0.0,>=4.2.0 (from r2r[core]==3.5.11)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pypdf2<4.0.0,>=3.0.1 (from r2r[core]==3.5.11)\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.0 (from r2r[core]==3.5.11)\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-multipart<0.0.19,>=0.0.9 (from r2r[core]==3.5.11)\n",
      "  Using cached python_multipart-0.0.18-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.1 (from r2r[core]==3.5.11)\n",
      "  Using cached python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting sendgrid<7.0.0,>=6.11.0 (from r2r[core]==3.5.11)\n",
      "  Downloading sendgrid-6.12.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mailersend<0.6.0,>=0.5.6 (from r2r[core]==3.5.11)\n",
      "  Using cached mailersend-0.5.8-py3-none-any.whl.metadata (47 kB)\n",
      "Requirement already satisfied: sentry-sdk<3.0.0,>=2.20.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from r2r[core]==3.5.11) (2.28.0)\n",
      "Collecting striprtf<0.0.29,>=0.0.28 (from r2r[core]==3.5.11)\n",
      "  Using cached striprtf-0.0.28-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting supabase<3.0.0,>=2.7.4 (from r2r[core]==3.5.11)\n",
      "  Using cached supabase-2.15.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tokenizers==0.19 (from r2r[core]==3.5.11)\n",
      "  Using cached tokenizers-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting unstructured-client (from unstructured==0.17.2->unstructured[md]==0.17.2)\n",
      "  Using cached unstructured_client-0.25.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting uvicorn<0.28.0,>=0.27.0.post1 (from r2r[core]==3.5.11)\n",
      "  Using cached uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting vecs<0.5.0,>=0.4.0 (from r2r[core]==3.5.11)\n",
      "  Using cached vecs-0.4.5-py3-none-any.whl\n",
      "Collecting xlrd<3.0.0,>=2.0.1 (from r2r[core]==3.5.11)\n",
      "  Using cached xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.8.3 (from hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting aiostream<0.6.0,>=0.5.2 (from hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached aiostream-0.5.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting cel-python<0.3.0,>=0.2.0 (from hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached cel_python-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: grpcio!=1.68.*,>=1.64.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from hatchet-sdk==0.47.0->r2r[core]==3.5.11) (1.71.0)\n",
      "Collecting grpcio-tools!=1.68.*,>=1.64.1 (from hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached grpcio_tools-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from hatchet-sdk==0.47.0->r2r[core]==3.5.11) (1.6.0)\n",
      "Collecting prometheus-client<0.22.0,>=0.21.1 (from hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: protobuf<6.0.0,>=5.29.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from hatchet-sdk==0.47.0->r2r[core]==3.5.11) (5.29.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from hatchet-sdk==0.47.0->r2r[core]==3.5.11) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.20 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from hatchet-sdk==0.47.0->r2r[core]==3.5.11) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from tokenizers==0.19->r2r[core]==3.5.11) (0.31.1)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (3.4.2)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2)\n",
      "  Using cached deepdiff-8.5.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: idna>=3.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (3.10)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2)\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (3.26.1)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (1.1.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (1.0.0)\n",
      "Requirement already satisfied: six>=1.16.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (1.17.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.23) (1.20.0)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.3->r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tzlocal>=3.0 (from apscheduler<4.0.0,>=3.10.4->r2r[core]==3.5.11)\n",
      "  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-inference<2.0.0,>=1.0.0b8->r2r[core]==3.5.11)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-ai-inference<2.0.0,>=1.0.0b8->r2r[core]==3.5.11)\n",
      "  Using cached azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting msrest<1.0.0,>=0.6.18 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-mgmt-core>=1.3.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (4.23.0)\n",
      "Collecting strictyaml<2.0.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting colorama<1.0.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting azure-storage-file-share (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_storage_file_share-12.21.0-py3-none-any.whl.metadata (50 kB)\n",
      "Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting azure-common>=1.1 (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting azure-monitor-opentelemetry (from azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from beautifulsoup4->unstructured==0.17.2->unstructured[md]==0.17.2) (2.7)\n",
      "Collecting botocore<1.39.0,>=1.38.18 (from boto3<2.0.0,>=1.35.17->r2r[core]==3.5.11)\n",
      "  Downloading botocore-1.38.18-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.35.17->r2r[core]==3.5.11)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3<2.0.0,>=1.35.17->r2r[core]==3.5.11)\n",
      "  Using cached s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting lark<0.13.0,>=0.12.0 (from cel-python<0.3.0,>=0.2.0->hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Using cached lark-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting types-python-dateutil<3.0.0.0,>=2.9.0.20240316 (from cel-python<0.3.0,>=0.2.0->hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240311 (from cel-python<0.3.0,>=0.2.0->hatchet-sdk==0.47.0->r2r[core]==3.5.11)\n",
      "  Downloading types_pyyaml-6.0.12.20250516-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<0.116.0,>=0.115.11->r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.37.0->r2r[core]==3.5.11) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.37.0->r2r[core]==3.5.11) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.37.0->r2r[core]==3.5.11) (4.9.1)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2.0.0,>=1.2.1->r2r[core]==3.5.11)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<15.0dev,>=13.0 (from google-genai<0.7.0,>=0.6.0->r2r[core]==3.5.11)\n",
      "  Using cached websockets-14.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19->r2r[core]==3.5.11) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19->r2r[core]==3.5.11) (1.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (0.24.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain==0.3.25) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain==0.3.25) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.25) (3.10.18)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.25) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from httpx>=0.27.0->r2r==3.5.11->r2r[core]==3.5.11) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from httpx>=0.27.0->r2r==3.5.11->r2r[core]==3.5.11) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->r2r==3.5.11->r2r[core]==3.5.11) (0.16.0)\n",
      "Requirement already satisfied: click in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from litellm<1.65.0,>=1.63.14->r2r[core]==3.5.11) (8.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from litellm<1.65.0,>=1.63.14->r2r[core]==3.5.11) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from litellm<1.65.0,>=1.63.14->r2r[core]==3.5.11) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm<1.65.0,>=1.63.14->r2r[core]==3.5.11) (3.0.2)\n",
      "Collecting httpx>=0.27.0 (from r2r==3.5.11->r2r[core]==3.5.11)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: sniffio in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from httpx>=0.27.0->r2r==3.5.11->r2r[core]==3.5.11) (1.3.1)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.2->r2r[core]==3.5.11)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pydantic>=2.10.6->r2r==3.5.11->r2r[core]==3.5.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pydantic>=2.10.6->r2r==3.5.11->r2r[core]==3.5.11) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pydantic>=2.10.6->r2r==3.5.11->r2r[core]==3.5.11) (0.4.0)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]<3.0.0,>=2.8.2; extra == \"core\"->r2r[core]==3.5.11)\n",
      "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pynacl<2.0.0,>=1.5.0->r2r[core]==3.5.11) (1.17.1)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.1->r2r[core]==3.5.11)\n",
      "  Using cached XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.37.0->r2r[core]==3.5.11) (0.6.1)\n",
      "Collecting python-http-client>=3.2.1 (from sendgrid<7.0.0,>=6.11.0->r2r[core]==3.5.11)\n",
      "  Using cached python_http_client-3.3.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting ecdsa<1,>=0.19.1 (from sendgrid<7.0.0,>=6.11.0->r2r[core]==3.5.11)\n",
      "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Collecting werkzeug>=3.0.0 (from sendgrid<7.0.0,>=6.11.0->r2r[core]==3.5.11)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.25) (3.2.2)\n",
      "Collecting gotrue<3.0.0,>=2.11.0 (from supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting postgrest<1.1,>0.19 (from supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached postgrest-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting realtime<2.5.0,>=2.4.0 (from supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached realtime-2.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting storage3<0.12,>=0.10 (from supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting supafunc<0.10,>=0.9 (from supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11) (8.3.5)\n",
      "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11)\n",
      "  Using cached StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from tiktoken<0.9.0,>=0.8.0->r2r==3.5.11->r2r[core]==3.5.11) (2024.11.6)\n",
      "Collecting pgvector==0.3.* (from vecs<0.5.0,>=0.4.0->r2r[core]==3.5.11)\n",
      "  Using cached pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting psycopg2-binary==2.9.* (from vecs<0.5.0,>=0.4.0->r2r[core]==3.5.11)\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting flupy==1.* (from vecs<0.5.0,>=0.4.0->r2r[core]==3.5.11)\n",
      "  Downloading flupy-1.2.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: deprecated==1.2.* in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from vecs<0.5.0,>=0.4.0->r2r[core]==3.5.11) (1.2.18)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from anthropic>=0.49.0->r2r[core]==3.5.11) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from anthropic>=0.49.0->r2r[core]==3.5.11) (0.9.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (44.0.3)\n",
      "Requirement already satisfied: pycparser in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from cffi>=1.4.1->pynacl<2.0.0,>=1.5.0->r2r[core]==3.5.11) (2.22)\n",
      "Collecting orderly-set<6,>=5.4.1 (from deepdiff>=6.0->unstructured-client->unstructured==0.17.2->unstructured[md]==0.17.2)\n",
      "  Using cached orderly_set-5.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]<3.0.0,>=2.8.2; extra == \"core\"->r2r[core]==3.5.11)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: setuptools in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from grpcio-tools!=1.68.*,>=1.64.1->hatchet-sdk==0.47.0->r2r[core]==3.5.11) (80.4.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm<1.65.0,>=1.63.14->r2r[core]==3.5.11) (3.21.0)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from mistralai>=1.5.2->r2r[core]==3.5.11) (0.2.2)\n",
      "INFO: pip is looking at multiple versions of mistralai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mistralai>=1.5.2 (from r2r[core]==3.5.11)\n",
      "  Using cached mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached mistralai-1.5.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: iniconfig in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase<3.0.0,>=2.7.4->r2r[core]==3.5.11) (1.5.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2.0.0,>=1.2.1->r2r[core]==3.5.11)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-monitor-opentelemetry-exporter~=1.0.0b31 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting opentelemetry-resource-detector-azure~=0.1.4 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opentelemetry-sdk<1.32,>=1.28.0 (from azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.12.0 in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11) (1.33.0)\n",
      "Collecting azure-identity~=1.17 (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Downloading azure_identity-1.23.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting opentelemetry-instrumentation-wsgi==0.52b1 (from opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_wsgi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.12.0 (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-instrumentation-dbapi==0.52b1 (from opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml<2.0.0,>=1.24.0->r2r[core]==3.5.11)\n",
      "  Using cached opentelemetry_instrumentation_dbapi-0.52b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: webencodings in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from html5lib->unstructured==0.17.2->unstructured[md]==0.17.2) (0.5.1)\n",
      "Requirement already satisfied: joblib in /home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/evaluation/eval/lib/python3.12/site-packages (from nltk->unstructured==0.17.2->unstructured[md]==0.17.2) (1.5.0)\n",
      "Using cached r2r-3.5.11-py3-none-any.whl (503 kB)\n",
      "Using cached langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "Using cached hatchet_sdk-0.47.0-py3-none-any.whl (365 kB)\n",
      "Using cached tokenizers-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached unstructured_client-0.25.5-py3-none-any.whl (43 kB)\n",
      "Using cached aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Using cached aioshutil-1.5-py3-none-any.whl (4.7 kB)\n",
      "Using cached aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Using cached alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Using cached APScheduler-3.11.0-py3-none-any.whl (64 kB)\n",
      "Using cached asyncpg-0.29.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
      "Downloading azure_ai_ml-1.27.1-py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hUsing cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "Downloading boto3-1.38.18-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.38.18-py3-none-any.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cel_python-0.2.0-py3-none-any.whl (71 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Using cached google_genai-0.6.0-py3-none-any.whl (118 kB)\n",
      "Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached lark-0.12.0-py2.py3-none-any.whl (103 kB)\n",
      "Using cached litellm-1.64.1-py3-none-any.whl (7.0 MB)\n",
      "Using cached mailersend-0.5.8-py3-none-any.whl (26 kB)\n",
      "Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached orgparse-0.4.20231004-py3-none-any.whl (34 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached pillow_heif-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Using cached prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading psycopg_binary-3.2.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached python_multipart-0.0.18-py3-none-any.whl (24 kB)\n",
      "Using cached python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
      "Downloading sendgrid-6.12.2-py3-none-any.whl (102 kB)\n",
      "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Using cached striprtf-0.0.28-py3-none-any.whl (7.7 kB)\n",
      "Using cached supabase-2.15.1-py3-none-any.whl (17 kB)\n",
      "Using cached gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Using cached postgrest-1.0.1-py3-none-any.whl (22 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
      "Using cached realtime-2.4.3-py3-none-any.whl (22 kB)\n",
      "Using cached storage3-0.11.3-py3-none-any.whl (17 kB)\n",
      "Using cached supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
      "Using cached StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading types_aiofiles-24.1.0.20250516-py3-none-any.whl (14 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
      "Downloading types_pyyaml-6.0.12.20250516-py3-none-any.whl (20 kB)\n",
      "Downloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
      "Using cached uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "Downloading flupy-1.2.2-py3-none-any.whl (12 kB)\n",
      "Using cached pgvector-0.3.6-py3-none-any.whl (24 kB)\n",
      "Using cached psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached websockets-14.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n",
      "Using cached xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
      "Using cached azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
      "Using cached azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
      "Using cached azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n",
      "Using cached deepdiff-8.5.0-py3-none-any.whl (85 kB)\n",
      "Using cached orderly_set-5.4.1-py3-none-any.whl (12 kB)\n",
      "Using cached email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading firecrawl_py-2.6.0-py3-none-any.whl (275 kB)\n",
      "Using cached grpcio_tools-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached mistralai-1.5.2-py3-none-any.whl (278 kB)\n",
      "Using cached msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached python_http_client-3.3.7-py3-none-any.whl (8.4 kB)\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
      "Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl (23 kB)\n",
      "Using cached azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl (154 kB)\n",
      "Using cached fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Downloading azure_identity-1.23.0-py3-none-any.whl (186 kB)\n",
      "Using cached opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
      "Using cached opentelemetry_instrumentation_wsgi-0.52b1-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n",
      "Using cached opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl (10 kB)\n",
      "Using cached opentelemetry_instrumentation_dbapi-0.52b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl (13 kB)\n",
      "Using cached opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n",
      "Using cached msal-1.32.3-py3-none-any.whl (115 kB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Using cached azure_storage_file_share-12.21.0-py3-none-any.whl (290 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: striprtf, strenum, orgparse, lark, fixedint, epub, azure-common, XlsxWriter, xlrd, werkzeug, websockets, uvicorn, tzlocal, types-requests, types-pyyaml, types-python-dateutil, types-aiofiles, toml, python-multipart, python-json-logger, python-http-client, python-docx, pypdf2, pypdf, pyjwt, pydash, psycopg2-binary, psycopg-binary, psutil, prometheus-client, pillow, orderly-set, opentelemetry-util-http, oauthlib, numpy, networkx, msg-parser, Mako, jsonpath-python, jmespath, isodate, hyperframe, hpack, gunicorn, grpcio-tools, future, fsspec, flupy, et-xmlfile, ecdsa, dnspython, deprecation, colorlog, colorama, bcrypt, asyncpg, asgiref, aiostream, aiosqlite, aioshutil, tiktoken, strictyaml, starlette, sendgrid, requests-oauthlib, python-pptx, pytest-mock, pynacl, pillow-heif, pgvector, pdf2image, opentelemetry-api, openpyxl, mailersend, httpx, h2, email-validator, deepdiff, cel-python, botocore, azure-core, apscheduler, alembic, vecs, unstructured-client, tokenizers, s3transfer, realtime, opentelemetry-semantic-conventions, ollama, msrest, mistralai, google-genai, google-auth-oauthlib, firecrawl-py, fastapi, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, azure-ai-inference, aiohttp-retry, supafunc, storage3, r2r, postgrest, opentelemetry-sdk, opentelemetry-instrumentation, msal, litellm, hatchet-sdk, gotrue, boto3, azure-storage-file-datalake, supabase, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-identity, langchain-community, azure-monitor-opentelemetry-exporter, azure-monitor-opentelemetry, azure-ai-ml\n",
      "\u001b[2K  Attempting uninstall: websockets249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m  9/132\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: websockets 15.0.1;5;237m\u001b[0m \u001b[32m  9/132\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling websockets-15.0.1:8;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m  9/132\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled websockets-15.0.138;5;237m\u001b[0m \u001b[32m  9/132\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: pypdf0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 22/132\u001b[0m [pypdf2]\n",
      "\u001b[2K    Found existing installation: pypdf 5.5.0m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 22/132\u001b[0m [pypdf2]\n",
      "\u001b[2K    Uninstalling pypdf-5.5.0:38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 22/132\u001b[0m [pypdf2]\n",
      "\u001b[2K      Successfully uninstalled pypdf-5.5.014m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 22/132\u001b[0m [pypdf2]\n",
      "\u001b[2K  Attempting uninstall: psutil0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 26/132\u001b[0m [psycopg2-binary]\n",
      "\u001b[2K    Found existing installation: psutil 7.0.0m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 26/132\u001b[0m [psycopg2-binary]\n",
      "\u001b[2K    Uninstalling psutil-7.0.0:38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 26/132\u001b[0m [psycopg2-binary]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.0.014m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 26/132\u001b[0m [psycopg2-binary]\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 33/132\u001b[0m [oauthlib]g2-binary]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.5[0m\u001b[38;5;237m\u001b[0m \u001b[32m 33/132\u001b[0m [oauthlib]\n",
      "\u001b[2K    Uninstalling numpy-2.2.5:0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 33/132\u001b[0m [oauthlib]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.5\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 33/132\u001b[0m [oauthlib]\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 45/132\u001b[0m [future]h]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.3.0114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 45/132\u001b[0m [future]\n",
      "\u001b[2K    Uninstalling fsspec-2025.3.0:m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 45/132\u001b[0m [future]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.3.08;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 45/132\u001b[0m [future]\n",
      "\u001b[2K  Attempting uninstall: tiktoken\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 58/132\u001b[0m [aiosqlite]\n",
      "\u001b[2K    Found existing installation: tiktoken 0.9.09;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 58/132\u001b[0m [aiosqlite]\n",
      "\u001b[2K    Uninstalling tiktoken-0.9.0:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 58/132\u001b[0m [aiosqlite]\n",
      "\u001b[2K      Successfully uninstalled tiktoken-0.9.0249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 58/132\u001b[0m [aiosqlite]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-api\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 70/132\u001b[0m [pdf2image]low-heif]\n",
      "\u001b[2K    Found existing installation: opentelemetry-api 1.33.0m\u001b[38;5;237m\u001b[0m \u001b[32m 70/132\u001b[0m [pdf2image]\n",
      "\u001b[2K    Uninstalling opentelemetry-api-1.33.0:\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 70/132\u001b[0m [pdf2image]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-api-1.33.0[0m\u001b[38;5;237m\u001b[0m \u001b[32m 70/132\u001b[0m [pdf2image]\n",
      "\u001b[2K  Attempting uninstall: httpx\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 72/132\u001b[0m [openpyxl]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.18;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 72/132\u001b[0m [openpyxl]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 72/132\u001b[0m [openpyxl]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.1[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 72/132\u001b[0m [openpyxl]\n",
      "\u001b[2K  Attempting uninstall: unstructured-client\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]ler]\n",
      "\u001b[2K    Found existing installation: unstructured-client 0.34.0114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K    Uninstalling unstructured-client-0.34.0:m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K      Successfully uninstalled unstructured-client-0.34.08;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K  Attempting uninstall: tokenizers\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.12;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.1:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.18;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 82/132\u001b[0m [alembic]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.54b0\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.54b0:\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.54b07m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K  Attempting uninstall: ollama\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K    Found existing installation: ollama 0.4.80m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K    Uninstalling ollama-0.4.8:\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K      Successfully uninstalled ollama-0.4.8\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 86/132\u001b[0m [s3transfer]\n",
      "\u001b[2K  Attempting uninstall: google-genai\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 91/132\u001b[0m [mistralai]\n",
      "\u001b[2K    Found existing installation: google-genai 1.14.0;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 91/132\u001b[0m [mistralai]\n",
      "\u001b[2K    Uninstalling google-genai-1.14.0:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 91/132\u001b[0m [mistralai]\n",
      "\u001b[2K      Successfully uninstalled google-genai-1.14.038;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m 91/132\u001b[0m [mistralai]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-sdk\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]e]share]\n",
      "\u001b[2K    Found existing installation: opentelemetry-sdk 1.33.02;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]\n",
      "\u001b[2K    Uninstalling opentelemetry-sdk-1.33.0:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.33.08;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]\n",
      "\u001b[2K  Attempting uninstall: litellm\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]\n",
      "\u001b[2K    Found existing installation: litellm 1.69.1\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m105/132\u001b[0m [postgrest]\n",
      "\u001b[2K    Uninstalling litellm-1.69.1:\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m109/132\u001b[0m [litellm]rest]\n",
      "\u001b[2K      Successfully uninstalled litellm-1.69.1\u001b[0m\u001b[38;5;237m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m109/132\u001b[0m [litellm]\n",
      "\u001b[2K  Attempting uninstall: langchain-community\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m126/132\u001b[0m [opentelemetry-instrumentation-django]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.3.24;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m126/132\u001b[0m [opentelemetry-instrumentation-django]\n",
      "\u001b[2K    Uninstalling langchain-community-0.3.24:\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m128/132\u001b[0m [langchain-community]go]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.3.240m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m128/132\u001b[0m [langchain-community]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m132/132\u001b[0m [azure-ai-ml]/132\u001b[0m [azure-ai-ml]xporter]hain-community]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-ollama 0.3.2 requires ollama<1,>=0.4.4, but you have ollama 0.3.3 which is incompatible.\n",
      "deepeval 2.8.2 requires google-genai<2.0.0,>=1.9.0, but you have google-genai 0.6.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.33.0 requires opentelemetry-sdk~=1.33.0, but you have opentelemetry-sdk 1.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 XlsxWriter-3.2.3 aiohttp-retry-2.9.1 aioshutil-1.5 aiosqlite-0.20.0 aiostream-0.5.2 alembic-1.15.2 apscheduler-3.11.0 asgiref-3.8.1 asyncpg-0.29.0 azure-ai-inference-1.0.0b9 azure-ai-ml-1.27.1 azure-common-1.1.28 azure-core-1.34.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-identity-1.23.0 azure-mgmt-core-1.5.0 azure-monitor-opentelemetry-1.6.9 azure-monitor-opentelemetry-exporter-1.0.0b36 azure-storage-blob-12.25.1 azure-storage-file-datalake-12.20.0 azure-storage-file-share-12.21.0 bcrypt-4.3.0 boto3-1.38.18 botocore-1.38.18 cel-python-0.2.0 colorama-0.4.6 colorlog-6.9.0 deepdiff-8.5.0 deprecation-2.1.0 dnspython-2.7.0 ecdsa-0.19.1 email-validator-2.2.0 epub-0.5.2 et-xmlfile-2.0.0 fastapi-0.115.12 firecrawl-py-2.6.0 fixedint-0.1.6 flupy-1.2.2 fsspec-2024.12.0 future-1.0.0 google-auth-oauthlib-1.2.2 google-genai-0.6.0 gotrue-2.12.0 grpcio-tools-1.71.0 gunicorn-21.2.0 h2-4.2.0 hatchet-sdk-0.47.0 hpack-4.1.0 httpx-0.27.2 hyperframe-6.1.0 isodate-0.7.2 jmespath-1.0.1 jsonpath-python-1.0.6 langchain-community-0.3.23 lark-0.12.0 litellm-1.64.1 mailersend-0.5.8 mistralai-1.5.2 msal-1.32.3 msal-extensions-1.3.1 msg-parser-1.2.0 msrest-0.7.1 networkx-3.4.2 numpy-1.26.4 oauthlib-3.2.2 ollama-0.3.3 openpyxl-3.1.5 opentelemetry-api-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-dbapi-0.52b1 opentelemetry-instrumentation-django-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-instrumentation-flask-0.52b1 opentelemetry-instrumentation-psycopg2-0.52b1 opentelemetry-instrumentation-requests-0.52b1 opentelemetry-instrumentation-urllib-0.52b1 opentelemetry-instrumentation-urllib3-0.52b1 opentelemetry-instrumentation-wsgi-0.52b1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 opentelemetry-util-http-0.52b1 orderly-set-5.4.1 orgparse-0.4.20231004 pdf2image-1.17.0 pgvector-0.3.6 pillow-11.2.1 pillow-heif-0.21.0 postgrest-1.0.1 prometheus-client-0.21.1 psutil-6.1.1 psycopg-binary-3.2.9 psycopg2-binary-2.9.10 pydash-8.0.5 pyjwt-2.10.1 pynacl-1.5.0 pypdf-4.3.1 pypdf2-3.0.1 pytest-mock-3.14.0 python-docx-1.1.2 python-http-client-3.3.7 python-json-logger-3.3.0 python-multipart-0.0.18 python-pptx-1.0.2 r2r-3.5.11 realtime-2.4.3 requests-oauthlib-2.0.0 s3transfer-0.12.0 sendgrid-6.12.2 starlette-0.46.2 storage3-0.11.3 strenum-0.4.15 strictyaml-1.7.3 striprtf-0.0.28 supabase-2.15.1 supafunc-0.9.4 tiktoken-0.8.0 tokenizers-0.19.0 toml-0.10.2 types-aiofiles-24.1.0.20250516 types-python-dateutil-2.9.0.20250516 types-pyyaml-6.0.12.20250516 types-requests-2.32.0.20250515 tzlocal-5.3.1 unstructured-client-0.25.5 uvicorn-0.27.1 vecs-0.4.5 websockets-14.2 werkzeug-3.1.3 xlrd-2.0.1\n",
      "[+] ENVIRONMENT IS SET AND READY TO BE USED. [+]\n",
      "================================================================================\n",
      "Generating dataset in ./datasets/1_dataset.jsonl\n",
      "TOP_K=5\n",
      "MAX_TOKENS_TO_SAMPLE=512\n",
      "CHUNK_SIZE=512\n",
      "CHUNK_OVERLAP=0\n",
      "CHAT_MODEL=llama3.1:8b\n",
      "TEMPERATURE=0.0\n",
      "================================================================================\n",
      "\n",
      "DELETION STEP COMPLETED...\n",
      "/tmp/tmpvu0wrb4i/special_assistance.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/managing_reservations.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/flight_delays.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/baggage_policies.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/inflight_services.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/schedule_changes.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/bookings.md: Document created and ingested successfully.\n",
      "/tmp/tmpvu0wrb4i/flight_cancellations.md: Document created and ingested successfully.\n",
      "INGESTION STEP COMPLETED...\n",
      "Added data to sample: 1 out of 52\n",
      "Added data to sample: 2 out of 52\n",
      "Added data to sample: 3 out of 52\n",
      "Added data to sample: 4 out of 52\n",
      "Added data to sample: 5 out of 52\n",
      "Added data to sample: 6 out of 52\n",
      "Added data to sample: 7 out of 52\n",
      "Added data to sample: 8 out of 52\n",
      "Added data to sample: 9 out of 52\n",
      "Added data to sample: 10 out of 52\n",
      "Added data to sample: 11 out of 52\n",
      "Added data to sample: 12 out of 52\n",
      "Added data to sample: 13 out of 52\n",
      "Added data to sample: 14 out of 52\n",
      "Added data to sample: 15 out of 52\n",
      "Added data to sample: 16 out of 52\n",
      "Added data to sample: 17 out of 52\n",
      "Added data to sample: 18 out of 52\n",
      "Added data to sample: 19 out of 52\n",
      "Added data to sample: 20 out of 52\n",
      "Added data to sample: 21 out of 52\n",
      "Added data to sample: 22 out of 52\n",
      "Added data to sample: 23 out of 52\n",
      "Added data to sample: 24 out of 52\n",
      "Added data to sample: 25 out of 52\n",
      "Added data to sample: 26 out of 52\n",
      "Added data to sample: 27 out of 52\n",
      "Added data to sample: 28 out of 52\n",
      "Added data to sample: 29 out of 52\n",
      "Added data to sample: 30 out of 52\n",
      "Added data to sample: 31 out of 52\n",
      "Added data to sample: 32 out of 52\n",
      "Added data to sample: 33 out of 52\n",
      "Added data to sample: 34 out of 52\n",
      "Added data to sample: 35 out of 52\n",
      "Added data to sample: 36 out of 52\n",
      "Added data to sample: 37 out of 52\n",
      "Added data to sample: 38 out of 52\n",
      "Added data to sample: 39 out of 52\n",
      "Added data to sample: 40 out of 52\n",
      "Added data to sample: 41 out of 52\n",
      "Added data to sample: 42 out of 52\n",
      "Added data to sample: 43 out of 52\n",
      "Added data to sample: 44 out of 52\n",
      "Added data to sample: 45 out of 52\n",
      "Added data to sample: 46 out of 52\n",
      "Added data to sample: 47 out of 52\n",
      "Added data to sample: 48 out of 52\n",
      "Added data to sample: 49 out of 52\n",
      "Added data to sample: 50 out of 52\n",
      "Added data to sample: 51 out of 52\n",
      "Added data to sample: 52 out of 52\n",
      "[+] FULL DATASET SAVED... [+]\n"
     ]
    }
   ],
   "source": [
    "goldens_filepath: str = f\"{goldens_id}_goldens\"\n",
    "test_id: str = f\"{goldens_id}\"\n",
    "\n",
    "# Run the script with arguments\n",
    "# Also do provide different names for the different configurations\n",
    "!./fill_dataset.sh {goldens_filepath} {test_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Synthetic Data Generation completed\n",
    "\n",
    "With this you have created your own synthetic goldens, used various configurations to fill out the rest of the missing fields and saved all the data locally. Now you can move on to the next notebook, check out all the relevant (in my opinion) metrics and evaluate your application using the different experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
