************************************************************************
-> RAGAs
    => start evaluating the LLMs responses
-> Check out instruction models for llama3.1 
    => on the model page on Ollama scroll down
-> Do research on further evaluation methods/frameworks
    => implement
-> Play around with chunk size, models, etc.
***********************************************************************