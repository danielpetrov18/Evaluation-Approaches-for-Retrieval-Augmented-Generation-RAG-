************************************************************************
-> RAGAs
    => start evaluating the LLMs responses
-> Check out instruction models for llama3.1 
    => on the model page on Ollama scroll down
-> Do research on further evaluation methods/frameworks
    => implement
-> Play around with chunk size, models, etc.
-> testset, that makes sense for all metrics
-> use metrics that are the same across frameworks 
-> use metrics that are unique to a framework 
***********************************************************************