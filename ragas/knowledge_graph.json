{
  "nodes": [
    {
      "id": "7861e247-897f-4b76-aeb7-6762d1b68201",
      "properties": {
        "page_content": "Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks\nPatrick Lewis†‡, Ethan Perez⋆,\nAleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\nMike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n†Facebook AI Research; ‡University College London; ⋆New York University;\nplewis@fb.com\nAbstract\nLarge pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\nstream NLP tasks. However, their ability to access and precisely manipulate knowl-\nedge is still limited, and hence on knowledge-intensive tasks, their performance\nlags behind task-speciﬁc architectures. Additionally, providing provenance for their\ndecisions and updating their world knowledge remain open research problems. Pre-\ntrained models with a differentiable access mechanism to explicit non-parametric\nmemory have so far been only investigated for extractive downstream tasks. We\nexplore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation\n(RAG) — models which combine pre-trained parametric and non-parametric mem-\nory for language generation. We introduce RAG models where the parametric\nmemory is a pre-trained seq2seq model and the non-parametric memory is a dense\nvector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\npare two RAG formulations, one which conditions on the same retrieved passages\nacross the whole generated sequence, and another which can use different passages\nper token. We ﬁne-tune and evaluate our models on a wide range of knowledge-\nintensive NLP tasks and set the state of the art on three open domain QA tasks,\noutperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\narchitectures. For language generation tasks, we ﬁnd that RAG models generate\nmore speciﬁc, diverse and factual language than a state-of-the-art parametric-only\nseq2seq baseline.\n1 Introduction\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowl-\nedge from data [47]. They can do so without any access to an external memory, as a parameterized\nimplicit knowledge base [51, 52]. While this development is exciting, such models do have down-\nsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into\ntheir predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric\nmemory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these\nissues because knowledge can be directly revised and expanded, and accessed knowledge can be\ninspected and interpreted. REALM [ 20] and ORQA [ 31], two recently introduced models that\ncombine masked language models [8] with a differentiable retriever, have shown promising results,\narXiv:2005.11401v4  [cs.CL]  12 Apr 2021",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "summary": "AI is transforming industries by automating tasks and analyzing data, driving innovations in areas like self-driving cars and personalized recommendations. However, current pre-trained language models have limitations, such as storing factual knowledge but struggling to access and manipulate it. A new approach combines parametric and non-parametric memory for language generation, outperforming existing models on open domain QA tasks.",
        "summary_embedding": [
          0.4712982773780823,
          0.16027234494686127,
          -0.5172178149223328,
          -0.5563904047012329,
          -0.23152127861976624,
          -0.6709834933280945,
          0.5055039525032043,
          -0.42783990502357483,
          -0.032440923154354095,
          0.00982101820409298,
          0.34580889344215393,
          -0.0219402052462101,
          -0.24915659427642822,
          -0.8376030325889587,
          -0.41804611682891846,
          0.19632285833358765,
          0.26012784242630005,
          -0.08802914619445801,
          -0.15889401733875275,
          -0.6673735976219177,
          -0.22481673955917358,
          -0.13518160581588745,
          -1.5601526498794556,
          0.012745797634124756,
          -0.9904784560203552,
          0.6732474565505981,
          1.1993780136108398,
          0.5256245136260986,
          1.152405023574829,
          0.31095460057258606,
          0.23429229855537415,
          -0.11244337260723114,
          0.21803554892539978,
          -0.7936697006225586,
          -0.5088722705841064,
          -0.6911918520927429,
          0.49108558893203735,
          -0.48629093170166016,
          -0.6508267521858215,
          0.08904360979795456,
          0.2599870562553406,
          -0.5839537978172302,
          0.7280011177062988,
          -1.698488473892212,
          -1.5899373292922974,
          -0.3236168622970581,
          0.48516273498535156,
          -0.5607411861419678,
          0.2739851176738739,
          -0.6814024448394775,
          -0.4026513397693634,
          0.700965404510498,
          0.1322704702615738,
          -0.2909665107727051,
          0.19914303719997406,
          -1.0548291206359863,
          0.14573781192302704,
          0.04967239126563072,
          -0.5145738124847412,
          -0.09305934607982635,
          0.7080989480018616,
          0.454010933637619,
          0.44582676887512207,
          -0.8239898681640625,
          -0.4497544765472412,
          0.2882069945335388,
          0.6974884271621704,
          0.07111870497465134,
          -0.520669162273407,
          0.4622119069099426,
          -1.6883817911148071,
          0.12898722290992737,
          -0.34655991196632385,
          -0.2862747609615326,
          -0.45911791920661926,
          -0.4818440079689026,
          0.763877272605896,
          0.4536910057067871,
          -0.45239007472991943,
          -0.08227962255477905,
          0.27483856678009033,
          1.034652829170227,
          0.13071735203266144,
          0.7668745517730713,
          -0.5685023665428162,
          -0.7108067274093628,
          1.0268326997756958,
          0.15601612627506256,
          -0.16034092009067535,
          -0.7090528607368469,
          -0.031120019033551216,
          0.5794673562049866,
          0.0640002191066742,
          0.22634008526802063,
          0.07397109270095825,
          0.571529746055603,
          -0.04006345570087433,
          0.42934083938598633,
          -0.013909481465816498,
          0.3336915671825409,
          0.3376404047012329,
          0.9328324198722839,
          -0.36968711018562317,
          0.5534908771514893,
          -0.8154381513595581,
          0.11669269949197769,
          0.27609124779701233,
          0.07169380784034729,
          0.22153659164905548,
          -0.27072346210479736,
          -0.20725034177303314,
          0.5671162009239197,
          0.7679847478866577,
          -0.2860594391822815,
          -0.5224436521530151,
          0.6445612907409668,
          -0.576553463935852,
          0.4246648848056793,
          -0.19572317600250244,
          0.024449888616800308,
          -0.5006523728370667,
          -0.5902493596076965,
          -0.23074102401733398,
          -0.3320300281047821,
          0.02791927009820938,
          -1.183849573135376,
          0.30505940318107605,
          0.7046871781349182,
          -0.4124886095523834,
          0.5136696100234985,
          -0.21403758227825165,
          0.15913531184196472,
          0.10484995692968369,
          1.3119566440582275,
          -0.042871613055467606,
          -0.31138381361961365,
          0.3334149122238159,
          0.6114914417266846,
          -0.28478020429611206,
          0.25177448987960815,
          0.4499388337135315,
          -0.4785255193710327,
          0.2595509886741638,
          1.6298999786376953,
          -0.29592713713645935,
          -0.2835596799850464,
          0.3608890473842621,
          -0.9844727516174316,
          -0.621684193611145,
          0.7239824533462524,
          -0.5288910269737244,
          -0.02799711748957634,
          0.10816806554794312,
          0.4707808792591095,
          -0.9946714639663696,
          -0.2922786772251129,
          -0.2328345626592636,
          -0.25174087285995483,
          0.060048457235097885,
          -0.07674288749694824,
          -0.4387490153312683,
          -0.02330225706100464,
          -0.49130359292030334,
          0.6819852590560913,
          -0.36387959122657776,
          0.5334694385528564,
          -0.5726076364517212,
          0.2686760425567627,
          -0.46361297369003296,
          -0.5398183465003967,
          0.1698841005563736,
          0.49757444858551025,
          -0.43912702798843384,
          -0.05154332518577576,
          0.1696585714817047,
          1.3223390579223633,
          0.5346217155456543,
          0.20243914425373077,
          0.5079532861709595,
          -0.0588964968919754,
          -0.5197519063949585,
          -0.639961302280426,
          -0.30742669105529785,
          0.20023967325687408,
          0.23049567639827728,
          0.10174224525690079,
          0.04399067908525467,
          0.06528770923614502,
          -0.4373237192630768,
          0.7765496969223022,
          0.19392281770706177,
          1.099220871925354,
          -0.7703278660774231,
          0.676003634929657,
          -0.37470749020576477,
          0.7348955273628235,
          -0.44589245319366455,
          0.7380289435386658,
          0.6548199653625488,
          -1.0690836906433105,
          -0.2593776285648346,
          1.069671630859375,
          0.29786011576652527,
          -0.459286093711853,
          -1.1739468574523926,
          0.8775736093521118,
          -0.4091855585575104,
          0.6118075847625732,
          -1.4307780265808105,
          1.0827218294143677,
          0.3448535203933716,
          0.2695600688457489,
          -0.24372252821922302,
          0.09106282889842987,
          0.9640135169029236,
          -0.23570886254310608,
          -0.914078414440155,
          0.10382633656263351,
          0.42418909072875977,
          0.3307393193244934,
          -0.4835057258605957,
          -0.4378681778907776,
          -0.1543542891740799,
          -0.7481051087379456,
          -0.07803980261087418,
          -0.16010764241218567,
          0.17466135323047638,
          0.6908207535743713,
          0.4540964365005493,
          0.01783478818833828,
          0.30160975456237793,
          0.4710754156112671,
          -0.7789563536643982,
          0.5681105256080627,
          0.36745402216911316,
          0.38844409584999084,
          1.2057292461395264,
          0.44222989678382874,
          -0.05500968545675278,
          0.06315696239471436,
          -0.425078809261322,
          0.10696710646152496,
          0.9261594414710999,
          1.0354597568511963,
          0.1448114663362503,
          -0.1547793745994568,
          -0.26927927136421204,
          -0.16469913721084595,
          0.3270879089832306,
          -0.0938083827495575,
          -0.4845896363258362,
          0.29551756381988525,
          0.33802342414855957,
          -0.26912668347358704,
          -0.9905492067337036,
          -0.11042824387550354,
          0.40855568647384644,
          1.1224019527435303,
          0.003682240843772888,
          -1.0908238887786865,
          -0.19456040859222412,
          0.6858472228050232,
          0.25977349281311035,
          -0.16043736040592194,
          0.3851371705532074,
          0.504997968673706,
          -0.01116026472300291,
          0.2921125888824463,
          -0.3592710793018341,
          -0.09077925980091095,
          -0.45378100872039795,
          -1.317496418952942,
          -1.2554326057434082,
          -0.07360883057117462,
          -0.41036877036094666,
          0.06650753319263458,
          0.8101674318313599,
          -1.1454086303710938,
          -0.16231155395507812,
          -0.6953901052474976,
          -0.3561590015888214,
          -0.1576433628797531,
          -0.45191970467567444,
          0.6762040853500366,
          0.6328344941139221,
          0.02816273272037506,
          -0.27265650033950806,
          0.5544428825378418,
          -0.6484467387199402,
          0.8995167016983032,
          0.12810806930065155,
          -0.05334801226854324,
          -0.06092940643429756,
          -0.5961670279502869,
          0.11261871457099915,
          0.20452290773391724,
          -0.18699303269386292,
          0.4794919192790985,
          -0.9166386723518372,
          -0.41958606243133545,
          -0.11737245321273804,
          -0.22500547766685486,
          0.5003140568733215,
          -0.20971311628818512,
          -0.5122235417366028,
          0.5761708617210388,
          0.5640578866004944,
          -0.3148755431175232,
          0.6105936765670776,
          0.5387611389160156,
          -1.0568838119506836,
          0.666035532951355,
          -0.12759162485599518,
          1.145464301109314,
          -0.4166300594806671,
          1.0035502910614014,
          0.6382332444190979,
          -0.25008225440979004,
          -0.47437965869903564,
          -0.6001008152961731,
          -0.808436930179596,
          0.06638218462467194,
          -0.048644594848155975,
          0.3064643144607544,
          -0.2529008090496063,
          0.5502350330352783,
          -0.29299396276474,
          -1.5171654224395752,
          0.21504800021648407,
          -0.27401596307754517,
          -0.7561947107315063,
          0.27475741505622864,
          0.26773712038993835,
          0.6654173731803894,
          0.047318361699581146,
          0.05280129984021187,
          -0.038469646126031876,
          0.071329765021801,
          -0.43673956394195557,
          0.6717769503593445,
          0.5175312757492065,
          -0.08602817356586456,
          -0.21890386939048767,
          0.6390310525894165,
          0.4350211024284363,
          0.4284411072731018,
          0.5196611285209656,
          -0.441603422164917,
          0.05423794686794281,
          -0.2659621834754944,
          0.18507851660251617,
          0.5735036730766296,
          -0.2900331914424896,
          -0.2690087854862213,
          0.20630115270614624,
          -0.35256919264793396,
          -0.038744062185287476,
          0.12772129476070404,
          0.3692154884338379,
          0.16701799631118774,
          0.582683801651001,
          0.6366360187530518,
          0.18168485164642334,
          0.736130952835083,
          0.1669483333826065,
          0.48615217208862305,
          -0.7817064523696899,
          0.09421820193529129,
          0.44206860661506653,
          -0.8717753291130066,
          0.08403994143009186,
          -0.19286061823368073,
          -0.433663010597229,
          0.5198913812637329,
          -0.6645562648773193,
          -1.3880960941314697,
          0.7153464555740356,
          -0.25219422578811646,
          0.6008630394935608,
          -0.41836851835250854,
          -0.12014220654964447,
          0.5415499210357666,
          -0.06708964705467224,
          0.028707951307296753,
          0.47804296016693115,
          0.5505342483520508,
          -0.17578400671482086,
          -0.09518532454967499,
          -0.38640904426574707,
          0.4982239305973053,
          -0.03166031092405319,
          0.6208707094192505,
          -0.6075484156608582,
          -0.25852838158607483,
          -0.27685219049453735,
          -0.3387697637081146,
          0.6812269687652588,
          0.2128356397151947,
          0.2970627248287201,
          0.04860173165798187,
          0.6191529631614685,
          -0.5334284901618958,
          0.2770993411540985,
          0.20408692955970764,
          0.3703969717025757,
          0.12823213636875153,
          -0.589411735534668,
          0.47174936532974243,
          0.15870818495750427,
          0.0817461758852005,
          -0.10996420681476593,
          -0.41279616951942444,
          -0.10707628726959229,
          0.14392198622226715,
          0.15293236076831818,
          0.14636968076229095,
          0.20932212471961975,
          0.15350914001464844,
          0.45733797550201416,
          0.036921776831150055,
          -0.48023179173469543,
          -0.21159875392913818,
          -0.5936360359191895,
          -0.0026252828538417816,
          0.7072255611419678,
          -0.557861864566803,
          0.01801750808954239,
          -0.36378398537635803,
          0.5439883470535278,
          0.528472363948822,
          -0.23975080251693726,
          -1.0387271642684937,
          -0.4124266505241394,
          0.06058327853679657,
          -0.7973423600196838,
          0.537291407585144,
          0.5217273235321045,
          -0.8638215661048889,
          0.4667404294013977,
          -0.2065877765417099,
          0.28408321738243103,
          0.4230874478816986,
          -0.012229971587657928,
          0.362395703792572,
          0.2995005249977112,
          -0.90997314453125,
          0.02859603427350521,
          0.29818907380104065,
          -0.2366432398557663,
          -0.5785741806030273,
          0.7908930778503418,
          -0.6167778968811035,
          0.5699092745780945,
          -0.7634297609329224,
          -0.15796330571174622,
          -0.5280731320381165,
          0.24750511348247528,
          0.34460604190826416,
          -0.008692789822816849,
          0.38971441984176636,
          0.23194465041160583,
          -0.563589870929718,
          -0.08760904520750046,
          -0.4576229751110077,
          -0.6965206265449524,
          0.6614059805870056,
          0.5113834142684937,
          -0.26438552141189575,
          0.10210909694433212,
          0.6098872423171997,
          -0.460541695356369,
          -0.15734495222568512,
          0.15587851405143738,
          -0.5156230926513672,
          0.4382677376270294,
          0.0765613317489624,
          0.8366960883140564,
          -0.4319983124732971,
          -0.5479353666305542,
          -0.8940569162368774,
          -0.6749075651168823,
          0.3993637263774872,
          0.5795810222625732,
          -0.07800757884979248,
          -0.100578173995018,
          -1.344839334487915,
          -0.4301466643810272,
          0.8670246005058289,
          -0.6330469250679016,
          -0.1681743860244751,
          0.11207647621631622,
          -0.256130576133728,
          0.43804678320884705,
          0.1816762089729309,
          -0.780967652797699,
          -0.1630432903766632,
          -0.9286841154098511,
          -0.03599382936954498,
          0.27904412150382996,
          0.4489799439907074,
          0.8105959296226501,
          -0.7043069005012512,
          -1.3044066429138184,
          0.8770487904548645,
          -0.5960105657577515,
          -0.1645563542842865,
          -0.5483583211898804,
          -0.7170163989067078,
          -0.2769671678543091,
          0.002936284989118576,
          -0.5867672562599182,
          0.1673489362001419,
          -0.4727059006690979,
          0.3919297754764557,
          0.6716173887252808,
          -0.4974534511566162,
          -0.5146809816360474,
          -0.18323154747486115,
          -0.2755012810230255,
          1.2420527935028076,
          0.09815696626901627,
          -0.501703143119812,
          -0.7427733540534973,
          0.7046344876289368,
          -0.6205337643623352,
          0.255318284034729,
          0.7458269596099854,
          0.22449034452438354,
          -0.2638566493988037,
          -1.0936944484710693,
          0.8812679052352905,
          -0.4458748698234558,
          0.06680198013782501,
          -0.5400972962379456,
          0.11797638982534409,
          0.5344441533088684,
          -0.09750498086214066,
          0.9849255084991455,
          -0.8930509686470032,
          -0.4913517236709595,
          0.08130785822868347,
          -0.07718230783939362,
          -0.8195739984512329,
          -0.7348307967185974,
          -0.6934134364128113,
          0.0049374960362911224,
          0.3451707661151886,
          1.4597339630126953,
          -0.24283182621002197,
          -0.051541298627853394,
          0.09528101980686188,
          -0.011761046946048737,
          0.01824135147035122,
          0.9092750549316406,
          -0.5027878284454346,
          0.07069805264472961,
          0.3565356135368347,
          -0.2501450181007385,
          0.6740289926528931,
          0.29867392778396606,
          -0.5383918285369873,
          0.2224658578634262,
          -0.5024989247322083,
          -0.5839885473251343,
          -1.1969577074050903,
          0.3211953043937683,
          -0.4263626039028168,
          -0.7470545172691345,
          0.7492715120315552,
          -1.0569469928741455,
          -0.18691231310367584,
          -0.2957780957221985,
          1.0321506261825562,
          0.46073389053344727,
          -0.06984437257051468,
          -0.725662350654602,
          -0.3324255049228668,
          -0.5290532112121582,
          -0.8204260468482971,
          -0.517977237701416,
          -1.3021297454833984,
          0.07800552994012833,
          0.4019933342933655,
          0.038861408829689026,
          0.2786121070384979,
          -0.9163007736206055,
          0.13514846563339233,
          1.5389701128005981,
          0.6130886673927307,
          -0.31342142820358276,
          -0.5212565660476685,
          -0.16562619805335999,
          0.16670265793800354,
          -0.42163676023483276,
          -0.2593578100204468,
          0.045356620103120804,
          -0.606376051902771,
          -0.5722114443778992,
          -1.0232433080673218,
          -0.9025272727012634,
          0.16232040524482727,
          0.1683398336172104,
          1.3993228673934937,
          -0.0596051849424839,
          0.5082209706306458,
          0.3234429955482483,
          -0.02541443333029747,
          -0.7089910507202148,
          0.5471681356430054,
          0.050502706319093704,
          -0.23167721927165985,
          0.38308897614479065,
          0.4146047830581665,
          -0.4687737822532654,
          0.08243637531995773,
          -0.9826556444168091,
          -0.7461029887199402,
          0.39370307326316833,
          1.1150065660476685,
          0.30167362093925476,
          -0.6036530137062073,
          0.3687158226966858,
          0.7272169589996338,
          -0.20350775122642517,
          -0.14950838685035706,
          0.03013603202998638,
          0.24232260882854462,
          -0.5474892258644104,
          -1.0243148803710938,
          0.2921263575553894,
          -0.2962806224822998,
          -0.10299278795719147,
          -0.3436017334461212,
          0.5469828844070435,
          0.266518235206604,
          0.3400815725326538,
          0.7442103028297424,
          -0.3155168294906616,
          -0.8712020516395569,
          -0.07166454195976257,
          0.21734017133712769,
          -0.44030287861824036,
          0.6994876265525818,
          -0.8933629989624023,
          -0.20935922861099243,
          -0.27554965019226074,
          -0.19141043722629547,
          0.7012560963630676,
          -0.09244315326213837,
          -0.5119029879570007,
          0.42558643221855164,
          0.33384400606155396,
          1.0895978212356567,
          -0.5372686386108398,
          -0.18028102815151215,
          0.2978053390979767,
          -0.808022141456604,
          -0.16630016267299652,
          -0.06624079495668411,
          0.8843865990638733,
          -0.7499908804893494,
          0.48817747831344604,
          -0.6875083446502686,
          0.443718820810318,
          0.5932360291481018,
          0.6966304183006287,
          -0.2760670483112335,
          -0.8633682131767273,
          -0.22225186228752136,
          -1.1768255233764648,
          -0.07791349291801453,
          -0.14270278811454773,
          -0.4625578224658966,
          -0.23970898985862732,
          0.9747285842895508,
          0.49832016229629517,
          -0.1972654163837433,
          -0.275810569524765,
          0.8013819456100464,
          -1.1339610815048218,
          -0.4587153196334839,
          -0.39254897832870483,
          0.24981501698493958,
          -0.1019880622625351,
          0.15743397176265717,
          0.04601719230413437,
          -0.35830891132354736,
          -0.403518944978714,
          0.7929635643959045,
          -0.4788808822631836,
          0.2769588828086853,
          0.021109754219651222,
          0.20833609998226166,
          -0.7376892566680908,
          -0.3067684471607208,
          -0.2559809982776642,
          0.5825636386871338,
          -0.15613704919815063,
          -0.3737075626850128,
          -0.4008508026599884,
          0.30000197887420654,
          -0.09743139892816544,
          -0.46924906969070435,
          -0.23348352313041687,
          -0.3804662823677063,
          0.5877700448036194,
          -0.7609411478042603,
          -0.03699090704321861,
          0.785434365272522,
          0.11890941113233566,
          0.7548232674598694,
          -0.6208675503730774,
          0.25470030307769775,
          -0.3429303467273712,
          0.2385626882314682,
          0.005854036659002304,
          -0.29096555709838867,
          -0.04386892914772034,
          0.5624306201934814,
          0.9111977219581604,
          1.4646613597869873,
          0.06229514628648758,
          0.5379014611244202,
          0.048696935176849365,
          -0.0789303258061409,
          0.6434100866317749,
          0.15263135731220245,
          0.7780355215072632,
          -0.3848411440849304,
          -0.21451207995414734,
          -0.5571830868721008,
          0.15843765437602997,
          0.9219014048576355,
          -0.8247013092041016,
          -0.08894723653793335,
          -0.24587735533714294,
          0.4694843888282776,
          -0.9443433284759521,
          -0.12997794151306152,
          0.6920332908630371,
          0.5893282890319824,
          0.5126365423202515,
          -0.1944967806339264,
          0.06680657714605331,
          -0.14973320066928864,
          -0.04886646196246147,
          -0.5072272419929504,
          -0.6608465313911438,
          -0.5202903747558594,
          0.3106057941913605,
          -0.36533236503601074,
          0.4358934760093689,
          0.5640007257461548,
          -0.017543984577059746,
          -0.007644202560186386,
          0.5754969120025635,
          0.06120515987277031,
          0.20757752656936646,
          0.8948455452919006,
          -0.35770660638809204,
          -0.07425329089164734,
          -1.1053167581558228,
          -0.6408127546310425,
          -0.22730723023414612,
          0.3693636953830719,
          -1.0759854316711426,
          -0.9262632727622986,
          0.4561506509780884,
          0.5026427507400513,
          0.1291743516921997,
          -0.2890627980232239,
          -1.3898571729660034,
          0.3149060904979706,
          -0.2603914141654968,
          0.4490779936313629,
          -1.1710907220840454,
          0.6044300198554993,
          0.022833287715911865,
          0.1067468672990799,
          -0.005155116319656372,
          0.6454361081123352,
          0.09139290452003479,
          0.5786374807357788,
          0.5824114680290222,
          0.7345286011695862,
          -0.0031798183917999268,
          0.5421942472457886,
          0.5594366192817688,
          -0.6887233257293701,
          0.49539849162101746,
          0.2494085431098938,
          0.12766505777835846,
          0.33478084206581116,
          -0.17852675914764404,
          -0.24516892433166504,
          0.6804183125495911,
          0.7345449328422546,
          -0.1682078242301941,
          -1.01753830909729,
          0.7358704805374146,
          0.3778935968875885,
          -0.7181601524353027,
          -0.2787855863571167,
          0.9104260206222534,
          0.6224446892738342,
          -0.6559372544288635,
          -0.37597715854644775,
          -0.9953670501708984,
          0.8826476335525513,
          -1.3833197355270386,
          0.34968411922454834,
          -0.25905686616897583,
          -0.6013469099998474,
          -1.030362606048584,
          0.09257099032402039,
          -1.0338326692581177,
          0.5337933897972107,
          0.9198018312454224,
          -0.9731494188308716,
          -0.434431791305542,
          0.2637389004230499,
          0.021139150485396385,
          0.4069625735282898,
          -0.004224663600325584,
          -0.5557945966720581,
          0.15971609950065613,
          0.013706803321838379,
          0.7907145619392395,
          -0.3163037598133087,
          0.20918357372283936,
          0.44094792008399963,
          0.4742226004600525,
          0.23514972627162933,
          0.7931466698646545,
          -0.30273938179016113,
          0.32658135890960693,
          0.4263274669647217,
          -0.5237001180648804,
          1.409369707107544,
          0.1830778867006302,
          -0.5261102318763733,
          0.09035065770149231,
          -0.342903733253479,
          -0.22925740480422974,
          -0.9973653554916382,
          0.2910885214805603,
          -1.4580061435699463,
          0.5399408340454102,
          0.7091159224510193,
          0.024715233594179153,
          -0.4209260940551758,
          0.18860863149166107,
          -0.13562166690826416,
          0.4039333164691925,
          0.5915449857711792,
          -0.1021672934293747,
          -0.3762860596179962,
          1.443363904953003,
          1.1144330501556396,
          -0.05405617877840996,
          0.2103806436061859,
          -0.19229808449745178,
          -0.1306792050600052,
          0.4705669581890106,
          0.29399868845939636,
          -0.7442545294761658,
          -0.5876303315162659,
          -0.42063671350479126,
          -1.2370318174362183,
          -0.22186559438705444,
          0.2881203889846802,
          0.20772114396095276,
          -0.11914541572332382,
          0.478039026260376,
          0.7702489495277405,
          -0.2740924060344696,
          0.2862789034843445,
          0.8640238046646118,
          -0.1825387179851532,
          0.742614209651947,
          -0.38629350066185,
          0.13709662854671478,
          0.08863066136837006,
          0.4423287808895111,
          -0.20954719185829163,
          0.4906806945800781,
          -0.39681363105773926,
          -0.6682220101356506,
          0.3069269061088562,
          -0.16264578700065613,
          -0.26892828941345215,
          -0.7255162596702576,
          0.35370874404907227,
          -0.9087457656860352,
          0.6370077133178711,
          0.1556224673986435,
          0.5524148941040039,
          -0.08823023736476898,
          -0.7703641653060913,
          -0.4686447083950043,
          1.3393068313598633,
          0.7066027522087097,
          0.17131666839122772,
          1.2681171894073486,
          0.673775851726532,
          0.5950348377227783,
          -0.038542769849300385,
          0.12879568338394165,
          0.14056891202926636,
          0.17062225937843323,
          -0.520623505115509,
          -0.32841038703918457,
          0.1201663687825203,
          -0.52060467004776,
          -0.739962100982666,
          0.4648396968841553,
          0.5629106760025024,
          0.21105732023715973,
          -0.29159483313560486,
          -1.3451032638549805,
          0.4267587959766388,
          -0.4900113344192505,
          -0.22270089387893677,
          -0.5320396423339844,
          0.8181017637252808,
          0.1807744801044464,
          -0.7204160094261169,
          -0.22921264171600342,
          -0.26423174142837524,
          3.7635679244995117,
          1.1488367319107056,
          0.21219389140605927,
          0.7256447672843933,
          0.5642764568328857,
          1.1208277940750122,
          1.1989530324935913,
          -0.06490838527679443,
          0.5938802361488342,
          -0.6727010011672974,
          0.6810255646705627,
          0.0579923540353775,
          0.20706412196159363,
          0.2789175808429718,
          -0.18459127843379974,
          -0.05147666484117508,
          -0.9045208692550659,
          0.0428854376077652,
          -0.8337814211845398,
          0.0055137574672698975,
          0.06499609351158142,
          0.7130545377731323,
          0.5555583834648132,
          -0.05906692147254944,
          0.9230724573135376,
          -0.4335605502128601,
          -0.818764865398407,
          -0.2675602436065674,
          0.278293639421463,
          -0.08649547398090363,
          0.18591180443763733,
          -0.613733172416687,
          0.11011496931314468,
          0.04752720147371292,
          -0.3173332214355469,
          0.7464537024497986,
          0.1573510766029358,
          -0.9173524975776672,
          0.10848728567361832,
          0.6251367926597595,
          -0.0433584600687027,
          -1.1105924844741821,
          -0.5197004675865173,
          0.46317243576049805,
          -0.3129562437534332,
          0.4962694048881531,
          0.5278312563896179,
          0.9655237197875977,
          1.0502125024795532,
          -0.731203019618988,
          0.7016077637672424,
          -0.8249850869178772,
          0.3701387941837311,
          -0.502267062664032,
          -0.09820227324962616,
          -0.1681559830904007,
          -1.0687050819396973,
          -0.2984459102153778,
          -0.6979244947433472,
          0.3961814045906067,
          -0.1351424604654312,
          -0.28260838985443115,
          0.08630280196666718,
          0.6425592303276062,
          -0.07313287258148193,
          0.053327396512031555,
          0.39792028069496155,
          -0.4033193588256836,
          -0.8858795166015625,
          -0.28186655044555664,
          0.11837765574455261,
          0.17208226025104523,
          -0.19629620015621185,
          -0.4121023714542389,
          0.1973087191581726,
          -0.5795027017593384,
          -0.7351219058036804,
          0.6102937459945679,
          -0.08834316581487656,
          -0.3303951919078827,
          -0.21531134843826294,
          -0.3038521111011505,
          -0.29160359501838684,
          0.16801100969314575,
          0.09072937816381454,
          0.5522674322128296,
          -0.38278406858444214,
          1.0433545112609863,
          -0.6140486598014832,
          0.7197881937026978,
          -0.21504345536231995,
          0.5719881057739258,
          0.37012460827827454,
          -0.11527495086193085,
          0.1840132176876068
        ]
      },
      "type": "document"
    },
    {
      "id": "64a706ff-71f6-4280-aa99-ff9b21227029",
      "properties": {
        "page_content": "The\tDivine\nComedy\t(x) q \nQuery \nEncoder \nq(x) \nMIPS p θ \nGenerator pθ\n(Parametric) \nMargin- \nalize \nThis\t14th\tcentury\twork\nis\tdivided\tinto\t3\nsections:\t\"Inferno\",\n\"Purgatorio\"\t&\n\"Paradiso\"\t\t\t\t\t\t\t\t\t(y)\nEnd-to-End Backprop through q  and p θ \nBarack\tObama\twas\nborn\tin\tHawaii.(x)\nFact Veriﬁcation: Fact Query\nsupports\t(y)\nQuestion Generation\nFact Veriﬁcation:\nLabel Generation\nDocument \nIndex \nDefine\t\"middle\tear\"(x)\nQuestion Answering:\nQuestion Query\nThe\tmiddle\tear\tincludes\nthe\ttympanic\tcavity\tand\nthe\tthree\tossicles.\t\t(y)\nQuestion Answering:\nAnswer GenerationRetriever pη \n(Non-Parametric) \nz 4 \nz 3 \nz 2 \nz 1 \nd(z) \nJeopardy Question\nGeneration:\nAnswer Query\nFigure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document\nIndex) with a pre-trained seq2seq model (Generator) and ﬁne-tune end-to-end. For query x , we use\nMaximum Inner Product Search (MIPS) to ﬁnd the top-K documents z i . For ﬁnal prediction y , we\ntreat z as a latent variable and marginalize over seq2seq predictions given different documents.\nbut have only explored open-domain extractive question answering. Here, we bring hybrid parametric\nand non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models.\nWe endow pre-trained, parametric-memory generation models with a non-parametric memory through\na general-purpose ﬁne-tuning approach which we refer to as retrieval-augmented generation (RAG).\nWe build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the\nnon-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural\nretriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The\nretriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on\nthe input, and the seq2seq model (BART [32]) then conditions on these latent documents together with\nthe input to generate the output. We marginalize the latent documents with a top-K approximation,\neither on a per-output basis (assuming the same document is responsible for all tokens) or a per-token\nbasis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG\ncan be ﬁne-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned.\nThere has been extensive previous work proposing architectures to enrich systems with non-parametric\nmemory which are trained from scratch for speciﬁc tasks, e.g. memory networks [ 64, 55], stack-\naugmented networks [25] and memory layers [ 30]. In contrast, we explore a setting where both\nparametric and non-parametric memory components are pre-trained and pre-loaded with extensive\nknowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is\npresent without additional training.\nOur results highlight the beneﬁts of combining parametric and non-parametric memory with genera-\ntion for knowledge-intensive tasks—tasks that humans could not reasonably be expected to perform\nwithout access to an external knowledge source. Our RAG models achieve state-of-the-art results\non open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform\nrecent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being\nextractive tasks, we ﬁnd that unconstrained generation outperforms previous extractive approaches.\nFor knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question\ngeneration, and we ﬁnd that our models generate responses that are more factual, speciﬁc, and\ndiverse than a BART baseline. For FEVER [56] fact veriﬁcation, we achieve results within 4.3% of\nstate-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that\nthe non-parametric memory can be replaced to update the models’ knowledge as the world changes.1\n2 Methods\nWe explore RAG models, which use the input sequencex to retrieve text documents z and use them\nas additional context when generating the target sequence y . As shown in Figure 1, our models\nleverage two components: (i) a retriever p η(z |x ) with parameters η that returns (top-K truncated)\ndistributions over text passages given a query x and (ii) a generator p θ(y i |x,z,y 1:i −1) parametrized\n1Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform-\ners Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/\nexamples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\n2",
        "document_metadata": {
          "page_label": "2",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "summary": "Our paper presents retrieval-augmented generation (RAG), which combines pre-trained, parametric-memory generation models with non-parametric memory to perform knowledge-intensive tasks. We achieve state-of-the-art results on open Natural Questions and WebQuestions, and our models generate responses that are more factual, specific, and diverse than a BART baseline. RAG can be fine-tuned on any seq2seq task, and we demonstrate its ability to update the models' knowledge as the world changes.",
        "summary_embedding": [
          0.6358233690261841,
          0.41370150446891785,
          -0.629599928855896,
          -0.5526120662689209,
          -0.30336683988571167,
          -0.4772963523864746,
          -0.12563565373420715,
          -0.32217663526535034,
          0.1308068484067917,
          0.45141366124153137,
          0.27210599184036255,
          -0.5040789246559143,
          0.3034307360649109,
          -0.2135847806930542,
          -0.21498943865299225,
          -0.8019222021102905,
          0.06014484167098999,
          -0.41329583525657654,
          0.04843035340309143,
          -0.9174118638038635,
          0.16990387439727783,
          0.016684485599398613,
          -1.0095009803771973,
          0.2152361273765564,
          -0.11665213108062744,
          -0.027697056531906128,
          0.7859612107276917,
          1.0084261894226074,
          1.25286066532135,
          0.7354247570037842,
          0.6288438439369202,
          -0.016370639204978943,
          -0.21678709983825684,
          -0.0024194587022066116,
          -0.5665192008018494,
          -0.7298939228057861,
          -0.04099961742758751,
          0.00017576664686203003,
          -0.4881975054740906,
          -0.16538240015506744,
          0.025528736412525177,
          -0.7276023626327515,
          0.9347684383392334,
          -1.356356143951416,
          -1.4700138568878174,
          -0.17994382977485657,
          0.16335240006446838,
          -0.30527693033218384,
          0.3017197251319885,
          -1.2263201475143433,
          0.1172371506690979,
          0.31627050042152405,
          -0.46284210681915283,
          0.2306937873363495,
          0.8303825259208679,
          -0.30839526653289795,
          0.08800903707742691,
          -0.3780365586280823,
          -0.2197083979845047,
          0.2364850491285324,
          0.6690399050712585,
          0.24283693730831146,
          0.7070596218109131,
          -0.6255348324775696,
          -0.8225465416908264,
          0.2514461576938629,
          0.5882435441017151,
          -0.18368278443813324,
          -0.2618524134159088,
          -0.10486887395381927,
          -1.031638741493225,
          -0.341562420129776,
          -0.3049178123474121,
          -0.4030514657497406,
          -0.21725915372371674,
          -0.021921925246715546,
          0.5143779516220093,
          0.6893681287765503,
          -0.43657994270324707,
          0.6847831010818481,
          -0.07905679941177368,
          0.9832465648651123,
          0.12759585678577423,
          1.0507876873016357,
          -0.45763862133026123,
          -1.1531976461410522,
          1.3320759534835815,
          0.002193049294874072,
          -0.07055719941854477,
          0.06416364014148712,
          -0.07191231101751328,
          0.5361189246177673,
          0.10813535004854202,
          0.8318643569946289,
          0.3033728003501892,
          0.6963776350021362,
          0.14782112836837769,
          0.4142182171344757,
          0.3357856571674347,
          -0.2911130487918854,
          0.46945127844810486,
          0.749092161655426,
          -0.6138626933097839,
          0.5163906812667847,
          -0.5198582410812378,
          -0.06347806751728058,
          -0.0012084096670150757,
          0.0774209201335907,
          0.6323469281196594,
          -0.5478032827377319,
          -0.18360908329486847,
          0.33158260583877563,
          0.43415316939353943,
          -0.653997540473938,
          -0.7969276905059814,
          0.6013957858085632,
          -0.18615810573101044,
          0.3545788526535034,
          -0.20753124356269836,
          -0.0011981893330812454,
          -0.25022658705711365,
          -0.5820869207382202,
          0.17894971370697021,
          0.019672121852636337,
          -0.10008786618709564,
          -0.9468187093734741,
          -0.0984947681427002,
          0.44802147150039673,
          -1.029819130897522,
          0.40488559007644653,
          -0.6753720641136169,
          0.3694002032279968,
          0.28043216466903687,
          1.2331141233444214,
          -0.27037447690963745,
          -0.30424049496650696,
          -0.04612570255994797,
          0.7390269041061401,
          0.2790932059288025,
          -0.5269575119018555,
          0.8292749524116516,
          -1.0575262308120728,
          -0.0654999241232872,
          1.641899824142456,
          -0.6927466988563538,
          -0.08681825548410416,
          0.49026960134506226,
          -0.540398120880127,
          -1.0443366765975952,
          0.8999890089035034,
          0.16330304741859436,
          -0.2719055116176605,
          -0.04557288810610771,
          0.7821115851402283,
          -0.5109195113182068,
          0.0658893957734108,
          0.14586062729358673,
          -0.6976377367973328,
          0.14925652742385864,
          -0.5823507905006409,
          -0.691530704498291,
          0.6149580478668213,
          -0.9252722859382629,
          0.5951124429702759,
          -0.2890245020389557,
          0.5893816351890564,
          0.3340207040309906,
          -0.341105580329895,
          -0.5668411254882812,
          -0.9083669185638428,
          -0.2567078173160553,
          0.09472382813692093,
          0.3010837137699127,
          0.40002644062042236,
          0.2407653033733368,
          0.9308476448059082,
          0.3879109025001526,
          0.23416554927825928,
          0.9339178800582886,
          0.1441553682088852,
          -0.18666484951972961,
          -0.504970371723175,
          0.32684627175331116,
          0.20772193372249603,
          -0.25952959060668945,
          0.8697537183761597,
          -0.25073081254959106,
          0.47639209032058716,
          -0.7352235913276672,
          0.6841118931770325,
          -0.13307711482048035,
          0.8373966813087463,
          -0.25272244215011597,
          0.41681355237960815,
          -0.18665136396884918,
          1.294426679611206,
          -0.4139612019062042,
          0.06729961931705475,
          0.6174732446670532,
          -1.2699785232543945,
          0.10103632509708405,
          1.4068573713302612,
          0.4906383156776428,
          -0.6384145021438599,
          -0.4526078999042511,
          0.6181596517562866,
          -0.27100640535354614,
          0.5438466668128967,
          -1.088368535041809,
          0.2746032476425171,
          0.738535463809967,
          0.64541095495224,
          -0.30104687809944153,
          0.2298232913017273,
          0.6432478427886963,
          -0.09720758348703384,
          -1.2101386785507202,
          0.05892378091812134,
          0.2829324007034302,
          0.08884288370609283,
          -0.8952118158340454,
          -0.2584689259529114,
          0.22087767720222473,
          -0.03283803164958954,
          -0.013324709609150887,
          -0.3425334692001343,
          0.6556308269500732,
          0.8847045302391052,
          -0.2577296793460846,
          0.7027373313903809,
          0.0626419186592102,
          0.6164171695709229,
          -0.4447959065437317,
          0.7677523493766785,
          0.8381744623184204,
          0.4803268313407898,
          1.3752405643463135,
          0.34182676672935486,
          0.5354338884353638,
          0.39193835854530334,
          -0.6163505911827087,
          0.011505715548992157,
          1.0198382139205933,
          0.6112527251243591,
          -0.19976095855236053,
          0.41121748089790344,
          -0.1472693532705307,
          0.03364947438240051,
          -0.05182108283042908,
          -0.266082227230072,
          -0.1726379692554474,
          -0.1297672539949417,
          0.000443924218416214,
          0.08421657234430313,
          -1.5146348476409912,
          -0.39324286580085754,
          0.4822462201118469,
          0.9274914264678955,
          0.008005382493138313,
          -0.9675519466400146,
          -0.8238123059272766,
          0.867582380771637,
          -0.03376426175236702,
          -0.5617656707763672,
          0.5332146883010864,
          0.18636614084243774,
          0.19332194328308105,
          0.8067227005958557,
          -0.08424187451601028,
          -0.3554476201534271,
          -0.5404865741729736,
          -1.4223600625991821,
          -1.5959315299987793,
          -0.017448686063289642,
          -0.027528613805770874,
          -0.27121829986572266,
          0.0179770365357399,
          -1.009303092956543,
          -1.0110182762145996,
          -0.7255048155784607,
          -0.2863578796386719,
          -0.002503950148820877,
          -0.38686150312423706,
          0.4711688160896301,
          -0.163944810628891,
          0.6435340046882629,
          -0.3975342810153961,
          0.9173505902290344,
          -0.03284289315342903,
          1.006087303161621,
          0.1835075467824936,
          0.07191132754087448,
          -0.4185951352119446,
          -0.4711992144584656,
          -0.004887968301773071,
          0.35625550150871277,
          -0.5176291465759277,
          0.3047622740268707,
          -0.5542460680007935,
          -0.30524688959121704,
          0.09426897764205933,
          0.07371223717927933,
          0.3238318860530853,
          -0.3062799572944641,
          -0.5779404640197754,
          0.35325315594673157,
          1.100562334060669,
          -0.3975290358066559,
          0.7795757055282593,
          0.2660253643989563,
          -0.5170673727989197,
          1.0478594303131104,
          0.020776133984327316,
          0.6749042272567749,
          -0.5818280577659607,
          1.228777289390564,
          0.7819703817367554,
          0.4076743721961975,
          -0.2659430503845215,
          -0.35590267181396484,
          -0.9381707906723022,
          -0.4148111939430237,
          0.14640802145004272,
          -0.1616351157426834,
          0.024180151522159576,
          0.5757825374603271,
          -0.886428952217102,
          -1.4179061651229858,
          -0.05183972418308258,
          0.05650337412953377,
          -1.4259426593780518,
          -0.14811566472053528,
          0.26554223895072937,
          0.3182588815689087,
          0.2902548909187317,
          0.46736836433410645,
          0.23324467241764069,
          -0.3078663647174835,
          0.030131839215755463,
          0.693794310092926,
          0.26401185989379883,
          -0.2416294813156128,
          -0.18566550314426422,
          0.4312319755554199,
          0.443109393119812,
          0.07289138436317444,
          0.3537978231906891,
          -0.15290957689285278,
          -0.23813694715499878,
          0.5533567667007446,
          0.4688195288181305,
          0.9814138412475586,
          0.3580362796783447,
          -0.4510430097579956,
          0.19839967787265778,
          -0.1706783026456833,
          -0.24458371102809906,
          0.5709398984909058,
          1.4247901439666748,
          -0.4693623185157776,
          0.4159250259399414,
          0.8481068015098572,
          0.10453464835882187,
          -0.2962391972541809,
          0.32194581627845764,
          -0.029325619339942932,
          -0.1499367356300354,
          -0.059216029942035675,
          0.542963981628418,
          -0.7347379922866821,
          0.3445075452327728,
          0.19685345888137817,
          0.08706939220428467,
          0.4573978781700134,
          -0.551510751247406,
          -1.6617412567138672,
          0.8214452266693115,
          0.15824571251869202,
          0.8640780448913574,
          -0.11545918881893158,
          -0.36788350343704224,
          0.10487481951713562,
          0.047575630247592926,
          0.34411653876304626,
          0.18436171114444733,
          1.0088034868240356,
          0.39900484681129456,
          -0.24449089169502258,
          -0.2661234438419342,
          0.15489038825035095,
          0.2688911557197571,
          0.1884303092956543,
          -0.35913652181625366,
          -0.2880464494228363,
          -0.45919811725616455,
          0.140969917178154,
          0.6055275797843933,
          0.7097553610801697,
          0.25690120458602905,
          -0.3112635016441345,
          -0.08378738164901733,
          -0.7723090648651123,
          0.42797887325286865,
          0.2697400152683258,
          0.4312150776386261,
          -0.25205597281455994,
          -0.9928854703903198,
          0.02138543501496315,
          0.44185149669647217,
          -0.19371210038661957,
          0.2835402190685272,
          0.34301912784576416,
          -0.5319405794143677,
          0.30930978059768677,
          0.6943221688270569,
          0.3891861140727997,
          -0.1568964272737503,
          0.1100025326013565,
          0.750926673412323,
          0.40426644682884216,
          0.23230668902397156,
          -0.3613629639148712,
          -0.4035985767841339,
          0.19046582281589508,
          -0.24684248864650726,
          -0.8043262958526611,
          0.3011745810508728,
          -0.7134445309638977,
          0.07060649991035461,
          0.4564827084541321,
          -0.5867161750793457,
          -1.2376347780227661,
          -0.12703564763069153,
          -0.11406417936086655,
          -1.0174275636672974,
          0.6658654808998108,
          0.47996047139167786,
          -0.30152633786201477,
          0.5079255104064941,
          -0.5671334862709045,
          0.07876911014318466,
          0.26897913217544556,
          0.33233803510665894,
          0.415009468793869,
          0.28494831919670105,
          -0.6216227412223816,
          -0.36560726165771484,
          0.5985226035118103,
          0.26202455163002014,
          -0.5579023957252502,
          -0.022593246772885323,
          -0.6599053144454956,
          0.4294349253177643,
          -0.4694859981536865,
          -0.34167996048927307,
          -0.36221665143966675,
          0.18652307987213135,
          -0.17661412060260773,
          0.09969710558652878,
          0.4474431872367859,
          0.19350787997245789,
          -0.2977367639541626,
          0.15436647832393646,
          -0.4495369791984558,
          -0.39359593391418457,
          0.6375665068626404,
          -0.08755375444889069,
          -0.30015283823013306,
          0.08344629406929016,
          0.6015979647636414,
          -0.17064732313156128,
          -0.20314732193946838,
          0.3109229803085327,
          -0.6887943148612976,
          0.5627254843711853,
          0.7499198317527771,
          0.9572509527206421,
          -0.3205787241458893,
          -0.1301266998052597,
          -0.5374974012374878,
          -0.5023385286331177,
          0.1956881582736969,
          -0.2548765540122986,
          0.021108996123075485,
          -0.5286687612533569,
          -0.873278021812439,
          -0.7059412598609924,
          0.6245348453521729,
          -0.5489935278892517,
          -0.011378340423107147,
          -0.05478629469871521,
          -0.5787424445152283,
          0.27310335636138916,
          -0.030553650110960007,
          -0.60560542345047,
          -0.289978563785553,
          -0.9234248399734497,
          0.5370095372200012,
          0.38122403621673584,
          0.5710121393203735,
          0.4704643785953522,
          -0.6081139445304871,
          -1.2417750358581543,
          0.4595302939414978,
          -0.1654628962278366,
          -0.1532110869884491,
          -0.7390568852424622,
          -0.8127148151397705,
          -0.31297042965888977,
          -0.12293273955583572,
          -0.6827273964881897,
          -0.09484855830669403,
          -0.3301223814487457,
          0.23609969019889832,
          0.3877168297767639,
          -0.1709710955619812,
          -0.2761925756931305,
          -0.5639522671699524,
          0.043298691511154175,
          0.6447151303291321,
          0.2845045030117035,
          -0.9582012295722961,
          -0.8973568081855774,
          0.5413292050361633,
          -0.38514745235443115,
          0.2679884731769562,
          1.0344539880752563,
          -0.13402651250362396,
          -0.28353801369667053,
          -0.8592835068702698,
          0.5709570646286011,
          -0.6709911227226257,
          0.09350068122148514,
          -0.871979296207428,
          -0.07613823562860489,
          0.026251286268234253,
          0.18653428554534912,
          0.8262903094291687,
          -0.3200468122959137,
          0.3745891749858856,
          0.15703120827674866,
          0.9149203896522522,
          -0.855887770652771,
          -0.34586381912231445,
          -0.6277949810028076,
          -0.1933712661266327,
          0.020653173327445984,
          1.2478166818618774,
          -0.20769287645816803,
          0.38217693567276,
          -0.6704055666923523,
          -0.22517605125904083,
          0.15041598677635193,
          1.220415472984314,
          -0.8882614970207214,
          -0.0044658854603767395,
          0.06526174396276474,
          -0.9898440837860107,
          0.6202412843704224,
          -0.07330580055713654,
          -0.28144219517707825,
          0.3735883831977844,
          -0.6962990164756775,
          -0.5573415756225586,
          -1.4505796432495117,
          -0.0498071163892746,
          -0.5682260394096375,
          -0.5752202272415161,
          0.28592991828918457,
          -0.5754497647285461,
          0.3633183538913727,
          -0.28776365518569946,
          0.49821603298187256,
          0.07726117968559265,
          0.6262343525886536,
          -0.6995370388031006,
          -0.22090651094913483,
          -0.5819898843765259,
          -0.6201944947242737,
          0.09938375651836395,
          -1.099607229232788,
          -0.09532512724399567,
          0.3626851439476013,
          0.31627780199050903,
          0.47165465354919434,
          -0.49207088351249695,
          0.17260673642158508,
          0.6793614625930786,
          0.23523586988449097,
          0.2263859212398529,
          -0.9454680681228638,
          0.15336203575134277,
          0.11572818458080292,
          0.015922605991363525,
          -0.23427392542362213,
          -0.26337680220603943,
          -0.6894765496253967,
          -0.35781484842300415,
          -0.6974142789840698,
          -0.6502751708030701,
          0.22766801714897156,
          0.12500405311584473,
          1.4901247024536133,
          -0.22948701679706573,
          0.6966530084609985,
          0.08546468615531921,
          -0.15465161204338074,
          -0.9031393527984619,
          0.5683948397636414,
          0.08621963113546371,
          0.7359112501144409,
          1.1065667867660522,
          0.2051624059677124,
          -0.3466411530971527,
          0.0552341490983963,
          -0.5866519212722778,
          -0.5765870213508606,
          0.06449615955352783,
          0.829516589641571,
          0.20991262793540955,
          -0.5435840487480164,
          0.5799317955970764,
          0.22094380855560303,
          0.0731913298368454,
          -0.05235447734594345,
          -0.3493707478046417,
          -0.6327745318412781,
          -0.8058854341506958,
          -1.0175809860229492,
          -0.20015275478363037,
          0.0856538861989975,
          -0.07269259542226791,
          -0.5860375761985779,
          0.5766381025314331,
          -0.17512916028499603,
          0.17234556376934052,
          0.4823872447013855,
          -0.5179861783981323,
          -0.8670347929000854,
          0.3324211835861206,
          0.4020808935165405,
          -0.03011755459010601,
          0.2537074685096741,
          -0.6783281564712524,
          0.09369481354951859,
          -0.4952758550643921,
          0.23862794041633606,
          0.2572540044784546,
          -0.47220468521118164,
          -0.3017098903656006,
          0.4347374737262726,
          0.624394416809082,
          0.8163748383522034,
          -0.9507784843444824,
          -0.028097819536924362,
          0.5039684176445007,
          -0.8434097766876221,
          0.1938450187444687,
          0.2703612744808197,
          0.2693997919559479,
          -0.23790735006332397,
          0.9964178800582886,
          -0.3871736228466034,
          -0.11633997410535812,
          1.008674144744873,
          0.9825137853622437,
          -0.26285725831985474,
          -1.1314488649368286,
          -0.18918199837207794,
          -0.7109436392784119,
          -0.2711392641067505,
          -0.2826496958732605,
          -0.5663103461265564,
          0.135120689868927,
          1.0242762565612793,
          -0.032547906041145325,
          -0.3498475253582001,
          -0.6818452477455139,
          1.1556321382522583,
          -0.9619923830032349,
          -0.08485904335975647,
          -0.39429450035095215,
          0.40096500515937805,
          -0.32914066314697266,
          0.48922932147979736,
          0.3096907436847687,
          -0.3539477586746216,
          -0.5037010312080383,
          0.38841569423675537,
          -0.21099403500556946,
          0.7871953248977661,
          -0.391887903213501,
          0.6379649043083191,
          -0.20368202030658722,
          -0.42859360575675964,
          -0.4366351366043091,
          0.1679324209690094,
          -0.5342387557029724,
          0.5247019529342651,
          -0.2792664170265198,
          -0.35741347074508667,
          -0.11195293068885803,
          -0.33095797896385193,
          -0.04147076606750488,
          0.24145716428756714,
          0.052633993327617645,
          -0.46848803758621216,
          -0.0853707566857338,
          0.5356473326683044,
          0.2898293733596802,
          0.04184704273939133,
          -0.16049326956272125,
          0.4604833126068115,
          -0.6485446691513062,
          -0.2968110740184784,
          -0.4964748024940491,
          -0.10365867614746094,
          -0.7844402194023132,
          1.068931221961975,
          0.9379131197929382,
          1.8468397855758667,
          0.8947561383247375,
          0.4510413408279419,
          0.1289805918931961,
          0.32067883014678955,
          0.7665181756019592,
          0.4294898808002472,
          0.27051088213920593,
          -0.13481050729751587,
          -0.259716659784317,
          -1.164345622062683,
          0.2784525752067566,
          0.7740188837051392,
          -0.48279261589050293,
          0.17017754912376404,
          -0.23858597874641418,
          0.5552057027816772,
          -0.7114368081092834,
          0.2989952266216278,
          0.11663998663425446,
          0.0499943271279335,
          0.5338997840881348,
          0.6117855310440063,
          -0.24826723337173462,
          -0.20631110668182373,
          0.12969644367694855,
          -0.1235383003950119,
          -1.2802996635437012,
          -0.5913804173469543,
          0.5702646970748901,
          -0.4969743490219116,
          0.4645482301712036,
          -0.010544195771217346,
          -0.3902651071548462,
          -0.023663969710469246,
          0.6536703705787659,
          0.06364502012729645,
          -0.6649456024169922,
          0.48161447048187256,
          -0.37706902623176575,
          0.030585333704948425,
          -0.739883542060852,
          -0.2205168604850769,
          -0.04989871382713318,
          -0.4678304195404053,
          -0.9642361402511597,
          -1.1315529346466064,
          0.16072461009025574,
          0.382367342710495,
          0.38758769631385803,
          -0.4782555103302002,
          -0.9231792092323303,
          0.4744539260864258,
          -0.4467456638813019,
          -0.036906275898218155,
          -0.9455162882804871,
          0.49499237537384033,
          -0.11204913258552551,
          0.0714065283536911,
          -0.1931312382221222,
          0.5436774492263794,
          -0.4891170561313629,
          0.5666942000389099,
          0.04753418639302254,
          0.4181777536869049,
          -0.14144963026046753,
          0.6773594617843628,
          0.16674929857254028,
          -0.12867845594882965,
          0.9010087251663208,
          -0.12661471962928772,
          -0.22594203054904938,
          -0.22124697268009186,
          -0.021910931915044785,
          0.2612627446651459,
          0.6745869517326355,
          0.33663561940193176,
          -0.16786815226078033,
          -1.1828430891036987,
          0.5751323699951172,
          0.027373306453227997,
          -0.8518730401992798,
          -0.11137495189905167,
          1.1494570970535278,
          0.26468324661254883,
          -0.12928512692451477,
          -0.5486013889312744,
          -0.9854496717453003,
          0.24241821467876434,
          -0.7686022520065308,
          0.09145680069923401,
          -0.43186795711517334,
          -0.14568492770195007,
          -0.566588282585144,
          0.22851520776748657,
          -0.7505552768707275,
          0.6775381565093994,
          0.04743608832359314,
          -0.6806329488754272,
          -0.4981571435928345,
          0.12910868227481842,
          0.07466895878314972,
          0.45079633593559265,
          0.1498328447341919,
          -0.5037630796432495,
          0.17857691645622253,
          0.3004962205886841,
          0.5353312492370605,
          0.5545241832733154,
          0.1354997158050537,
          0.45422837138175964,
          0.4902043342590332,
          -0.15117937326431274,
          0.325182169675827,
          0.04196462035179138,
          -0.23928552865982056,
          -0.30879098176956177,
          -0.183750718832016,
          0.6843040585517883,
          0.21040429174900055,
          -0.5010986924171448,
          0.2427346408367157,
          -0.10879352688789368,
          -0.7119385004043579,
          -0.8148065209388733,
          -0.025177370756864548,
          -1.0942139625549316,
          0.1770901381969452,
          0.5518171787261963,
          0.01549344789236784,
          -0.24435141682624817,
          0.05369977280497551,
          -0.013816110789775848,
          0.7000464797019958,
          -0.05619725584983826,
          -0.010272391140460968,
          -0.47335386276245117,
          0.586400032043457,
          0.794621467590332,
          0.11992993950843811,
          0.13299834728240967,
          0.2339451014995575,
          0.6584492921829224,
          0.4810982048511505,
          0.7366766333580017,
          -1.142608880996704,
          -0.26935556530952454,
          -0.8095813393592834,
          -0.7229251861572266,
          0.4031491279602051,
          0.10731588304042816,
          0.03617800772190094,
          -0.34186699986457825,
          -0.1754423826932907,
          0.08098465949296951,
          -0.35013386607170105,
          -0.004928365349769592,
          1.3640551567077637,
          -0.4117593765258789,
          0.10200250893831253,
          0.12713706493377686,
          0.31508514285087585,
          -0.16920635104179382,
          -0.017342817038297653,
          -0.8545175194740295,
          0.4548121392726898,
          -0.21233534812927246,
          -1.2736201286315918,
          -0.2805674076080322,
          -0.684073269367218,
          0.24375054240226746,
          -0.4868246912956238,
          0.47974807024002075,
          0.029204372316598892,
          0.6795548796653748,
          0.3569692075252533,
          0.5567076802253723,
          -0.7581110000610352,
          -0.6674553155899048,
          0.123772032558918,
          1.1039538383483887,
          0.5591873526573181,
          0.4662025570869446,
          1.2552696466445923,
          0.35831165313720703,
          0.29640814661979675,
          -0.21841181814670563,
          -0.09724695980548859,
          0.26536765694618225,
          -0.05041097477078438,
          -0.6379954814910889,
          -0.7189701199531555,
          0.18341408669948578,
          -0.39793166518211365,
          -0.5116385817527771,
          0.1720818430185318,
          0.6929911375045776,
          0.19988605380058289,
          -0.4144870638847351,
          -0.836078405380249,
          0.9217619895935059,
          -0.24048742651939392,
          -0.29845041036605835,
          -0.4252435266971588,
          0.9087033271789551,
          -0.126654252409935,
          -0.48193106055259705,
          -0.651875913143158,
          -0.8518053293228149,
          3.7927088737487793,
          0.9718778133392334,
          0.46165600419044495,
          0.12439330667257309,
          0.31803128123283386,
          0.9261002540588379,
          1.330230474472046,
          0.18495136499404907,
          0.6799605488777161,
          -0.02918495237827301,
          0.3781059980392456,
          0.3015229105949402,
          0.034034304320812225,
          -0.14549395442008972,
          0.2257765382528305,
          -0.37806808948516846,
          -1.0552161931991577,
          0.15624605119228363,
          -0.7577230334281921,
          -0.06517218798398972,
          0.15959008038043976,
          0.38167083263397217,
          -0.2830689549446106,
          0.48150530457496643,
          0.35318711400032043,
          -1.0713417530059814,
          -0.47354650497436523,
          -0.34674912691116333,
          0.6312457323074341,
          -0.24160701036453247,
          0.4474349319934845,
          -0.11934429407119751,
          0.797850489616394,
          -0.2645750045776367,
          -0.1073254644870758,
          0.5791398286819458,
          0.0983031839132309,
          -1.5054463148117065,
          0.1399352252483368,
          0.06894861906766891,
          -0.7196871638298035,
          -0.764329195022583,
          -0.29615238308906555,
          0.5813437104225159,
          -0.21381144225597382,
          0.5479562282562256,
          0.26477915048599243,
          0.7276458740234375,
          0.6818445920944214,
          -0.9705095887184143,
          0.5281003713607788,
          -0.6129931807518005,
          0.34126147627830505,
          -0.4666995704174042,
          -0.7573015093803406,
          -0.49258795380592346,
          -0.6877830624580383,
          -0.9543663859367371,
          -0.46603143215179443,
          0.5564016699790955,
          -0.043940089643001556,
          -0.11864091455936432,
          -0.17483395338058472,
          1.0121015310287476,
          0.285973459482193,
          0.36728399991989136,
          0.5127577781677246,
          -0.9131791591644287,
          -0.8926557302474976,
          -0.041392333805561066,
          0.3123285174369812,
          -0.2652081251144409,
          -0.5749748945236206,
          -0.6380753517150879,
          0.18934239447116852,
          -0.3862329423427582,
          -0.44149208068847656,
          0.8146873712539673,
          -0.04349439591169357,
          -0.6504190564155579,
          -0.5506468415260315,
          -0.6413045525550842,
          -0.6462486386299133,
          0.17824570834636688,
          -0.12051866948604584,
          0.5573299527168274,
          -0.4878310561180115,
          1.2353229522705078,
          -0.24769602715969086,
          1.062687635421753,
          0.24824894964694977,
          0.8148683309555054,
          -0.0395657904446125,
          0.4620581269264221,
          0.5194827318191528
        ]
      },
      "type": "document"
    },
    {
      "id": "cebcfccc-06e1-4417-af00-157d82513ca4",
      "properties": {
        "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 Models\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 Generator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 Training\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
        "document_metadata": {
          "page_label": "3",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Models",
          "Retriever: DPR",
          "Generator: BART",
          "Training"
        ]
      },
      "type": "document"
    },
    {
      "id": "b4df9f44-7f56-49b9-b23d-2e8f148fbc1e",
      "properties": {
        "page_content": "minimize the negative marginal log-likelihood of each target, ∑\nj−log p(yj|xj) using stochastic\ngradient descent with Adam [28]. Updating the document encoder BERTd during training is costly as\nit requires the document index to be periodically updated as REALM does during pre-training [20].\nWe do not ﬁnd this step necessary for strong performance, and keep the document encoder (and\nindex) ﬁxed, only ﬁne-tuning the query encoder BERTq and the BART generator.\n2.5 Decoding\nAt test time, RAG-Sequence and RAG-Token require different ways to approximatearg maxyp(y|x).\nRAG-Token The RAG-Token model can be seen as a standard, autoregressive seq2seq genera-\ntor with transition probability: p′\nθ(yi|x,y1:i−1) = ∑\nz∈top-k(p(·|x)) pη(zi|x)pθ(yi|x,zi,y1:i−1) To\ndecode, we can plug p′\nθ(yi|x,y1:i−1) into a standard beam decoder.\nRAG-Sequence For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-\ntoken likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for\neach document z, scoring each hypothesis using pθ(yi|x,z,y 1:i−1). This yields a set of hypotheses\nY, some of which may not have appeared in the beams of all documents. To estimate the probability\nof an hypothesis y we run an additional forward pass for each document z for which y does not\nappear in the beam, multiply generator probability with pη(z|x) and then sum the probabilities across\nbeams for the marginals. We refer to this decoding procedure as “Thorough Decoding.” For longer\noutput sequences, |Y|can become large, requiring many forward passes. For more efﬁcient decoding,\nwe can make a further approximation that pθ(y|x,zi) ≈0 where ywas not generated during beam\nsearch from x,zi. This avoids the need to run additional forward passes once the candidate set Y has\nbeen generated. We refer to this decoding procedure as “Fast Decoding.”\n3 Experiments\nWe experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use\na single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and\nKarpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint\n100-word chunks, to make a total of 21M documents. We use the document encoder to compute an\nembedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical\nNavigable Small World approximation for fast retrieval [37]. During training, we retrieve the top\nkdocuments for each query. We consider k∈{5,10}for training and set kfor test time using dev\ndata. We now discuss experimental details for each task.\n3.1 Open-domain Question Answering\nOpen-domain question answering (QA) is an important real-world application and common testbed\nfor knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x,y)\nand train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to\nthe popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved\ndocuments, relying primarily on non-parametric knowledge. We also compare to “Closed-Book\nQA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead\nrelying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural\nQuestions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As\nCT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG\nmodel. We use the same train/dev/test splits as prior work [ 31, 26] and report Exact Match (EM)\nscores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.\n3.2 Abstractive Question Answering\nRAG models can go beyond simple extractive QA and answer questions with free-form, abstractive\ntext generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting,\nwe use the MSMARCO NLG task v2.1 [ 43]. The task consists of questions, ten gold passages\nretrieved from a search engine for each question, and a full sentence answer annotated from the\nretrieved passages. We do not use the supplied passages, only the questions and answers, to treat\n4",
        "document_metadata": {
          "page_label": "4",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "d7c2d5b6-86f0-4932-b4c7-a9dc846a8ba8",
      "properties": {
        "page_content": "MSMARCO as an open-domain abstractive QA task. MSMARCO has some questions that cannot be\nanswered in a way that matches the reference answer without access to the gold passages, such as\n“What is the weather in V olcano, CA?” so performance will be lower without using gold passages.\nWe also note that some MSMARCO questions cannot be answered using Wikipedia alone. Here,\nRAG can rely on parametric knowledge to generate reasonable responses.\n3.3 Jeopardy Question Generation\nTo evaluate RAG’s generation abilities in a non-QA setting, we study open-domain question gen-\neration. Rather than use questions from standard open-domain QA tasks, which typically consist\nof short, simple questions, we propose the more demanding task of generating Jeopardy questions.\nJeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity.\nFor example, “The World Cup” is the answer to the question “In 1986 Mexico scored as the ﬁrst\ncountry to host this international sports competition twice.” As Jeopardy questions are precise,\nfactual statements, generating Jeopardy questions conditioned on their answer entities constitutes a\nchallenging knowledge-intensive generation task.\nWe use the splits from SearchQA [ 10], with 100K train, 14K dev, and 27K test examples. As\nthis is a new task, we train a BART model for comparison. Following [67], we evaluate using the\nSQuAD-tuned Q-BLEU-1 metric [ 42]. Q-BLEU is a variant of BLEU with a higher weight for\nmatching entities and has higher correlation with human judgment for question generation than\nstandard metrics. We also perform two human evaluations, one to assess generation factuality, and\none for speciﬁcity. We deﬁne factuality as whether a statement can be corroborated by trusted external\nsources, and speciﬁcity as high mutual dependence between the input and output [ 33]. We follow\nbest practice and use pairwise comparative evaluation [34]. Evaluators are shown an answer and two\ngenerated questions, one from BART and one from RAG. They are then asked to pick one of four\noptions—quuestion A is better, question B is better, both are good, or neither is good.\n3.4 Fact Veriﬁcation\nFEVER [ 56] requires classifying whether a natural language claim is supported or refuted by\nWikipedia, or whether there is not enough information to decide. The task requires retrieving\nevidence from Wikipedia relating to the claim and then reasoning over this evidence to classify\nwhether the claim is true, false, or unveriﬁable from Wikipedia alone. FEVER is a retrieval problem\ncoupled with an challenging entailment reasoning task. It also provides an appropriate testbed for\nexploring the RAG models’ ability to handle classiﬁcation rather than generation. We map FEVER\nclass labels (supports, refutes, or not enough info) to single output tokens and directly train with\nclaim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on\nretrieved evidence. In many real-world applications, retrieval supervision signals aren’t available, and\nmodels that do not require such supervision will be applicable to a wider range of tasks. We explore\ntwo variants: the standard 3-way classiﬁcation task (supports/refutes/not enough info) and the 2-way\n(supports/refutes) task studied in Thorne and Vlachos [57]. In both cases we report label accuracy.\n4 Results\n4.1 Open-domain Question Answering\nTable 1 shows results for RAG along with state-of-the-art models. On all four open-domain QA\ntasks, RAG sets a new state of the art (only on the T5-comparable split for TQA). RAG combines\nthe generation ﬂexibility of the “closed-book” (parametric only) approaches and the performance of\n\"open-book\" retrieval-based approaches. Unlike REALM and T5+SSM, RAG enjoys strong results\nwithout expensive, specialized “salient span masking” pre-training [20]. It is worth noting that RAG’s\nretriever is initialized using DPR’s retriever, which uses retrieval supervision on Natural Questions\nand TriviaQA. RAG compares favourably to the DPR QA system, which uses a BERT-based “cross-\nencoder” to re-rank documents, along with an extractive reader. RAG demonstrates that neither a\nre-ranker nor extractive reader is necessary for state-of-the-art performance.\nThere are several advantages to generating answers even when it is possible to extract them. Docu-\nments with clues about the answer but do not contain the answer verbatim can still contribute towards\na correct answer being generated, which is not possible with standard extractive approaches, leading\n5",
        "document_metadata": {
          "page_label": "5",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "1bddec6b-f44d-4d6e-9351-c9792f6f933d",
      "properties": {
        "page_content": "Table 1: Open-Domain QA Test Scores. For TQA,\nleft column uses the standard test set for Open-\nDomain QA, right column uses the TQA-Wiki\ntest set. See Appendix D for further details.\nModel NQ TQA WQ CT\nClosed\nBook\nT5-11B [52] 34.5 - /50.1 37.4 -\nT5-11B+SSM[52] 36.6 - /60.5 44.7 -\nOpen\nBook\nREALM [20] 40.4 - / - 40.7 46.8\nDPR [26] 41.5 57.9/ - 41.1 50.6\nRAG-Token 44.1 55.2/66.1 45.5 50.0\nRAG-Seq. 44.5 56.8/68.0 45.2 52.2\nTable 2: Generation and classiﬁcation Test Scores.\nMS-MARCO SotA is [4], FEVER-3 is [68] and\nFEVER-2 is [ 57] *Uses gold context/evidence.\nBest model without gold access underlined.\nModel Jeopardy MSMARCO FVR3 FVR2\nB-1 QB-1 R-L B-1 Label Acc.\nSotA - - 49.8* 49.9* 76.8 92.2 *\nBART 15.1 19.7 38.2 41.6 64.0 81.1\nRAG-Tok. 17.3 22.2 40.1 41.5 72.5 89.5RAG-Seq. 14.7 21.4 40.8 44.2\nto more effective marginalization over documents. Furthermore, RAG can generate correct answers\neven when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such\ncases for NQ, where an extractive model would score 0%.\n4.2 Abstractive Question Answering\nAs shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu\npoints and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is\nimpressive given that (i) those models access gold passages with speciﬁc information required to\ngenerate the reference answer , (ii) many questions are unanswerable without the gold passages, and\n(iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers\nfrom our models. Qualitatively, we ﬁnd that RAG models hallucinate less and generate factually\ncorrect text more often than BART. Later, we also show that RAG generations are more diverse than\nBART generations (see §4.5).\n4.3 Jeopardy Question Generation\nTable 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation,\nwith both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452\npairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual\nthan RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and\nBART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on\nthe task over a state-of-the-art generation model. Evaluators also ﬁnd RAG generations to be more\nspeciﬁc by a large margin. Table 3 shows typical generations from each model.\nJeopardy questions often contain two separate pieces of information, and RAG-Token may perform\nbest because it can generate responses that combine content from several documents. Figure 2 shows\nan example. When generating “Sun”, the posterior is high for document 2 which mentions “The\nSun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is\ngenerated. Intriguingly, after the ﬁrst token of each book is generated, the document posterior ﬂattens.\nThis observation suggests that the generator can complete the titles without depending on speciﬁc\ndocuments. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We\nﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding\"The\nSun. BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun\nAlso Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly,\nBART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A\nwith \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\". This example shows\nhow parametric and non-parametric memories work together—the non-parametric component helps\nto guide the generation, drawing out speciﬁc knowledge stored in the parametric memory.\n4.4 Fact Veriﬁcation\nTable 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of\nstate-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and\nsubstantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\n6",
        "document_metadata": {
          "page_label": "6",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "summary": "Artificial intelligence is transforming various industries by automating tasks. AI analyzes data quickly and accurately, driving innovations in areas like self-driving cars and personalized recommendations.",
        "summary_embedding": [
          -0.0033709965646266937,
          0.7643808722496033,
          -0.4307177662849426,
          -0.852218508720398,
          -0.10415328294038773,
          0.0685122013092041,
          0.08623036742210388,
          -0.07440581172704697,
          0.6017941236495972,
          0.5305898785591125,
          0.06893309205770493,
          0.2835967540740967,
          -0.5573556423187256,
          -1.0007615089416504,
          0.2758815586566925,
          -0.5125831365585327,
          0.11791038513183594,
          -0.0224732868373394,
          0.3032207489013672,
          -0.17108914256095886,
          -0.09723593294620514,
          0.6989084482192993,
          -0.5078181028366089,
          -0.9845340847969055,
          -0.9858464598655701,
          0.5519775748252869,
          0.6958093047142029,
          -0.768258273601532,
          0.7167258858680725,
          0.6332435607910156,
          -0.41804778575897217,
          0.050154805183410645,
          0.13344871997833252,
          -0.5144307613372803,
          -0.5648650527000427,
          -0.13190492987632751,
          0.3596702516078949,
          -0.3305966854095459,
          -1.0023224353790283,
          -0.48911160230636597,
          0.15483605861663818,
          0.13998480141162872,
          0.14125525951385498,
          -1.0657737255096436,
          -0.9407073259353638,
          0.48352503776550293,
          0.4237760007381439,
          -1.2383874654769897,
          -0.014684871770441532,
          -0.13265973329544067,
          -0.6181780695915222,
          0.14998723566532135,
          -0.14639891684055328,
          -0.32221779227256775,
          0.015546728856861591,
          -1.0569382905960083,
          -0.31028658151626587,
          -0.3483668267726898,
          -0.5676734447479248,
          -0.024241358041763306,
          1.2547348737716675,
          -0.33836355805397034,
          0.4874292016029358,
          0.051454998552799225,
          0.17064137756824493,
          0.4826734662055969,
          -0.12953336536884308,
          -0.7544170618057251,
          -0.41616469621658325,
          0.16241875290870667,
          -1.0421977043151855,
          -0.3482011556625366,
          0.2452799379825592,
          0.25165754556655884,
          -0.44785216450691223,
          -0.03824644535779953,
          0.3081938326358795,
          -0.1099531427025795,
          -0.9312204718589783,
          -0.2222130298614502,
          -0.4499593675136566,
          0.7884374260902405,
          -0.2759636640548706,
          1.002314567565918,
          0.06546974927186966,
          -0.6193936467170715,
          0.5776747465133667,
          0.8774828314781189,
          -0.22918736934661865,
          -0.5434805750846863,
          -0.2278142273426056,
          0.056209102272987366,
          -0.06257516145706177,
          -0.03547103330492973,
          0.20908406376838684,
          0.7620674967765808,
          -0.7055591344833374,
          0.8071275353431702,
          0.19501309096813202,
          -0.011903982609510422,
          0.5316839814186096,
          1.0835318565368652,
          -0.03107803873717785,
          0.9649612903594971,
          -0.7981842160224915,
          0.03065723180770874,
          0.5350054502487183,
          -0.7630518078804016,
          -0.012659162282943726,
          -0.8977363109588623,
          0.5954545736312866,
          0.1049153208732605,
          -0.11376085877418518,
          0.251620888710022,
          -0.2558760344982147,
          1.3872414827346802,
          -0.28840163350105286,
          0.1795811802148819,
          -0.38360270857810974,
          0.2652021050453186,
          -0.25918734073638916,
          -0.48748689889907837,
          0.2904888093471527,
          -0.31306150555610657,
          0.1826987862586975,
          -1.1780589818954468,
          -0.02872016280889511,
          0.7253391742706299,
          -0.624438464641571,
          0.8118951320648193,
          -0.1689356416463852,
          0.16540959477424622,
          -0.11504943668842316,
          0.6602291464805603,
          -0.05333413928747177,
          -0.7828757166862488,
          0.021842367947101593,
          0.9362214803695679,
          -0.2800266146659851,
          0.7272681593894958,
          0.06436476111412048,
          0.030649704858660698,
          -0.1342698335647583,
          1.6521384716033936,
          -0.2991746962070465,
          -0.2933623194694519,
          -0.2100171148777008,
          0.10100695490837097,
          -0.464089572429657,
          0.8557481169700623,
          -1.0238345861434937,
          0.3853173553943634,
          0.34094691276550293,
          -0.15397080779075623,
          -0.5286007523536682,
          -0.8808781504631042,
          -0.697976291179657,
          -0.0813814252614975,
          0.5188480615615845,
          0.6295152902603149,
          -0.4038171172142029,
          0.009600747376680374,
          -0.1286740005016327,
          1.2178714275360107,
          -0.43529629707336426,
          0.7838952541351318,
          -0.9973812103271484,
          0.12581294775009155,
          -0.36451244354248047,
          -0.26588207483291626,
          0.43380478024482727,
          -0.7030292749404907,
          -0.5848766565322876,
          0.038391828536987305,
          0.9116736054420471,
          1.011136770248413,
          0.7995487451553345,
          -0.03246266394853592,
          0.18449367582798004,
          -0.29632145166397095,
          -1.1248912811279297,
          -0.3374449610710144,
          -0.6978825926780701,
          -0.10121110081672668,
          0.3512216806411743,
          0.5857329964637756,
          0.21928948163986206,
          0.224288210272789,
          0.5469323396682739,
          -0.4595412015914917,
          0.3731176555156708,
          0.7765247821807861,
          -1.0340778827667236,
          0.055197861045598984,
          -0.06778284907341003,
          0.4414997100830078,
          -0.6951891183853149,
          0.5361623764038086,
          0.28719550371170044,
          0.040759794414043427,
          -0.22889788448810577,
          0.5308629274368286,
          0.024140994995832443,
          -0.5633692741394043,
          -0.9870584607124329,
          0.5993420481681824,
          -0.2912209928035736,
          1.1993486881256104,
          -1.6245293617248535,
          1.259501576423645,
          0.6377584934234619,
          0.23813816905021667,
          -0.149057999253273,
          -0.4294854700565338,
          0.7940109968185425,
          0.11859677731990814,
          -0.24150565266609192,
          0.4115622937679291,
          0.21333129703998566,
          -0.4509846568107605,
          0.07810672372579575,
          -0.35952579975128174,
          0.39570340514183044,
          -0.5506486296653748,
          -0.41928157210350037,
          -0.16631922125816345,
          -0.24887847900390625,
          0.9191075563430786,
          -0.044006720185279846,
          0.2510354220867157,
          0.8040218353271484,
          0.7730847597122192,
          -0.35301604866981506,
          0.7666432857513428,
          -0.09911258518695831,
          0.20084838569164276,
          -0.40057921409606934,
          0.525991678237915,
          -0.2300729900598526,
          -0.1793314814567566,
          0.9397839307785034,
          0.12531277537345886,
          1.3110538721084595,
          0.4915844798088074,
          -0.5931249260902405,
          0.05879657715559006,
          0.11690733581781387,
          -0.08466233313083649,
          0.6117026805877686,
          0.8751910328865051,
          -0.7762245535850525,
          0.22473686933517456,
          0.18269868195056915,
          -0.22918888926506042,
          -0.28627318143844604,
          0.3813851773738861,
          0.8703374266624451,
          0.471902996301651,
          0.36518028378486633,
          -1.3109585046768188,
          -0.9432248473167419,
          0.7568231821060181,
          0.5775321125984192,
          -0.10628710687160492,
          0.4654673933982849,
          0.47611576318740845,
          -0.057878267019987106,
          0.042237427085638046,
          -0.8836337924003601,
          -0.2987182140350342,
          -1.2409330606460571,
          -1.180815577507019,
          -0.3897973299026489,
          -0.2652444839477539,
          -0.9339601397514343,
          -0.12261303514242172,
          0.016369841992855072,
          -0.8065477609634399,
          0.8069004416465759,
          -0.14544719457626343,
          -0.3153896629810333,
          -0.44683533906936646,
          -0.8513064384460449,
          0.6535044312477112,
          0.84038245677948,
          0.669815182685852,
          -1.1872321367263794,
          0.04511668533086777,
          -0.5378910303115845,
          0.8278838992118835,
          0.6759163737297058,
          0.34789156913757324,
          -0.2395447939634323,
          -0.5102114677429199,
          0.13542784750461578,
          -0.38823357224464417,
          0.9654724597930908,
          0.22246746718883514,
          -0.8821517825126648,
          -0.504508376121521,
          -0.01862344518303871,
          -0.007016118615865707,
          -0.6540858149528503,
          0.042335353791713715,
          0.026642141863703728,
          0.6465350389480591,
          0.21934784948825836,
          0.10173316299915314,
          0.9029935002326965,
          0.08467890322208405,
          -1.1005548238754272,
          0.261690616607666,
          -0.21060307323932648,
          0.7553063631057739,
          -0.5526247620582581,
          0.7527046203613281,
          0.42858555912971497,
          -0.9371541738510132,
          0.2598262429237366,
          -1.2807859182357788,
          -0.3178726136684418,
          0.13800561428070068,
          -0.5909164547920227,
          0.684872567653656,
          0.23777639865875244,
          0.4535987973213196,
          -0.04628781974315643,
          -1.8391200304031372,
          0.08146893233060837,
          -0.17702525854110718,
          -0.20895910263061523,
          -0.019721899181604385,
          0.2472567856311798,
          0.7563285827636719,
          0.9221444129943848,
          -0.4521021544933319,
          -0.06718941032886505,
          0.1936764419078827,
          -0.2671750485897064,
          0.9229550957679749,
          0.5404876470565796,
          -0.3177478313446045,
          0.5062013864517212,
          0.3872968256473541,
          -0.4955478608608246,
          0.5857774615287781,
          1.2957026958465576,
          -0.254823237657547,
          0.6076428294181824,
          -0.14110545814037323,
          -0.11472882330417633,
          -0.025066006928682327,
          -0.41627055406570435,
          -0.31059956550598145,
          0.4795602858066559,
          -0.06318686902523041,
          -0.5026215314865112,
          0.6277416348457336,
          -0.2356339991092682,
          0.16233797371387482,
          0.7878351807594299,
          0.3895772099494934,
          -0.32625535130500793,
          0.3126499652862549,
          -0.4943455457687378,
          0.2104206383228302,
          -0.08159744739532471,
          0.2731885015964508,
          0.2714635729789734,
          -0.5949902534484863,
          0.6154035329818726,
          0.0016380427405238152,
          -0.26967036724090576,
          0.6068075299263,
          -0.763658881187439,
          -0.8805904984474182,
          0.5511773824691772,
          -0.7279072403907776,
          0.0700208842754364,
          -0.9034616947174072,
          0.3797953426837921,
          -0.03025810420513153,
          0.02482767403125763,
          -0.2402731478214264,
          -0.34159064292907715,
          0.6106697916984558,
          -0.5294281244277954,
          0.6248581409454346,
          -0.23794597387313843,
          0.022278815507888794,
          0.45839279890060425,
          -0.026069458574056625,
          -0.4424046277999878,
          0.0890100970864296,
          -0.8235406279563904,
          -0.8201376795768738,
          0.9799301028251648,
          -0.07650668174028397,
          0.4439947009086609,
          -0.6686888337135315,
          0.9588595032691956,
          -0.12562350928783417,
          0.19775189459323883,
          0.5043455958366394,
          0.4841224253177643,
          0.10587533563375473,
          0.38106492161750793,
          0.9518947601318359,
          0.5559024810791016,
          -0.1526300460100174,
          -0.29321879148483276,
          -0.7984540462493896,
          0.3561774790287018,
          -0.1683288961648941,
          -0.3334484100341797,
          0.3105015754699707,
          -0.3037800192832947,
          -0.014485090970993042,
          -0.767385721206665,
          0.14421257376670837,
          -0.5192917585372925,
          -0.24076656997203827,
          -0.7150105834007263,
          0.27026259899139404,
          0.5515260100364685,
          -0.11588741093873978,
          -0.5332620739936829,
          -1.3407001495361328,
          0.9797664284706116,
          0.6127535700798035,
          -0.7085195183753967,
          -0.9389512538909912,
          0.5853370428085327,
          -0.2741020917892456,
          -0.2578011155128479,
          0.1476375311613083,
          1.460871696472168,
          -1.2278361320495605,
          0.8006134629249573,
          -0.10595206171274185,
          0.016261503100395203,
          0.6407477259635925,
          0.3745585083961487,
          -0.15232351422309875,
          -0.3102336525917053,
          -0.438340425491333,
          0.08787497878074646,
          0.3751847743988037,
          -0.4478708505630493,
          -0.5849093794822693,
          0.748894453048706,
          -1.157789945602417,
          0.9320448040962219,
          -0.5670242309570312,
          0.6132574677467346,
          -0.3530963659286499,
          -0.4063701033592224,
          0.002145208418369293,
          0.09722531586885452,
          0.15829253196716309,
          0.25116103887557983,
          0.35815104842185974,
          0.6465046405792236,
          -0.6038382649421692,
          -0.4854067265987396,
          0.08477406203746796,
          0.8978455066680908,
          0.24173665046691895,
          0.7366210222244263,
          0.25234463810920715,
          0.04740499332547188,
          -0.2568208575248718,
          0.15703603625297546,
          -0.5829671025276184,
          0.8879944086074829,
          -0.6893054246902466,
          0.496661514043808,
          0.0936717614531517,
          -0.5408447980880737,
          -0.31390202045440674,
          -0.7776990532875061,
          -0.1063804030418396,
          0.4420817494392395,
          -0.002287190407514572,
          -0.3733198642730713,
          -1.0806130170822144,
          0.49646472930908203,
          1.0577495098114014,
          -0.1793150007724762,
          0.6653681397438049,
          0.30828744173049927,
          0.1746513545513153,
          -0.16369551420211792,
          0.45886367559432983,
          -0.041532471776008606,
          -0.11429642140865326,
          0.19859176874160767,
          0.2304539680480957,
          -0.10879534482955933,
          -0.7323301434516907,
          1.0807758569717407,
          -1.4569330215454102,
          -0.9887740015983582,
          -0.1255451887845993,
          -0.5089572668075562,
          -0.5187685489654541,
          -0.05856664478778839,
          -0.31847476959228516,
          -0.012481041252613068,
          0.16905592381954193,
          -0.04197569191455841,
          0.0566701665520668,
          -0.07723771035671234,
          0.7023005485534668,
          0.56573885679245,
          -0.16730599105358124,
          0.15767721831798553,
          0.24578292667865753,
          -0.2838446795940399,
          1.431913137435913,
          0.38361701369285583,
          -1.08768630027771,
          -0.3952357769012451,
          1.360298752784729,
          -0.866901159286499,
          -0.033015258610248566,
          0.1938680112361908,
          -0.9420097470283508,
          0.04253154993057251,
          -1.591890811920166,
          0.211769700050354,
          -0.29266297817230225,
          -0.1387346237897873,
          -0.17726784944534302,
          -0.0018133297562599182,
          0.07246893644332886,
          0.5054937601089478,
          0.4512888789176941,
          -0.2937277555465698,
          -0.380582720041275,
          0.018055036664009094,
          -0.06268016993999481,
          -0.2753971815109253,
          -0.6504202485084534,
          -0.09508635103702545,
          -0.3305000960826874,
          0.6125059127807617,
          0.587367594242096,
          -0.5123195648193359,
          -0.7171103954315186,
          0.31643199920654297,
          -0.6899263262748718,
          0.13985925912857056,
          0.348171204328537,
          -1.0682094097137451,
          -0.386809766292572,
          0.16964998841285706,
          0.26222309470176697,
          0.38834357261657715,
          0.9381816983222961,
          -0.5775454640388489,
          -0.4638400673866272,
          0.29711174964904785,
          0.013943355530500412,
          -0.43627285957336426,
          0.17728418111801147,
          -0.8942844271659851,
          -0.5777038931846619,
          1.356497883796692,
          -0.30798864364624023,
          -0.6893442869186401,
          0.07758258283138275,
          0.5483869314193726,
          0.7886185050010681,
          0.4515112638473511,
          -0.9531080722808838,
          -0.5303629636764526,
          -0.27767691016197205,
          -0.7480067014694214,
          -0.07267999649047852,
          -0.6078914403915405,
          -0.21294239163398743,
          -0.493602454662323,
          0.13468119502067566,
          0.6006765961647034,
          -0.42384031414985657,
          0.21612809598445892,
          1.2107629776000977,
          0.384385347366333,
          -0.5518835783004761,
          0.26690444350242615,
          -0.07411201298236847,
          0.3023350238800049,
          -0.4276045262813568,
          -0.12927758693695068,
          -0.17990919947624207,
          0.03561094403266907,
          -0.49865755438804626,
          -0.08303895592689514,
          -0.42153075337409973,
          -0.1271541267633438,
          0.39520761370658875,
          0.8409481644630432,
          -0.808546781539917,
          0.7106654644012451,
          0.30488941073417664,
          -0.5691473484039307,
          -0.6114124655723572,
          -0.017052061855793,
          -0.0775744840502739,
          -0.17021261155605316,
          0.1724618673324585,
          0.6567572355270386,
          0.045316845178604126,
          0.5968488454818726,
          -0.4771167039871216,
          -1.1489405632019043,
          -0.2946908175945282,
          0.883470892906189,
          0.08905169367790222,
          -0.6188161969184875,
          0.06404608488082886,
          0.9275630712509155,
          -0.3076910078525543,
          -0.4240506589412689,
          0.6171751618385315,
          -0.020872674882411957,
          0.6587415337562561,
          -0.44570523500442505,
          0.5957741737365723,
          -0.5705384016036987,
          0.26107946038246155,
          0.07516463845968246,
          0.6069249510765076,
          -0.3248780369758606,
          0.1296301782131195,
          1.4485048055648804,
          0.6940237879753113,
          -0.6111653447151184,
          -0.12160201370716095,
          0.5127471685409546,
          -0.1446867138147354,
          0.21402323246002197,
          -1.4317363500595093,
          0.11305147409439087,
          -0.1635659784078598,
          -0.7456389665603638,
          0.7597655057907104,
          -1.336964726448059,
          -0.5579689741134644,
          0.5606786608695984,
          0.31303003430366516,
          -0.029725849628448486,
          -0.4865785837173462,
          -0.3185907006263733,
          0.14953777194023132,
          0.26745498180389404,
          -0.5469111204147339,
          -0.6473439931869507,
          1.0638710260391235,
          -0.08327078074216843,
          0.13121125102043152,
          -0.20851953327655792,
          -0.3378167748451233,
          1.147608757019043,
          0.6993881464004517,
          -0.38616839051246643,
          -0.4639381766319275,
          -0.16876192390918732,
          -1.1786264181137085,
          -0.585291862487793,
          -0.0993962362408638,
          0.3077039420604706,
          -0.23479431867599487,
          0.5147221088409424,
          0.6274125576019287,
          -0.34595897793769836,
          -0.412663072347641,
          0.2171960175037384,
          -0.8314945697784424,
          -1.0576026439666748,
          -0.272727906703949,
          0.5855919122695923,
          -0.20561040937900543,
          0.2389863133430481,
          -0.016418809071183205,
          0.24565184116363525,
          -0.08913808315992355,
          0.799334704875946,
          -0.4443941116333008,
          0.37104693055152893,
          0.23716533184051514,
          0.40801671147346497,
          -0.6938250660896301,
          -0.14983390271663666,
          -0.5075463652610779,
          0.08589372038841248,
          -0.4782314896583557,
          0.2026463896036148,
          -0.11313095688819885,
          0.39300215244293213,
          0.28061845898628235,
          -0.7254053354263306,
          0.4788980782032013,
          -0.4656945466995239,
          0.31946060061454773,
          -0.5592806339263916,
          0.17792756855487823,
          0.3951292634010315,
          -0.3547537922859192,
          0.2356826812028885,
          -1.0408934354782104,
          0.7900311350822449,
          -0.05570638179779053,
          -0.8829078078269958,
          0.7866925001144409,
          -0.18813546001911163,
          0.06687802076339722,
          -0.1410534828901291,
          -0.49718743562698364,
          0.6844659447669983,
          -0.432567834854126,
          0.727409839630127,
          -0.2842622995376587,
          0.31219518184661865,
          0.08696218580007553,
          -0.9340333938598633,
          0.18362949788570404,
          -0.9278713464736938,
          -0.2853296995162964,
          -0.6719756722450256,
          -0.40166759490966797,
          0.16569814085960388,
          -0.3568531274795532,
          -0.48374927043914795,
          0.5982677936553955,
          -0.44168463349342346,
          -1.0558412075042725,
          -0.18985183537006378,
          -0.1560712307691574,
          0.8951230049133301,
          0.6442514657974243,
          -0.008680397644639015,
          0.2656356394290924,
          -0.5743634700775146,
          -0.6836667656898499,
          -0.45300644636154175,
          -0.5723114013671875,
          -0.07691320776939392,
          0.6359285712242126,
          0.4154624044895172,
          0.24234899878501892,
          0.6985113620758057,
          0.05090511590242386,
          -0.1336546540260315,
          0.29326343536376953,
          0.5635210275650024,
          -0.010762214660644531,
          0.7988141179084778,
          0.5134821534156799,
          -0.2961580157279968,
          -0.399387925863266,
          -1.0384899377822876,
          0.04846736788749695,
          0.6876875162124634,
          -0.4317811131477356,
          -0.6035442352294922,
          0.39069071412086487,
          -0.04456868767738342,
          0.36120620369911194,
          -0.7891027331352234,
          -0.4919852614402771,
          0.29421111941337585,
          -0.4523623287677765,
          0.23830847442150116,
          -0.2969173491001129,
          0.21739253401756287,
          -0.5579757690429688,
          0.2597030997276306,
          0.6427697539329529,
          0.7285953760147095,
          -0.803175151348114,
          0.5576884150505066,
          0.5257341861724854,
          -0.8093786239624023,
          -0.608320951461792,
          -0.2928752899169922,
          0.6701194047927856,
          -0.704083263874054,
          0.07182780653238297,
          -0.32527267932891846,
          0.34154194593429565,
          0.3072882294654846,
          -0.1054064929485321,
          -0.28536826372146606,
          0.29921746253967285,
          0.6938059329986572,
          -0.13364315032958984,
          0.15100805461406708,
          -0.009428076446056366,
          1.2724360227584839,
          0.020381120964884758,
          0.24299630522727966,
          0.12566348910331726,
          0.797244668006897,
          -0.8394690752029419,
          0.23921342194080353,
          -0.3645164966583252,
          0.8499849438667297,
          -1.5269681215286255,
          -0.7197340726852417,
          0.35798099637031555,
          0.22977641224861145,
          -0.6609259247779846,
          -0.36102890968322754,
          -0.6420952081680298,
          0.8094066977500916,
          0.3148760199546814,
          -0.6085069179534912,
          0.10792136192321777,
          0.0453595370054245,
          0.043227940797805786,
          0.22606872022151947,
          0.3619498312473297,
          -0.764369547367096,
          0.23259186744689941,
          -0.013724889606237411,
          0.40281230211257935,
          -0.4688369929790497,
          0.40945252776145935,
          0.1979721635580063,
          -0.18169331550598145,
          -0.33701664209365845,
          0.5359815955162048,
          -0.4237588942050934,
          0.9582515954971313,
          0.2771686613559723,
          -0.618366539478302,
          1.1031692028045654,
          0.29361164569854736,
          -0.5256521701812744,
          0.6130971312522888,
          -0.5342586636543274,
          -0.4583866596221924,
          -1.148437738418579,
          0.9849449992179871,
          -0.9103699922561646,
          0.5158506631851196,
          0.38454240560531616,
          -0.27859044075012207,
          -0.7226073741912842,
          -0.14755302667617798,
          -0.18154865503311157,
          0.01878562569618225,
          0.24395914375782013,
          0.48959940671920776,
          0.4478840231895447,
          1.4115935564041138,
          1.293330430984497,
          -0.31181663274765015,
          -0.49171537160873413,
          0.1804848611354828,
          -0.012381374835968018,
          -0.2500850558280945,
          -0.09301218390464783,
          -0.51315838098526,
          -0.39038997888565063,
          0.04837590456008911,
          -0.8487421274185181,
          -0.7682617902755737,
          0.17768602073192596,
          -0.05785408616065979,
          0.27283167839050293,
          -0.4619971811771393,
          1.3023145198822021,
          -0.09477086365222931,
          0.19266971945762634,
          -0.2594541609287262,
          0.44006916880607605,
          0.503440797328949,
          0.2713507413864136,
          0.44357067346572876,
          -0.1952895224094391,
          0.4273549020290375,
          -1.3438037633895874,
          0.6357337832450867,
          -0.04094555974006653,
          -0.3934740424156189,
          0.14761511981487274,
          -0.01568935438990593,
          -0.6126208901405334,
          -0.6907224655151367,
          0.7069803476333618,
          -0.7563186883926392,
          0.018629485741257668,
          -0.030544809997081757,
          -0.05482649803161621,
          0.3380246162414551,
          -0.6296223998069763,
          -0.26459309458732605,
          1.2175443172454834,
          0.7903764247894287,
          -0.27313828468322754,
          0.6984723806381226,
          1.3540579080581665,
          0.7196106314659119,
          -0.055413827300071716,
          0.5441582202911377,
          -0.08292710781097412,
          0.3041960597038269,
          -0.7956596612930298,
          0.7865538597106934,
          -0.30172911286354065,
          -0.062389589846134186,
          -0.9408955574035645,
          1.230796456336975,
          0.7916334867477417,
          -0.0873073935508728,
          0.2356247901916504,
          -0.8057617545127869,
          -0.4443466067314148,
          -0.7079818248748779,
          0.4762749671936035,
          -0.4423762559890747,
          1.0463740825653076,
          -0.4160104990005493,
          0.1226806640625,
          0.7404676675796509,
          -0.4705600440502167,
          3.6198391914367676,
          1.304778814315796,
          -0.02732674777507782,
          0.45216700434684753,
          0.5740651488304138,
          1.0680286884307861,
          0.8804393410682678,
          -0.2250007688999176,
          0.7770000100135803,
          -0.5264014005661011,
          0.45623379945755005,
          -0.8408702611923218,
          0.9053432941436768,
          0.30034640431404114,
          -0.0275811105966568,
          -0.07916320860385895,
          -0.6750099062919617,
          0.3724897801876068,
          -0.04994431138038635,
          -0.14617912471294403,
          -1.4187524318695068,
          0.41960471868515015,
          0.21775157749652863,
          -0.4033007323741913,
          0.26138293743133545,
          0.7724621891975403,
          0.2622428834438324,
          -0.15945547819137573,
          -0.045493993908166885,
          -0.24347913265228271,
          0.06003725528717041,
          -0.8098164796829224,
          -0.4666171371936798,
          -0.25579145550727844,
          0.2758438289165497,
          0.9296218752861023,
          -0.06819066405296326,
          -0.7776265740394592,
          -0.317390114068985,
          1.5062958002090454,
          0.2966685891151428,
          -0.7478776574134827,
          -0.4954310953617096,
          -0.5075501203536987,
          0.2511218190193176,
          0.9065314531326294,
          0.4853411316871643,
          0.10099784284830093,
          0.8707804679870605,
          -1.15579092502594,
          0.31326615810394287,
          -1.237791657447815,
          -0.10693655908107758,
          -0.31706395745277405,
          0.4355061948299408,
          -0.06995145976543427,
          -0.06275267899036407,
          -0.18615244328975677,
          -1.102166771888733,
          0.43133726716041565,
          0.6239427924156189,
          -0.7340735793113708,
          -0.5032763481140137,
          0.6416704654693604,
          -0.24001438915729523,
          -0.6030829548835754,
          0.9125437140464783,
          0.4382650852203369,
          -0.3416736423969269,
          -0.0031812209635972977,
          0.3029974102973938,
          0.09761279076337814,
          -0.29363101720809937,
          0.12395432591438293,
          0.009734690189361572,
          0.4369860887527466,
          -0.2725297510623932,
          0.8199573159217834,
          -0.03281418979167938,
          -0.6419483423233032,
          -0.03762011229991913,
          -0.5348828434944153,
          -0.3350631296634674,
          -0.07515720278024673,
          0.23170018196105957,
          0.641777753829956,
          -0.3154255747795105,
          0.245738685131073,
          -0.466682106256485,
          0.05166245996952057,
          -0.23549696803092957,
          -0.21764646470546722,
          0.23932600021362305,
          -0.16717040538787842,
          -0.012140180915594101
        ]
      },
      "type": "document"
    },
    {
      "id": "64293f28-7635-4d79-98e0-407ee97df4ee",
      "properties": {
        "page_content": "Document 1: his works are considered classics of American\nliterature ... His wartime experiences formed the basis for his novel\n”A Farewell to Arms”(1929) ...\nDocument 2: ... artists of the 1920s ”Lost Generation” expatriate\ncommunity. His debut novel,”The Sun Also Rises”, was published\nin 1926.\nBOS\n”\nTheSunAlso\nR ises\n” is a\nnovel\nby this\nauthor\nof ” A\nFarewellto\nArms\n”\nDoc 1\nDoc 2\nDoc 3\nDoc 4\nDoc 5\nFigure 2: RAG-Token document posterior p(zi|x,yi,y−i) for each generated token for input “Hem-\ningway\" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high\nwhen generating “A Farewell to Arms\" and for document 2 when generating “The Sun Also Rises\".\nTable 3: Examples from generation tasks. RAG models generate more speciﬁc and factually accurate\nresponses. ‘?’ indicates factually incorrect responses, * indicates partially correct responses.\nTask Input Model Generation\nMS-\nMARCO\ndeﬁne middle\near\nBART ?The middle ear is the part of the ear between the middle ear and the nose.\nRAG-T The middle ear is the portion of the ear internal to the eardrum.\nRAG-S The middle ear includes the tympanic cavity and the three ossicles.\nwhat currency\nneeded in\nscotland\nBART The currency needed in Scotland is Pound sterling.\nRAG-T Pound is the currency needed in Scotland.\nRAG-S The currency needed in Scotland is the pound sterling.\nJeopardy\nQuestion\nGener\n-ation\nWashington\nBART ?This state has the largest number of counties in the U.S.\nRAG-T It’s the only U.S. state named for a U.S. president\nRAG-S It’s the state where you’ll ﬁnd Mount Rainier National Park\nThe Divine\nComedy\nBART *This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio & the Purgatorio\nRAG-T Dante’s \"Inferno\" is the ﬁrst part of this epic poem\nRAG-S This 14th century work is divided into 3 sections: \"Inferno\", \"Purgatorio\" & \"Paradiso\"\nFor 2-way classiﬁcation, we compare against Thorne and Vlachos [57], who train RoBERTa [35]\nto classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy\nwithin 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence.\nWe also analyze whether documents retrieved by RAG correspond to documents annotated as gold\nevidence in FEVER. We calculate the overlap in article titles between the topkdocuments retrieved\nby RAG and gold evidence annotations. We ﬁnd that the top retrieved document is from a gold article\nin 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.\n4.5 Additional Results\nGeneration Diversity Section 4.3 shows that RAG models are more factual and speciﬁc than\nBART for Jeopardy question generation. Following recent work on diversity-promoting decoding\n[33, 59, 39], we also investigate generation diversity by calculating the ratio of distinct ngrams to\ntotal ngrams generated by different models. Table 5 shows that RAG-Sequence’s generations are\nmore diverse than RAG-Token’s, and both are signiﬁcantly more diverse than BART without needing\nany diversity-promoting decoding.\nRetrieval Ablations A key feature of RAG is learning to retrieve relevant information for the task.\nTo assess the effectiveness of the retrieval mechanism, we run ablations where we freeze the retriever\nduring training. As shown in Table 6, learned retrieval improves results for all tasks.\nWe compare RAG’s dense retriever to a word overlap-based BM25 retriever [53]. Here, we replace\nRAG’s retriever with a ﬁxed BM25 system, and use BM25 retrieval scores as logits when calculating\np(z|x). Table 6 shows the results. For FEVER, BM25 performs best, perhaps since FEVER claims are\nheavily entity-centric and thus well-suited for word overlap-based retrieval. Differentiable retrieval\nimproves results on all other tasks, especially for Open-Domain QA, where it is crucial.\nIndex hot-swapping An advantage of non-parametric memory models like RAG is that knowledge\ncan be easily updated at test time. Parametric-only models like T5 or BART need further training to\nupdate their behavior as the world changes. To demonstrate, we build an index using the DrQA [5]\nWikipedia dump from December 2016 and compare outputs from RAG using this index to the newer\nindex from our main results (December 2018). We prepare a list of 82 world leaders who had changed\n7",
        "document_metadata": {
          "page_label": "7",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "75e72603-0562-4466-a8c5-078389e4facb",
      "properties": {
        "page_content": "Table 4: Human assessments for the Jeopardy\nQuestion Generation Task.\nFactuality Speciﬁcity\nBART better 7.1% 16.8%\nRAG better 42.7% 37.4%\nBoth good 11.7% 11.8%\nBoth poor 17.7% 6.9%\nNo majority 20.8% 20.1%\nTable 5: Ratio of distinct to total tri-grams for\ngeneration tasks.\nMSMARCO Jeopardy QGen\nGold 89.6% 90.0%\nBART 70.7% 32.4%\nRAG-Token 77.8% 46.8%\nRAG-Seq. 83.5% 53.8%\nTable 6: Ablations on the dev set. As FEVER is a classiﬁcation task, both RAG models are equivalent.\nModel NQ TQA WQ CT Jeopardy-QGen MSMarco FVR-3 FVR-2\nExact Match B-1 QB-1 R-L B-1 Label Accuracy\nRAG-Token-BM25 29.7 41.5 32.1 33.1 17.5 22.3 55.5 48.4 75.1 91.6RAG-Sequence-BM25 31.8 44.1 36.6 33.8 11.1 19.5 56.5 46.9\nRAG-Token-Frozen 37.8 50.1 37.1 51.1 16.7 21.7 55.9 49.4 72.9 89.4RAG-Sequence-Frozen 41.2 52.1 41.8 52.6 11.8 19.6 56.7 47.3\nRAG-Token 43.5 54.8 46.5 51.9 17.9 22.6 56.2 49.4 74.5 90.6RAG-Sequence 44.0 55.8 44.9 53.4 15.3 21.5 57.2 47.5\nbetween these dates and use a template “Who is {position}?” (e.g. “Who is the President of Peru?”)\nto query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for\n2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched\nindices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders).\nThis shows we can update RAG’s world knowledge by simply replacing its non-parametric memory.\nEffect of Retrieving more documents Models are trained with either 5 or 10 retrieved latent\ndocuments, and we do not observe signiﬁcant differences in performance between them. We have the\nﬂexibility to adjust the number of retrieved documents at test time, which can affect performance and\nruntime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves\nOpen-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved\ndocuments. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for\nRAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.\n10 20 30 40 50\nKR e t r i e v e dD o c s\n39\n40\n41\n42\n43\n44NQ Exact Match RAG-Tok\nRAG-Seq\n10 20 30 40 50\nKR e t r i e v e dD o c s\n40\n50\n60\n70\n80NQ Answer Recall @ K\nRAG-Tok\nRAG-Seq\nFixed DPR\nBM25\n10 20 30 40 50\nKR e t r i e v e dD o c s\n48\n50\n52\n54\n56Bleu-1 / Rouge-L score\nRAG-Tok R-L\nRAG-Tok B-1\nRAG-Seq R-L\nRAG-Seq B-1\nFigure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall perfor-\nmance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\n5 Related Work\nSingle-Task Retrieval Prior work has shown that retrieval improves performance across a variety of\nNLP tasks when considered in isolation. Such tasks include open-domain question answering [5, 29],\nfact checking [ 56], fact completion [ 48], long-form question answering [ 12], Wikipedia article\ngeneration [36], dialogue [ 41, 65, 9, 13], translation [ 17], and language modeling [ 19, 27]. Our\nwork uniﬁes previous successes in incorporating retrieval into individual tasks, showing that a single\nretrieval-based architecture is capable of achieving strong performance across several tasks.\n8",
        "document_metadata": {
          "page_label": "8",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing vast amounts of data. It's also driving innovations in areas like self-driving cars, personalized recommendations, and more.",
        "summary_embedding": [
          0.16271454095840454,
          0.6396447420120239,
          -0.5445219278335571,
          -0.5780285596847534,
          -0.036485686898231506,
          0.004848930984735489,
          0.1869882196187973,
          -0.013377677649259567,
          0.6391928195953369,
          0.42612335085868835,
          0.07738392055034637,
          0.17992253601551056,
          -0.47922587394714355,
          -1.3347127437591553,
          0.37955528497695923,
          -0.537700355052948,
          0.04548408091068268,
          -0.08333984017372131,
          0.022239789366722107,
          -0.17214083671569824,
          -0.15899179875850677,
          0.7628830075263977,
          -0.6126391887664795,
          -1.0994454622268677,
          -0.958942711353302,
          0.6391268968582153,
          0.6510990262031555,
          -0.5980463624000549,
          0.6771944761276245,
          0.710425615310669,
          -0.2203076183795929,
          -0.12519732117652893,
          0.03161963075399399,
          -0.592079222202301,
          -0.7007654905319214,
          -0.12206454575061798,
          0.44299381971359253,
          -0.1358461081981659,
          -1.1425288915634155,
          -0.46871858835220337,
          0.12693464756011963,
          -0.217140793800354,
          0.24752923846244812,
          -1.2813235521316528,
          -0.8052725791931152,
          0.5059859752655029,
          0.5317162275314331,
          -1.2141859531402588,
          0.13798008859157562,
          -0.20131056010723114,
          -0.6183086633682251,
          0.17975081503391266,
          -0.2978018820285797,
          -0.3594428598880768,
          0.148939311504364,
          -1.0261025428771973,
          -0.34945276379585266,
          -0.2695465385913849,
          -0.7017399668693542,
          -0.014288544654846191,
          0.8661367893218994,
          -0.31290578842163086,
          0.5867483615875244,
          0.0350818932056427,
          0.24224016070365906,
          0.6002794504165649,
          0.09751374274492264,
          -0.5333328247070312,
          -0.48965853452682495,
          0.10495701432228088,
          -1.2633999586105347,
          -0.32784679532051086,
          0.17243915796279907,
          0.10373051464557648,
          -0.2589932978153229,
          -0.07121960073709488,
          0.28973567485809326,
          -0.15176117420196533,
          -0.7404450178146362,
          -0.17462915182113647,
          -0.5395832061767578,
          0.6966541409492493,
          -0.4140365421772003,
          1.064995527267456,
          -0.018567383289337158,
          -0.5486446619033813,
          0.6770654916763306,
          0.8454210758209229,
          -0.2558779716491699,
          -0.6250367760658264,
          -0.1376168578863144,
          -0.05778094381093979,
          -0.15307971835136414,
          -0.11013723909854889,
          0.20142008364200592,
          0.7614086270332336,
          -0.6526834964752197,
          0.8046691417694092,
          0.1498197615146637,
          -0.12512734532356262,
          0.3283872604370117,
          1.1096980571746826,
          -0.1353803277015686,
          0.8944263458251953,
          -0.6385396718978882,
          0.20986969769001007,
          0.48109015822410583,
          -0.7977728247642517,
          0.022389743477106094,
          -1.0817792415618896,
          0.6777696013450623,
          0.09269300848245621,
          0.036293283104896545,
          0.2031317800283432,
          -0.07906882464885712,
          1.5061612129211426,
          -0.38477328419685364,
          0.2063208520412445,
          -0.5308052897453308,
          0.09816459566354752,
          -0.3065759837627411,
          -0.5888904929161072,
          0.10690085589885712,
          -0.33717820048332214,
          0.2746920585632324,
          -0.9308822154998779,
          -0.12197530269622803,
          0.8281819820404053,
          -0.5166530013084412,
          0.7785946726799011,
          -0.3458189070224762,
          -0.025690585374832153,
          -0.4572634696960449,
          0.9424963593482971,
          -0.13779552280902863,
          -0.9411827325820923,
          -0.03321971744298935,
          0.8097372651100159,
          -0.33256110548973083,
          0.5629850625991821,
          0.005705994553864002,
          0.05364567041397095,
          -0.31723710894584656,
          1.8469210863113403,
          -0.27189406752586365,
          -0.1631072461605072,
          -0.3443787395954132,
          -0.13225437700748444,
          -0.42152050137519836,
          0.8628708720207214,
          -0.8439804911613464,
          0.6498588919639587,
          0.4213511645793915,
          -0.024439571425318718,
          -0.7449625730514526,
          -0.5677566528320312,
          -0.6059220433235168,
          -0.06031779944896698,
          0.5218625664710999,
          0.5961475372314453,
          -0.3211411237716675,
          0.10065241158008575,
          -0.14622381329536438,
          1.1892231702804565,
          -0.4448627829551697,
          0.8289324641227722,
          -1.089806079864502,
          0.19100424647331238,
          -0.5405040979385376,
          -0.33100610971450806,
          0.242137148976326,
          -0.3285418152809143,
          -0.7072567343711853,
          -0.1777820587158203,
          0.9857323169708252,
          1.0883733034133911,
          0.8803785443305969,
          0.18350206315517426,
          0.1662394404411316,
          -0.24019986391067505,
          -1.2369582653045654,
          -0.4147624969482422,
          -0.9050871133804321,
          -0.09175127744674683,
          0.24204502999782562,
          0.5424241423606873,
          0.2729470729827881,
          0.22761230170726776,
          0.37086349725723267,
          -0.40884703397750854,
          0.15990860760211945,
          0.8502035737037659,
          -1.0244503021240234,
          -0.01150253415107727,
          -0.028977366164326668,
          0.38504934310913086,
          -0.6351456046104431,
          0.31516292691230774,
          0.2906569838523865,
          -0.15935133397579193,
          -0.23761269450187683,
          0.6057921648025513,
          0.000742495059967041,
          -0.5217112898826599,
          -0.6764063835144043,
          0.5701748132705688,
          -0.19459855556488037,
          1.139339804649353,
          -1.871540904045105,
          1.1812636852264404,
          0.5079679489135742,
          0.386186808347702,
          -0.16821618378162384,
          -0.28693968057632446,
          0.7334355711936951,
          -0.07145528495311737,
          -0.30863213539123535,
          0.4099438190460205,
          0.032187048345804214,
          -0.38220980763435364,
          -0.16829848289489746,
          -0.30154725909233093,
          0.4782901704311371,
          -0.5337154269218445,
          -0.3882618248462677,
          -0.18343079090118408,
          -0.31097936630249023,
          0.9544433951377869,
          0.030123358592391014,
          0.2117592692375183,
          0.6710535287857056,
          0.6782439351081848,
          -0.33991947770118713,
          0.7613152265548706,
          -0.108360156416893,
          0.18759958446025848,
          -0.43809080123901367,
          0.4391550123691559,
          -0.16585901379585266,
          -0.18739759922027588,
          0.7602629065513611,
          0.18202564120292664,
          1.3229409456253052,
          0.5284218788146973,
          -0.6920583248138428,
          0.22672948241233826,
          -0.13780993223190308,
          -0.028473490849137306,
          0.5883102416992188,
          0.7636860013008118,
          -0.5922800302505493,
          0.1629164218902588,
          0.23262035846710205,
          -0.23924186825752258,
          -0.4287331700325012,
          0.4295913875102997,
          0.6656215190887451,
          0.5927994251251221,
          0.2714574933052063,
          -1.3723833560943604,
          -0.7426238059997559,
          0.8957061171531677,
          0.4057317078113556,
          -0.03730210289359093,
          0.5889778733253479,
          0.5457394123077393,
          -0.303469717502594,
          -0.12911750376224518,
          -0.9317306280136108,
          -0.3211100399494171,
          -1.2986642122268677,
          -1.3430488109588623,
          -0.474011093378067,
          -0.2749558389186859,
          -0.9374642968177795,
          -0.1667887568473816,
          0.078120157122612,
          -0.6541852355003357,
          0.7747740149497986,
          0.054990656673908234,
          -0.2705657482147217,
          -0.5489562749862671,
          -0.7288913726806641,
          0.43884772062301636,
          0.801075279712677,
          0.5329099893569946,
          -1.2470637559890747,
          0.26450303196907043,
          -0.6321595311164856,
          0.7669284343719482,
          0.6325686573982239,
          0.4774702191352844,
          -0.10173610597848892,
          -0.49453070759773254,
          -0.031805552542209625,
          -0.22565628588199615,
          0.7253713607788086,
          0.14151808619499207,
          -1.0464805364608765,
          -0.3184022307395935,
          -0.07388140261173248,
          0.009147034026682377,
          -0.7230890989303589,
          -0.024371720850467682,
          -0.01784328557550907,
          0.4559790790081024,
          0.34488943219184875,
          0.0035905204713344574,
          1.044201135635376,
          0.12863922119140625,
          -1.150638222694397,
          0.20370399951934814,
          -0.14583167433738708,
          0.9552018642425537,
          -0.5042911767959595,
          0.7470431923866272,
          0.27943694591522217,
          -0.6156044602394104,
          0.29740458726882935,
          -1.1459777355194092,
          -0.2922893166542053,
          0.2962716817855835,
          -0.6442066431045532,
          0.5956922769546509,
          0.12965840101242065,
          0.47438013553619385,
          0.11700752377510071,
          -2.06618595123291,
          -0.04482971131801605,
          0.04355471208691597,
          -0.440712571144104,
          -0.09373608231544495,
          0.19127735495567322,
          0.997108519077301,
          0.7661407589912415,
          -0.46695104241371155,
          -0.02502659149467945,
          -0.05043837055563927,
          -0.4337215721607208,
          0.9273598790168762,
          0.5188859701156616,
          -0.23615926504135132,
          0.3869062662124634,
          0.4548216462135315,
          -0.5815951824188232,
          0.6476903557777405,
          1.1281458139419556,
          -0.37631556391716003,
          0.8452250361442566,
          -0.13323068618774414,
          -0.12410258501768112,
          -0.3117976486682892,
          -0.45021775364875793,
          -0.3753153383731842,
          0.5521018505096436,
          0.04374799504876137,
          -0.48143550753593445,
          0.4809100329875946,
          -0.14996254444122314,
          0.0767011046409607,
          0.7480023503303528,
          0.282002717256546,
          -0.4308995008468628,
          0.33564093708992004,
          -0.48874330520629883,
          0.12956023216247559,
          -0.12354803085327148,
          0.3038997948169708,
          0.3618547022342682,
          -0.7113178372383118,
          0.5851577520370483,
          -0.04477090388536453,
          -0.3824709355831146,
          0.59253990650177,
          -0.8048205971717834,
          -1.0161757469177246,
          0.4667409062385559,
          -0.9828438758850098,
          0.19100503623485565,
          -0.7682362198829651,
          0.3119955062866211,
          -0.09789004921913147,
          0.046012043952941895,
          -0.2848508954048157,
          -0.2230502963066101,
          0.9089663624763489,
          -0.7702645659446716,
          0.6026925444602966,
          -0.23632463812828064,
          0.06137251481413841,
          0.4583342671394348,
          -0.033142175525426865,
          -0.5087572932243347,
          0.22244411706924438,
          -0.5419586896896362,
          -0.688734233379364,
          1.024336814880371,
          -0.03152112290263176,
          0.30703291296958923,
          -0.45576420426368713,
          1.2861979007720947,
          -0.13300815224647522,
          0.12126981467008591,
          0.3843553364276886,
          0.35361969470977783,
          0.3445897698402405,
          0.3530235290527344,
          0.7787325978279114,
          0.5277367830276489,
          -0.42289477586746216,
          -0.12967023253440857,
          -0.619866669178009,
          0.3852491080760956,
          -0.181432843208313,
          -0.33542242646217346,
          0.18828609585762024,
          -0.10090404003858566,
          0.016401372849941254,
          -0.8399924039840698,
          0.1522497832775116,
          -0.5974336266517639,
          -0.0444457046687603,
          -0.752129316329956,
          0.1288357526063919,
          0.4593730568885803,
          -0.20104952156543732,
          -0.48907750844955444,
          -1.4752095937728882,
          0.742529034614563,
          0.5077875852584839,
          -0.5502292513847351,
          -0.7530555129051208,
          0.7405477166175842,
          -0.28336989879608154,
          -0.08825235813856125,
          0.16377165913581848,
          1.5413388013839722,
          -1.1401176452636719,
          0.9057874083518982,
          -0.08367760479450226,
          0.14329662919044495,
          0.7288774847984314,
          0.44265803694725037,
          0.010278452187776566,
          -0.36774784326553345,
          -0.5668999552726746,
          -0.027672603726387024,
          0.4535060226917267,
          -0.39276862144470215,
          -0.6737301349639893,
          0.7509374022483826,
          -1.1581249237060547,
          0.9918414950370789,
          -0.3386496305465698,
          0.4592416286468506,
          -0.16406360268592834,
          -0.38958990573883057,
          0.027765076607465744,
          0.04629902541637421,
          0.14364203810691833,
          0.20154468715190887,
          0.24034881591796875,
          0.6573651432991028,
          -0.5651204586029053,
          -0.380851686000824,
          0.1142173707485199,
          0.7276598215103149,
          0.38461965322494507,
          0.5636887550354004,
          0.21750478446483612,
          0.154026061296463,
          -0.23687465488910675,
          0.04230947047472,
          -0.6660844683647156,
          0.7973472476005554,
          -0.6918871998786926,
          0.5705477595329285,
          0.3382017910480499,
          -0.6513983607292175,
          -0.4536764621734619,
          -0.8079985976219177,
          -0.03389205038547516,
          0.47454023361206055,
          0.05317675322294235,
          -0.3921595513820648,
          -0.8754084706306458,
          0.40142175555229187,
          1.1099649667739868,
          -0.07701975107192993,
          0.535896897315979,
          0.30567675828933716,
          0.2132917195558548,
          -0.0059820134192705154,
          0.5785690546035767,
          0.12604132294654846,
          0.20160916447639465,
          0.12599074840545654,
          0.22979438304901123,
          -0.23248395323753357,
          -0.7418884634971619,
          1.3793681859970093,
          -1.502799153327942,
          -1.1361750364303589,
          -0.14681315422058105,
          -0.43584591150283813,
          -0.41267329454421997,
          -0.12969234585762024,
          -0.3816169500350952,
          -0.2084539383649826,
          0.2650195360183716,
          -0.16441859304904938,
          0.15762856602668762,
          0.017446402460336685,
          0.3505900800228119,
          0.5327624678611755,
          -0.04857980087399483,
          -0.039291828870773315,
          0.11637028306722641,
          -0.19269607961177826,
          1.36958646774292,
          0.4313746988773346,
          -1.1465100049972534,
          -0.20268288254737854,
          1.4531524181365967,
          -0.9257375001907349,
          -0.018994279205799103,
          0.3205917477607727,
          -1.0453267097473145,
          0.040167491883039474,
          -1.539113163948059,
          0.3309572637081146,
          -0.32206207513809204,
          -0.10502010583877563,
          -0.1408083438873291,
          0.191131591796875,
          0.11753751337528229,
          0.5604574084281921,
          0.6536614298820496,
          -0.6260156035423279,
          -0.4467252194881439,
          0.14824703335762024,
          -0.0584244504570961,
          -0.3063490688800812,
          -0.6071650981903076,
          -0.0937492847442627,
          -0.3504621386528015,
          0.3098025918006897,
          0.6680561304092407,
          -0.5667842626571655,
          -0.7445100545883179,
          0.4002232849597931,
          -0.6572416424751282,
          -0.08738819509744644,
          0.5388944149017334,
          -1.180517315864563,
          -0.36399367451667786,
          0.27777719497680664,
          0.27995479106903076,
          0.42456763982772827,
          1.0456042289733887,
          -0.5526371598243713,
          -0.5096763968467712,
          0.28399375081062317,
          -0.06066856533288956,
          -0.43022000789642334,
          0.2358124852180481,
          -0.9127166271209717,
          -0.6105399131774902,
          1.1941019296646118,
          -0.3832578957080841,
          -0.5641233921051025,
          0.18435564637184143,
          0.5924457311630249,
          0.6825500726699829,
          0.4597536325454712,
          -0.8876218199729919,
          -0.47152140736579895,
          -0.3571528196334839,
          -1.0697158575057983,
          -0.1113913506269455,
          -0.6149764657020569,
          -0.30133962631225586,
          -0.3284311890602112,
          0.07677483558654785,
          0.5409180521965027,
          -0.5112452507019043,
          0.33720821142196655,
          1.1724408864974976,
          0.5709857940673828,
          -0.5659909248352051,
          0.40217113494873047,
          -0.22047117352485657,
          0.40857598185539246,
          -0.24662147462368011,
          -0.04595530778169632,
          -0.17285215854644775,
          0.029425188899040222,
          -0.4997834861278534,
          0.2675017714500427,
          -0.38404256105422974,
          -0.025904547423124313,
          0.2339036464691162,
          0.8511468172073364,
          -0.7742043137550354,
          0.8597748279571533,
          0.5156788229942322,
          -0.4648801386356354,
          -0.8085821866989136,
          -0.06561838090419769,
          -0.1968654841184616,
          -0.1677379012107849,
          0.42894887924194336,
          0.7377327680587769,
          0.24710869789123535,
          0.6083108186721802,
          -0.4156648516654968,
          -0.9594030380249023,
          -0.3939911127090454,
          0.9466145038604736,
          0.02904655411839485,
          -0.6938760280609131,
          0.19062909483909607,
          0.9426143765449524,
          -0.42693793773651123,
          -0.206091046333313,
          0.5485153198242188,
          -0.15624244511127472,
          0.5951895713806152,
          -0.5806409120559692,
          0.606866180896759,
          -0.5872106552124023,
          0.2507689595222473,
          0.0777365118265152,
          0.5767568945884705,
          -0.3254140317440033,
          0.34991732239723206,
          1.5101999044418335,
          0.6797696948051453,
          -0.7793609499931335,
          0.06757012009620667,
          0.5468959212303162,
          -0.09318535774946213,
          0.2739526927471161,
          -1.5272027254104614,
          0.15971043705940247,
          -0.17974866926670074,
          -0.8168891072273254,
          0.6312704086303711,
          -1.2844902276992798,
          -0.35462886095046997,
          0.5995376706123352,
          0.380728155374527,
          0.09424309432506561,
          -0.6683058142662048,
          -0.2771862745285034,
          0.23005598783493042,
          0.30952197313308716,
          -0.7026965022087097,
          -0.4968372583389282,
          0.9539483189582825,
          -0.09912961721420288,
          0.26828575134277344,
          -0.13495276868343353,
          -0.4430428445339203,
          1.0995628833770752,
          0.5452547669410706,
          -0.4349673092365265,
          -0.315181702375412,
          -0.23384952545166016,
          -1.2931329011917114,
          -0.7464997172355652,
          0.12334568798542023,
          0.39514246582984924,
          -0.17350232601165771,
          0.49443289637565613,
          0.557932436466217,
          -0.41065528988838196,
          -0.3945349156856537,
          0.3101535141468048,
          -1.0089633464813232,
          -1.012171745300293,
          -0.255245566368103,
          0.37370550632476807,
          -0.22837406396865845,
          0.14892341196537018,
          -0.0922776460647583,
          0.13822613656520844,
          0.05615905299782753,
          0.7776774168014526,
          -0.35695576667785645,
          0.4154244661331177,
          0.1569003164768219,
          0.3664834499359131,
          -0.6089815497398376,
          -0.21044373512268066,
          -0.3233802318572998,
          -0.1447732001543045,
          -0.3974946439266205,
          -0.04130825400352478,
          -0.0749121904373169,
          0.29542043805122375,
          0.2393328696489334,
          -0.5516712069511414,
          0.4795197546482086,
          -0.49462515115737915,
          0.37050575017929077,
          -0.6175273060798645,
          0.151596337556839,
          0.5485655069351196,
          -0.25156667828559875,
          0.36052364110946655,
          -1.058221459388733,
          0.962149977684021,
          0.07646889239549637,
          -0.8796294331550598,
          0.9747380614280701,
          0.0366363525390625,
          0.14762099087238312,
          -0.3183155953884125,
          -0.3441360294818878,
          0.7308542728424072,
          -0.23028884828090668,
          0.6276175379753113,
          -0.2563444972038269,
          0.30311599373817444,
          0.18664181232452393,
          -0.9924442768096924,
          0.14556477963924408,
          -1.012378454208374,
          -0.2706870436668396,
          -0.7497057318687439,
          -0.3932237923145294,
          0.13607445359230042,
          -0.2828614115715027,
          -0.5970210433006287,
          0.8038877248764038,
          -0.19793108105659485,
          -0.9530733823776245,
          -0.2089444398880005,
          -0.168709859251976,
          0.8603473901748657,
          0.39374154806137085,
          0.18349690735340118,
          0.11923078447580338,
          -0.5290153622627258,
          -0.7544491291046143,
          -0.3268653154373169,
          -0.4639231264591217,
          -0.11129359900951385,
          0.6645117402076721,
          0.4770338833332062,
          0.2784801423549652,
          0.6480095386505127,
          0.021828800439834595,
          0.039872415363788605,
          0.3794510066509247,
          0.6855066418647766,
          -0.04034337028861046,
          0.6173351407051086,
          0.35379335284233093,
          -0.10531648993492126,
          -0.47568419575691223,
          -0.8553391098976135,
          0.12064571678638458,
          0.7680644392967224,
          -0.30428606271743774,
          -0.7008139491081238,
          0.3452030420303345,
          -0.12119948863983154,
          0.40710964798927307,
          -0.5838967561721802,
          -0.43263810873031616,
          0.4346306622028351,
          -0.38662901520729065,
          0.10914365947246552,
          -0.3436782956123352,
          0.4033939242362976,
          -0.6861604452133179,
          0.05076569691300392,
          0.6028050184249878,
          0.7117880582809448,
          -0.7521830201148987,
          0.5854641795158386,
          0.5261220932006836,
          -0.609749972820282,
          -0.43645551800727844,
          -0.1668839007616043,
          0.6188547611236572,
          -0.640120267868042,
          0.1939055323600769,
          -0.48083290457725525,
          0.33767664432525635,
          0.34498536586761475,
          -0.17157550156116486,
          -0.19189991056919098,
          0.218057319521904,
          0.5346510410308838,
          -0.1489364206790924,
          0.16485363245010376,
          0.1941428929567337,
          1.2029467821121216,
          -0.08904975652694702,
          0.4748326539993286,
          0.19119927287101746,
          0.5738576054573059,
          -0.8113337755203247,
          0.3547390401363373,
          -0.5107621550559998,
          1.110550045967102,
          -1.615705132484436,
          -0.5438764095306396,
          0.30042266845703125,
          0.20538905262947083,
          -0.8083916306495667,
          -0.4149404764175415,
          -0.7832204699516296,
          0.9847620725631714,
          0.27546924352645874,
          -0.7588815689086914,
          -0.005538687109947205,
          0.17271050810813904,
          0.09776182472705841,
          0.1883382797241211,
          0.12105555832386017,
          -0.576983630657196,
          0.11153722554445267,
          0.022781845182180405,
          0.3763485848903656,
          -0.4964216351509094,
          0.27992066740989685,
          0.0625610277056694,
          -0.026959024369716644,
          -0.22117486596107483,
          0.5970182418823242,
          -0.4514666497707367,
          1.078749656677246,
          0.31348568201065063,
          -0.6910613179206848,
          1.1515820026397705,
          0.440024197101593,
          -0.6467345356941223,
          0.535118579864502,
          -0.5947012901306152,
          -0.3132402300834656,
          -1.0532053709030151,
          0.9956092834472656,
          -0.9245556592941284,
          0.28596293926239014,
          0.39068305492401123,
          -0.3050684332847595,
          -0.3507915437221527,
          -0.022958435118198395,
          -0.3886079788208008,
          0.0039521679282188416,
          0.333193302154541,
          0.5563533902168274,
          0.12642928957939148,
          1.6240723133087158,
          1.5280804634094238,
          -0.18681195378303528,
          -0.4375664293766022,
          0.23313689231872559,
          -0.08027274906635284,
          -0.073531873524189,
          0.011306766420602798,
          -0.6904821395874023,
          -0.38118550181388855,
          -0.04686475545167923,
          -0.8588519096374512,
          -0.6161767840385437,
          0.0928235650062561,
          0.011627446860074997,
          0.5908205509185791,
          -0.5108662247657776,
          1.3439959287643433,
          -0.005445647984743118,
          0.2912152409553528,
          -0.2837376892566681,
          0.5089232921600342,
          0.3268861472606659,
          0.31829777359962463,
          0.18954986333847046,
          -0.3666260540485382,
          0.28227442502975464,
          -1.2603424787521362,
          0.619239330291748,
          -0.19557446241378784,
          -0.16269874572753906,
          0.2264018952846527,
          -0.04267193377017975,
          -0.391753613948822,
          -0.761174201965332,
          0.8551551699638367,
          -0.5402527451515198,
          -0.10664267838001251,
          -0.04711443930864334,
          -0.04104930907487869,
          0.32871177792549133,
          -0.6671139001846313,
          -0.218019500374794,
          1.175540566444397,
          0.7012569904327393,
          -0.09875985980033875,
          0.8190729022026062,
          1.325235366821289,
          1.0335056781768799,
          0.03636704385280609,
          0.34902411699295044,
          -0.1498228758573532,
          0.201372429728508,
          -0.9452787637710571,
          0.7535593509674072,
          -0.15303288400173187,
          0.08847706764936447,
          -0.775606095790863,
          1.1525522470474243,
          0.7888583540916443,
          0.011949341744184494,
          0.2601809799671173,
          -0.8265709280967712,
          -0.2047913372516632,
          -0.6748647689819336,
          0.40073084831237793,
          -0.25442516803741455,
          0.869564414024353,
          -0.23418456315994263,
          -0.07176393270492554,
          0.6531910300254822,
          -0.70095294713974,
          3.590125560760498,
          1.1953229904174805,
          -0.17844083905220032,
          0.3782581090927124,
          0.5062284469604492,
          0.8801693320274353,
          1.012667179107666,
          -0.26792508363723755,
          0.5259778499603271,
          -0.6063072681427002,
          0.5425254702568054,
          -0.8465042114257812,
          0.8559965491294861,
          0.4163017272949219,
          -0.1445646584033966,
          -0.17627757787704468,
          -0.7636996507644653,
          0.4443552792072296,
          0.016208380460739136,
          -0.14283595979213715,
          -1.4154047966003418,
          0.14495167136192322,
          0.30869126319885254,
          -0.39159759879112244,
          0.2965690791606903,
          0.6495646834373474,
          0.1106937974691391,
          -0.12457894533872604,
          -0.21970772743225098,
          -0.48523378372192383,
          0.11773031949996948,
          -0.5879945755004883,
          -0.33216825127601624,
          -0.18102796375751495,
          0.19809311628341675,
          0.8784318566322327,
          0.08191724121570587,
          -0.8469700813293457,
          -0.37350064516067505,
          1.4939461946487427,
          0.37980616092681885,
          -0.7888400554656982,
          -0.4707522690296173,
          -0.6610011458396912,
          0.1534663587808609,
          0.7045064568519592,
          0.4006023705005646,
          0.11834315210580826,
          0.8720000982284546,
          -1.042748212814331,
          0.07611303776502609,
          -1.1937806606292725,
          -0.06350582093000412,
          -0.21122130751609802,
          0.37235599756240845,
          0.21303008496761322,
          -0.15541385114192963,
          -0.2433135211467743,
          -1.095449686050415,
          0.31289640069007874,
          0.6800278425216675,
          -0.7498314380645752,
          -0.5203354954719543,
          0.5843186974525452,
          -0.17106902599334717,
          -0.45601803064346313,
          0.8157615661621094,
          0.4043969213962555,
          -0.3284693956375122,
          -0.047251876443624496,
          0.021595196798443794,
          0.1371181309223175,
          -0.22491466999053955,
          0.19639772176742554,
          0.1553317904472351,
          0.11841237545013428,
          -0.339929461479187,
          0.9034684300422668,
          -0.09530003368854523,
          -0.37582820653915405,
          0.016977697610855103,
          -0.5899252891540527,
          -0.2827615439891815,
          -0.00274503231048584,
          0.2614177465438843,
          0.7987704277038574,
          -0.22633613646030426,
          0.2478589415550232,
          -0.47050318121910095,
          0.08149385452270508,
          -0.3938266336917877,
          -0.2386334240436554,
          0.3619503974914551,
          -0.08282928913831711,
          0.01242142915725708
        ]
      },
      "type": "document"
    },
    {
      "id": "1d9c8f91-a5a5-485d-93f2-46219bdd62e0",
      "properties": {
        "page_content": "General-Purpose Architectures for NLP Prior work on general-purpose architectures for NLP\ntasks has shown great success without the use of retrieval. A single, pre-trained language model\nhas been shown to achieve strong performance on various classiﬁcation tasks in the GLUE bench-\nmarks [60, 61] after ﬁne-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained\nlanguage model could achieve strong performance across both discriminative and generative tasks.\nFor further improvement, BART [32] and T5 [51, 52] propose a single, pre-trained encoder-decoder\nmodel that leverages bi-directional attention to achieve stronger performance on discriminative\nand generative tasks. Our work aims to expand the space of possible tasks with a single, uniﬁed\narchitecture, by learning a retrieval module to augment pre-trained, generative language models.\nLearned Retrieval There is signiﬁcant work on learning to retrieve documents in information\nretrieval, more recently with pre-trained, neural language models [ 44, 26] similar to ours. Some\nwork optimizes the retrieval module to aid in a speciﬁc, downstream task such as question answering,\nusing search [46], reinforcement learning [6, 63, 62], or a latent variable approach [31, 20] as in our\nwork. These successes leverage different retrieval-based architectures and optimization techniques to\nachieve strong performance on a single task, while we show that a single retrieval-based architecture\ncan be ﬁne-tuned for strong performance on a variety of tasks.\nMemory-based Architectures Our document index can be seen as a large external memory for\nneural networks to attend to, analogous to memory networks [64, 55]. Concurrent work [14] learns\nto retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our\nwork. Other work improves the ability of dialog models to generate factual text by attending over\nfact embeddings [15, 13]. A key feature of our memory is that it is comprised of raw text rather\ndistributed representations, which makes the memory both (i) human-readable, lending a form of\ninterpretability to our model, and (ii) human-writable, enabling us to dynamically update the model’s\nmemory by editing the document index. This approach has also been used in knowledge-intensive\ndialog, where generators have been conditioned on retrieved text directly, albeit obtained via TF-IDF\nrather than end-to-end learnt retrieval [9].\nRetrieve-and-Edit approaches Our method shares some similarities with retrieve-and-edit style\napproaches, where a similar training input-output pair is retrieved for a given input, and then edited\nto provide a ﬁnal output. These approaches have proved successful in a number of domains including\nMachine Translation [ 18, 22] and Semantic Parsing [21]. Our approach does have several differences,\nincluding less of emphasis on lightly editing a retrieved item, but on aggregating content from several\npieces of retrieved content, as well as learning latent retrieval, and retrieving evidence documents\nrather than related training pairs. This said, RAG techniques may work well in these settings, and\ncould represent promising future work.\n6 Discussion\nIn this work, we presented hybrid generation models with access to parametric and non-parametric\nmemory. We showed that our RAG models obtain state of the art results on open-domain QA. We\nfound that people prefer RAG’s generation over purely parametric BART, ﬁnding RAG more factual\nand speciﬁc. We conducted an thorough investigation of the learned retrieval component, validating\nits effectiveness, and we illustrated how the retrieval index can be hot-swapped to update the model\nwithout requiring any retraining. In future work, it may be fruitful to investigate if the two components\ncan be jointly pre-trained from scratch, either with a denoising objective similar to BART or some\nanother objective. Our work opens up new research directions on how parametric and non-parametric\nmemories interact and how to most effectively combine them, showing promise in being applied to a\nwide variety of NLP tasks.\n9",
        "document_metadata": {
          "page_label": "9",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "summary": "AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.09557442367076874,
          0.5917006731033325,
          -0.3716878592967987,
          -0.36844250559806824,
          0.1810879111289978,
          -0.20083369314670563,
          -0.11306161433458328,
          -0.18365120887756348,
          0.8529327511787415,
          0.28102290630340576,
          -0.11035503447055817,
          0.11218027025461197,
          -0.5052893161773682,
          -0.8742839097976685,
          0.34360405802726746,
          -0.3131340444087982,
          -0.07195702195167542,
          -0.3698134422302246,
          -0.22363926470279694,
          -0.044750988483428955,
          0.04048082232475281,
          0.745326578617096,
          -0.5912765860557556,
          -1.49360990524292,
          -0.792955219745636,
          0.5824881196022034,
          0.786318302154541,
          -0.5094679594039917,
          0.6536781787872314,
          0.8745157122612,
          0.37444207072257996,
          0.07125842571258545,
          0.0720890536904335,
          -0.48164501786231995,
          -0.70054030418396,
          -0.3260500729084015,
          0.4467546343803406,
          -0.1501740664243698,
          -1.0429400205612183,
          -0.2460862696170807,
          0.3615124225616455,
          -0.2544897198677063,
          0.7554886937141418,
          -1.232443928718567,
          -1.10512113571167,
          0.5947213768959045,
          0.6053286790847778,
          -1.0477805137634277,
          0.08008693158626556,
          -0.27512702345848083,
          -0.5859770178794861,
          0.34039661288261414,
          0.26679348945617676,
          -0.0344657339155674,
          -0.003660917282104492,
          -0.7281141877174377,
          -0.5914082527160645,
          -0.4707638621330261,
          -0.15977275371551514,
          0.08580076694488525,
          0.9861599206924438,
          -0.22802937030792236,
          0.9384590983390808,
          0.25710809230804443,
          0.11057940125465393,
          0.564959704875946,
          0.21744497120380402,
          -0.6631613969802856,
          -0.19013936817646027,
          0.0655190572142601,
          -0.8587900996208191,
          -0.29645830392837524,
          0.2851434648036957,
          0.015566900372505188,
          -0.6966560482978821,
          0.13295133411884308,
          -0.30293723940849304,
          -0.045616406947374344,
          -0.6129682660102844,
          -0.3643989861011505,
          -0.19397567212581635,
          0.7056000232696533,
          -0.37626051902770996,
          0.8197504281997681,
          -0.28448110818862915,
          -0.2114272564649582,
          0.8481359481811523,
          0.8390682935714722,
          -0.19979892671108246,
          -0.7154859900474548,
          -0.06522618234157562,
          -0.07644856721162796,
          0.16134198009967804,
          0.17657819390296936,
          0.0017857402563095093,
          0.8428934812545776,
          -0.718901515007019,
          0.6080209612846375,
          0.13996373116970062,
          0.3187209963798523,
          0.15692704916000366,
          1.06525719165802,
          -0.09416830539703369,
          0.7302311658859253,
          -0.6892550587654114,
          0.5312532186508179,
          0.5488885641098022,
          -0.4467991292476654,
          0.25266239047050476,
          -1.3348255157470703,
          0.35050898790359497,
          0.29221248626708984,
          0.0687674880027771,
          0.37987667322158813,
          -0.26017534732818604,
          1.1891433000564575,
          -0.31010332703590393,
          0.278935968875885,
          -0.3372204899787903,
          0.5517401695251465,
          -0.5969853401184082,
          -0.6594493985176086,
          -0.10859031975269318,
          -0.6174302697181702,
          0.13380542397499084,
          -1.124927282333374,
          0.14211037755012512,
          0.7889682054519653,
          -0.46495020389556885,
          1.032935619354248,
          -0.47846636176109314,
          0.15253007411956787,
          -0.030841343104839325,
          0.7209072709083557,
          -0.0959177166223526,
          -0.74724942445755,
          0.2921706736087799,
          0.6239399313926697,
          -0.42344528436660767,
          0.6951251029968262,
          -0.023998335003852844,
          -0.12970022857189178,
          -0.6534463167190552,
          1.704041838645935,
          -0.1366855651140213,
          0.05550716817378998,
          -0.6583564877510071,
          0.14295974373817444,
          -0.4496084153652191,
          1.029815912246704,
          -0.7459796667098999,
          0.38809117674827576,
          0.2841087579727173,
          0.2037678211927414,
          -0.6509552001953125,
          -0.593869686126709,
          -0.7284699082374573,
          -0.1019415557384491,
          0.481717973947525,
          0.3173343241214752,
          0.010743461549282074,
          0.10406558215618134,
          -0.18675170838832855,
          0.9724626541137695,
          -0.39720484614372253,
          0.8837658762931824,
          -1.2704687118530273,
          -0.12780623137950897,
          -0.6265919804573059,
          -0.07650747895240784,
          0.47533589601516724,
          -0.23709526658058167,
          -0.8172165751457214,
          -0.5462501645088196,
          0.9361964464187622,
          0.827658474445343,
          0.6460142135620117,
          0.060503147542476654,
          -0.0805504098534584,
          -0.4459359645843506,
          -1.5404300689697266,
          -0.5939789414405823,
          -0.9645528793334961,
          -0.044843897223472595,
          -0.00170234777033329,
          0.5179499387741089,
          0.04344068467617035,
          0.3640483021736145,
          0.5703238248825073,
          -0.4732063412666321,
          0.5344792008399963,
          0.387540340423584,
          -1.0902562141418457,
          0.06878277659416199,
          0.09332175552845001,
          0.3396373689174652,
          -0.5947502851486206,
          0.35212984681129456,
          0.5953266024589539,
          -0.2493838220834732,
          0.3280866742134094,
          0.6169419288635254,
          0.028659265488386154,
          -0.5214598178863525,
          -0.8426816463470459,
          0.9281793832778931,
          -0.01985369622707367,
          1.145997166633606,
          -1.8311628103256226,
          0.9448096752166748,
          0.4326115846633911,
          0.28304874897003174,
          -0.3062875270843506,
          -0.26946908235549927,
          0.8398028612136841,
          -0.19748198986053467,
          -0.49554210901260376,
          0.15565058588981628,
          0.30520743131637573,
          -0.492609441280365,
          -0.10562301427125931,
          -0.40021273493766785,
          0.5381574630737305,
          -0.4004201292991638,
          -0.4736381769180298,
          -0.10517476499080658,
          -0.229171484708786,
          0.6659902930259705,
          0.09367643296718597,
          0.015290871262550354,
          0.7352038025856018,
          0.6268242597579956,
          -0.9397681951522827,
          1.0367070436477661,
          -0.25917568802833557,
          0.21150915324687958,
          -0.4717581272125244,
          0.3743574917316437,
          -0.118555448949337,
          -0.24917706847190857,
          0.8517168760299683,
          -0.16678038239479065,
          1.0611834526062012,
          0.676598846912384,
          -0.5725884437561035,
          0.5634968280792236,
          0.288095623254776,
          -0.3000292479991913,
          0.3397165834903717,
          0.6546885967254639,
          -0.4851294159889221,
          0.38237059116363525,
          -0.08248022198677063,
          -0.3972926139831543,
          -0.9207156300544739,
          0.5385898351669312,
          0.6160528063774109,
          0.47132861614227295,
          0.18423521518707275,
          -1.0704867839813232,
          -0.9143854975700378,
          0.7869094014167786,
          0.47887012362480164,
          0.2036494016647339,
          0.5972900986671448,
          0.34216010570526123,
          -0.4534238576889038,
          0.20067793130874634,
          -0.9740211367607117,
          -0.08473345637321472,
          -1.1105053424835205,
          -1.172290325164795,
          -0.349073201417923,
          -0.20075653493404388,
          -0.9648564457893372,
          -0.012180982157588005,
          -0.058730438351631165,
          -0.4348052442073822,
          0.24806106090545654,
          -0.0694698840379715,
          -0.45035749673843384,
          -0.4296804368495941,
          -0.638954758644104,
          0.5700812935829163,
          0.9559347629547119,
          0.15018776059150696,
          -1.092523455619812,
          -0.3563551902770996,
          -0.7213876843452454,
          0.6775517463684082,
          0.5692557096481323,
          0.5593953132629395,
          -0.3809961974620819,
          -0.1351737380027771,
          -0.26687926054000854,
          -0.0727483406662941,
          0.5502753257751465,
          0.24589310586452484,
          -0.9470085501670837,
          -0.3103730082511902,
          0.23022647202014923,
          0.11177074164152145,
          -0.42874953150749207,
          -0.20567527413368225,
          -0.10381835699081421,
          0.46497049927711487,
          0.22223903238773346,
          0.05514957755804062,
          0.8586540818214417,
          0.09318986535072327,
          -1.3096290826797485,
          0.3685588836669922,
          -0.6706473231315613,
          0.6278464794158936,
          -0.47862812876701355,
          0.8173006772994995,
          0.4229930341243744,
          -0.5469916462898254,
          0.1547636091709137,
          -1.1405192613601685,
          -0.3480469882488251,
          0.07718141376972198,
          -0.6188845038414001,
          0.3731672465801239,
          0.094267338514328,
          0.40454965829849243,
          0.06034725904464722,
          -1.885884404182434,
          0.30857613682746887,
          -0.05573910474777222,
          -0.6660481095314026,
          -0.6181671023368835,
          0.16581842303276062,
          0.7678385972976685,
          0.3811313211917877,
          -0.47897088527679443,
          -0.32209905982017517,
          0.10097143799066544,
          -0.7728496789932251,
          0.6089708805084229,
          0.46675631403923035,
          -0.23317834734916687,
          0.2864474356174469,
          0.593575656414032,
          -0.6456066370010376,
          0.5471383929252625,
          1.018409252166748,
          -0.18332254886627197,
          0.724532425403595,
          -0.25005224347114563,
          -0.1854609102010727,
          -0.37455713748931885,
          -0.5022316575050354,
          -0.24467715620994568,
          0.4115614593029022,
          0.2491239458322525,
          -0.37003093957901,
          0.669474720954895,
          -0.1134522333741188,
          0.21588720381259918,
          0.8080736398696899,
          0.6332430839538574,
          -0.4583977460861206,
          0.5895153284072876,
          -0.48879557847976685,
          0.251240074634552,
          -0.41419368982315063,
          0.4808288812637329,
          0.251146137714386,
          -0.6717185378074646,
          0.5517297983169556,
          0.1737871766090393,
          -0.34450340270996094,
          0.47771939635276794,
          -0.5481829047203064,
          -0.9627611041069031,
          0.29087957739830017,
          -0.7856232523918152,
          0.4525688588619232,
          -0.7369488477706909,
          0.2626233696937561,
          -0.0007060989737510681,
          -0.028258517384529114,
          -0.4270421266555786,
          -0.12042765319347382,
          0.6541765332221985,
          -0.2019018828868866,
          0.49788403511047363,
          0.02280249074101448,
          0.04676864668726921,
          0.419471800327301,
          0.2575438320636749,
          -0.784583330154419,
          0.3762742280960083,
          -0.4432215392589569,
          -0.5065362453460693,
          1.1076308488845825,
          -0.024051953107118607,
          0.37229952216148376,
          -0.6068447232246399,
          1.280246376991272,
          -0.2521790862083435,
          0.48118284344673157,
          0.5431567430496216,
          0.7925353646278381,
          0.5420989990234375,
          0.24733872711658478,
          0.9447295665740967,
          0.2893223762512207,
          -0.2786514461040497,
          -0.28913766145706177,
          -0.39904993772506714,
          0.4751431345939636,
          -0.4447433352470398,
          -0.2731104791164398,
          0.049556486308574677,
          0.05648969113826752,
          -0.3255051374435425,
          -0.5718376040458679,
          0.07832518219947815,
          -0.5502053499221802,
          -0.2052907794713974,
          -0.6579335331916809,
          0.2404354214668274,
          0.4232640266418457,
          -0.25949764251708984,
          -0.8073635101318359,
          -1.3075605630874634,
          0.6157048344612122,
          0.320763498544693,
          -0.8596393465995789,
          -0.8751752376556396,
          0.4344821572303772,
          -0.40759363770484924,
          -0.06758517771959305,
          0.17091095447540283,
          0.8695771098136902,
          -1.6322077512741089,
          0.7362163662910461,
          0.2781570255756378,
          0.01501946896314621,
          0.6539371609687805,
          0.49459898471832275,
          -0.1867053508758545,
          -0.1828206479549408,
          -0.20906701683998108,
          0.2680501937866211,
          0.45524880290031433,
          -0.034256428480148315,
          -0.7867367267608643,
          0.4786783456802368,
          -0.8060294985771179,
          1.271706223487854,
          -0.13774116337299347,
          0.5261433720588684,
          -0.717454195022583,
          -0.3473976254463196,
          0.34248900413513184,
          -0.0698205828666687,
          0.6213657855987549,
          0.31756043434143066,
          0.1248910203576088,
          1.0758601427078247,
          -0.19234421849250793,
          -0.676425039768219,
          0.3868715763092041,
          1.0579676628112793,
          0.5332707166671753,
          0.15343764424324036,
          0.19781014323234558,
          -0.11867660284042358,
          -0.2412526160478592,
          0.2777114808559418,
          -0.47618260979652405,
          0.7149038314819336,
          -0.8458890318870544,
          0.6538445949554443,
          0.5115357637405396,
          -0.6622107028961182,
          -0.34457093477249146,
          -0.7421861886978149,
          -0.11709517240524292,
          0.1951046735048294,
          -0.18207591772079468,
          -0.26586610078811646,
          -1.0402944087982178,
          0.6052955985069275,
          0.8704835772514343,
          -0.1867339313030243,
          0.8363679051399231,
          0.07187557220458984,
          0.05606512725353241,
          -0.04157779738306999,
          0.5926694273948669,
          0.07983247935771942,
          0.22766506671905518,
          -0.06136070936918259,
          0.32620707154273987,
          -0.11066663265228271,
          -1.0459495782852173,
          0.7730979323387146,
          -1.1784040927886963,
          -1.031030297279358,
          0.1871686577796936,
          -0.5019228458404541,
          -0.4038245677947998,
          -0.38361144065856934,
          -0.5225803256034851,
          0.06739529222249985,
          0.308021605014801,
          -0.3974885642528534,
          -0.1499428153038025,
          -0.38704541325569153,
          0.6194810271263123,
          0.4876353442668915,
          0.10552159696817398,
          -0.09783489257097244,
          0.27846765518188477,
          -0.06212789937853813,
          1.2811059951782227,
          0.06912421435117722,
          -0.7564463019371033,
          -0.46667471528053284,
          1.80078125,
          -1.0179256200790405,
          0.11095833778381348,
          0.1883435994386673,
          -0.6916512250900269,
          -0.04614025354385376,
          -1.5744287967681885,
          0.4357551336288452,
          -0.17759375274181366,
          -0.06955701112747192,
          -0.11940833926200867,
          -0.27656641602516174,
          0.025782637298107147,
          0.38946184515953064,
          0.6291816234588623,
          -0.5828274488449097,
          -0.3594185709953308,
          0.0986163541674614,
          -0.19792020320892334,
          -0.07799006253480911,
          -0.5585483312606812,
          -0.11999361217021942,
          -0.19982892274856567,
          0.3864216208457947,
          0.4937470555305481,
          -0.6749312877655029,
          -0.3878166973590851,
          0.283866286277771,
          -0.2837044298648834,
          -0.13558873534202576,
          0.4864007532596588,
          -1.071386694908142,
          -0.10037165135145187,
          0.38540369272232056,
          0.0834401398897171,
          0.48152193427085876,
          1.0743101835250854,
          -0.5594956278800964,
          -0.8526121973991394,
          0.10510903596878052,
          -0.26833897829055786,
          -0.6625157594680786,
          -0.052547305822372437,
          -0.5699484944343567,
          -0.8234978914260864,
          1.2793935537338257,
          -0.6839644908905029,
          -0.49848300218582153,
          0.3359106481075287,
          0.5913991928100586,
          0.7180237770080566,
          0.10059623420238495,
          -0.5917444229125977,
          -0.667252779006958,
          -0.37835410237312317,
          -1.100041389465332,
          -0.16812297701835632,
          -0.542327880859375,
          -0.1534036546945572,
          -0.11982327699661255,
          0.05075947940349579,
          0.34831923246383667,
          -0.8354305624961853,
          -0.14141850173473358,
          1.286941647529602,
          0.39943283796310425,
          -0.6882132291793823,
          0.20571154356002808,
          -0.46379756927490234,
          0.2798088788986206,
          -0.05405426025390625,
          -0.0134314876049757,
          -0.44740402698516846,
          0.0783294141292572,
          -0.6545759439468384,
          0.3337061107158661,
          -0.8073477149009705,
          -0.11538994312286377,
          0.3530857563018799,
          0.9273709058761597,
          -0.7158897519111633,
          0.3525143563747406,
          0.19607886672019958,
          -0.5448416471481323,
          -0.6221285462379456,
          -0.3304472863674164,
          -0.296145498752594,
          -0.4210480749607086,
          0.5040891170501709,
          0.6958808898925781,
          0.05171816051006317,
          0.5833619236946106,
          -0.28167223930358887,
          -1.0716060400009155,
          0.017344694584608078,
          0.761075496673584,
          0.1924678236246109,
          -0.46254193782806396,
          0.2535635530948639,
          0.990435004234314,
          -0.21703903377056122,
          -0.5900929570198059,
          0.6454318761825562,
          -0.35646989941596985,
          0.6155710816383362,
          -0.6704509854316711,
          0.3415994644165039,
          -0.4482124149799347,
          0.18445232510566711,
          -0.21080468595027924,
          0.9593873620033264,
          -0.18760205805301666,
          -0.17614595592021942,
          1.4974521398544312,
          0.21571706235408783,
          -0.5803819894790649,
          -0.005472958087921143,
          0.43351152539253235,
          -0.13065168261528015,
          0.44716086983680725,
          -1.592444896697998,
          -0.10213965177536011,
          -0.12874771654605865,
          -0.5769273042678833,
          0.2330278754234314,
          -1.2184325456619263,
          -0.46853870153427124,
          0.33697646856307983,
          0.40605953335762024,
          0.028398975729942322,
          -0.6178343892097473,
          -0.3811308741569519,
          0.2062295377254486,
          -0.16625629365444183,
          -0.659927487373352,
          -0.6594203114509583,
          0.8635306358337402,
          -0.2477552890777588,
          0.3742777407169342,
          -0.02904205024242401,
          -0.3504513204097748,
          0.8075942397117615,
          0.23777899146080017,
          -0.26172617077827454,
          -0.40552425384521484,
          -0.20139677822589874,
          -1.2164183855056763,
          -0.7040377855300903,
          -0.25287628173828125,
          0.564376711845398,
          -0.1923159658908844,
          0.849950909614563,
          0.5214777588844299,
          -0.2247782200574875,
          -0.4131202697753906,
          0.0363965779542923,
          -0.9054848551750183,
          -0.9175283312797546,
          0.0627409964799881,
          0.29768455028533936,
          0.05953429639339447,
          0.012594431638717651,
          -0.2235448807477951,
          -0.003006022423505783,
          0.14992308616638184,
          0.6260957717895508,
          -0.4195795953273773,
          0.39059531688690186,
          0.8273983001708984,
          0.42253726720809937,
          -0.6748482584953308,
          -0.1469932496547699,
          0.025615334510803223,
          0.01259620487689972,
          -0.38016277551651,
          -0.1641366183757782,
          -0.3909358084201813,
          0.4051990509033203,
          0.3789493143558502,
          -0.7931033968925476,
          0.16969527304172516,
          -0.527547299861908,
          0.22859908640384674,
          -0.4700491726398468,
          0.2567019462585449,
          0.26756322383880615,
          -0.1647372990846634,
          0.4103046655654907,
          -1.1742370128631592,
          0.5859609842300415,
          0.3535721004009247,
          -0.8831823468208313,
          0.618251621723175,
          -0.19269753992557526,
          -0.14732304215431213,
          0.06674838811159134,
          -0.42887043952941895,
          0.6611902713775635,
          -0.448619544506073,
          0.965042769908905,
          -0.2153327763080597,
          0.44930002093315125,
          0.22742271423339844,
          -1.014797568321228,
          0.03786292299628258,
          -0.6960169076919556,
          -0.2043619453907013,
          -0.9756791591644287,
          -0.4382471740245819,
          0.1213020384311676,
          -0.14887724816799164,
          -0.6236888766288757,
          0.4479125738143921,
          -0.3717501759529114,
          -0.7008146643638611,
          -0.5737035870552063,
          0.008570825681090355,
          0.68207186460495,
          0.30393993854522705,
          0.5589455962181091,
          0.01089203730225563,
          -0.5983786582946777,
          -0.5387409925460815,
          -0.6070533394813538,
          -0.49541959166526794,
          -0.00643351674079895,
          0.47152113914489746,
          0.22896058857440948,
          0.2736380994319916,
          0.9926045536994934,
          0.06762609630823135,
          0.242656409740448,
          0.6779271960258484,
          0.3068489730358124,
          0.18843066692352295,
          0.8530422449111938,
          0.7620474100112915,
          -0.3409850001335144,
          -0.4118809103965759,
          -1.0471042394638062,
          -0.21749484539031982,
          0.7012234926223755,
          0.0008706189692020416,
          -0.5660429000854492,
          0.6277405619621277,
          0.1719720959663391,
          0.022125817835330963,
          -0.5271599292755127,
          -0.502360463142395,
          0.17594444751739502,
          -0.2193070650100708,
          0.2653612792491913,
          -0.5660746693611145,
          0.681524395942688,
          -0.8570670485496521,
          0.07146155834197998,
          0.6352501511573792,
          0.921772837638855,
          -0.7267941236495972,
          0.5895218849182129,
          0.5850337147712708,
          -0.4764755964279175,
          -0.1720559149980545,
          -0.43865838646888733,
          0.2789166271686554,
          -0.8517090082168579,
          0.27064138650894165,
          -0.5665395259857178,
          0.00520053505897522,
          0.6265646815299988,
          0.11275531351566315,
          -0.4360494315624237,
          0.2227107584476471,
          0.4226788878440857,
          -0.2666451632976532,
          0.18137119710445404,
          0.3213551938533783,
          1.2073335647583008,
          0.42951500415802,
          0.237156942486763,
          0.14387282729148865,
          0.4185420572757721,
          -0.884128212928772,
          0.5767431855201721,
          -0.6746410727500916,
          1.075116515159607,
          -1.8397029638290405,
          -0.6465660929679871,
          0.1374427080154419,
          0.2901446521282196,
          -0.7616342306137085,
          0.027590185403823853,
          -0.9704511761665344,
          0.8131359815597534,
          0.4283590316772461,
          -0.8115636110305786,
          0.30837130546569824,
          -0.059981994330883026,
          0.018286675214767456,
          0.1899617612361908,
          0.3245165944099426,
          -0.7043401598930359,
          0.44214704632759094,
          -0.17159408330917358,
          0.30587518215179443,
          -0.39279744029045105,
          0.058580026030540466,
          0.04366379976272583,
          0.49131858348846436,
          -0.5075950622558594,
          0.6547595858573914,
          -0.165104478597641,
          1.282546043395996,
          0.4476456642150879,
          -0.5592791438102722,
          1.0989034175872803,
          0.7883446216583252,
          -0.5126949548721313,
          0.7242935299873352,
          -0.2611982524394989,
          -0.13881398737430573,
          -0.914864718914032,
          0.6140943169593811,
          -0.5611937642097473,
          0.27217382192611694,
          0.5183238983154297,
          -0.29252079129219055,
          -0.660622239112854,
          0.1387070119380951,
          0.2623703181743622,
          0.15750236809253693,
          0.1847740113735199,
          0.6615347862243652,
          0.01876736432313919,
          1.3571521043777466,
          1.778169870376587,
          -0.2789038419723511,
          -0.2435399889945984,
          -0.019055142998695374,
          0.004350535571575165,
          0.109097421169281,
          -0.23323892056941986,
          -0.7622546553611755,
          -0.3684051036834717,
          0.336283415555954,
          -0.9737634062767029,
          -0.3162679374217987,
          0.1638849377632141,
          -0.24186661839485168,
          0.5480189323425293,
          -0.3664921820163727,
          1.0328692197799683,
          0.23175065219402313,
          0.02992738038301468,
          -0.21834197640419006,
          0.5958175659179688,
          0.6202502250671387,
          0.1323508322238922,
          0.16743457317352295,
          0.19694072008132935,
          0.6951044201850891,
          -1.3495498895645142,
          0.7924509048461914,
          -0.08286872506141663,
          -0.26655495166778564,
          0.14441001415252686,
          -0.19547337293624878,
          -0.6671624779701233,
          -1.1927711963653564,
          1.017988920211792,
          -0.6397350430488586,
          0.0498705692589283,
          0.1724790781736374,
          0.1477736234664917,
          0.3872392177581787,
          -0.9486610889434814,
          -0.5955722332000732,
          1.2241398096084595,
          0.9416923522949219,
          0.006402358412742615,
          0.9445599317550659,
          1.1357040405273438,
          1.047577977180481,
          -0.007201220840215683,
          0.6722529530525208,
          -0.2552807331085205,
          0.19744332134723663,
          -0.7628332376480103,
          0.39736852049827576,
          -0.23529237508773804,
          -0.09550031274557114,
          -0.7260382771492004,
          1.2201234102249146,
          0.7744801044464111,
          0.18850886821746826,
          0.2876589000225067,
          -1.0754185914993286,
          -0.02591463178396225,
          -0.9534260630607605,
          0.13076747953891754,
          -0.06557895988225937,
          0.8986799716949463,
          -0.582558810710907,
          0.23859083652496338,
          0.6356217861175537,
          -0.3719273805618286,
          3.581587314605713,
          0.7292966842651367,
          -0.23829078674316406,
          0.3191234767436981,
          0.502914309501648,
          0.672002375125885,
          0.9064181447029114,
          -0.26618409156799316,
          0.9930312633514404,
          -0.4197479784488678,
          0.21121621131896973,
          -0.6592556834220886,
          0.9638981819152832,
          0.10506945848464966,
          0.06832492351531982,
          -0.008073285222053528,
          -1.017158031463623,
          0.4491116404533386,
          -0.18577635288238525,
          0.04319165647029877,
          -1.0536479949951172,
          0.32200634479522705,
          0.2624005675315857,
          -0.871880829334259,
          0.18633654713630676,
          0.5248112678527832,
          0.15822458267211914,
          -0.31195807456970215,
          -0.2989236116409302,
          -0.3631473481655121,
          -0.06729015707969666,
          -0.4538363516330719,
          -0.6791152954101562,
          0.19173981249332428,
          0.09161649644374847,
          0.832672119140625,
          0.0332525260746479,
          -0.6281567215919495,
          -0.1610235720872879,
          1.7180628776550293,
          0.6334441304206848,
          -0.4642385244369507,
          -0.894741952419281,
          -0.3476741909980774,
          0.2274264395236969,
          0.48546501994132996,
          0.4823650121688843,
          -0.0034151896834373474,
          0.9911807179450989,
          -0.7788832783699036,
          0.29464051127433777,
          -0.9982519745826721,
          0.21988755464553833,
          -0.0706275999546051,
          0.4993690252304077,
          0.4350995123386383,
          -0.1264406442642212,
          -0.22676926851272583,
          -1.177691102027893,
          0.4627913236618042,
          0.833085834980011,
          -0.6094534397125244,
          -0.39085182547569275,
          0.274508535861969,
          0.1941833347082138,
          -0.2883893847465515,
          1.1831721067428589,
          0.1489710658788681,
          -0.23950330913066864,
          0.1578604131937027,
          0.3071710169315338,
          0.18053923547267914,
          -0.14395886659622192,
          0.15747737884521484,
          0.4975227117538452,
          0.02970203012228012,
          -0.38237398862838745,
          0.41831615567207336,
          -0.2426205575466156,
          -0.1759064644575119,
          -0.12042397260665894,
          -0.5527037978172302,
          -0.28501203656196594,
          0.007431536912918091,
          0.0741870254278183,
          0.4699935019016266,
          0.05786047875881195,
          0.3601761758327484,
          -0.6136714220046997,
          0.1865096390247345,
          -0.6436507105827332,
          -0.14778485894203186,
          -0.18112128973007202,
          0.10746526718139648,
          0.15374793112277985
        ]
      },
      "type": "document"
    },
    {
      "id": "f671c425-fd24-429e-b8c7-d744904eb1b6",
      "properties": {
        "page_content": "Broader Impact\nThis work offers several positive societal beneﬁts over previous work: the fact that it is more\nstrongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less\nwith generations that are more factual, and offers more control and interpretability. RAG could be\nemployed in a wide variety of scenarios with direct beneﬁt to society, for example by endowing it\nwith a medical index and asking it open-domain questions on that topic, or by helping people be more\neffective at their jobs.\nWith these advantages also come potential downsides: Wikipedia, or any potential external knowledge\nsource, will probably never be entirely factual and completely devoid of bias. Since RAG can be\nemployed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably\nto a lesser extent, including that it might be used to generate abuse, faked or misleading content in\nthe news or on social media; to impersonate others; or to automate the production of spam/phishing\ncontent [54]. Advanced language models may also lead to the automation of various jobs in the\ncoming decades [16]. In order to mitigate these risks, AI systems could be employed to ﬁght against\nmisleading content and automated spam/phishing.\nAcknowledgments\nThe authors would like to thank the reviewers for their thoughtful and constructive feedback on this\npaper, as well as HuggingFace for their help in open-sourcing code to run RAG models. The authors\nwould also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. EP\nthanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR PhD\nprogram.\nReferences\n[1] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan\nMajumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina\nStoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Generated MAchine\nReading COmprehension Dataset. arXiv:1611.09268 [cs], November 2016. URL http:\n//arxiv.org/abs/1611.09268. arXiv: 1611.09268.\n[2] Petr Baudiš and Jan Šediv`y. Modeling of the question answering task in the yodaqa system. In\nInternational Conference of the Cross-Language Evaluation Forum for European Languages,\npages 222–228. Springer, 2015. URL https://link.springer.com/chapter/10.1007%\n2F978-3-319-24027-5_20 .\n[3] Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic Parsing on Freebase\nfrom Question-Answer Pairs. In Proceedings of the 2013 Conference on Empirical Methods\nin Natural Language Processing, pages 1533–1544, Seattle, Washington, USA, October 2013.\nAssociation for Computational Linguistics. URL http://www.aclweb.org/anthology/\nD13-1160.\n[4] Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang. Palm: Pre-training an autoencod-\ning&autoregressive language model for context-conditioned generation. ArXiv, abs/2004.07159,\n2020. URL https://arxiv.org/abs/2004.07159.\n[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer\nOpen-Domain Questions. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver, Canada,\nJuly 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL\nhttps://www.aclweb.org/anthology/P17-1171.\n[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and\nJonathan Berant. Coarse-to-ﬁne question answering for long documents. In Proceedings of the\n55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 209–220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi:\n10.18653/v1/P17-1020. URL https://www.aclweb.org/anthology/P17-1020.\n10",
        "document_metadata": {
          "page_label": "10",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "4276afbc-0fa3-49d4-86b4-708bbf31a527",
      "properties": {
        "page_content": "[7] Christopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Compre-\nhension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723.\narXiv: 1710.10723.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis,\nMinnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423.\nURL https://www.aclweb.org/anthology/N19-1423.\n[9] Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wiz-\nard of wikipedia: Knowledge-powered conversational agents. In International Conference on\nLearning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.\n[10] Matthew Dunn, Levent Sagun, Mike Higgins, V . Ugur Guney, V olkan Cirik, and Kyunghyun\nCho. SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine.\narXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv:\n1704.05179.\n[11] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceed-\nings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), pages 889–898, Melbourne, Australia, July 2018. Association for Computational\nLinguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anthology/\nP18-1082.\n[12] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5:\nLong form question answering. In Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics, pages 3558–3567, Florence, Italy, July 2019. Association for\nComputational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/\nanthology/P19-1346.\n[13] Angela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers\nwith KNN-based composite memory, 2020. URL https://openreview.net/forum?id=\nH1gx1CNKPH.\n[14] Thibault Févry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski.\nEntities as experts: Sparse memory access with entity supervision. ArXiv, abs/2004.07202,\n2020. URL https://arxiv.org/abs/2004.07202.\n[15] Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen\ntau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI\nConference on Artiﬁcial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/\nAAAI/AAAI18/paper/view/16710.\n[16] Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI\nexceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL\nhttp://arxiv.org/abs/1705.08807.\n[17] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural\nmachine translation. In AAAI Conference on Artiﬁcial Intelligence , 2018. URL https:\n//www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.\n[18] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural\nmachine translation. In 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 , 32nd\nAAAI Conference on Artiﬁcial Intelligence, AAAI 2018, pages 5133–5140. AAAI press, 2018.\n32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018\nThrough 07-02-2018.\n[19] Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by\nediting prototypes. Transactions of the Association for Computational Linguistics, 6:437–450,\n2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anthology/Q18-1031.\n11",
        "document_metadata": {
          "page_label": "11",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ]
      },
      "type": "document"
    },
    {
      "id": "16d82600-0c4f-4903-a822-3d652c14ae61",
      "properties": {
        "page_content": "[20] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM:\nRetrieval-augmented language model pre-training. ArXiv, abs/2002.08909, 2020. URL https:\n//arxiv.org/abs/2002.08909.\n[21] Tatsunori B Hashimoto, Kelvin Guu, Yonatan Oren, and Percy S Liang. A\nretrieve-and-edit framework for predicting structured outputs. In S. Bengio,\nH. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, ed-\nitors, Advances in Neural Information Processing Systems 31 , pages 10052–\n10062. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/\n8209-a-retrieve-and-edit-framework-for-predicting-structured-outputs.\npdf.\n[22] Nabil Hossain, Marjan Ghazvininejad, and Luke Zettlemoyer. Simple and effective retrieve-\nedit-rerank text generation. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 2532–2538, Online, July 2020. Association for Computa-\ntional Linguistics. doi: 10.18653/v1/2020.acl-main.228. URL https://www.aclweb.org/\nanthology/2020.acl-main.228.\n[23] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. arXiv\npreprint arXiv:1702.08734, 2017. URL https://arxiv.org/abs/1702.08734.\n[24] Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A Large Scale\nDistantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the\n55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 1601–1611, Vancouver, Canada, July 2017. Association for Computational Linguistics.\ndoi: 10.18653/v1/P17-1147. URL https://www.aclweb.org/anthology/P17-1147.\n[25] Armand Joulin and Tomas Mikolov. Inferring algorithmic patterns with stack-\naugmented recurrent nets. In Proceedings of the 28th International Conference on\nNeural Information Processing Systems - Volume 1 , NIPS’15, page 190–198, Cam-\nbridge, MA, USA, 2015. MIT Press. URL https://papers.nips.cc/paper/\n5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets .\n[26] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and\nWen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint\narXiv:2004.04906, 2020. URL https://arxiv.org/abs/2004.04906.\n[27] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generaliza-\ntion through memorization: Nearest neighbor language models. In International Conference on\nLearning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.\n[28] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua\nBengio and Yann LeCun, editors, 3rd International Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL\nhttp://arxiv.org/abs/1412.6980.\n[29] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redﬁeld, Michael Collins, Ankur Parikh,\nChris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Ken-\nton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. Natural Questions: a Benchmark for Ques-\ntion Answering Research. Transactions of the Association of Computational Lin-\nguistics, 2019. URL https://tomkwiat.users.x20web.corp.google.com/papers/\nnatural-questions/main-1455-kwiatkowski.pdf .\n[30] Guillaume Lample, Alexandre Sablayrolles, Marc’ Aurelio Ranzato, Ludovic Denoyer, and\nHerve Jegou. Large memory layers with product keys. In H. Wallach, H. Larochelle,\nA. Beygelzimer, F. d’ Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural In-\nformation Processing Systems 32, pages 8548–8559. Curran Associates, Inc., 2019. URL http:\n//papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf .\n[31] Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised\nopen domain question answering. In Proceedings of the 57th Annual Meeting of the Association\n12",
        "document_metadata": {
          "page_label": "12",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "summary": "This text is about papers published in various conferences and journals, including NIPS and ACL, discussing AI, machine learning, and natural language processing.",
        "summary_embedding": [
          0.6127049922943115,
          -0.013746269047260284,
          0.34935253858566284,
          -0.3979746997356415,
          0.5814960598945618,
          -0.33449408411979675,
          0.12430429458618164,
          -0.2440299689769745,
          0.0879729837179184,
          0.7577383518218994,
          -0.1958548128604889,
          0.34481653571128845,
          -0.22229012846946716,
          -1.1122723817825317,
          0.3215489983558655,
          0.07380408048629761,
          0.053616054356098175,
          -0.46516963839530945,
          -0.3114428222179413,
          -0.4091179370880127,
          0.23811981081962585,
          0.7967585325241089,
          -1.2506579160690308,
          0.32265427708625793,
          -0.2303880751132965,
          -0.11087659001350403,
          0.3016781210899353,
          0.10805459320545197,
          1.5420690774917603,
          0.11549939215183258,
          0.7707634568214417,
          -0.4053892493247986,
          0.0676952600479126,
          -0.4551829397678375,
          -0.40460219979286194,
          -0.8393325805664062,
          0.737501859664917,
          -0.2779847979545593,
          -0.2594051957130432,
          -0.5138996839523315,
          0.594606876373291,
          0.027572661638259888,
          0.4216140806674957,
          -1.4288877248764038,
          -0.7140204310417175,
          0.2264128029346466,
          0.11080196499824524,
          -0.17343467473983765,
          0.29118919372558594,
          -1.1267421245574951,
          -0.3044576644897461,
          -0.059872422367334366,
          0.31389158964157104,
          -0.6966202259063721,
          -0.4028753638267517,
          -0.5227566957473755,
          -0.1206832230091095,
          -0.3206574618816376,
          0.1420971006155014,
          -0.41590720415115356,
          0.7835706472396851,
          0.11994057893753052,
          0.3348013460636139,
          -0.3595588207244873,
          0.3932972848415375,
          -0.22251252830028534,
          -0.034668345004320145,
          -0.20812071859836578,
          0.5717494487762451,
          -0.29982393980026245,
          -1.120534896850586,
          -0.38254493474960327,
          -0.4883548617362976,
          0.05954007804393768,
          -0.6566353440284729,
          -0.08519445359706879,
          0.3783789873123169,
          -0.09086307883262634,
          -0.4148678481578827,
          0.9997379183769226,
          0.17442256212234497,
          0.5383951663970947,
          -0.5952969193458557,
          0.43916410207748413,
          -0.09344261884689331,
          -1.3598939180374146,
          0.6777542233467102,
          0.3968283236026764,
          0.015434911474585533,
          -0.5143194794654846,
          -0.024916021153330803,
          0.07130741328001022,
          -0.20925846695899963,
          -0.04438773915171623,
          0.4384942054748535,
          0.7166059613227844,
          -0.4848453402519226,
          0.6655091047286987,
          -0.5493840575218201,
          -0.019295044243335724,
          0.3455500304698944,
          0.8083406686782837,
          -0.7215207815170288,
          0.9772668480873108,
          -1.1056801080703735,
          0.058774832636117935,
          0.20048820972442627,
          -0.7960096001625061,
          -0.29774197936058044,
          -0.1420905888080597,
          -0.44519880414009094,
          0.14334404468536377,
          0.30278483033180237,
          -0.09984242916107178,
          0.3654993772506714,
          0.2544008493423462,
          0.7040207982063293,
          0.1378961205482483,
          -0.2684752345085144,
          -0.06693889200687408,
          0.0882856696844101,
          0.0789681077003479,
          -0.12171584367752075,
          0.411969929933548,
          -0.429595947265625,
          -0.12175975739955902,
          0.1602828949689865,
          0.8203263878822327,
          -0.4474356174468994,
          0.018988989293575287,
          -0.34053128957748413,
          -0.42703282833099365,
          -0.21583673357963562,
          0.8750926852226257,
          0.08286654204130173,
          -0.21795785427093506,
          0.27084779739379883,
          0.3644651472568512,
          -0.09925734996795654,
          0.02413693070411682,
          0.1827176958322525,
          -0.03062882274389267,
          0.5380882024765015,
          1.2365520000457764,
          0.1108255609869957,
          0.5566019415855408,
          -0.03710492327809334,
          -0.37750402092933655,
          -0.9765657186508179,
          0.4224688410758972,
          -0.660115659236908,
          0.8154804110527039,
          0.6530510187149048,
          0.4215526282787323,
          -0.5090237259864807,
          -0.004225388169288635,
          0.3608284592628479,
          -0.3876489996910095,
          0.037850357592105865,
          0.663054347038269,
          -0.19248977303504944,
          -0.0731290727853775,
          -1.083500862121582,
          0.49009087681770325,
          -0.2547559440135956,
          0.5122596025466919,
          -0.6523280739784241,
          0.3019230365753174,
          0.2820277810096741,
          -0.45103055238723755,
          0.12896715104579926,
          0.21499958634376526,
          -0.37876197695732117,
          0.5977708101272583,
          0.19242674112319946,
          0.5607881546020508,
          0.37699365615844727,
          -0.11772117018699646,
          0.40289053320884705,
          0.0131264328956604,
          -0.4846796691417694,
          -0.42067334055900574,
          -0.8404120206832886,
          0.11386841535568237,
          -0.12299686670303345,
          0.5795705318450928,
          0.6025887727737427,
          -0.01781030185520649,
          -0.40973833203315735,
          -0.5275158286094666,
          0.42510929703712463,
          0.9421080350875854,
          -0.744377076625824,
          0.6845294237136841,
          -0.18946786224842072,
          0.42914846539497375,
          -0.7286233901977539,
          1.010221242904663,
          0.5582801699638367,
          -0.539038360118866,
          -0.6009818315505981,
          0.43157345056533813,
          0.2141752541065216,
          -0.33920934796333313,
          -1.0569124221801758,
          0.28022682666778564,
          0.3305153548717499,
          0.7915661334991455,
          -1.691330909729004,
          0.5705791711807251,
          0.7422077059745789,
          0.9067460298538208,
          -0.18452413380146027,
          -0.10844678431749344,
          0.6592846512794495,
          -0.053071584552526474,
          -0.48074793815612793,
          0.5592246055603027,
          -0.27203890681266785,
          -0.16326871514320374,
          0.3889015018939972,
          0.036837637424468994,
          -0.07448931783437729,
          -0.26337724924087524,
          0.0016360282897949219,
          -0.6610702872276306,
          0.7322627902030945,
          0.5044280886650085,
          -0.2803489863872528,
          0.04877621680498123,
          0.41054922342300415,
          0.4356166124343872,
          -0.31522437930107117,
          0.594971239566803,
          0.785426139831543,
          0.06978441029787064,
          0.979132354259491,
          1.1198731660842896,
          0.0899750292301178,
          0.08546744287014008,
          0.5347898006439209,
          0.01613401621580124,
          0.17454591393470764,
          0.9573559165000916,
          -0.32491573691368103,
          0.6116234064102173,
          0.1455208659172058,
          -0.04690169170498848,
          -0.0009291879832744598,
          0.18601633608341217,
          -0.4909517765045166,
          1.3533748388290405,
          -0.45403438806533813,
          -0.4162374436855316,
          -1.3966883420944214,
          -0.7871159911155701,
          0.14714795351028442,
          0.28084486722946167,
          -0.9592675566673279,
          -0.7103772759437561,
          -0.7414693832397461,
          0.5837314128875732,
          0.09947054088115692,
          0.07949195802211761,
          0.4073355793952942,
          1.281661868095398,
          -0.06988038122653961,
          -0.3682173490524292,
          -0.368332177400589,
          -0.057060495018959045,
          -1.1038944721221924,
          -0.6755498051643372,
          -1.7020894289016724,
          0.17663262784481049,
          -0.7840335369110107,
          0.05700500309467316,
          0.2501762807369232,
          -1.038845181465149,
          0.10624217242002487,
          0.1535409688949585,
          -0.3725031018257141,
          0.4571133255958557,
          -0.5050835609436035,
          0.15748929977416992,
          0.43004173040390015,
          0.28470999002456665,
          -1.1793960332870483,
          0.6666284799575806,
          -0.10381580889225006,
          0.9811052083969116,
          0.25204917788505554,
          0.44449540972709656,
          -0.3752017915248871,
          0.24307489395141602,
          0.5137918591499329,
          -0.10433519631624222,
          -0.6173412799835205,
          -0.08932599425315857,
          -0.756187915802002,
          -1.0463407039642334,
          0.14966747164726257,
          -0.5406990647315979,
          0.4509759247303009,
          -0.09116769582033157,
          -1.1439099311828613,
          0.6729453206062317,
          0.5396647453308105,
          -0.1302180290222168,
          0.9478042721748352,
          -0.025137707591056824,
          -0.7870760560035706,
          0.8536494970321655,
          0.12293088436126709,
          0.559609591960907,
          -0.6832020282745361,
          1.0325217247009277,
          0.32851195335388184,
          -0.33196648955345154,
          0.12129192054271698,
          -1.3455448150634766,
          -0.5805402398109436,
          0.5733160376548767,
          0.7473182082176208,
          -0.3303331136703491,
          0.0010689906775951385,
          0.3934842050075531,
          0.7807607650756836,
          -1.864137887954712,
          0.32874709367752075,
          -0.36520957946777344,
          -1.388792872428894,
          -0.1262526512145996,
          0.12202306091785431,
          0.8046860694885254,
          0.0136711485683918,
          0.508653998374939,
          -0.7735822200775146,
          -0.4107179343700409,
          -0.7976816296577454,
          0.17247557640075684,
          -0.04891116917133331,
          -0.6132520437240601,
          0.21533259749412537,
          0.8909083604812622,
          -0.7035276293754578,
          -0.4519936144351959,
          -0.16823767125606537,
          -0.13518108427524567,
          0.6354045867919922,
          -0.241958349943161,
          -0.3495897650718689,
          0.5508615374565125,
          -0.26179584860801697,
          -0.7057039141654968,
          -0.007414907217025757,
          0.06338170170783997,
          -0.28000909090042114,
          0.10123984515666962,
          0.26390933990478516,
          0.29291975498199463,
          0.33218151330947876,
          0.8385054469108582,
          0.24137268960475922,
          -0.10907290130853653,
          -0.4929282069206238,
          -0.4631401300430298,
          -0.5271886587142944,
          -0.07505790144205093,
          0.8003438711166382,
          -0.9897128939628601,
          0.5516899824142456,
          -0.22795039415359497,
          -0.04318768158555031,
          0.586133599281311,
          -0.7092081904411316,
          -1.2326635122299194,
          0.8696824312210083,
          -0.1549420803785324,
          1.9299204349517822,
          -0.7407761216163635,
          -0.2734297513961792,
          0.461445152759552,
          0.6867027282714844,
          0.267894983291626,
          -0.06486275047063828,
          0.7559146285057068,
          -0.2770862579345703,
          0.016271017491817474,
          -0.18065135180950165,
          0.14076799154281616,
          -0.3679092824459076,
          -0.029587671160697937,
          -0.520075261592865,
          0.524004340171814,
          -0.5508861541748047,
          -0.2735542058944702,
          1.2317235469818115,
          0.23331713676452637,
          0.36922305822372437,
          0.029559262096881866,
          1.2364856004714966,
          -0.6744018197059631,
          0.32094860076904297,
          0.4284304678440094,
          0.7644943594932556,
          0.23746725916862488,
          0.09845137596130371,
          0.012612007558345795,
          -0.9440707564353943,
          -0.08394844830036163,
          0.2855691611766815,
          0.41527897119522095,
          0.16813668608665466,
          0.43117499351501465,
          -0.33439943194389343,
          0.1506558209657669,
          -0.7079689502716064,
          0.16129788756370544,
          -0.49220210313796997,
          0.1823754906654358,
          -0.6605821847915649,
          -0.44259941577911377,
          -0.20800769329071045,
          0.6357393860816956,
          0.05150251090526581,
          0.16991589963436127,
          0.4165283441543579,
          -0.5969924926757812,
          0.5865374803543091,
          -0.053252361714839935,
          -0.7469334602355957,
          -0.38029634952545166,
          0.3666625916957855,
          -0.8322599530220032,
          -0.7959985136985779,
          0.1987963169813156,
          -0.1900249421596527,
          -0.7886655330657959,
          0.4176394045352936,
          -0.4724954068660736,
          0.22269412875175476,
          -0.010726943612098694,
          0.5476884245872498,
          0.5885454416275024,
          0.1778046190738678,
          0.07106797397136688,
          0.48913559317588806,
          0.23911318182945251,
          -0.129543274641037,
          -0.33204761147499084,
          0.0083171296864748,
          -0.6751130223274231,
          0.00028224289417266846,
          -0.774912416934967,
          -0.2657700777053833,
          0.29639285802841187,
          -0.17063723504543304,
          -0.29138877987861633,
          0.18647122383117676,
          0.25595933198928833,
          0.137162446975708,
          -0.22987517714500427,
          1.2985798120498657,
          -0.3174118399620056,
          -0.5998799204826355,
          0.42321446537971497,
          0.3213661313056946,
          0.6380309462547302,
          0.4503929913043976,
          -0.22151005268096924,
          0.18496200442314148,
          -0.4193800091743469,
          -0.0737932026386261,
          -0.7554270625114441,
          -0.49251580238342285,
          -0.07513701915740967,
          -0.1299923062324524,
          -0.36660805344581604,
          -0.33370986580848694,
          0.0024608001112937927,
          -0.24479396641254425,
          0.053807102143764496,
          -0.3313129246234894,
          0.04459717869758606,
          -0.7940277457237244,
          -0.8207817673683167,
          -0.19664239883422852,
          0.13751563429832458,
          0.30397650599479675,
          0.13484719395637512,
          0.1686077117919922,
          -0.3312086760997772,
          0.4117932617664337,
          -0.21776826679706573,
          -0.3070177435874939,
          0.007793493568897247,
          -0.3189586400985718,
          -0.7025726437568665,
          -0.3630892038345337,
          0.12023317813873291,
          1.6522107124328613,
          -0.31358373165130615,
          -0.9937230348587036,
          -0.15061844885349274,
          0.2831976115703583,
          -0.5160574316978455,
          -0.30104660987854004,
          -0.26683616638183594,
          -0.2513790726661682,
          -0.13628694415092468,
          0.10730969905853271,
          -0.328304648399353,
          0.4658621549606323,
          0.18580226600170135,
          1.0222476720809937,
          0.4035486876964569,
          0.586392343044281,
          -0.392909973859787,
          -0.381149023771286,
          0.397018164396286,
          0.43046748638153076,
          -0.6160931587219238,
          -0.938546895980835,
          0.5924586057662964,
          -0.671849250793457,
          -0.030594967305660248,
          0.49697673320770264,
          -0.47322890162467957,
          -0.08552683889865875,
          -0.5154010057449341,
          -0.01328585296869278,
          -0.6508222222328186,
          -0.6517535448074341,
          -0.6215465068817139,
          0.5599926114082336,
          0.4320487976074219,
          0.21459509432315826,
          0.7368166446685791,
          -0.038313671946525574,
          -0.005403149873018265,
          -1.2772586345672607,
          0.5539148449897766,
          0.02083554118871689,
          -0.4132383465766907,
          0.2610629200935364,
          -0.28323569893836975,
          -0.061983585357666016,
          1.678134560585022,
          -0.053674716502428055,
          -0.005969792604446411,
          -0.3655911087989807,
          0.019865967333316803,
          0.1796402931213379,
          0.45226040482521057,
          -0.8161991238594055,
          -0.240797221660614,
          0.2119179517030716,
          -0.0042396653443574905,
          0.6235150098800659,
          -0.17103545367717743,
          -0.1724613755941391,
          0.1447434425354004,
          -0.7637237310409546,
          -0.6988251209259033,
          -0.29167690873146057,
          -0.05131349712610245,
          -0.3707725405693054,
          -0.4247575104236603,
          0.9661903977394104,
          -0.6911845803260803,
          -0.6030319333076477,
          -0.1085737869143486,
          1.1612094640731812,
          -0.2875910997390747,
          0.12681534886360168,
          -1.5160235166549683,
          -0.05532360076904297,
          -1.0693845748901367,
          -0.5466316938400269,
          -0.031525060534477234,
          -0.23071138560771942,
          0.4410228729248047,
          -0.33467093110084534,
          -0.4447883367538452,
          0.7146366238594055,
          -0.9655458927154541,
          1.5202945470809937,
          0.6963907480239868,
          -0.00020018592476844788,
          -0.0601608008146286,
          -0.08180627226829529,
          -0.165289044380188,
          0.3504384160041809,
          -0.3664397597312927,
          0.19823148846626282,
          -0.414390504360199,
          0.04572753608226776,
          -0.2658267617225647,
          -0.12107963860034943,
          -0.4669094383716583,
          -0.3612828850746155,
          0.08757060766220093,
          1.2430219650268555,
          -1.1281541585922241,
          0.5327585935592651,
          0.6553926467895508,
          -0.42971110343933105,
          -1.4910651445388794,
          0.13501837849617004,
          -0.25869661569595337,
          -0.1330198347568512,
          0.520214319229126,
          -0.3040703237056732,
          0.38262099027633667,
          -0.2309231460094452,
          0.16844803094863892,
          -0.8570647835731506,
          -0.0818653404712677,
          0.5658519864082336,
          -0.016565632075071335,
          -0.5009867548942566,
          0.029072575271129608,
          1.1652588844299316,
          0.19830060005187988,
          0.4858546257019043,
          0.8929653167724609,
          0.39716842770576477,
          0.3946573734283447,
          -0.3329716920852661,
          0.2978585362434387,
          0.0784858912229538,
          -0.46757176518440247,
          -0.5239024758338928,
          -0.15613988041877747,
          -0.7052354216575623,
          0.059771765023469925,
          0.5135172009468079,
          -0.10130894929170609,
          -0.710168182849884,
          1.5220401287078857,
          0.7760187983512878,
          0.1279044896364212,
          0.34667807817459106,
          0.018470142036676407,
          -0.09625345468521118,
          -0.03135065361857414,
          -0.976806640625,
          0.5705893635749817,
          -0.3984382748603821,
          -0.25177690386772156,
          1.0310943126678467,
          -0.14629994332790375,
          0.43122825026512146,
          -0.7999454140663147,
          -0.6287629008293152,
          0.2160693109035492,
          0.038763098418712616,
          -0.8334206938743591,
          -0.24711361527442932,
          0.25847214460372925,
          0.06325270235538483,
          1.2279046773910522,
          -0.2736490070819855,
          0.4124723970890045,
          1.22884202003479,
          0.11091001331806183,
          -0.010846138000488281,
          -1.2213770151138306,
          0.04122950881719589,
          -0.7974616885185242,
          -0.294321745634079,
          0.013105833902955055,
          0.20930150151252747,
          0.04202764853835106,
          -0.3035532534122467,
          0.3391968011856079,
          -0.07782948017120361,
          -0.5304278135299683,
          1.1351978778839111,
          -1.2973960638046265,
          0.3445760905742645,
          0.10291942209005356,
          0.5111168622970581,
          -0.3930072784423828,
          -1.1182546615600586,
          0.46899327635765076,
          -0.31949037313461304,
          -0.18384933471679688,
          0.5452273488044739,
          0.5505509376525879,
          -0.14456555247306824,
          0.3226418197154999,
          0.1231890320777893,
          0.1918662190437317,
          -0.5288635492324829,
          -0.9096724987030029,
          -0.1356881856918335,
          -0.12875986099243164,
          0.27505823969841003,
          -0.03379102051258087,
          0.07297530025243759,
          -0.1074603870511055,
          0.32252055406570435,
          -0.21164914965629578,
          0.21514162421226501,
          -0.07806017994880676,
          -0.4553939998149872,
          -0.03734578564763069,
          1.0311007499694824,
          -0.6968278288841248,
          -0.19189301133155823,
          -0.22299574315547943,
          0.36362457275390625,
          -0.7553998231887817,
          -0.133712038397789,
          0.8645833730697632,
          -0.5096681714057922,
          -0.1767369508743286,
          -0.5942632555961609,
          0.8075889945030212,
          1.0120769739151,
          0.5684036016464233,
          0.7191976308822632,
          -0.2191661298274994,
          0.6810204386711121,
          0.15623605251312256,
          0.01499301940202713,
          0.989978015422821,
          0.03269774466753006,
          -0.35190919041633606,
          -0.9523422718048096,
          0.035012636333703995,
          -0.10846593976020813,
          -0.9138882160186768,
          -0.042781829833984375,
          0.8651164174079895,
          -0.7844728231430054,
          -1.6168180704116821,
          0.469868004322052,
          -0.14526665210723877,
          0.7560703754425049,
          0.24205756187438965,
          0.294432133436203,
          -0.04390362650156021,
          0.07806715369224548,
          -0.4934332072734833,
          0.5895298719406128,
          -0.09434971958398819,
          -0.22013577818870544,
          0.42341452836990356,
          -0.010419242084026337,
          -0.8608753085136414,
          0.1798829734325409,
          -0.21324533224105835,
          0.35372212529182434,
          0.1225493997335434,
          0.7716878056526184,
          0.011883623898029327,
          0.6431961059570312,
          0.4375395178794861,
          0.05438397079706192,
          -0.39504528045654297,
          -0.7461667060852051,
          -0.6232610940933228,
          0.03233838826417923,
          -0.4302762746810913,
          -0.3272882103919983,
          0.5246821641921997,
          0.2585395872592926,
          0.12895958125591278,
          0.14862167835235596,
          -1.1306047439575195,
          -0.08934738487005234,
          -0.14292724430561066,
          0.1412625014781952,
          -0.5966926217079163,
          0.3354334831237793,
          -0.8456604480743408,
          -0.319715291261673,
          0.40369194746017456,
          0.11066466569900513,
          -0.8729254007339478,
          0.2950833737850189,
          0.48662927746772766,
          -0.5844513773918152,
          -0.18167972564697266,
          -0.18188916146755219,
          0.28217971324920654,
          -0.5436222553253174,
          0.3027989864349365,
          -0.11147840321063995,
          0.25544625520706177,
          0.9166747331619263,
          0.37597864866256714,
          -0.2704644203186035,
          0.1568177044391632,
          0.2285664975643158,
          -0.3522942364215851,
          -0.24469855427742004,
          0.895488440990448,
          0.9798394441604614,
          -0.5661433935165405,
          0.30479711294174194,
          0.5609574317932129,
          -0.29116693139076233,
          -0.09024465084075928,
          -0.36409586668014526,
          -0.8161674737930298,
          1.3408563137054443,
          -0.36533480882644653,
          -0.7370079159736633,
          0.2721954584121704,
          -0.6427499651908875,
          -0.45467862486839294,
          -0.036354608833789825,
          -1.0810776948928833,
          0.5621243715286255,
          -0.6385648250579834,
          -0.6304371356964111,
          -0.7587661147117615,
          0.3410266041755676,
          0.04295062646269798,
          0.1995084434747696,
          1.0624761581420898,
          0.15139493346214294,
          0.962817370891571,
          -0.17777042090892792,
          0.2231033742427826,
          0.46756088733673096,
          -0.10076342523097992,
          0.4400545358657837,
          -0.05404956638813019,
          -0.06028304249048233,
          -0.14307862520217896,
          0.7404569387435913,
          0.9456260800361633,
          -0.26959094405174255,
          -0.30154234170913696,
          0.7893853187561035,
          0.2454690933227539,
          -0.8476642966270447,
          0.8093914985656738,
          -0.44670745730400085,
          -0.5013561248779297,
          -0.640186071395874,
          0.3731546401977539,
          -0.3145442306995392,
          -0.11437083780765533,
          0.4590268135070801,
          -0.80583655834198,
          0.2874382436275482,
          0.3494231104850769,
          -0.01481674611568451,
          0.7370748519897461,
          0.21777105331420898,
          0.7682595252990723,
          -0.2614476680755615,
          1.2095237970352173,
          1.1248856782913208,
          -0.5460376739501953,
          -0.7730520963668823,
          0.037418171763420105,
          1.1049662828445435,
          -0.6588671803474426,
          -0.46287134289741516,
          -0.3391556441783905,
          0.3573927879333496,
          -0.5683369040489197,
          -0.5952023863792419,
          0.7614993453025818,
          0.07713013887405396,
          0.1234288290143013,
          0.6539278626441956,
          -0.27942824363708496,
          0.23698683083057404,
          -0.29396501183509827,
          0.06527721881866455,
          0.21971538662910461,
          0.10611450672149658,
          0.3872095048427582,
          0.5058680772781372,
          0.14128711819648743,
          -0.9010516405105591,
          0.19708086550235748,
          -0.9014477729797363,
          0.24319206178188324,
          -0.32579609751701355,
          -0.3773932456970215,
          0.49113917350769043,
          -1.2250467538833618,
          -0.0857553631067276,
          -0.7444731593132019,
          0.30895134806632996,
          -0.862066388130188,
          0.097282774746418,
          0.3872458040714264,
          0.22092384099960327,
          0.6885477900505066,
          -0.9929336309432983,
          -0.16392874717712402,
          1.0523653030395508,
          0.21478751301765442,
          0.552765965461731,
          1.199847936630249,
          0.7459079027175903,
          0.20934228599071503,
          0.18110595643520355,
          0.1520259976387024,
          0.5663588643074036,
          0.06071373075246811,
          -1.1161220073699951,
          -0.33008453249931335,
          0.448037713766098,
          0.16161856055259705,
          -0.8662916421890259,
          0.36809027194976807,
          1.416189193725586,
          0.40950655937194824,
          -0.628441333770752,
          -0.9716353416442871,
          0.09567835927009583,
          -0.4270581901073456,
          0.4883902072906494,
          -0.868103563785553,
          0.99577397108078,
          0.18796907365322113,
          -0.7632049322128296,
          -0.2717170715332031,
          -0.7735457420349121,
          3.7999320030212402,
          1.0708463191986084,
          0.8853999376296997,
          -0.3175923824310303,
          0.4185732305049896,
          0.8951917290687561,
          0.10830532014369965,
          -0.11078567802906036,
          0.4776371717453003,
          0.21714745461940765,
          0.4509129226207733,
          -0.5816876888275146,
          0.49170762300491333,
          0.8524112105369568,
          -0.03284159302711487,
          0.43760743737220764,
          -1.1961809396743774,
          0.06861011683940887,
          -0.25870823860168457,
          -0.3489682674407959,
          -0.4415546953678131,
          -0.08512312173843384,
          -0.25821763277053833,
          -0.31897929310798645,
          0.4929807186126709,
          0.09888076782226562,
          -0.3066934645175934,
          0.13492146134376526,
          0.2252676784992218,
          -0.1117381751537323,
          -0.29705917835235596,
          -0.5222057104110718,
          -0.06001186743378639,
          -0.4377654492855072,
          -0.16149842739105225,
          0.5593975782394409,
          -0.2299879789352417,
          -1.299453616142273,
          -0.09230412542819977,
          0.9389898777008057,
          0.19330987334251404,
          -0.6020939946174622,
          0.05298994854092598,
          -0.4610382318496704,
          0.30697742104530334,
          0.9475796222686768,
          0.42928504943847656,
          -0.0006164386868476868,
          0.7812319993972778,
          -0.4018474817276001,
          0.20660680532455444,
          -0.8932991623878479,
          -0.10630775988101959,
          -0.7391958832740784,
          -0.7001811861991882,
          -0.800772488117218,
          -0.43295371532440186,
          -0.7646387815475464,
          -0.5866986513137817,
          0.6535106897354126,
          0.3090837299823761,
          -0.18076753616333008,
          -0.11718957126140594,
          0.13848631083965302,
          0.2869676649570465,
          -0.5382862687110901,
          0.822949230670929,
          0.5147457718849182,
          -0.3929700553417206,
          -0.39241230487823486,
          0.2146252989768982,
          0.2657260000705719,
          -0.44127607345581055,
          0.1008242666721344,
          -0.2414611577987671,
          -0.24850201606750488,
          -0.29388412833213806,
          0.21623148024082184,
          0.0645778626203537,
          -0.3136228621006012,
          -0.036980584263801575,
          0.24833598732948303,
          -0.40300676226615906,
          0.07432772219181061,
          0.3778091073036194,
          0.907302975654602,
          0.11693035066127777,
          0.2916889488697052,
          -0.6754310727119446,
          0.567201554775238,
          -0.20266279578208923,
          -0.03443668782711029,
          0.2361733317375183,
          0.3126569092273712,
          -0.2614167630672455
        ]
      },
      "type": "document"
    },
    {
      "id": "0587e7ff-2d57-43a7-badd-5efc09f98b5e",
      "properties": {
        "page_content": "for Computational Linguistics, pages 6086–6096, Florence, Italy, July 2019. Association for\nComputational Linguistics. doi: 10.18653/v1/P19-1612. URL https://www.aclweb.org/\nanthology/P19-1612.\n[32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,\nOmer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence\npre-training for natural language generation, translation, and comprehension. arXiv preprint\narXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.\n[33] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting\nobjective function for neural conversation models. In Proceedings of the 2016 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 110–119, San Diego, California, June 2016. Association for Computational\nLinguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/\nN16-1014.\n[34] Margaret Li, Jason Weston, and Stephen Roller. Acute-eval: Improved dialogue evaluation\nwith optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL\nhttps://arxiv.org/abs/1909.03087.\n[35] Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He. Robust neural machine\ntranslation with joint textual and phonetic embedding. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics, pages 3044–3049, Florence, Italy,\nJuly 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL\nhttps://www.aclweb.org/anthology/P19-1291.\n[36] Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser,\nand Noam Shazeer. Generating wikipedia by summarizing long sequences. In International\nConference on Learning Representations, 2018. URL https://openreview.net/forum?\nid=Hyg0vbWC-.\n[37] Yury A. Malkov and D. A. Yashunin. Efﬁcient and robust approximate nearest neighbor search\nusing hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 42:824–836, 2016. URL https://arxiv.org/abs/1603.09320.\n[38] Gary Marcus. The next decade in ai: four steps towards robust artiﬁcial intelligence. arXiv\npreprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.\n[39] Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis\nPlachouras, Fabrizio Silvestri, and Sebastian Riedel. How decoding strategies affect the\nveriﬁability of generated text. arXiv preprint arXiv:1911.03587 , 2019. URL https:\n//arxiv.org/abs/1911.03587.\n[40] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia,\nBoris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. Mixed\nprecision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.\n[41] Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploit-\ning background knowledge for building conversation systems. In Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing, pages 2322–2332, Brus-\nsels, Belgium, October-November 2018. Association for Computational Linguistics. doi:\n10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.\n[42] Preksha Nema and Mitesh M. Khapra. Towards a better metric for evaluating question generation\nsystems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language\nProcessing, pages 3950–3959, Brussels, Belgium, October-November 2018. Association for\nComputational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/\nanthology/D18-1429.\n[43] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder,\nand Li Deng. MS MARCO: A human generated machine reading comprehension dataset. In\nTarek Richard Besold, Antoine Bordes, Artur S. d’Avila Garcez, and Greg Wayne, editors,\nProceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic\n13",
        "document_metadata": {
          "page_label": "13",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "b403853f-216a-47d5-ba2f-746ac240e7db",
      "properties": {
        "page_content": "approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing\nSystems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop\nProceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_\n2016_paper9.pdf.\n[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint\narXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.\n[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier,\nand Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings\nof the 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota, June 2019. Association\nfor Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb.\norg/anthology/N19-4009.\n[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun\nCho. Finding generalizable evidence by learning to convince q&a models. In Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pages\n2402–2411, Hong Kong, China, November 2019. Association for Computational Linguistics.\ndoi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\n[47] Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,\nand Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019\nConference on Empirical Methods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473, Hong\nKong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/\nD19-1250. URL https://www.aclweb.org/anthology/D19-1250.\n[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H.\nMiller, and Sebastian Riedel. How context affects language models’ factual predictions. In\nAutomated Knowledge Base Construction, 2020. URL https://openreview.net/forum?\nid=025X0zPfn.\n[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Im-\nproving Language Understanding by Generative Pre-Training, 2018. URL\nhttps://s3-us-west-2.amazonaws.com/openai-assets/research-covers/\nlanguage-unsupervised/language_understanding_paper.pdf.\n[50] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya\nSutskever. Language models are unsupervised multitask learners, 2019. URL\nhttps://d4mucfpksywv.cloudfront.net/better-language-models/language_\nmodels_are_unsupervised_multitask_learners.pdf.\n[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed\ntext-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.\n[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into\nthe parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/\n2002.08910.\n[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and\nbeyond. Found. Trends Inf. Retr., 3(4):333–389, April 2009. ISSN 1554-0669. doi: 10.1561/\n1500000019. URL https://doi.org/10.1561/1500000019.\n[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-V oss, Jeff Wu, Alec\nRadford, and Jian-Bing Wang. Release strategies and the social impacts of language models.\nArXiv, abs/1908.09203, 2019.\n[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory net-\nworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,Advances\nin Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015.\nURL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf .\n14",
        "document_metadata": {
          "page_label": "14",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "611573d8-288b-4072-8228-ba289ba09294",
      "properties": {
        "page_content": "[56] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a\nlarge-scale dataset for fact extraction and VERiﬁcation. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers), pages 809–819, New Orleans, Louisiana,\nJune 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL\nhttps://www.aclweb.org/anthology/N18-1074.\n[57] James H. Thorne and Andreas Vlachos. Avoiding catastrophic forgetting in mitigating model\nbiases in sentence-pair classiﬁcation with elastic weight consolidation. ArXiv, abs/2004.14366,\n2020. URL https://arxiv.org/abs/2004.14366.\n[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nŁ ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V . Luxburg,\nS. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors,Advances in Neural\nInformation Processing Systems 30, pages 5998–6008. Curran Associates, Inc., 2017. URL\nhttp://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf .\n[59] Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David\nCrandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes.\nAAAI Conference on Artiﬁcial Intelligence, 2018. URL https://www.aaai.org/ocs/index.\nphp/AAAI/AAAI18/paper/view/17329.\n[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman.\nGLUE: A multi-task benchmark and analysis platform for natural language understanding.\nIn Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting\nNeural Networks for NLP, pages 353–355, Brussels, Belgium, November 2018. Association for\nComputational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/\nanthology/W18-5446.\n[61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. SuperGLUE: A Stickier Benchmark for General-\nPurpose Language Understanding Systems. In H. Wallach, H. Larochelle, A. Beygelzimer,\nF. d\\textquotesingle Alché-Buc, E. Fox, and R. Garnett, editors,Advances in Neural Information\nProcessing Systems 32, pages 3261–3275. Curran Associates, Inc., 2019. URL https://\narxiv.org/abs/1905.00537.\n[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang,\nGerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain\nquestion answering. In Sheila A. McIlraith and Kilian Q. Weinberger, editors, Proceedings of\nthe Thirty-Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-18), the 30th innovative\nApplications of Artiﬁcial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational\nAdvances in Artiﬁcial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7,\n2018, pages 5981–5988. AAAI Press, 2018. URL https://www.aaai.org/ocs/index.\nphp/AAAI/AAAI18/paper/view/16712.\n[63] Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang,\nTim Klinger, Gerald Tesauro, and Murray Campbell. Evidence aggregation for answer re-\nranking in open-domain question answering. In ICLR, 2018. URL https://openreview.\nnet/forum?id=rJl3yM-Ab.\n[64] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Yoshua Bengio\nand Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR\n2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings , 2015. URL\nhttp://arxiv.org/abs/1410.3916.\n[65] Jason Weston, Emily Dinan, and Alexander Miller. Retrieve and reﬁne: Improved sequence\ngeneration models for dialogue. In Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd\nInternational Workshop on Search-Oriented Conversational AI, pages 87–92, Brussels, Belgium,\nOctober 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5713. URL\nhttps://www.aclweb.org/anthology/W18-5713.\n15",
        "document_metadata": {
          "page_label": "15",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "023ae277-0465-474b-8b00-cfe4a527743f",
      "properties": {
        "page_content": "[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony\nMoi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer,\nPatrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain\nGugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface’s transformers:\nState-of-the-art natural language processing. ArXiv, abs/1910.03771, 2019.\n[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi-\nsupervised question answering. In Proceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP) , pages 2495–2509, Hong Kong, China, Novem-\nber 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL\nhttps://www.aclweb.org/anthology/D19-1253.\n[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and\nJian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019.\nURL https://arxiv.org/abs/1909.03745.\n16",
        "document_metadata": {
          "page_label": "16",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "themes": [
          "Artificial Intelligence",
          "Automation",
          "Data Analysis",
          "Innovation",
          "Self-driving Cars",
          "Personalized Recommendations",
          "Natural Language Processing",
          "Question Generation",
          "Semi-supervised Question Answering",
          "Semantic Drift",
          "Fact Checking",
          "Graph Reasoning"
        ]
      },
      "type": "document"
    },
    {
      "id": "26a5cf08-b882-4f1c-afa7-85027dee0f11",
      "properties": {
        "page_content": "Appendices for Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks\nA Implementation Details\nFor Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models.\nFor RAG-Sequence models, we report test results using 50 retrieved documents, and we use the\nThorough Decoding approach since answers are generally short. We use greedy decoding for QA as\nwe did not ﬁnd beam search improved results. For Open-MSMarco and Jeopardy question generation,\nwe report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence,\nand we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast\nDecoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.\nB Human Evaluation\nFigure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions\nand a worked example appear when clicking \"view tool guide\".\nFigure 4 shows the user interface for human evaluation. To avoid any biases for screen position,\nwhich model corresponded to sentence A and sentence B was randomly selected for each example.\nAnnotators were encouraged to research the topic using the internet, and were given detailed instruc-\ntions and worked examples in a full instructions tab. We included some gold sentences in order to\nassess the accuracy of the annotators. Two annotators did not perform well on these examples and\ntheir annotations were removed from the results.\nC Training setup Details\nWe train all RAG models and BART baselines using Fairseq [45].2 We train with mixed precision\nﬂoating point arithmetic [40], distributing training across 8, 32GB NVIDIA V100 GPUs, though\ntraining and inference can be run on one GPU. We ﬁnd that doing Maximum Inner Product Search\nwith FAISS is sufﬁciently fast on CPU, so we store document index vectors on CPU, requiring∼100\nGB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace\nTransformers [66]3, which achieves equivalent performance to the previous version but is a cleaner\nand easier to use implementation. This version is also open-sourced. We also compress the document\nindex using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to\nrun experiments with RAG can be found athttps://github.com/huggingface/transformers/\nblob/master/examples/rag/README.md and an interactive demo of a RAG model can be found\nat https://huggingface.co/rag/\n2https://github.com/pytorch/fairseq\n3https://github.com/huggingface/transformers\n17",
        "document_metadata": {
          "page_label": "17",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing vast amounts of data. AI is driving innovations in self-driving cars, personalized recommendations, and knowledge-intensive NLP tasks like Open-domain QA, Open-MSMarco, and Jeopardy question generation.",
        "summary_embedding": [
          0.28273504972457886,
          0.4883143901824951,
          -0.7173258662223816,
          -0.6628891229629517,
          0.1486896276473999,
          -0.03617054969072342,
          -0.15412041544914246,
          -0.14570356905460358,
          0.2868398427963257,
          0.29168713092803955,
          0.22221340239048004,
          0.21219012141227722,
          -0.3825528919696808,
          -1.1579965353012085,
          0.26198428869247437,
          -0.1466563194990158,
          -0.08826319873332977,
          -0.03372303768992424,
          0.2851622700691223,
          -0.19029992818832397,
          -0.23664233088493347,
          0.6558727622032166,
          -0.5422330498695374,
          -0.48672789335250854,
          -1.1568394899368286,
          0.5978264212608337,
          0.693135678768158,
          -0.21197274327278137,
          0.6252393126487732,
          0.611061155796051,
          -0.1740179806947708,
          -0.025935299694538116,
          -0.03482081741094589,
          -0.515080451965332,
          -0.6489332914352417,
          -0.3965451121330261,
          0.44741302728652954,
          -0.07895021885633469,
          -0.9162542819976807,
          -0.577549159526825,
          -0.2833746075630188,
          -0.19165095686912537,
          0.2795432209968567,
          -1.1796480417251587,
          -1.1767865419387817,
          0.4512990713119507,
          0.7175167202949524,
          -1.2435426712036133,
          -0.1827152520418167,
          -0.2892187237739563,
          -0.41635942459106445,
          0.26592308282852173,
          -0.21965807676315308,
          -0.1752009093761444,
          0.15311497449874878,
          -1.0209941864013672,
          -0.49637383222579956,
          -0.19744035601615906,
          -0.6314728260040283,
          -0.34826451539993286,
          1.2562745809555054,
          -0.029891006648540497,
          0.3683710992336273,
          -0.1205584853887558,
          -0.10580887645483017,
          0.2825331389904022,
          0.11815637350082397,
          -0.6368861794471741,
          -0.2590043842792511,
          -0.03051074594259262,
          -1.2053604125976562,
          0.0029897335916757584,
          0.3661099672317505,
          0.12744784355163574,
          -0.6684339046478271,
          -0.047842033207416534,
          0.4889751374721527,
          -0.06414831429719925,
          -0.7244518399238586,
          -0.07527878880500793,
          -0.33521348237991333,
          0.9267970323562622,
          -0.06496851146221161,
          0.6156395673751831,
          0.19488123059272766,
          -0.5308423042297363,
          0.7629460692405701,
          0.8218730092048645,
          -0.24101504683494568,
          -0.7379756569862366,
          -0.2659566104412079,
          -0.10172192007303238,
          -0.15476791560649872,
          0.1524774432182312,
          0.227756068110466,
          0.7831743359565735,
          -0.47916877269744873,
          0.5134660005569458,
          0.07890364527702332,
          0.08849908411502838,
          0.5093348622322083,
          0.8785773515701294,
          -0.19851061701774597,
          0.7778089046478271,
          -1.0205031633377075,
          0.10524764657020569,
          0.44758620858192444,
          -0.5749932527542114,
          0.32047173380851746,
          -0.8016420006752014,
          0.4291623830795288,
          0.2793261706829071,
          -0.19760262966156006,
          -0.045471370220184326,
          -0.4934821128845215,
          1.3557521104812622,
          -0.36459454894065857,
          0.15632764995098114,
          -0.40804460644721985,
          0.14331673085689545,
          -0.4332912564277649,
          -0.5526138544082642,
          0.13367094099521637,
          -0.10402517765760422,
          0.0679573267698288,
          -0.9999945163726807,
          -0.2975507080554962,
          0.6373729109764099,
          -0.7134222388267517,
          0.5838317275047302,
          0.07351615279912949,
          0.23509147763252258,
          -0.06317747384309769,
          0.8857632875442505,
          -0.23423388600349426,
          -0.7488169074058533,
          0.09207847714424133,
          1.0258710384368896,
          -0.210860013961792,
          0.5992709398269653,
          0.24112451076507568,
          0.06407752633094788,
          -0.32049253582954407,
          1.4829802513122559,
          -0.04089696332812309,
          -0.28398293256759644,
          -0.38590604066848755,
          0.13838200271129608,
          -0.5763769149780273,
          0.7013335824012756,
          -0.9558308124542236,
          0.4089667499065399,
          0.4636949896812439,
          0.10955264419317245,
          -0.8941792845726013,
          -0.8122900128364563,
          -0.4378564953804016,
          -0.1425287276506424,
          0.8021683692932129,
          0.43212035298347473,
          -0.4639616906642914,
          0.16698285937309265,
          -0.42611557245254517,
          1.0760505199432373,
          -0.43398433923721313,
          0.5942527055740356,
          -0.6087261438369751,
          0.1348731517791748,
          -0.4298018515110016,
          -0.4281090795993805,
          0.22189277410507202,
          -0.4755585491657257,
          -0.38776853680610657,
          0.2536312937736511,
          0.6562729477882385,
          0.9536263346672058,
          0.8246648907661438,
          -0.025478456169366837,
          0.09335703402757645,
          -0.37966418266296387,
          -1.0791287422180176,
          -0.41195419430732727,
          -0.9020344614982605,
          -0.10980863869190216,
          -0.018803168088197708,
          0.6524885892868042,
          0.04559122771024704,
          0.421660840511322,
          0.3775672912597656,
          -0.3181006610393524,
          0.32702451944351196,
          0.7509984970092773,
          -0.8246872425079346,
          -0.10900400578975677,
          0.052515484392642975,
          0.6783661246299744,
          -0.643272876739502,
          0.5993617177009583,
          0.40489137172698975,
          -0.23611153662204742,
          -0.1843509078025818,
          0.9205740690231323,
          0.10103118419647217,
          -0.3985966444015503,
          -0.33603060245513916,
          1.0081920623779297,
          -0.238980233669281,
          0.8419325947761536,
          -1.559352159500122,
          1.4496909379959106,
          0.43295183777809143,
          0.604720950126648,
          -0.030859896913170815,
          -0.12715750932693481,
          0.9166349172592163,
          -0.02010788768529892,
          -0.7415631413459778,
          0.2574838697910309,
          0.16840910911560059,
          -0.4630534052848816,
          0.013842172920703888,
          -0.22304591536521912,
          0.5366549491882324,
          -0.18732506036758423,
          -0.16516555845737457,
          -0.20365265011787415,
          -0.16785046458244324,
          0.7338446378707886,
          -0.2559610903263092,
          0.23559825122356415,
          0.9017424583435059,
          0.4971255660057068,
          -0.43586504459381104,
          0.8015137314796448,
          -0.28814762830734253,
          0.05842071771621704,
          0.061657071113586426,
          0.27861812710762024,
          0.1062285378575325,
          -0.21545284986495972,
          0.7194399833679199,
          -0.08186276257038116,
          1.4955642223358154,
          0.4197418987751007,
          -0.4228428304195404,
          0.0818493515253067,
          -0.006465654820203781,
          -0.11624310910701752,
          0.7300779223442078,
          0.5233705043792725,
          -0.6162888407707214,
          0.18020160496234894,
          0.3048786520957947,
          -0.35440582036972046,
          -0.5429679155349731,
          0.5488064289093018,
          0.9777611494064331,
          0.6366177797317505,
          0.16142067313194275,
          -1.2344778776168823,
          -0.697474479675293,
          0.79932701587677,
          0.5200378894805908,
          -0.13806582987308502,
          0.37097153067588806,
          0.31529927253723145,
          -0.29352903366088867,
          -0.06766639649868011,
          -0.769976019859314,
          -0.38121098279953003,
          -1.2834479808807373,
          -1.1141654253005981,
          -0.6181085705757141,
          -0.019879797473549843,
          -0.6701787114143372,
          0.05268232524394989,
          -0.042411357164382935,
          -0.6511106491088867,
          0.29499828815460205,
          -0.35055384039878845,
          -0.33855992555618286,
          -0.2823420763015747,
          -0.6995921730995178,
          0.48863857984542847,
          0.6202774047851562,
          0.5023964643478394,
          -1.156623125076294,
          -0.1182369515299797,
          -0.6859535574913025,
          0.8697482347488403,
          0.6826643943786621,
          0.4278066158294678,
          -0.29816457629203796,
          -0.6008409857749939,
          0.1423988789319992,
          0.005102574825286865,
          0.7797589302062988,
          0.5904954075813293,
          -0.8179770708084106,
          -0.2903202176094055,
          0.21785540878772736,
          0.10926095396280289,
          -0.3456735610961914,
          0.027785874903202057,
          -0.3464454114437103,
          0.7994500994682312,
          0.4248649477958679,
          0.18173782527446747,
          0.9517986178398132,
          0.1353502869606018,
          -1.3492259979248047,
          0.6378246545791626,
          0.13916468620300293,
          0.8051950931549072,
          -0.40180301666259766,
          0.7316240072250366,
          0.4735143482685089,
          -0.6907918453216553,
          0.38586482405662537,
          -1.0892642736434937,
          -0.7154833078384399,
          0.2645527124404907,
          -0.4905455708503723,
          0.28065603971481323,
          0.3793664574623108,
          0.4437651038169861,
          -0.24180254340171814,
          -2.027890920639038,
          0.01774889975786209,
          -0.2132660299539566,
          -0.6766248941421509,
          -0.01877181977033615,
          0.29011785984039307,
          0.768977165222168,
          0.6218068599700928,
          -0.2930435836315155,
          -0.23480182886123657,
          0.08654732257127762,
          -0.3635243773460388,
          0.983788251876831,
          0.6602077484130859,
          -0.23097413778305054,
          0.24501194059848785,
          0.39709997177124023,
          -0.3176245093345642,
          0.7044956684112549,
          1.0909861326217651,
          -0.08473912626504898,
          0.6339142918586731,
          -0.06550058722496033,
          -0.18609772622585297,
          0.3506729304790497,
          -0.6819310188293457,
          -0.49984556436538696,
          0.5389689207077026,
          -0.0620339959859848,
          -0.6127691864967346,
          0.4920229911804199,
          -0.01298745721578598,
          -0.009279197081923485,
          0.25190508365631104,
          0.17953774333000183,
          -0.13649128377437592,
          0.16770242154598236,
          -0.45860257744789124,
          0.1721493899822235,
          -0.2117079496383667,
          0.28256887197494507,
          0.4136795401573181,
          -0.7831483483314514,
          0.37541306018829346,
          -0.3813394010066986,
          -0.09531654417514801,
          0.2937471568584442,
          -0.9538689255714417,
          -1.342661738395691,
          0.42489585280418396,
          -0.7533559799194336,
          0.04265551641583443,
          -0.8955046534538269,
          0.5144835710525513,
          0.04512234032154083,
          -0.15031269192695618,
          -0.16682401299476624,
          -0.3301162123680115,
          0.8044393658638,
          -0.5289282202720642,
          0.6049917936325073,
          -0.1625371277332306,
          0.21674486994743347,
          0.5656957626342773,
          -0.201565682888031,
          -0.418853223323822,
          0.21697697043418884,
          -0.6629928350448608,
          -0.7464247941970825,
          0.8304399847984314,
          -0.017092039808630943,
          0.464961439371109,
          -0.6346359848976135,
          1.0437588691711426,
          -0.3539297878742218,
          0.1129031628370285,
          0.4548555016517639,
          0.12426876276731491,
          0.22163455188274384,
          0.13554565608501434,
          0.5177662968635559,
          0.3898146152496338,
          -0.2331642508506775,
          -0.29904353618621826,
          -0.13502219319343567,
          0.45226043462753296,
          -0.007797686383128166,
          -0.3028704822063446,
          0.3432987332344055,
          -0.11559703946113586,
          -0.14667145907878876,
          -0.5910253524780273,
          0.22324171662330627,
          -0.5597549676895142,
          -0.23370130360126495,
          -0.6825875043869019,
          0.049559008330106735,
          0.4947230815887451,
          -0.06087592989206314,
          -0.2766055166721344,
          -1.052298665046692,
          0.8050069212913513,
          0.6869403719902039,
          -0.6475535035133362,
          -0.5609824061393738,
          0.48959386348724365,
          -0.38684237003326416,
          -0.3628365099430084,
          0.1689090132713318,
          1.338668942451477,
          -1.067729115486145,
          0.7494984269142151,
          -0.0748150646686554,
          0.10884491354227066,
          0.4079679846763611,
          0.604737401008606,
          0.06049008667469025,
          -0.18315814435482025,
          -0.5753300189971924,
          0.15023711323738098,
          0.4384792745113373,
          -0.3674580752849579,
          -0.5403754711151123,
          0.3255789279937744,
          -1.1061651706695557,
          0.7207283973693848,
          -0.5023881196975708,
          0.3497336208820343,
          -0.48826712369918823,
          -0.37340861558914185,
          0.131748765707016,
          0.45261725783348083,
          0.529779314994812,
          0.1409335434436798,
          0.3998273015022278,
          0.8465757966041565,
          -0.9133831262588501,
          -0.44258955121040344,
          0.2476564645767212,
          0.6227993965148926,
          0.38791143894195557,
          0.516441285610199,
          0.23535087704658508,
          -0.001444980502128601,
          -0.1584589034318924,
          0.2946558892726898,
          -0.49711453914642334,
          0.5467110276222229,
          -0.4306916296482086,
          0.3661097288131714,
          0.10625094175338745,
          -0.4389098286628723,
          -0.593368649482727,
          -0.9562622904777527,
          -0.03963879495859146,
          0.21700283885002136,
          0.16996292769908905,
          -0.43959349393844604,
          -0.9293279051780701,
          0.3840695023536682,
          1.2434356212615967,
          -0.08240059018135071,
          0.30851927399635315,
          0.08818616718053818,
          0.28694894909858704,
          0.19639623165130615,
          0.38152605295181274,
          -0.3413010835647583,
          -0.1554052233695984,
          0.10760223865509033,
          0.007322661578655243,
          -0.091916024684906,
          -0.5353050231933594,
          1.2633707523345947,
          -1.2726824283599854,
          -1.0100377798080444,
          0.08699961751699448,
          -0.3296847641468048,
          -0.5504658818244934,
          -0.030878670513629913,
          -0.2920440435409546,
          0.05111153423786163,
          0.3104472756385803,
          0.034833475947380066,
          0.523211658000946,
          0.10949452966451645,
          0.8469704985618591,
          0.7690287232398987,
          -0.12134122848510742,
          0.052324146032333374,
          0.14055460691452026,
          -0.19956402480602264,
          1.2262742519378662,
          0.1847352236509323,
          -0.9359337687492371,
          -0.45570164918899536,
          1.1367969512939453,
          -0.5447860360145569,
          0.18018631637096405,
          0.29480740427970886,
          -0.6319096088409424,
          0.15777315199375153,
          -1.5524097681045532,
          0.29266735911369324,
          -0.4128672480583191,
          -0.07670535147190094,
          -0.26249563694000244,
          0.29255566000938416,
          0.12807179987430573,
          0.6157630681991577,
          0.4290236234664917,
          -0.28196650743484497,
          -0.3370371460914612,
          -0.1352217048406601,
          -0.03657037019729614,
          -0.46341845393180847,
          -0.30306562781333923,
          -0.24824658036231995,
          -0.29536375403404236,
          0.3578811585903168,
          0.53885817527771,
          -0.30074045062065125,
          -0.6093862056732178,
          0.18686552345752716,
          -0.6650837659835815,
          -0.06499040126800537,
          0.3532647490501404,
          -1.1332529783248901,
          -0.09112831950187683,
          0.32949861884117126,
          -0.056514084339141846,
          0.3291788697242737,
          0.8621901273727417,
          -0.604016125202179,
          -0.40226906538009644,
          -0.10913627594709396,
          -0.3659484386444092,
          -0.5676001310348511,
          -0.11468487232923508,
          -1.0688725709915161,
          -0.6775947213172913,
          1.1587084531784058,
          -0.2777753472328186,
          -0.5400654673576355,
          0.2607859969139099,
          0.6308953166007996,
          0.4315720200538635,
          0.502687394618988,
          -0.8150383830070496,
          -0.5107312202453613,
          -0.20834679901599884,
          -0.7942677736282349,
          -0.19134092330932617,
          -0.6644670367240906,
          -0.2011573761701584,
          -0.06571277230978012,
          -0.02485990896821022,
          0.4400562644004822,
          -0.5725864768028259,
          0.38877058029174805,
          1.0599181652069092,
          0.3479732275009155,
          -0.3343057632446289,
          0.139992356300354,
          -0.07736147940158844,
          0.16405454277992249,
          -0.24748508632183075,
          -0.12612926959991455,
          -0.2943568229675293,
          0.13077417016029358,
          -0.7182112336158752,
          -0.11469583213329315,
          -0.5918152332305908,
          -0.21935506165027618,
          0.2573855519294739,
          0.8940338492393494,
          -0.6304810047149658,
          0.6711798906326294,
          0.7128099203109741,
          -0.36368879675865173,
          -0.9027146697044373,
          0.2848987281322479,
          -0.11517445743083954,
          0.04630466178059578,
          0.2944983243942261,
          0.6433866024017334,
          -0.2906656861305237,
          0.4727882444858551,
          -0.533551037311554,
          -1.1609472036361694,
          -0.16165460646152496,
          0.7796913981437683,
          0.12233565747737885,
          -0.5672289729118347,
          0.10506132990121841,
          0.9677531123161316,
          -0.2632486820220947,
          -0.31319186091423035,
          0.5641208291053772,
          -0.1690441071987152,
          0.23222677409648895,
          -0.6199741959571838,
          0.5970149636268616,
          -0.4193015992641449,
          0.1932956725358963,
          -0.3062831163406372,
          0.5046598315238953,
          -0.42162227630615234,
          0.0007540266960859299,
          1.2571523189544678,
          0.5081967711448669,
          -0.4085192382335663,
          0.02713778428733349,
          0.7596380114555359,
          -0.03639252483844757,
          0.3972662091255188,
          -1.2874947786331177,
          0.22790293395519257,
          -0.03649492189288139,
          -0.5394576191902161,
          0.6569576859474182,
          -1.4326305389404297,
          -0.6607818007469177,
          0.622220516204834,
          0.2515983581542969,
          0.1357981264591217,
          -0.8278352618217468,
          -0.3969736695289612,
          0.39415907859802246,
          0.08669114112854004,
          -0.4534739553928375,
          -0.505393922328949,
          0.7544097900390625,
          -0.07775121927261353,
          0.3514711856842041,
          -0.09432096034288406,
          -0.4762750267982483,
          1.217598795890808,
          0.44350171089172363,
          -0.15162713825702667,
          -0.3950973451137543,
          -0.30138099193573,
          -1.0663460493087769,
          -0.49836230278015137,
          -0.1677510291337967,
          0.1319182813167572,
          -0.11726512014865875,
          0.8456336855888367,
          0.529518187046051,
          -0.3110418915748596,
          -0.5216890573501587,
          0.4433862864971161,
          -0.8416181802749634,
          -0.7515040040016174,
          -0.32783225178718567,
          0.6468288898468018,
          -0.2832724153995514,
          0.416953980922699,
          0.252530038356781,
          0.003145787864923477,
          -0.26286593079566956,
          0.803314745426178,
          -0.3837970495223999,
          0.27906742691993713,
          0.5002181529998779,
          0.5516610145568848,
          -0.8205143809318542,
          -0.13185378909111023,
          -0.8249671459197998,
          0.2989688515663147,
          -0.18908865749835968,
          0.0730222687125206,
          -0.08169408142566681,
          0.2834029197692871,
          0.14813052117824554,
          -0.5787646770477295,
          0.3867770731449127,
          -0.42863741517066956,
          0.408980131149292,
          -0.5231047868728638,
          -0.05692005902528763,
          0.6988641619682312,
          -0.47881221771240234,
          0.38538849353790283,
          -0.9294249415397644,
          0.7342240810394287,
          -0.24959595501422882,
          -0.891308605670929,
          0.6660147905349731,
          0.00803811103105545,
          0.0006201490759849548,
          -0.12948906421661377,
          -0.25815898180007935,
          0.7812530398368835,
          -0.22867277264595032,
          0.5714354515075684,
          -0.20155072212219238,
          0.39378851652145386,
          0.146111398935318,
          -0.923427939414978,
          0.3219586908817291,
          -0.8133455514907837,
          -0.30754876136779785,
          -0.5512842535972595,
          -0.3746491074562073,
          0.37848031520843506,
          -0.4185040295124054,
          -0.5530574321746826,
          0.7283436059951782,
          -0.2421990931034088,
          -1.0744365453720093,
          -0.46640482544898987,
          -0.305040180683136,
          0.8164876699447632,
          0.7527945637702942,
          0.1838417947292328,
          0.280418336391449,
          -0.2301170527935028,
          -0.6337047219276428,
          -0.4194681644439697,
          -0.4379692077636719,
          -0.17594090104103088,
          0.46060794591903687,
          0.3802329897880554,
          0.42616093158721924,
          0.751551628112793,
          -0.13936492800712585,
          -0.23963184654712677,
          0.24874188005924225,
          0.6425026059150696,
          -0.07589342445135117,
          0.8249211311340332,
          0.516404390335083,
          -0.36361318826675415,
          -0.32000964879989624,
          -1.1196898221969604,
          -0.17447476089000702,
          0.46913862228393555,
          -0.15359562635421753,
          -0.7445295453071594,
          0.5175073742866516,
          -0.055023714900016785,
          0.6635873317718506,
          -0.5154236555099487,
          -0.718357264995575,
          0.6289899349212646,
          -0.7917941808700562,
          0.3892776668071747,
          -0.48737213015556335,
          0.6054415106773376,
          -0.5101771950721741,
          -0.14207059144973755,
          0.4995918869972229,
          0.9121224880218506,
          -0.5888696908950806,
          0.6089319586753845,
          0.5249113440513611,
          -0.6182595491409302,
          -0.4365678131580353,
          -0.28577134013175964,
          0.3464892506599426,
          -0.823716938495636,
          -0.10511355102062225,
          -0.20255130529403687,
          0.29267197847366333,
          0.42624616622924805,
          -0.07013457268476486,
          -0.331577867269516,
          0.3969283998012543,
          0.5419604182243347,
          -0.11244487762451172,
          -0.2538296580314636,
          -0.024823598563671112,
          1.1619384288787842,
          0.006140759214758873,
          0.2729922831058502,
          0.32997265458106995,
          0.6568038463592529,
          -0.5726433992385864,
          0.11011602729558945,
          -0.44957685470581055,
          1.0961581468582153,
          -1.4555636644363403,
          -0.7261807322502136,
          0.19264382123947144,
          0.2488282024860382,
          -0.6993893980979919,
          -0.30416274070739746,
          -0.9976094961166382,
          0.712674081325531,
          0.18370842933654785,
          -0.8438637852668762,
          -0.18730732798576355,
          -0.0002789907157421112,
          0.15127454698085785,
          0.44116172194480896,
          0.35177719593048096,
          -0.7069845795631409,
          0.17985881865024567,
          0.10965590924024582,
          0.5963935256004333,
          -0.4550668001174927,
          0.29148948192596436,
          0.09784232079982758,
          -0.12936805188655853,
          -0.320720374584198,
          0.5525872707366943,
          -0.31923094391822815,
          0.6011622548103333,
          0.3160281479358673,
          -0.5052382946014404,
          1.2859885692596436,
          0.47238966822624207,
          -0.189992293715477,
          0.6447864770889282,
          -0.7720522284507751,
          -0.25533539056777954,
          -1.1824560165405273,
          0.7769326567649841,
          -1.1133027076721191,
          0.20318922400474548,
          0.20458844304084778,
          -0.5486488342285156,
          -0.6608966588973999,
          -0.1341482251882553,
          -0.30135416984558105,
          0.09836900234222412,
          0.06255707889795303,
          0.3846808969974518,
          0.4570077061653137,
          1.4264428615570068,
          1.140721321105957,
          -0.1381116509437561,
          -0.43970370292663574,
          0.26268884539604187,
          -0.06604789942502975,
          0.06415398418903351,
          0.10653574764728546,
          -0.5751822590827942,
          -0.4044733941555023,
          -0.04864577576518059,
          -1.0762511491775513,
          -0.6348446011543274,
          0.3881339430809021,
          0.22127258777618408,
          0.35343050956726074,
          -0.6019400358200073,
          1.3975938558578491,
          -0.14383769035339355,
          0.35783693194389343,
          -0.12731553614139557,
          0.39383870363235474,
          0.43485090136528015,
          0.39856213331222534,
          0.46791934967041016,
          -0.010808589868247509,
          0.3166365623474121,
          -1.28699791431427,
          0.3181246519088745,
          -0.24305689334869385,
          -0.6089962720870972,
          -0.08107079565525055,
          -0.1640353798866272,
          -0.3269760310649872,
          -0.6045222878456116,
          0.7728458046913147,
          -0.9627549052238464,
          -0.10751904547214508,
          -0.06517219543457031,
          0.14718523621559143,
          0.01975902169942856,
          -0.71456378698349,
          -0.45360442996025085,
          1.0594592094421387,
          0.7444745302200317,
          0.05481177568435669,
          0.867861270904541,
          1.2490373849868774,
          0.7865917682647705,
          0.012217044830322266,
          0.46544206142425537,
          0.17305923998355865,
          0.2810133993625641,
          -0.7583386301994324,
          0.38518550992012024,
          -0.1562051922082901,
          -0.14081212878227234,
          -0.9288468956947327,
          1.018975019454956,
          1.1812268495559692,
          0.14847877621650696,
          0.06739137321710587,
          -0.9957450032234192,
          -0.026633530855178833,
          -0.8052534461021423,
          0.26820874214172363,
          -0.2264939695596695,
          1.183540940284729,
          -0.7132707834243774,
          -0.0725138783454895,
          0.7104089260101318,
          -0.8122684955596924,
          3.7983622550964355,
          1.1804530620574951,
          0.010691031813621521,
          0.5435748100280762,
          0.3264559507369995,
          0.9706614017486572,
          0.9604485630989075,
          -0.04584217071533203,
          0.642381489276886,
          -0.3874053657054901,
          0.5338943600654602,
          -0.7428995370864868,
          0.7256671190261841,
          0.42204713821411133,
          0.048158444464206696,
          -0.10714992880821228,
          -0.6708438396453857,
          0.26507389545440674,
          -0.3067358136177063,
          -0.1964656561613083,
          -1.090725302696228,
          0.4318927526473999,
          0.20299379527568817,
          -0.4786735773086548,
          0.4455408751964569,
          0.40102866291999817,
          0.06013956293463707,
          -0.1793360710144043,
          0.11153607070446014,
          -0.06840656697750092,
          0.11396970599889755,
          -0.8154985308647156,
          -0.4627988934516907,
          -0.17519360780715942,
          0.12318862974643707,
          0.9520569443702698,
          0.1459219753742218,
          -1.0608513355255127,
          -0.42315006256103516,
          1.4100902080535889,
          0.6293387413024902,
          -0.8601775765419006,
          -0.1095612570643425,
          -0.20607241988182068,
          0.02688276395201683,
          0.7657341957092285,
          0.45298290252685547,
          -0.013442270457744598,
          0.768077552318573,
          -0.7929475903511047,
          0.0707891657948494,
          -0.9947997331619263,
          -0.05508801341056824,
          -0.14249494671821594,
          0.35110166668891907,
          -0.012280242517590523,
          -0.3064778745174408,
          -0.26996132731437683,
          -1.3254648447036743,
          0.49023181200027466,
          0.573275625705719,
          -0.7155883312225342,
          -0.40058666467666626,
          0.5695637464523315,
          -0.003227807581424713,
          -0.5100485682487488,
          0.9090713858604431,
          0.18901017308235168,
          -0.2538278102874756,
          0.04371323436498642,
          0.2138606756925583,
          0.29818135499954224,
          -0.32047340273857117,
          -0.07267031073570251,
          -0.3663756847381592,
          0.2555738389492035,
          -0.32060250639915466,
          0.8178600072860718,
          0.08495254814624786,
          -0.35561734437942505,
          -0.21715468168258667,
          -0.2715323567390442,
          -0.5594290494918823,
          0.09482669830322266,
          0.24913747608661652,
          0.8541201949119568,
          -0.2673191428184509,
          0.441142737865448,
          -0.6488744616508484,
          0.23703095316886902,
          -0.30193597078323364,
          -0.4031129479408264,
          0.5240327715873718,
          -0.4428868293762207,
          0.14734506607055664
        ]
      },
      "type": "document"
    },
    {
      "id": "e697a572-289b-4477-b7ad-448cf24f0944",
      "properties": {
        "page_content": "D Further Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE Further Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG Parameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
        "document_metadata": {
          "page_label": "18",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Further Details on Open-Domain QA",
          "Further Details on FEVER",
          "Null Document Probabilities",
          "Parameters"
        ]
      },
      "type": "document"
    },
    {
      "id": "894e9ca2-5ba7-4d5f-b1b9-ff8c8754d16f",
      "properties": {
        "page_content": "Table 7: Number of instances in the datasets used. *A hidden subset of this data is used for evaluation\nTask Train Development Test\nNatural Questions 79169 8758 3611\nTriviaQA 78786 8838 11314\nWebQuestions 3418 362 2033\nCuratedTrec 635 134 635\nJeopardy Question Generation 97392 13714 26849\nMS-MARCO 153726 12468 101093*\nFEVER-3-way 145450 10000 10000\nFEVER-2-way 96966 6666 6666\nparameters. The best performing \"closed-book\" (parametric only) open-domain QA model is T5-11B\nwith 11 Billion trainable parameters. The T5 model with the closest number of parameters to our\nmodels is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52],\nsubstantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non-\nparametric models require far fewer trainable parameters for strong open-domain QA performance.\nThe non-parametric memory index does not consist of trainable parameters, but does consists of 21M\n728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit ﬂoating\npoint precision to manage memory and disk footprints.\nH Retrieval Collapse\nIn preliminary experiments, we observed that for some tasks such as story generation [ 11], the\nretrieval component would “collapse” and learn to retrieve the same documents regardless of the\ninput. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents,\nand the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit\nrequirement for factual knowledge in some tasks, or the longer target sequences, which could result\nin less informative gradients for the retriever. Perez et al.[46] also found spurious retrieval results\nwhen optimizing a retrieval component in order to improve performance on downstream tasks.\nI Number of instances per dataset\nThe number of training, development and test datapoints in each of our datasets is shown in Table 7.\n19",
        "document_metadata": {
          "page_label": "19",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "H Retrieval Collapse",
          "I Number of instances per dataset"
        ]
      },
      "type": "document"
    },
    {
      "id": "d873ff71-619f-4aa4-8a47-2d2922e1167b",
      "properties": {
        "page_content": "KILT: a Benchmark for Knowledge Intensive Language Tasks\nFabio Petroni1 Aleksandra Piktus1 Angela Fan1,3 Patrick Lewis1,2\nMajid Yazdani1 Nicola De Cao6 James Thorne4 Yacine Jernite5 Vladimir Karpukhin1\nJean Maillard1 Vassilis Plachouras1 Tim Rocktäschel1,2 Sebastian Riedel1,2\n1Facebook AI Research 2University College London 3LORIA\n4University of Cambridge 5HuggingFace 6University of Amsterdam\nAbstract\nChallenging problems such as open-domain\nquestion answering, fact checking, slot ﬁlling\nand entity linking require access to large, exter-\nnal knowledge sources. While some models\ndo well on individual tasks, developing gen-\neral models is difﬁcult as each task might re-\nquire computationally expensive indexing of\ncustom knowledge sources, in addition to ded-\nicated infrastructure. To catalyze research\non models that condition on speciﬁc informa-\ntion in large textual resources, we present a\nbenchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded\nin the same snapshot of Wikipedia, reduc-\ning engineering turnaround through the re-\nuse of components, as well as accelerating\nresearch into task-agnostic memory architec-\ntures. We test both task-speciﬁc and gen-\neral baselines, evaluating downstream perfor-\nmance in addition to the ability of the mod-\nels to provide provenance. We ﬁnd that\na shared dense vector index coupled with\na seq2seq model is a strong baseline, out-\nperforming more tailor-made approaches for\nfact checking, open-domain question answer-\ning and dialogue, and yielding competitive re-\nsults on entity linking and slot ﬁlling, by gen-\nerating disambiguated text. KILT data and\ncode are available at https://github.com/\nfacebookresearch/KILT.1\n1 Introduction\nThere has been substantial progress on natural lan-\nguage processing tasks where the inputs are short\ntextual contexts such as a sentences, paragraphs,\nor perhaps a handful of documents. Critically, we\nhave seen the emergence of general-purpose archi-\ntectures and pre-trained models that can be applied\nto a wide range of such tasks (Devlin et al., 2019).\nHowever, for many real world problems, process-\ning at this local level is insufﬁcient. For example,\n1and at https://huggingface.co/datasets?\nsearch=kilt\nin open-domain question answering (Chen et al.,\n2017) models need to ﬁnd answers within a large\ncorpus of text. Fact checking a claim (Thorne et al.,\n2018a) requires models to ﬁnd evidence, often on\nthe web. In knowledgeable open dialogue (Dinan\net al., 2019), models need access to knowledge\nfrom large corpora to sustain informed conversa-\ntions.\nIn general, solving knowledge-intensive tasks\nrequires–even for humans–access to a large body\nof information. Like in Information Retrieval (IR)\nthis involves satisfying an information need lever-\naging large collections of text (Manning et al.,\n2008). However, while IR focuses of ﬁnding rel-\nevant material (usually documents), the tasks we\nconsider focus on more ﬁne-grained behavior, such\nas producing speciﬁc answers to queries. For such\nknowledge-intensive tasks, general infrastructure\nand architectures across tasks have yet to emerge,\nand fundamental research questions remain open.\nFor example, while it was long assumed that non-\nparametric and explicit memory accessed through\nretrieval is strictly required for competitive re-\nsults (Chen et al., 2017), recent large pre-trained\nsequence-to-sequence models such as T5 (Raffel\net al., 2019a) and BART (Lewis et al., 2019) store\nall knowledge in their parameters while performing\nremarkably well (Petroni et al., 2019). Likewise,\nwhile the classical approach of information extrac-\ntion for populating a Knowledge Base (KB, Riedel\net al., 2013; Surdeanu and Ji, 2014) seems out-\nof-fashion, recent results show that they remain\ncontenders (Fan et al., 2019a; Xiong et al., 2019).\nWhile there are numerous datasets for\nknowledge-intensive tasks (e.g. Thorne et al.,\n2018a; Dinan et al., 2019; Kwiatkowski et al.,\n2019, to name just a few), it is difﬁcult to\nanswer the above questions generally across\nthem. Each dataset comes in a different format,\nis pre-processed with different assumptions, and\nrequires different loaders, evaluations, and analysis\narXiv:2009.02252v4  [cs.CL]  27 May 2021",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Introduction",
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ],
        "summary": "KILT is a benchmark for knowledge-intensive language tasks that presents a shared dense vector index coupled with a seq2seq model as a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue.",
        "summary_embedding": [
          0.5304874181747437,
          -0.21967917680740356,
          -0.461745947599411,
          -0.07057255506515503,
          0.2212558090686798,
          0.37307316064834595,
          0.061579570174217224,
          -1.3922187089920044,
          -0.15932433307170868,
          0.9265982508659363,
          0.333976149559021,
          0.14120101928710938,
          0.03089303895831108,
          -0.9927936792373657,
          0.5542159676551819,
          0.307546466588974,
          -0.8166283369064331,
          -0.2348547875881195,
          -0.4423106610774994,
          -0.6528815031051636,
          0.556172788143158,
          -0.029899876564741135,
          -1.5265724658966064,
          0.4328732192516327,
          -0.2650538682937622,
          0.436661958694458,
          0.22774910926818848,
          -0.18819838762283325,
          1.4073282480239868,
          1.070258378982544,
          0.9005892872810364,
          0.15834400057792664,
          -0.4108738303184509,
          -0.26411086320877075,
          -0.5893253087997437,
          -1.3968865871429443,
          0.4412580132484436,
          -0.28919482231140137,
          -0.4341265559196472,
          -0.3816760182380676,
          0.12243509292602539,
          -0.38552743196487427,
          0.0854005366563797,
          -0.6694934368133545,
          -0.790623128414154,
          -0.13862603902816772,
          0.5710242986679077,
          -0.9665054678916931,
          0.25318190455436707,
          -0.24783924221992493,
          0.13104715943336487,
          0.06425457447767258,
          0.2747739851474762,
          0.22972792387008667,
          0.28904440999031067,
          -0.059059903025627136,
          -0.5103001594543457,
          0.5919521450996399,
          -0.5860928893089294,
          0.09915041923522949,
          1.4295930862426758,
          0.09821498394012451,
          0.052247047424316406,
          -0.8432082533836365,
          0.09054331481456757,
          -0.1053931713104248,
          0.021318016573786736,
          -0.7386612296104431,
          -0.33386528491973877,
          -0.6172064542770386,
          -1.109084129333496,
          -0.0733145922422409,
          -0.38132399320602417,
          -0.5438082218170166,
          -1.2125781774520874,
          0.5533878207206726,
          0.13091585040092468,
          0.42295849323272705,
          -0.09709739685058594,
          0.3314397633075714,
          1.0157947540283203,
          0.99996417760849,
          -0.40440285205841064,
          0.32379022240638733,
          -1.0268369913101196,
          -0.9298384189605713,
          0.613330066204071,
          0.2798958718776703,
          0.29539403319358826,
          -0.41304901242256165,
          0.39797455072402954,
          0.7394974231719971,
          0.21128617227077484,
          0.016552813351154327,
          0.13989749550819397,
          0.044738076627254486,
          0.25503575801849365,
          0.26551908254623413,
          -0.7330243587493896,
          0.3678729832172394,
          0.05657413601875305,
          0.9281209707260132,
          -0.3182719349861145,
          0.6612990498542786,
          -1.1480575799942017,
          0.5883702635765076,
          -0.224117249250412,
          -0.6040412783622742,
          0.35204946994781494,
          -0.4331968128681183,
          -0.005720324814319611,
          0.23883330821990967,
          0.19491572678089142,
          -0.5898728370666504,
          -0.07698188722133636,
          -0.21492409706115723,
          0.22255441546440125,
          0.6165264248847961,
          -0.05057259276509285,
          0.8154669404029846,
          -0.4150469899177551,
          -0.023143503814935684,
          -0.4921644330024719,
          0.09030438959598541,
          0.11284888535737991,
          -0.8109838366508484,
          0.27298837900161743,
          0.27960091829299927,
          -0.6061583757400513,
          -0.23209890723228455,
          0.1873459815979004,
          -0.08658948540687561,
          0.4224497377872467,
          0.8283108472824097,
          0.3162277042865753,
          -0.3608283996582031,
          -0.05486937239766121,
          0.6955376863479614,
          0.0010150372982025146,
          0.3321773409843445,
          0.7850071787834167,
          -0.667294442653656,
          -0.2004098743200302,
          1.304742455482483,
          -0.0670243352651596,
          0.1714099943637848,
          -0.2032729685306549,
          -0.9389318227767944,
          -0.17803452908992767,
          0.5029085874557495,
          -0.007275313138961792,
          0.5503230094909668,
          0.11167492717504501,
          -0.3650434613227844,
          -0.7175458669662476,
          -0.6198100447654724,
          0.027000710368156433,
          -0.324728399515152,
          0.05680851638317108,
          -0.25717693567276,
          -0.5138116478919983,
          0.6386115550994873,
          -0.3737422525882721,
          0.539506196975708,
          -0.2829822301864624,
          0.19443511962890625,
          -0.188007652759552,
          0.06009213253855705,
          -0.3423629105091095,
          -0.3907294273376465,
          0.29381006956100464,
          -0.03034481778740883,
          0.13495588302612305,
          0.22369885444641113,
          0.4384590983390808,
          1.1442477703094482,
          0.6721659898757935,
          -0.5109366774559021,
          0.4000396430492401,
          0.36118537187576294,
          0.35106492042541504,
          -0.613249659538269,
          -0.24079705774784088,
          0.3617825508117676,
          -0.5097202658653259,
          0.7919707894325256,
          -0.20912262797355652,
          0.09717774391174316,
          0.037241917103528976,
          0.03136379271745682,
          -0.43672794103622437,
          1.2089507579803467,
          -0.14632277190685272,
          0.451223760843277,
          0.29377973079681396,
          0.19440679252147675,
          -0.143142968416214,
          0.8079768419265747,
          0.467646986246109,
          -1.0842708349227905,
          -0.2196601778268814,
          1.4423296451568604,
          0.7473222613334656,
          -0.14633312821388245,
          -0.3455270528793335,
          -0.4421803653240204,
          0.21088764071464539,
          0.03467675298452377,
          -1.4685550928115845,
          0.2055920660495758,
          0.46934792399406433,
          -0.12039582431316376,
          -0.3267556130886078,
          -0.09045471996068954,
          0.7278845310211182,
          -0.5220389366149902,
          -0.952333390712738,
          -0.4085182845592499,
          -0.04126530885696411,
          0.23217476904392242,
          -0.7039722800254822,
          0.4765952229499817,
          0.8636894822120667,
          -0.04525834321975708,
          0.22878889739513397,
          -0.5012824535369873,
          0.2814820408821106,
          1.1859320402145386,
          -0.07617070525884628,
          0.5975154042243958,
          0.06085042655467987,
          0.5738160014152527,
          -0.4208129644393921,
          0.17148862779140472,
          0.2654613256454468,
          0.5474028587341309,
          0.9801401495933533,
          0.48350197076797485,
          0.07326972484588623,
          0.16336660087108612,
          0.057072460651397705,
          0.028498992323875427,
          1.2790632247924805,
          1.0389500856399536,
          0.454477995634079,
          -0.37372109293937683,
          0.19240890443325043,
          0.5457926392555237,
          0.019945241510868073,
          0.23727214336395264,
          -0.5809445977210999,
          0.594261109828949,
          0.38241347670555115,
          -0.41533786058425903,
          -0.4719007611274719,
          -0.23609015345573425,
          0.2947975993156433,
          1.1439777612686157,
          0.07186074554920197,
          0.030622020363807678,
          -0.5737022757530212,
          0.34256452322006226,
          0.15230682492256165,
          0.07206392288208008,
          -0.15638980269432068,
          0.4681903123855591,
          -0.34261927008628845,
          0.27249616384506226,
          0.008300403133034706,
          -0.12249965220689774,
          -0.343696653842926,
          -0.6138231158256531,
          -1.5741151571273804,
          -0.19425652921199799,
          -0.28774595260620117,
          -0.5533773899078369,
          -0.7846713662147522,
          -0.6277583241462708,
          -0.2981736958026886,
          -0.053010135889053345,
          0.28437289595603943,
          0.613844633102417,
          -0.9750043749809265,
          0.7057512998580933,
          0.24266910552978516,
          0.6224331855773926,
          -0.6048542261123657,
          0.5343773365020752,
          0.002329479902982712,
          0.7849633097648621,
          -0.02220931276679039,
          -0.40448707342147827,
          -0.25880956649780273,
          -0.38298502564430237,
          0.015239477157592773,
          0.12302136421203613,
          -0.3064955472946167,
          0.14055055379867554,
          -0.4606645405292511,
          -0.65278559923172,
          0.24428880214691162,
          -0.23262259364128113,
          0.37966737151145935,
          -0.7086543440818787,
          -0.6171985864639282,
          0.18843655288219452,
          0.7382254004478455,
          -0.23385509848594666,
          0.8715972900390625,
          0.5044146776199341,
          -0.35462623834609985,
          0.6032142043113708,
          -0.182404026389122,
          0.5044457912445068,
          -0.4276076555252075,
          0.754264771938324,
          1.1011461019515991,
          0.06711874902248383,
          -0.5864975452423096,
          -0.5863817930221558,
          -1.2573237419128418,
          -0.5970036387443542,
          0.037241168320178986,
          -0.7313687801361084,
          -0.2804788649082184,
          0.5650262832641602,
          -0.31237542629241943,
          -1.6731034517288208,
          0.17143072187900543,
          -0.3545449376106262,
          -1.4810118675231934,
          -0.5992251634597778,
          0.11295607686042786,
          0.3159010410308838,
          -0.049337275326251984,
          -0.007116749882698059,
          -0.2282497137784958,
          -0.002577400766313076,
          0.1780034601688385,
          1.0522594451904297,
          0.586929976940155,
          -0.20685890316963196,
          -0.21178407967090607,
          0.6615254878997803,
          0.3649372160434723,
          0.4844913184642792,
          -0.08283577859401703,
          -0.692496657371521,
          -0.263065904378891,
          0.23511038720607758,
          -0.05648822709918022,
          1.4857896566390991,
          0.38114428520202637,
          0.6881550550460815,
          0.28314775228500366,
          -0.5586265325546265,
          -0.3012251853942871,
          0.5337411165237427,
          0.7039243578910828,
          0.37982702255249023,
          0.44877496361732483,
          0.4667368233203888,
          0.2339601367712021,
          0.5206822752952576,
          0.17574864625930786,
          0.17372983694076538,
          -0.9267902970314026,
          0.19547903537750244,
          0.06381368637084961,
          -1.4124151468276978,
          -0.05578649044036865,
          0.10561790317296982,
          0.1273009181022644,
          0.3576332628726959,
          -0.4615596532821655,
          -1.9842044115066528,
          0.6765285134315491,
          0.6959547996520996,
          0.3126419186592102,
          -0.5443319082260132,
          -0.012447848916053772,
          -0.6532484292984009,
          0.3725239336490631,
          0.6140990257263184,
          0.5378149747848511,
          -0.045739322900772095,
          -0.19605475664138794,
          -0.24002143740653992,
          -0.1877654641866684,
          0.20859648287296295,
          -0.10245804488658905,
          0.9595248699188232,
          -0.2559910714626312,
          -0.16910874843597412,
          -0.2898687720298767,
          -0.684015691280365,
          0.8044465780258179,
          0.12458523362874985,
          -0.09214957058429718,
          -0.07151233404874802,
          0.962868869304657,
          -0.3961583077907562,
          0.624445915222168,
          0.43989261984825134,
          -0.12553654611110687,
          -0.43611472845077515,
          -0.5202075839042664,
          -0.1060263067483902,
          0.1309618353843689,
          0.3497334122657776,
          0.1921459287405014,
          0.2743798792362213,
          -0.3827362656593323,
          -0.21450108289718628,
          0.6437751650810242,
          0.31267982721328735,
          -0.7489836812019348,
          -0.07114538550376892,
          1.4240856170654297,
          0.6666536331176758,
          -0.15117698907852173,
          -0.4147234857082367,
          0.06082598865032196,
          0.4267285168170929,
          -0.35025763511657715,
          -0.2905564606189728,
          0.034837789833545685,
          -0.4502449035644531,
          -0.14335811138153076,
          -0.26355448365211487,
          -0.37520870566368103,
          -0.36380869150161743,
          -0.055833570659160614,
          -0.022059813141822815,
          -0.5928685069084167,
          0.6395426392555237,
          0.8510688543319702,
          0.2843981981277466,
          0.07393664866685867,
          -0.547435998916626,
          -0.1786082684993744,
          -0.0024867504835128784,
          -0.026853494346141815,
          -0.26830264925956726,
          0.35855555534362793,
          -0.22493436932563782,
          -0.06636248528957367,
          0.39801478385925293,
          0.36328208446502686,
          -0.863679051399231,
          0.06924499571323395,
          -1.3693691492080688,
          0.5398141741752625,
          -0.4043814241886139,
          -0.6496396064758301,
          -0.42506349086761475,
          0.2923448085784912,
          -0.005333937704563141,
          0.5540902018547058,
          0.7780733704566956,
          0.20302774012088776,
          -0.30213555693626404,
          0.6854183673858643,
          -0.07474704086780548,
          -0.49857819080352783,
          0.907903254032135,
          -0.014634795486927032,
          -0.491698682308197,
          0.14612412452697754,
          -0.19106359779834747,
          0.299640029668808,
          -0.42399922013282776,
          -0.10566066205501556,
          0.06853272020816803,
          0.3432309031486511,
          -0.27038514614105225,
          0.4968920648097992,
          -0.2850780785083771,
          -0.24468955397605896,
          -1.0397305488586426,
          0.2732541561126709,
          0.08653794229030609,
          0.04202279448509216,
          -0.04999526962637901,
          -0.39314979314804077,
          -0.6063862442970276,
          -0.09729912877082825,
          0.6543639302253723,
          0.17008717358112335,
          -0.031939730048179626,
          0.08302333205938339,
          0.23994509875774384,
          -0.20824424922466278,
          -0.5644493103027344,
          -0.9873958826065063,
          -0.14216922223567963,
          -0.45086121559143066,
          -0.15385159850120544,
          0.43398424983024597,
          0.925482988357544,
          0.6740121841430664,
          -0.38988643884658813,
          -0.8839668035507202,
          0.6534181833267212,
          -0.13635455071926117,
          -0.41672903299331665,
          -0.7772120237350464,
          -0.5967052578926086,
          0.34111160039901733,
          -0.2765662670135498,
          0.2746473252773285,
          0.14835843443870544,
          -0.20279470086097717,
          0.4307090938091278,
          0.1371048390865326,
          -0.4814175069332123,
          0.00909331813454628,
          0.027336757630109787,
          -0.0769757479429245,
          1.02500319480896,
          -0.0904005914926529,
          -1.6132900714874268,
          -0.12411199510097504,
          0.48942965269088745,
          -0.2587311863899231,
          0.21894967555999756,
          0.6206309199333191,
          0.21682637929916382,
          -1.1153100728988647,
          -0.9081915020942688,
          0.1200157105922699,
          -0.05872887372970581,
          -0.16442428529262543,
          -0.6685085296630859,
          -0.28392910957336426,
          0.831442654132843,
          0.138905331492424,
          0.5279415249824524,
          -0.5921199917793274,
          -0.7040258646011353,
          -0.2198125422000885,
          0.7016100883483887,
          0.10718588531017303,
          -0.4597175717353821,
          -0.39126110076904297,
          0.18038639426231384,
          0.5788700580596924,
          1.1129335165023804,
          0.0030562467873096466,
          0.5434020161628723,
          -0.36727669835090637,
          -0.45369553565979004,
          0.3614046573638916,
          1.1806528568267822,
          -0.935738742351532,
          -0.49318456649780273,
          0.4136495888233185,
          -0.9953384399414062,
          0.311909943819046,
          -0.28201591968536377,
          -0.6106144189834595,
          0.41509541869163513,
          -0.6194769740104675,
          -0.3164069652557373,
          -1.796260118484497,
          -0.27206775546073914,
          -1.4983775615692139,
          -0.9796956777572632,
          0.762697160243988,
          -0.5903394222259521,
          -0.2749646008014679,
          0.10963240265846252,
          1.1418735980987549,
          0.2502659857273102,
          0.40593963861465454,
          -1.1102436780929565,
          -0.6681542992591858,
          -0.4336366057395935,
          -0.8974332809448242,
          0.7847524881362915,
          -0.5070618391036987,
          0.6023179292678833,
          0.0601470060646534,
          0.291224867105484,
          0.3406505286693573,
          -0.6733221411705017,
          0.5674195289611816,
          0.548755407333374,
          0.0777101218700409,
          0.18160387873649597,
          -0.7954380512237549,
          0.13425104320049286,
          -0.43406355381011963,
          0.019925981760025024,
          -0.35778722167015076,
          -1.0406320095062256,
          -0.6596682071685791,
          0.007194675505161285,
          -1.1141151189804077,
          -0.5103773474693298,
          0.4509420394897461,
          0.07800053060054779,
          1.141573429107666,
          -1.0756007432937622,
          0.7665833830833435,
          0.2846147418022156,
          0.13578779995441437,
          -1.062395453453064,
          -0.1101732850074768,
          0.36228030920028687,
          0.2571541666984558,
          0.574775755405426,
          0.09093063324689865,
          -0.2837371230125427,
          -0.4989171028137207,
          -0.23786598443984985,
          -0.4185497760772705,
          0.05011661350727081,
          0.46275651454925537,
          -0.2707153558731079,
          -0.5846871733665466,
          0.8968982696533203,
          -0.18635523319244385,
          -0.4877300262451172,
          -0.4259796440601349,
          0.05092180147767067,
          -0.37550118565559387,
          0.1566184163093567,
          -0.4623420238494873,
          0.38479045033454895,
          -0.33477434515953064,
          -0.0388946607708931,
          -0.6872650384902954,
          0.5144658088684082,
          -0.303438663482666,
          -0.3941825330257416,
          0.007237005978822708,
          0.02122184820473194,
          -0.4750736653804779,
          0.1875297576189041,
          0.711329460144043,
          -0.7259559631347656,
          0.6240572929382324,
          -0.29746732115745544,
          0.2693674862384796,
          -0.01669597253203392,
          0.14700980484485626,
          0.6635621786117554,
          -0.6919212937355042,
          -0.9612414240837097,
          0.49603769183158875,
          0.29372096061706543,
          0.7400283217430115,
          -0.660193145275116,
          -0.6215813755989075,
          0.7775463461875916,
          -0.6730989813804626,
          0.014973828569054604,
          -0.26032906770706177,
          0.7779700756072998,
          0.3831813633441925,
          0.7026702761650085,
          -0.1120811253786087,
          0.8179827332496643,
          0.8813006281852722,
          -0.3358322083950043,
          0.5215592384338379,
          -0.8398352265357971,
          0.2783009111881256,
          -0.577271044254303,
          -0.5083131790161133,
          -0.05525793135166168,
          -0.1498570293188095,
          -0.1283457726240158,
          0.5690281391143799,
          0.01265488937497139,
          -0.5539700984954834,
          -1.0285978317260742,
          0.40658318996429443,
          -0.968117356300354,
          0.6733312606811523,
          -0.12804605066776276,
          0.8143384456634521,
          -0.4742984175682068,
          -0.05159170180559158,
          -0.27738556265830994,
          -0.38262054324150085,
          -0.5955880284309387,
          0.4098527133464813,
          -0.3260018229484558,
          0.017977513372898102,
          0.6246107816696167,
          -0.09490518271923065,
          -0.5053117275238037,
          -0.07554066181182861,
          -1.1646541357040405,
          -0.7342944741249084,
          0.03230847045779228,
          0.03482883423566818,
          -0.1914295256137848,
          0.015254087746143341,
          -0.1583624631166458,
          0.10310878604650497,
          -0.44511666893959045,
          0.8772802352905273,
          0.3903440237045288,
          -0.6258599758148193,
          0.23868349194526672,
          1.2903259992599487,
          -0.2734023630619049,
          0.1910121887922287,
          -0.7316857576370239,
          -0.18324337899684906,
          -0.22431084513664246,
          0.05371161922812462,
          0.05609041452407837,
          -0.9989979267120361,
          -0.8197799921035767,
          0.4868951439857483,
          0.8621318340301514,
          1.4239604473114014,
          0.7230350971221924,
          0.7002956867218018,
          0.19326762855052948,
          0.4468672573566437,
          0.44125238060951233,
          -0.10993950068950653,
          0.23517827689647675,
          0.23775701224803925,
          -0.5582833290100098,
          -0.19620957970619202,
          0.0680704116821289,
          0.39635521173477173,
          -0.6841211915016174,
          -0.1102081760764122,
          0.06204256787896156,
          0.12787452340126038,
          0.01766064390540123,
          -0.09475037455558777,
          0.004385234788060188,
          0.5051864981651306,
          0.6699134707450867,
          0.2292354702949524,
          0.232020765542984,
          -0.08576199412345886,
          -0.9730613827705383,
          -0.1524491012096405,
          -0.7561003565788269,
          -0.20770521461963654,
          0.21769340336322784,
          -0.09296087920665741,
          0.5094266533851624,
          -0.028430096805095673,
          -1.0309927463531494,
          -0.23705795407295227,
          0.2257249504327774,
          0.18232494592666626,
          -0.23605036735534668,
          0.8451269268989563,
          0.022052999585866928,
          0.0880039855837822,
          0.023440558463335037,
          -0.6981170773506165,
          0.08256169408559799,
          0.30768075585365295,
          -0.6338419914245605,
          -0.5222769975662231,
          -0.47386693954467773,
          0.24393567442893982,
          0.49746036529541016,
          0.8283634781837463,
          -1.0898281335830688,
          0.6862115859985352,
          -0.06253685057163239,
          -0.3520962595939636,
          -0.5931586027145386,
          0.615483820438385,
          -0.22661972045898438,
          0.07454322278499603,
          0.07454803586006165,
          0.6983240246772766,
          -0.17223447561264038,
          0.3458589017391205,
          -0.2830553948879242,
          0.18846207857131958,
          -0.18840263783931732,
          0.03079640492796898,
          -0.08280372619628906,
          -0.8186400532722473,
          0.6329393982887268,
          0.2056516706943512,
          -0.088646799325943,
          0.006721879355609417,
          -0.40664783120155334,
          -0.4870237410068512,
          0.39676499366760254,
          -0.119974784553051,
          0.30674612522125244,
          -0.6917511820793152,
          0.2834671139717102,
          0.029238484799861908,
          0.10895011574029922,
          -0.03935584798455238,
          0.13527469336986542,
          0.04621252045035362,
          0.2583147883415222,
          0.08885546028614044,
          -0.8860949873924255,
          0.14992433786392212,
          -0.35303956270217896,
          0.3659471869468689,
          0.28836584091186523,
          -0.6851829290390015,
          -0.45804256200790405,
          -0.03926924616098404,
          -0.7164149284362793,
          0.10268720239400864,
          0.2933127284049988,
          -0.6363492012023926,
          -0.4528070092201233,
          0.2734266221523285,
          0.1407281905412674,
          0.7573334574699402,
          0.3234800398349762,
          0.34796327352523804,
          0.25353583693504333,
          -0.2694283425807953,
          0.15132391452789307,
          0.08655446767807007,
          -0.02368534356355667,
          -0.4114857017993927,
          0.13090716302394867,
          -0.014075223356485367,
          0.09073639661073685,
          -0.277515709400177,
          0.37425702810287476,
          -0.01755337417125702,
          -1.0104660987854004,
          0.68994140625,
          0.5025498867034912,
          -0.43338245153427124,
          0.41609033942222595,
          -0.49312055110931396,
          -0.7392033934593201,
          -0.52182537317276,
          0.09055592864751816,
          -1.4708024263381958,
          -0.04819820821285248,
          0.3733559846878052,
          0.06936408579349518,
          -0.23816761374473572,
          0.19877538084983826,
          0.11698293685913086,
          0.7015648484230042,
          0.4448508620262146,
          0.5047546029090881,
          0.2220880091190338,
          1.7696177959442139,
          0.6338537931442261,
          0.2896256148815155,
          -0.1500653624534607,
          0.18960583209991455,
          -0.015851184725761414,
          0.36772429943084717,
          -0.34417060017585754,
          -0.48859846591949463,
          0.18740202486515045,
          -0.03437183424830437,
          -1.1286252737045288,
          0.46808838844299316,
          0.526695728302002,
          0.18369701504707336,
          -0.5042461156845093,
          0.16672325134277344,
          0.415865421295166,
          0.08632918447256088,
          0.007189668715000153,
          1.4021341800689697,
          0.39673107862472534,
          1.216333270072937,
          -0.7100046277046204,
          0.7406506538391113,
          -0.760383665561676,
          -0.08908923715353012,
          -0.6942795515060425,
          0.6103814244270325,
          -0.45237040519714355,
          -1.6073423624038696,
          0.2615964710712433,
          -1.0904728174209595,
          -0.44797685742378235,
          -0.16894644498825073,
          0.08873820304870605,
          -0.6653529405593872,
          0.9777142405509949,
          0.30655282735824585,
          0.8903158903121948,
          -0.33498814702033997,
          -1.035936713218689,
          -0.5161008834838867,
          0.9135537147521973,
          0.7178100347518921,
          -0.5672029256820679,
          2.0273287296295166,
          0.8749969601631165,
          0.11798487603664398,
          -0.34656935930252075,
          -0.5868127346038818,
          0.6511219143867493,
          0.30148306488990784,
          -0.5726731419563293,
          -0.6914852261543274,
          0.0872587189078331,
          -0.08412192761898041,
          -0.7486073970794678,
          0.689430832862854,
          0.44701671600341797,
          0.6041668653488159,
          -0.6200527548789978,
          -0.8916274905204773,
          0.5792434215545654,
          -0.8407267332077026,
          -0.02380654402077198,
          -0.39633312821388245,
          0.9373611211776733,
          0.03728712722659111,
          0.009205073118209839,
          0.34223321080207825,
          -0.7211994528770447,
          3.82273006439209,
          0.14205244183540344,
          0.9569764137268066,
          0.38980504870414734,
          0.11304085701704025,
          0.40926164388656616,
          0.23304329812526703,
          -0.1370900571346283,
          0.8515428304672241,
          0.015515677630901337,
          -0.17176152765750885,
          0.4366082549095154,
          -0.27357035875320435,
          -0.05396481975913048,
          -0.14460104703903198,
          -0.10139867663383484,
          -0.5771613121032715,
          0.01900848001241684,
          -0.5873457789421082,
          -0.15006360411643982,
          -0.2251264601945877,
          0.4467715919017792,
          0.2999213933944702,
          -0.4331181049346924,
          0.4186822175979614,
          -0.6409933567047119,
          -0.2999570667743683,
          -0.46445876359939575,
          0.7070980072021484,
          -0.4486841857433319,
          0.5310023427009583,
          -0.7303103804588318,
          0.7035118341445923,
          -0.12320283055305481,
          0.16748400032520294,
          0.8911693096160889,
          0.6458408236503601,
          -1.2977495193481445,
          0.1496182084083557,
          1.0304665565490723,
          -0.03935907036066055,
          -1.0132124423980713,
          0.12052387744188309,
          -0.3531439006328583,
          -0.3272906541824341,
          0.6885119676589966,
          0.08260238170623779,
          -0.08025141060352325,
          1.26924467086792,
          -0.7905396223068237,
          0.23650780320167542,
          -0.6812415719032288,
          0.7993640303611755,
          -0.5331510901451111,
          -1.0638206005096436,
          -0.2843821346759796,
          -0.2892497181892395,
          -1.0683133602142334,
          -0.4110390245914459,
          0.3870847523212433,
          -0.04815893620252609,
          0.21853744983673096,
          0.5281767845153809,
          0.004654034972190857,
          -0.3473241925239563,
          0.1421714425086975,
          0.6841868758201599,
          0.35924577713012695,
          -0.1785738319158554,
          -0.47279617190361023,
          0.05370527505874634,
          0.2262556552886963,
          0.11796616017818451,
          0.05582579970359802,
          0.25638893246650696,
          0.4655193090438843,
          -0.40626779198646545,
          1.045600414276123,
          -0.38939565420150757,
          -0.2467379868030548,
          -0.5412783026695251,
          -0.6766862273216248,
          -0.6611834764480591,
          0.269806444644928,
          0.09274521470069885,
          0.784923255443573,
          -0.46491876244544983,
          0.6695244908332825,
          -0.2500375509262085,
          1.2667407989501953,
          -0.18145856261253357,
          0.2706211805343628,
          0.36974966526031494,
          -0.08281033486127853,
          0.20027464628219604
        ]
      },
      "type": "document"
    },
    {
      "id": "64f157b8-2fbd-4aed-9f28-695db4b96497",
      "properties": {
        "page_content": "Figure 1: Common KILT interface for knowledge intensive language tasks: each instance consists of\ninput and output with a provenance (text span) from the common KILT knowledge source. Source:\nhttps://en.wikipedia.org/wiki/{Star_Trek,Three_Men_and_a_Baby,Treklanta}\ntools. Critically, they all use different knowledge\nsources, from different versions of Wikipedia to\nentirely different corpora. This makes task-to-task\ncomparisons difﬁcult and substantially increases\ncomputational overhead. For example, one\ncannot easily assess whether the same knowledge\nrepresentation can be re-used if each dataset is tied\nto a different source. Moreover, if one decides\nto work with different sources across different\ntasks, many approaches require re-indexing and\nre-encoding large numbers of documents. If a\nlanguage model is pre-trained on one snapshot of\nWikipedia to capture its knowledge, tasks that use\nother snapshots might require re-training.\nTo facilitate research on models that must ac-\ncess speciﬁc information in a knowledge source,\nwe introduce KILT, a benchmark and library for\nKnowledge Intensive Language Tasks. KILT aims\nto lower the entry barrier for such research by for-\nmulating several knowledge-intensive NLP tasks\nwith respect to a common interface and the same\nuniﬁed knowledge source—a single Wikipedia\nsnapshot. The KILT benchmark consists of eleven\ndatasets spanning ﬁve distinct tasks, and includes\nthe test set for all datasets considered. 2 An im-\nportant aim of KILT is to cover many different\nways of seeking knowledge. For this reason, we\nselect tasks that provide a variety of ways to for-\nmulate both the input query (e.g., a claim to verify,\na text chunk to annotate, a structured query, a nat-\nural question or a conversation) and the expected\noutput (e.g., discrete, extractive, or abstractive).\nMoreover, while some tasks are factoid in nature\n(e.g., slot ﬁlling), others require using background\nknowledge to answer more complex questions (e.g,\nELI5) or to sustain a conversation (e.g,. Wizard of\nWikipedia). The format of the KILT benchmark is\nmodel-agnostic, so any system capable of produc-\ning a textual output given a textual input is eligible\nto participate. KILT is an in-KB resource (Petroni\net al., 2015), i.e., the evidence required to answer\neach of the ~3.2M instances in KILT is present\nsomewhere in the knowledge source. Hence there\nare no unanswerable instances in KILT. Although\nrecognizing unanswerable instances is important,\nwe believe the in-KB setting already poses an hard\n2A brand new portion of the Natural Question (NQ) dataset,\noriginally held out, is used as the KILT test set for NQ.",
        "document_metadata": {
          "page_label": "2",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "8c0b5fa0-81e5-4a41-9b53-e62e8588cc52",
      "properties": {
        "page_content": "challenge to current state-of-the-art techniques, and\nthus leave unanswerable instances as future work.\nKILT enables researchers to develop general-\npurpose models and evaluate them across multiple\ndomains, testing hypotheses around task-agnostic\nmemory and knowledge representations without\nindexing different large-scale textual corpora or\nwriting new IO routines. Furthermore, the KILT\nlibrary provides general building blocks to ease re-\nsearch on knowledge intensive NLP. We provide\nvarious state-of-the-art information retrieval sys-\ntems (both neural and non-neural) coupled with\ndifferent models that read text in the knowledge\nsource and make predictions for different tasks.\nWe evaluate several state-of-the-art models\nthat represent diverse approaches to knowledge-\nintensive NLP, and ﬁnd that a hybrid approach com-\nbining a neural retriever with a pretrained sequence-\nto-sequence model outperforms most task-speciﬁc\nsolutions when trained end-to-end. We additionally\nevaluate whether systems can provide evidence for\ntheir predictions. With this aim, we augment ev-\nery instance in KILT with provenance information\nin the form of textual spans in speciﬁc Wikipedia\npages to corroborate the output. We additionally\nperform an annotation campaign via Amazon Me-\nchanical Turk to increase the provenance coverage.\nLastly, in addition to evaluating downstream per-\nformance with popular metrics we formulate novel\nKILT variants for those that award points only if\nsystems ﬁnd provenance Wikipedia pages for the\noutput given the input. The poor absolute perfor-\nmance of our baselines for those metrics indicates\nthe need for focused research on systems able to\nexplain their decisions.\nIn summary, we contribute:\n1. a publicly-available benchmark of knowledge-\nintensive tasks aligned to a single Wikipedia\nsnapshot, to spur the development of general-\npurpose models and enable their comparison;\n2. an open-source library to facilitate the devel-\nopment of new architectures for knowledge-\nintensive tasks;\n3. a provenance indication for all instances in\nKILT, made more comprehensive with an an-\nnotation campaign, which allows to jointly\nassess output accuracy and ability to provide\nsupporting evidence in the knowledge source;\n4. a comparative performance of various model-\ning approaches, showing promising results for\ngeneral baselines across all tasks.\n2 Knowledge Source\nA main feature of the KILT benchmark is the use of\na uniﬁed knowledge source that contains all infor-\nmation necessary for all tasks. Deﬁning a uniﬁed\nknowledge source is a challenging problem — al-\nthough all tasks use Wikipedia, they consider differ-\nent snapshots. As Wikipedia pages are constantly\nmodiﬁed, added, and removed, the knowledge can\ndiffer drastically from snapshot to snapshot. Con-\ncretely, the KILT knowledge source is based on\nthe 2019/08/01 Wikipedia snapshot and contains\n5.9M articles. We describe how each dataset is\nrepresented in KILT, and our mapping strategy for\naligning data to our chosen snapshot. Additional\ndetails are in the appendix.\nMapping Datasets to a Fixed Snapshot The\nmain challenge in deﬁning a uniﬁed knowledge\nsource is ensuring the knowledge for all task ex-\namples is available. We assume tasks provide an\ninput (e.g. a question in question answering, or\na conversation in dialogue) needed to produce an\noutput (e.g. an answer or a subsequent utterance).\nIn addition, tasks provide provenance, deﬁned as\na set of textual spans in Wikipedia that contain\nevidence for producing an output given a speciﬁc\ninput. These provenance spans range from single\nentities, short answers, sentences, paragraphs, to\nwhole articles. The idea of our mapping strategy\nis to identify provenance spans in the KILT knowl-\nedge source—if we ﬁnd all the provenance spans\nfor an input-output pair, the knowledge needed to\nproduce the output is available in our snapshot. The\nprovenance can be a span of any size, from a single\ntoken to a paragraph to an entire document.\nConcretely, the mapping strategy operates as fol-\nlows.3 First, we try to match Wikipedia pages in\neach dataset to our snapshot, relying on Wikipedia\nURL redirections for pages that changed title.\nSecond, we look for the provenance span in the\nmatched page. We scan the whole page and return\nthe span with the highest BLEU (Papineni et al.,\n2002) with the given provenance span.4 Third, we\nreplace the original provenance in a task’s input-\noutput pair with the span from the KILT knowledge\nsource, and we report the BLEU score between the\ntwo. Finally, we remove from the dev and test sets\nall outputs for which the BLEU score is lower than\na threshold for at least one provenance span (we\n3Scripts for the mapping algorithm available on GitHub.\n4We return the shortest span if there’s a tie in BLEU score.",
        "document_metadata": {
          "page_label": "3",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "c8acd236-9a3b-46fb-8fb8-d789a5e6f759",
      "properties": {
        "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
        "document_metadata": {
          "page_label": "4",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "3 Tasks",
          "3.1 Fact Checking",
          "3.2 Entity Linking"
        ]
      },
      "type": "document"
    },
    {
      "id": "0f405357-730f-4ff4-bf67-72dfc3da8764",
      "properties": {
        "page_content": "Label Dataset Reference Task Input Format Output Format\nFEV FEVER Thorne et al. (2018a) Fact Checking Claim Classiﬁcation\nAY2 AIDA CoNLL-Y AGO Hoffart et al. (2011b) Entity Linking Text Chunk Entity\nWnWi WNED-WIKI Guo and Barbosa (2018) Entity Linking Text Chunk Entity\nWnCw WNED-CWEB Guo and Barbosa (2018) Entity Linking Text Chunk Entity\nT-REx T-REx Elsahar et al. (2018) Slot Filling Structured Entity\nzsRE Zero Shot RE Levy et al. (2017) Slot Filling Structured Entity\nNQ Natural Questions Kwiatkowski et al. (2019) Open Domain QA Question Extractive\nHoPo HotpotQA Yang et al. (2018) Open Domain QA Question Short Abstractive\nTQA TriviaQA Joshi et al. (2017) Open Domain QA Question Extractive\nELI5 ELI5 Fan et al. (2019b) Open Domain QA Question Long Abstractive\nWoW Wizard of Wikipedia Dinan et al. (2019) Dialogue Conversation Long Abstractive\nTable 1: Datasets and tasks considered in KILT.\nWNED-CWEB (Guo and Barbosa, 2018) is a\ndataset created with the same strategy as WNED-\nWIKI, but sampling from the ClueWeb 2012 cor-\npora annotated with the FACC1 system.7 Similarly,\nwe randomly split into dev and test.\n3.3 Slot Filling\nThe goal of the Slot Filling (SF) is to collect in-\nformation on certain relations (or slots) of entities\n(e.g., subject entity Albert Einstein and relation\neducated_at) from large collections of natural lan-\nguage texts. A potential application is structured\nKnowledge Base Population (KBP Surdeanu and\nJi, 2014). SF requires (1) disambiguation of the\ninput entity and (2) acquiring relational knowledge\nfor that entity. For KILT, we model the input as\na structured string subject entity [SEP] relation ,\nthe output as a list of equally-valid object-entities,\neach one accompanied with provenance where the\nsubject-relation-object fact manifests.\nZero Shot RE (Levy et al., 2017) is a dataset de-\nsigned to translate relation extraction into a reading\ncomprehension problem. We consider the open-\ndomain version of this dataset and align the in-\nput/output with the KILT interface. Additional\ndetails are in the appendix.\nT-REx (Elsahar et al., 2018) provides a large-\nscale collection of facts aligned to sentences in\nWikipedia abstracts through distant supervision.\nWe consider each sentence as provenance and for-\nmulate the input as above (details in the appendix).\n3.4 Open Domain Question Answering\nOpen domain Question Answering (Chen et al.,\n2017) is the task of producing the correct answer\nfor a question, without a predeﬁned location for the\n7http://lemurproject.org/clueweb12\nanswer. Standard tasks such as SQuAD (Rajpurkar\net al., 2016) provide an evidence document, but in\nopen domain tasks, models must reason over an\nentire knowledge source (such as Wikipedia). We\nconsider the question as input and the answer as\noutput with dataset-speciﬁc provenance.\nNatural Questions (Kwiatkowski et al., 2019)\nis a corpus of real questions issued to the Google\nsearch engine. Each question comes with an ac-\ncompanied Wikipedia page with an annotated long\nanswer (a paragraph) and a short answer (one or\nmore entities). We consider the open-version of the\ndataset and use both long and short answers spans\nas provenance. We collaborated with the authors of\nNatural Questions to access a held out, unpublished\nportion of the original dataset to form a new test\nset for KILT. By construction each QA pair is asso-\nciated with a single Wikipedia page, although other\npages might contain enough evidence to answer the\nquestion. To increase the provenance coverage we\nperform an Amazon Mechanical Turk campaign\nfor the dev and test sets and increase the average\nnumber of provenance pages per question from 1\nto 1.57 (details in section 4).\nHotpotQA (Yang et al., 2018) requires multi-\nhop reasoning over multiple Wikipedia pages to\nanswer each question. For each question-answer\npair, a set of supporting sentences are provided,\nand we consider these as provenance. We focus on\nthe fullwiki setting, where systems are required to\nretrieve and reason over the whole Wikipedia.\nTriviaQA (Joshi et al., 2017) is a collection of\nquestion-answer-evidence triples. Evidence docu-\nments are automatically gathered from Wikipedia\nor the Web. We consider only the Wikipedia case.\nWe use the answer span asprovenance and consider\nthe full version of the dev and test set.",
        "document_metadata": {
          "page_label": "5",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "e8006f91-72d4-4033-95c5-78204b915a85",
      "properties": {
        "page_content": "ELI5 (Fan et al., 2019b) 8 is a collection of\nquestion-answer-evidence triples where the ques-\ntions are complex, and the answers are long, ex-\nplanatory, and free-form. For dev and test, we col-\nlect annotations using Amazon Mechanical Turk,\nasking evaluators to select which supporting docu-\nments from Wikipedia can be used to answer the\nquestion. We treat these as gold provenance anno-\ntations for evaluation (details in section 4).\n3.5 Dialogue\nChitchat dialogue is the task of developing an en-\ngaging chatbot that can discuss a wide array of\ntopics with a user, which often relies on topical,\nfactual knowledge. For example, it would be dif-\nﬁcult to have a conversation about “grayhounds”\nwithout any information about that dog breed. We\nconsider the conversation history as input and the\nnext utterance as output.\nWizard of Wikipedia (Dinan et al., 2019) is a\nlarge dataset of conversation grounded with knowl-\nedge retrieved from Wikipedia. One speaker in the\nconversation must ground their utterances in a spe-\nciﬁc knowledge sentence, chosen from a Wikipedia\npage. The chosen sentence forms the provenance\nfor KILT.\n4 Provenance Annotation Campaign\nWe perform an Amazon Mechanical Turk cam-\npaign on the NQ and ELI5 datasets for the dev\nand test splits. While for the NQ our aim is to in-\ncrease the provenance coverage (i.e., we already\nhave a provenance page for each qa pair) for ELI5\nwe want to collect provenance information from\nscratch. For each question we ask annotators to\nindicate if four pre-determined passages contain\nenough evidence to answer the question and addi-\ntionally highlight a salient span in them. We select\nthe passages to annotate using our baseline retrieval\nmodels, namely Tf-idf, DPR, RAG and BLINK +\nﬂair (details in the Appendix).9 We only consider\npassages with some tokens overlap with the gold\nanswers (at least 10%).\nFor NQ, we additionally include gold passages\namong those to annotate, with the twofold objec-\ntive of controlling the quality of the annotation\nprocess and ﬁlter out questions that can’t be an-\n8https://yjernite.github.io/lfqa.html\n9for Tf-idf and BLINK + ﬂair we consider the ﬁrst passage\nin the retrieved page\nswered given the KILT Wikipedia snapshot.10 If\nno passage is selected by an annotator we ask to\nprovide either another one from Wikipedia or an\nexplanation. We collect three annotations for each\npassage, and insert the passage as new provenance\nfor the question if at least two annotators found\nenough evidence to answer in it. The average inter-\nannotator agreement is 0.3 and 0.1 Cohen’s kappa\nfor NQ and ELI5 respectively. Note that ELI5 ques-\ntions are in general more complex than NQ ones,\nthe required answer is not an extracted span from\na page but a free-form explanation that not always\ncan be grounded in Wikipedia.\nTo make ELI5 data more robust we computed the\noverlap between provenance passages and answers\nfor each instance using ROUGE-L and manually\nannotate instances with low overlap (ROUGE-L <\n0.15). Overall, we were able to collect provenance\ninformation for 1507 dev instances (3000 anno-\ntated) and 600 test instances (2000 annotated) for\nELI5, with an average of 1.18 Wikipedia pages as\nprovenance per instance. For NQ, we ﬁlter out on\naverage 8% of data (258 dev and 110 test instances)\nand include on average 1.57 Wikipedia pages as\nprovenance per instance. Additional details in the\nAppendix, table 6.\n5 Evaluation Metrics\nVarious tasks in the KILT Benchmark need to be\nevaluated differently, which can make task-wide\ncomparison challenging. Further, there are multi-\nple aspects of each system that we want to assess,\nnamely (1) downstream results, (2) performance in\nretrieving relevant evidence to corroborate a predic-\ntion and (3) a combination of the two. We report\ndifferent metrics to capture these aspects.11\nDownstream performance. We consider differ-\nent metrics to capture the uniqueness of the differ-\nent tasks in KILT and mimic the typical way to\nassess performance for each dataset. We use Accu-\nracy for tasks that require a discrete output (e.g.,\nan entity); Exact Match (EM) for tasks with ex-\ntractive (i.e., Natural Questions, TriviaQA) or short\nabstractive output format (i.e., HotpotQA); ﬁnally,\nfor tasks with long abstractive output format, we\nuse ROUGE-L (Lin, 2004) for ELI5 and F1-score\nfor Wizard of Wikipedia. For EM and F1-score\nwe follow standard post-processing to lowercase,\n10we present passages in random order to the annotator to\nexclude biases.\n11evaluation scripts available in GitHub.",
        "document_metadata": {
          "page_label": "6",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "638a8994-4b97-47b1-99cc-d454e878e908",
      "properties": {
        "page_content": "Model #Parameters\nTrans MemNet (Dinan et al., 2019) 15.5M\nBERT (base) (Devlin et al., 2019) 110M\nNSMN (Nie et al., 2019) 199M +93M nt\nT5 (base) (Raffel et al., 2019b) 220M\nDPR (Karpukhin et al., 2020) 220M +15B idx\nBERT (large) (Devlin et al., 2019) 340M\nBART (large) (Lewis et al., 2019) 406M\nRAG (Lewis et al., 2020b) 626M +15B idx\nBLINK (Wu et al., 2019) 680M +6B idx\nTable 2: Baselines considered and total number of their\ntrainable parameters. Non trainable (nt) parameters and\nindex (idx) sizes are also reported.\nstrip articles, punctuation, and duplicate whites-\npace from gold and predicted output (Rajpurkar\net al., 2016). Note that Accuracy is equivalent to\nstrict exact match, without post-processing. We\nreport additional metrics for some datasets in the\nappendix (Table 7-17).\nRetrieval. We adopt a page-level formulation\nand measure the ability of a model to provide a\nset of Wikipedia pages as evidence for a predic-\ntion.12 For most datasets in KILT a single page\nis enough to provide complete evidence, with the\nexception of FEVER (~12% which requires more\nthan one page) and HotpotQA (two pages are al-\nways required). We consider the following retrieval\nmetrics in KILT:\nR-precision, calculated as r\nR, where R is the\nnumber of Wikipedia pages inside each prove-\nnance set and r is the number of relevant pages\namong the top-R retrieved pages. For most of the\ndatasets R = 1and this formulation is equivalent\nto Precision@1. Concretely, R-precision=1 if all\nWikipedia pages in a provenance set are ranked at\nthe top. We report the maximum value among all\nprovenance sets for any given input.\nRecall@k, calculated as w\nn , where n is the num-\nber of distinct provenance sets for a given input\nand w is the number of complete provenance sets\namong the top- k retrieved pages. For datasets\nthat require more than one page of evidence (e.g.,\nFEVER and HotpotQA), we use the lowest ranked\npage in each provenance set to determine its posi-\ntion and remove the other pages in the set from the\nrank. For both metrics, we report the mean over all\ntest datapoints.\n12our evaluation scripts allow to evaluate retrieval perfor-\nmance at a more ﬁne-grained level (e.g., paragraph).\nKILT scores. We propose a KILT version for\ndownstream metrics that, inspired by the FEVER-\nscore (Thorne et al., 2018a), takes into account the\nprovenance supporting the output. For each data-\npoint, we only award Accuracy, EM, ROUGE-L,\nand F1 points to KILT-AC, KILT-EM, KILT-RL and\nKILT-F1 respectively, if the R-precision is 1. This\nis equivalent to awarding points if the system ﬁnds\n(and ranks at the top) a complete set of provenance\nWikipedia pages for at least one ground truth out-\nput given the input. We choose this metric to em-\nphasize that systems must be able to explain their\noutput with proper evidence, not simply answer.\n6 Baselines\nThe KILT tasks provide a dual challenge of retriev-\ning information and conditioning upon that to cre-\nate an output. Various directions could be applied\nto these. For example, the Wikipedia knowledge\ncould be represented explicitly, as natural language\nor in a structured form, or represented implicitly,\nas knowledge stored in model parameters. Models\ncould be discriminative, extractive, where a spe-\nciﬁc span is selected as output, orgenerative, where\nthe model writes an output. We consider retrieval,\ntask-speciﬁc, and general baselines for KILT (see\nTable 2). Additional details are in the appendix.\n7 Results\nWe summarize the main results in three tables:\ndownstream performance in Table 3, retrieval in\nTable 4 and KILT scores in Table 5. Additional\nresults, as well as comparisons with recent works\nreported numbers, can be found in the appendix.\nIt’s possible to get the performance of a system for\nthe KILT test sets by uploading its predictions to\nour EvalAI challenge.5\nWhen considering downstream performance (Ta-\nble 3), although pre-trained sequence-to-sequence\nmodels can embed knowledge implicitly in their\nparameters to some extent (Petroni et al., 2019;\nRoberts et al., 2020), they clearly lag behind mod-\nels with explicit knowledge access in almost all\ndatasets. The BART+DPR baseline that incorpo-\nrates an explicit retrieval step in addition to the\ngenerative pretraining, works well. It outperforms\nsome of the task-speciﬁc solutions, and gets close\nto others. Performance are even stronger when the\nretriever and reader components are trained end-to-\nend, as in the case of RAG. We ﬁnd this a promising\ndirection for knowledge intensive tasks.",
        "document_metadata": {
          "page_label": "7",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "32c55478-d3ca-4877-b454-480f8c32a110",
      "properties": {
        "page_content": "Fact Check. Entity Linking Slot Filling Open Domain QA Dial.\nmodel FEV AY2 WnWi WnCw T-REx zsRE NQ HoPo TQA ELI5 WoW\nAccuracy Exact Match RL F1\nts\nNSMN 66.1 - - - - - - - - - -\nBERT + DPR 69.68 - - - - 6.93 38.64 11.29 70.38 - -\nBLINK - 81.54 80.24 68.77 - - - - - - -\nTrans MemNet - - - - - - - - - - 11.85\nim\nBART (large) 78.93 77.55 45.91 49.16 45.06 9.14 21.75 15.37 32.39 20.55 12.86\nT5 (base) 76.3 74.05 47.13 49.29 43.56 9.02 19.6 12.64 18.11 19.08 13.53\nex\nBART + DPR 86.74 75.49 45.2 46.87 59.16 30.43 41.27 25.18 58.55 17.41 15.19\nRAG 86.31 72.62 48.07 47.61 59.2 44.74 44.39 26.97 71.27 14.05 13.11\nTable 3: Downstream performance on the test data. Baselines are grouped by task-speciﬁc ( ts) and general with\nimplicit (im) or explicit (ex) knowledge access. Task-speciﬁc solutions cannot be generally applied to all datasets\nin KILT, hence there are empty cells in the top part of the table. We report the typical metric to assess performance\nfor each dataset, speciﬁed in the ﬁrst row.\nFact Check. Entity Linking Slot Filling Open Domain QA Dial.\nmodel FEV AY2 WnWi WnCw T-REx zsRE NQ HoPo TQA ELI5 WoW\nR-Precision\nDPR + BERT 72.93 - - - - 40.11 60.66 25.04 43.4 - -\nDPR 55.33 1.81 0.3 0.51 13.26 28.96 54.29 25.04 44.49 10.67 25.48\nMulti-task DPR 74.48 26.48 4.91 1.86 69.46 80.91 59.42 42.92 61.49 15.5 41.07\nTf-idf 50.85 3.74 0.24 2.09 44.74 60.83 28.12 34.14 46.37 13.67 49.01\nRAG 61.94 72.62 48.07 47.61 28.68 53.73 59.49 30.59 48.68 11.0 57.78\nBLINK + ﬂair 63.71 81.54 80.24 68.77 59.56 78.78 24.52 46.12 65.58 9.5 38.21\nTable 4: Page-level R-Precision on test data. For DPR, we additionally report the performance after the BERT-\nbased classiﬁer (for FE) or reader (for NQ,HP,TR) re-ranked relevant pages (i.e., DPR + BERT). R-Precision is\nequivalent to Precision@1 for all datasets except FEV and HoPo that require multi-hop.\nBy formulating Entity Linking within KILT, we\ncan evaluate the ability of seq2seq models at this\ntask. They perform surprisingly well, even with-\nout any explicit access to knowledge (i.e., BART\nand T5). These solutions are able to link entity\nmentions by either leaving them untouched (if they\nmatch the correct Wikipedia title), completely alter-\ning mention text (e.g., “European Cup”→“UEFA\nChampions League”), or adding disambiguation\ntokens (e.g., “Galatasaray” → “Galatasaray S.K.\n(football)”). We report an example in Figure 4.\nWhen considering retrieval alone (Table 4) there\nis no clear winner—entity-centric tasks (Entity\nLinking and Slot Filling) clearly beneﬁt from entity-\nbased retrieval, while DPR works better for NQ,\nFEV and ELI5, that require more ﬁne grained pas-\nsages supervision. We believe that combining all\nthese ingredients (i.e., dense representations, ﬁne\ngrained supervision, entity awareness) will be nec-\nessary for general task-agnostic memories. More-\nover, jointly training a single DPR model on all\nKILT training data (Multi-task DPR) led to strong\nperformance gains on all datasets compared with\nthe original model (DPR), that considers only NQ\nand TQA as training data (Karpukhin et al., 2020).\nThis suggests synergies between KILT datasets that\nare beneﬁcial in terms of model performance.\nFinally, the KILT scores formulation allows us\nto systematically assesses the performance for out-\nput and provenance jointly (Table 5). We don’t\nreport results for BART and T5 since answers are\ngenerated solely from the input with no explicit\nretrieval and there is no straightforward way to ac-\ncess provenance for each prediction. The relative\nperformance of the other baselines with respect to\nKILT scores is consistent with downstream results.\nHowever, the generally low absolute numbers leave\na large room for improvement for systems able to\nprovide the correct output but also successfully jus-\ntify their decision.",
        "document_metadata": {
          "page_label": "8",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "a788b5e2-7d8c-42b9-a3ee-962e9e31d2aa",
      "properties": {
        "page_content": "Fact Check. Entity Linking Slot Filling Open Domain QA Dial.\nmodel FEV AY2 WnWi WnCw T-REx zsRE NQ HoPo TQA ELI5 WoW\nKILT-AC KILT-EM -RL -F1\nts\nNSMN 41.88 - - - - - - - - - -\nBERT + DPR 58.58 - - - - 4.47 31.99 0.74 34.48 - -\nBLINK - 81.54 80.24 68.77 - - - - - - -\nTrans MemNet - - - - - - - - - - 2.2\nex\nBART + DPR 47.68 75.49 45.2 46.87 11.12 18.91 30.06 1.96 31.4 1.9 4.37\nRAG 53.45 72.62 48.07 47.61 23.12 36.83 32.69 3.21 38.13 1.69 8.75\nTable 5: KILT scores on the test data. We do not report KILT scores for baselines with implicit knowledge access\nsince no provenance information is returned by them. We report the KILT version of donwstream metrics, speciﬁed\nin the ﬁrst row (to save space we abbreviate KILT-RL and KILT-F1). KILT scores are computed by awarding points\nonly if provenance pages are found (i.e., R-Precision = 1).\n8 Discussion\nThere are custom solutions that can easily simplify\nthe slot ﬁlling task. For instance, subject entities\ncan be used for lookups by title in Wikipedia to\nretrieve knowledge (this heuristic will always work\nfor zsRE), and structured human-curated resources\n(such as Wikidata13) could be used to get all an-\nswers right. Nevertheless, we are interested in test-\ning if a general model can extract attributes about\nspeciﬁc entities from a large body of text.\nThe provenance to justify each system prediction\ncan come from anywhere, including a different\nsystem, and this is difﬁcult to detect. Moreover\nour provenance might not be exhaustive—given\nthe redundancy of information in Wikipedia there\ncould be other pages with the knowledge needed to\nsolve a KILT instance. We conduct an annotation\ncampaign to mitigate the problem.\n9 Related Work\nSeveral natural language benchmarks have been in-\ntroduced to track and support NLP progress, includ-\ning natural language understanding (Wang et al.,\n2018, 2019), multitask question answering (Mc-\nCann et al., 2018), reading comprehension (Dua\net al., 2019), question understanding (Wolfson\net al., 2020), and dialogue (Shuster et al., 2019).\nWe focus on multi-domain tasks that need to seek\nknowledge in a large body of documents to produce\nan output. Although there exist several tasks and re-\nsources that deﬁne large-scale external knowledge\nsources—including the TAC-KBP challenges (Mc-\nNamee and Dang, 2009; Ji et al., 2010; Surdeanu,\n2013; Surdeanu and Ji, 2014), ARC (Clark et al.,\n13https://www.wikidata.org\n2018), TriviaQA-web (Joshi et al., 2017), Quasar-\nT (Dhingra et al., 2017), WebQuestions (Berant\net al., 2013) and ComplexWebQuestions (Talmor\nand Berant, 2018)—in KILT we exclusively con-\nsider publicly available Wikipedia-based datasets\nin order to merge and unify the knowledge source.\n10 Conclusion\nWe introduce KILT, a benchmark for assessing\nmodels that need to condition on speciﬁc knowl-\nedge in a deﬁned snapshot of Wikipedia to solve\ntasks spanning ﬁve domains. The goal is to cat-\nalyze and facilitate research towards general and\nexplainable models equipped with task-agnostic\nrepresentations of knowledge. Our experiments\nshow promising results for a general solution com-\nbining dense retrieval and seq2seq generations, al-\nthough there is large room for improvements. In\nparticular, we ﬁnd that provenance of current mod-\nels is generally low.\n11 Acknowledgment\nThe authors would like to greatly thank the team be-\nhind Natural Questions14 for the held out data, that\ndeﬁnes our NQ test set; FEVER 15, HotpotQA16\nand TriviaQA17 teams for sharing ofﬁcial test data\nfor the KILT leaderboard; Luke Zettlemoyer and\nScott Wen-tau Yih for helpful discussions; Rishabh\nJain for the help in setting up the EvalAI challenge.\n14https://ai.google.com/research/\nNaturalQuestions\n15https://fever.ai\n16https://hotpotqa.github.io\n17https://nlp.cs.washington.edu/\ntriviaqa",
        "document_metadata": {
          "page_label": "9",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "4088fffb-a806-468f-b786-69552e697410",
      "properties": {
        "page_content": "References\nAlan Akbik, Tanja Bergmann, Duncan Blythe, Kashif\nRasul, Stefan Schweter, and Roland V ollgraf. 2019.\nFlair: An easy-to-use framework for state-of-the-art\nnlp. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics (Demonstrations) , pages 54–\n59.\nJonathan Berant, Andrew Chou, Roy Frostig, and Percy\nLiang. 2013. Semantic parsing on freebase from\nquestion-answer pairs. In Proceedings of the 2013\nconference on empirical methods in natural lan-\nguage processing, pages 1533–1544.\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine\nBordes. 2017. Reading wikipedia to answer open-\ndomain questions. ACL.\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,\nAshish Sabharwal, Carissa Schoenick, and Oyvind\nTafjord. 2018. Think you have solved question an-\nswering? try arc, the ai2 reasoning challenge. arXiv\npreprint arXiv:1803.05457.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nBhuwan Dhingra, Kathryn Mazaitis, and William W\nCohen. 2017. Quasar: Datasets for question an-\nswering by search and reading. arXiv preprint\narXiv:1707.03904.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\nFan, Michael Auli, and Jason Weston. 2019. Wizard\nof wikipedia: Knowledge-powered conversational\nagents. Proceedings of the International Conference\non Learning Representations (ICLR).\nDheeru Dua, Ananth Gottumukkala, Alon Talmor,\nSameer Singh, and Matt Gardner. 2019. Orb: An\nopen reading benchmark for comprehensive evalu-\nation of machine reading comprehension. arXiv\npreprint arXiv:1912.12598.\nHady Elsahar, Pavlos V ougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon Hare, Elena Simperl,\nand Frederique Laforest. 2018. T-rex: A large scale\nalignment of natural language with knowledge base\ntriples. LREC.\nAngela Fan, Claire Gardent, Chloé Braud, and An-\ntoine Bordes. 2019a. Using local knowledge graph\nconstruction to scale Seq2Seq models to multi-\ndocument inputs. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 4186–4196, Hong Kong, China. As-\nsociation for Computational Linguistics.\nAngela Fan, Yacine Jernite, Ethan Perez, David Grang-\nier, Jason Weston, and Michael Auli. 2019b. ELI5:\nlong form question answering. In Proceedings of\nthe 57th Conference of the Association for Compu-\ntational Linguistics, ACL 2019, Florence, Italy, July\n28- August 2, 2019, Volume 1: Long Papers , pages\n3558–3567. Association for Computational Linguis-\ntics.\nPaolo Ferragina and Ugo Scaiella. 2011. Fast and ac-\ncurate annotation of short texts with wikipedia pages.\nIEEE software, 29(1):70–75.\nZhaochen Guo and Denilson Barbosa. 2018. Robust\nnamed entity disambiguation with random walks.\nSemantic Web, 9(4):459–479.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Ming-Wei Chang. 2020. Realm: Retrieval-\naugmented language model pre-training.\nJohannes Hoffart, Fabian M Suchanek, Klaus\nBerberich, Edwin Lewis-Kelham, Gerard De Melo,\nand Gerhard Weikum. 2011a. Yago2: exploring and\nquerying world knowledge in time, space, context,\nand many languages. In Proceedings of the 20th\ninternational conference companion on World wide\nweb, pages 229–232.\nJohannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-\ndino, Hagen Fürstenau, Manfred Pinkal, Marc Span-\niol, Bilyana Taneva, Stefan Thater, and Gerhard\nWeikum. 2011b. Robust disambiguation of named\nentities in text. In Proceedings of the Conference on\nEmpirical Methods in Natural Language Processing,\npages 782–792. Association for Computational Lin-\nguistics.\nHeng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-\nﬁtt, and Joe Ellis. 2010. Overview of the tac 2010\nknowledge base population track. In Third text anal-\nysis conference (TAC 2010), volume 3, pages 3–3.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. TriviaQA: A large scale dis-\ntantly supervised challenge dataset for reading com-\nprehension. In Proceedings of the 55th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 1601–1611, Van-\ncouver, Canada. Association for Computational Lin-\nguistics.\nVladimir Karpukhin, Barlas O ˘guz, Sewon Min, Ledell\nWu, Sergey Edunov, Danqi Chen, and Wen-\ntau Yih. 2020. Dense passage retrieval for\nopen-domain question answering. arXiv preprint\narXiv:2004.04906.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nﬁeld, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin,",
        "document_metadata": {
          "page_label": "10",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "46499f0b-0d8d-4721-b135-34cb1fd55cb4",
      "properties": {
        "page_content": "Kenton Lee, et al. 2019. Natural questions: a bench-\nmark for question answering research. Transactions\nof the Association for Computational Linguistics ,\n7:453–466.\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova.\n2019. Latent retrieval for weakly supervised\nopen domain question answering. arXiv preprint\narXiv:1906.00300.\nOmer Levy, Minjoon Seo, Eunsol Choi, and Luke\nZettlemoyer. 2017. Zero-shot relation extraction via\nreading comprehension. CoNLL.\nMike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Ar-\nmen Aghajanyan, Sida Wang, and Luke Zettle-\nmoyer. 2020a. Pre-training via paraphrasing. arXiv\npreprint arXiv:2006.15020.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Ves Stoyanov, and Luke Zettlemoyer. 2019.\nBart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and\ncomprehension. ArXiv, abs/1910.13461.\nPatrick Lewis, Ethan Perez, Aleksandara Piktus,\nFabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich Küttler, Mike Lewis, Wen tau Yih,\nTim Rocktäschel, Sebastian Riedel, and Douwe\nKiela. 2020b. Retrieval-augmented generation for\nknowledge-intensive nlp tasks.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text summarization\nbranches out, pages 74–81.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nChristopher D Manning, Hinrich Schütze, and Prab-\nhakar Raghavan. 2008. Introduction to information\nretrieval. Cambridge university press.\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong,\nand Richard Socher. 2018. The natural language de-\ncathlon: Multitask learning as question answering.\narXiv preprint arXiv:1806.08730.\nPaul McNamee and Hoa Trang Dang. 2009. Overview\nof the tac 2009 knowledge base population track. In\nText Analysis Conference (TAC), volume 17, pages\n111–113. National Institute of Standards and Tech-\nnology (NIST) Gaithersburg, Maryland . . . .\nAlexander H Miller, Will Feng, Adam Fisch, Jiasen Lu,\nDhruv Batra, Antoine Bordes, Devi Parikh, and Ja-\nson Weston. 2017. Parlai: A dialog research soft-\nware platform. arXiv preprint arXiv:1705.06476.\nYixin Nie, Haonan Chen, and Mohit Bansal. 2019.\nCombining fact extraction and veriﬁcation with neu-\nral semantic matching networks. In Proceedings of\nthe AAAI Conference on Artiﬁcial Intelligence , vol-\nume 33, pages 6859–6866.\nMyle Ott, Sergey Edunov, Alexei Baevski, Angela\nFan, Sam Gross, Nathan Ng, David Grangier, and\nMichael Auli. 2019. fairseq: A fast, extensible\ntoolkit for sequence modeling. In Proceedings of\nthe 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics\n(Demonstrations), pages 48–53.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of\nthe 40th annual meeting on association for compu-\ntational linguistics, pages 311–318. Association for\nComputational Linguistics.\nFabio Petroni, Luciano del Corro, and Rainer Gemulla.\n2015. Core: Context-aware open relation extraction\nwith factorization machines. In EMNLP. Assoc. for\nComputational Linguistics.\nFabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim\nRocktäschel, Yuxiang Wu, Alexander H Miller, and\nSebastian Riedel. 2020. How context affects lan-\nguage models’ factual predictions. AKBC.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton\nBakhtin, Yuxiang Wu, Alexander H Miller, and Se-\nbastian Riedel. 2019. Language models as knowl-\nedge bases? EMNLP.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019a. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. arXiv e-prints.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019b. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100,000+ questions for\nmachine comprehension of text. EMNLP.\nSebastian Riedel, Limin Yao, Andrew McCallum, and\nBenjamin M Marlin. 2013. Relation extraction with\nmatrix factorization and universal schemas. In Pro-\nceedings of the 2013 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n74–84.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the pa-\nrameters of a language model? arXiv preprint\narXiv:2002.08910.\nErik F Sang and Fien De Meulder. 2003. Intro-\nduction to the conll-2003 shared task: Language-\nindependent named entity recognition. arXiv\npreprint cs/0306050.",
        "document_metadata": {
          "page_label": "11",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "004512bf-e5e7-4d19-bb56-41c7c88d8270",
      "properties": {
        "page_content": "Kurt Shuster, Da Ju, Stephen Roller, Emily Dinan,\nY-Lan Boureau, and Jason Weston. 2019. The\ndialogue dodecathlon: Open-domain knowledge\nand image grounded conversational agents. arXiv\npreprint arXiv:1911.03768.\nMihai Surdeanu. 2013. Overview of the tac2013\nknowledge base population evaluation: English slot\nﬁlling and temporal slot ﬁlling. In TAC.\nMihai Surdeanu and Heng Ji. 2014. Overview of the\nenglish slot ﬁlling track at the tac2014 knowledge\nbase population evaluation. In Proc. Text Analysis\nConference (TAC2014).\nAlon Talmor and Jonathan Berant. 2018. The web as\na knowledge-base for answering complex questions.\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 641–651.\nJames Thorne and Andreas Vlachos. 2020. Avoiding\ncatastrophic forgetting in mitigating model biases in\nsentence-pair classiﬁcation with elastic weight con-\nsolidation. arXiv preprint arXiv:2004.14366.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018a.\nFEVER: a large-scale dataset for fact extraction and\nveriﬁcation. In NAACL-HLT.\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\nChristos Christodoulopoulos, and Arpit Mittal.\n2018b. The fact extraction and veriﬁcation (fever)\nshared task. EMNLP.\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\nChristos Christodoulopoulos, and Arpit Mittal. 2019.\nThe fever2. 0 shared task. In Proceedings of the Sec-\nond Workshop on Fact Extraction and VERiﬁcation\n(FEVER), pages 1–6.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia,\nAmanpreet Singh, Julian Michael, Felix Hill, Omer\nLevy, and Samuel Bowman. 2019. Superglue: A\nstickier benchmark for general-purpose language un-\nderstanding systems. In Advances in Neural Infor-\nmation Processing Systems, pages 3261–3275.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2018.\nGlue: A multi-task benchmark and analysis platform\nfor natural language understanding. arXiv preprint\narXiv:1804.07461.\nThomas Wolf, L Debut, V Sanh, J Chaumond, C De-\nlangue, A Moi, P Cistac, T Rault, R Louf, M Fun-\ntowicz, et al. 2019. Huggingface’s transformers:\nState-of-the-art natural language processing. ArXiv,\nabs/1910.03771.\nTomer Wolfson, Mor Geva, Ankit Gupta, Matt Gard-\nner, Yoav Goldberg, Daniel Deutch, and Jonathan\nBerant. 2020. Break it down: A question under-\nstanding benchmark. Transactions of the Associa-\ntion for Computational Linguistics, 8:183–198.\nLedell Wu, Fabio Petroni, Martin Josifoski, Sebastian\nRiedel, and Luke Zettlemoyer. 2019. Zero-shot\nentity linking with dense entity retrieval. arXiv\npreprint arXiv:1911.03814.\nWenhan Xiong, Jingfei Du, William Yang Wang, and\nVeselin Stoyanov. 2019. Pretrained encyclopedia:\nWeakly supervised knowledge-pretrained language\nmodel. arXiv preprint arXiv:1912.09637.\nDeshraj Yadav, Rishabh Jain, Harsh Agrawal, Prithvi-\njit Chattopadhyay, Taranjeet Singh, Akash Jain,\nShiv Baran Singh, Stefan Lee, and Dhruv Batra.\n2019. Evalai: Towards better evaluation systems for\nai agents. arXiv preprint arXiv:1902.03570.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\npher D. Manning. 2018. HotpotQA: A dataset for\ndiverse, explainable multi-hop question answering.\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing , pages\n2369–2380.",
        "document_metadata": {
          "page_label": "12",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "17edfd58-a864-41f7-a01c-5da7ab9f19ce",
      "properties": {
        "page_content": "A Appendix\nWikipedia Representation We represent the\nKILT knowledge source as a collection of JSON\nrecords, one per Wikipedia page. Each record is\nassigned: (i) a unique Wikipedia id; (ii) a unique\nWikipedia title; (iii) a text ﬁeld containing a list of\nstrings, one for each paragraph, bulleted list item,\nand section header (for which we preserve the hier-\narchical structure); (iv) a list of anchors elements,\none for each hyperlink in the original page text,\nwith span reference in the text ﬁeld and page linked;\n(v) a list of categories; (vi) a url redirecting to the\noriginal html for the page, with timestamp of the\nlast page revision before the considered snapshot.\nDatasets Mapping Details In FEVER, often\nmultiple pieces of knowledge must be combined\nto produce an output. For example, 30% of claims\nhave more than one equally-valid provenance and\n16% require the combination of multiple evidence\nspans. The second iteration ( FEVER2.0, Thorne\net al., 2019) introduces a collection of adversar-\nial instances. For KILT, we merge the two ver-\nsions of FEVER into a single resource and con-\nsider only supported refuted claims. We exclude all\nclaims classiﬁed as not having enough information\nsince these instances have no evidence to assess the\nclaim and cannot be mapped to the KILT knowl-\nedge source. Therefore we cannot asses whether\nsuch label is still appropriated given our snapshot.\nMoreover, we design KILT as an in-KB resource\nwhere each instance can be answered and corrobo-\nrated by information in the knowledge source.\nIn the Zero Shot RE dataset a set crowd-sourced\ntemplate questions are deﬁned for each relation —\nfor example, What is Albert Einstein’s alma mater?.\nEach datapoint reports a Wikipedia sentence ex-\npressing the fact that we take as provenance. Some\nexamples in the dataset are negative, obtained by\nmatching a valid question and a random sentence,\nthat likely does not contain the answer. To consider\nan open-domain version of this dataset and align\nthe input/output with the KILT interface we refor-\nmatted this dataset, as follows: (i) exclude neaga-\ntive pairs - since we consider the whole knowledge\nsource (as opposite to a single sentence) as text\nall questions can be answered; (ii) group template\nquestions by the subject-relation pair, and create a\nsingle datapoint for each (input as above); (iii) ran-\ndomly split the set of relations, in line with the\noriginal dataset, into three disjoint sets train (with\n84 relations), dev (12 relations) and test (24 rela-\ntions)—systems are tested on relations never seen\nduring training; (iv) use the subject entity as the\nquery against Wikipedia titles for the ﬁrst step of\nthe mapping strategy, and (v) include all template\nquestions in a meta ﬁeld.\nFor T-REx, We ﬁlter out facts with more than\n20 provenances, relations with less than 1000 facts,\nand merge all the facts for the same subject-relation\npair (i.e., for 1-N and M-N relations there could\nbe multiple valid answers), resulting in 113 rela-\ntions and 2.3M facts. We include object aliases as\nequally valid answers and report in ameta ﬁeld sub-\nject aliases as well as all surface mentions for the\nsubject, relation and object. We randomly select 5k\nfacts for both dev and test set.\nTo deﬁne an open-version of the Natural Ques-\ntions dataset we follow Lee et al. (2019) and (1)\nkeep only questions with short answers and (2)\ndiscard all answers with more than ﬁve tokens.\nTo ﬁnd answers in TriviaQA, the original work\nused distant supervision: (1) ﬁnd Wikipedia entities\nin the question with the TAGME entity linked (Fer-\nragina and Scaiella, 2011); (2) search for the an-\nswer (and all Wikipedia aliases) in the correspond-\ning page; (3) if the answer is found, add the page\nin the evidence documents. Therefore, the docu-\nments are not guaranteed to contain evidence for\nthe question-answer pair (but the authors estimate\nthat they do 79.7% of the time).\nIn ELI5 Evidence documents are automatically\ngathered, and we focus on the case where evidence\ndocuments are extracted from Wikipedia. However,\nas the original work ﬁrst collected question-answer\npairs from the subreddit Explain Like I’m Five, the\ndocuments are not guaranteed to contain evidence.\nFor Wizard of Wikipediawe discard cases where\nthe dataset does not contain provenance. More-\nover, we consider a full open-domain setting where\nno topic is provided for the conversation and the\nmodel must search over all of Wikipedia for knowl-\nedge at each dialogue turn (rather than the provided\nknowledge candidates for each turn in the original\ndataset). We use the unseen split for dev and test.\nPerformance Impact Of The Mapping Strategy\nWe want to assess if the performance we obtain\nafter mapping each dataset to a uniﬁed Wikipedia\nsnapshot are in line with what reported in previous\nwork. Thorne and Vlachos (2020) report a 2-way\naccuracy of 79.09 for the FEVER dev set when\nconsidering purely claims in input to a RoBERTa-",
        "document_metadata": {
          "page_label": "13",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "d9edb78e-a3ac-4e6c-94fc-2bad6875e8f0",
      "properties": {
        "page_content": " 10\n 100\n 1000\n 10000\n 100000\n 1x106\n 1x107\n 1  2  3  4  5  6  7  8  9\nnumber of Wikipedia pages\nnumber of datasets\nFigure 2: Number of pages vs number of dataset\nwith knowledge in a page. 1,642,311 pages contains\nknowledge needed for KILT (~28% of the knowledge\nsource).\nbased classiﬁer (Liu et al., 2019). Our dev set in-\ncludes also the adversarial examples of FEVER 2.0,\nnevertheless the performance of BART are in line\n(80.67 dev, 78.93 test). Karpukhin et al. (2020) re-\nport 41.5 for EM on the open domain version of the\nNQ dev set18. With our setting, DPR achieves an\non-par performance on the dev set, with a 42.58 EM\n(50.43 F1-score). Results on our brand new NQ test\nset are 3/4 points lower for EM and F1-score than\ndev results. We don’t evaluate multi-hop speciﬁc\nbaselines on KILT but the current best F1-score for\nHotpotQA is 75.43 according to the ofﬁcial lead-\nearboard19, that is quite far from what achieved by\nour general solutions. BLINK results are in line\nwith what reported in the GitHub repository20 for\nall three entity linking datasets. The Tranformer\nMemNet of Dinan et al. (2019) achieves a F1-score\nof 14.3 on the original version of the WW dataset\nwhile 11.5 in our setting, probably because in KILT\nwe consider an harder open-domain setting.\nRetrieval Baselines The ability to retrieve rele-\nvant documents from Wikipedia given an input is\nan important aspect we assess in KILT. A system\nshould select only the relevant knowledge needed\nfor the task, without redundant or excess informa-\ntion. A way to surface such knowledge is using\na dedicated retrieval system. We consider three\noff-the-shelf retrievers and investigate drastically\ndifferent retrieval paradigms: (i) Tf-idf with the\nDrQA Document Retriever (Chen et al., 2017)—-\ntraditional page-level sparse vector space retrieval\nmodel; (ii) DPR (Karpukhin et al., 2020)—a mod-\nern passage-level retrieval solution using dense rep-\n18Reported as test results in (Karpukhin et al., 2020)\n19https://hotpotqa.github.io\n20https://github.com/facebookresearch/\nBLINK\nresentations; (iii) A combination of BLINK (Wu\net al., 2019) andﬂair (Akbik et al., 2019)—retrieval\nsolution that ranks pages according to entities in\nthe input.\nThe DrQA Document Retriever combines bi-\ngram hashing and TF-IDF matching to return rel-\nevant Wikipedia pages given an input. DPR splits\neach Wikipedia page into disjoint 100-word pas-\nsages21 and encodes passages and inputs with a\nBERT-based bi-encoder to perform dense Maxi-\nmum Inner Product Search. The BLINK entity\nlinking system uses a BERT-based bi-encoder to\nencode each Wikipedia page as well as each input,\nwhere a single entity mention is tagged. Final re-\nsults are reﬁned with a BERT-based cross-encoder.\nTo use BLINK for retrieval, we look for entity men-\ntions in each input with ﬂair, then use BLINK to\nreturn a ranked list of Wikipedia pages for each\nentity mention. When multiple entities are iden-\ntiﬁed in the input, we merge results and sort by\nscore. The input string might not contain tags. For\nall systems, we use the index created on the KILT\nknowledge source.\nWe also experiment with multi-tasking, by\njointly training a single DPR model on all KILT\ntraining data. We use uniform sampling to balance\nthe datasets. In particular, the Multi-task variant of\nDPR is a single dense passage retriever, trained\njointly on the union of TQA, NQ, HoPo, FEV ,\nzsRE, AY2, T-REx and WoW. In order to avoid\nlarge datasets, such as T-REx, from having an over-\nsize effect, we resample all datasets uniformly, such\nthat every training epoch contains 150k samples\nfrom each task. Batches are formed from a sin-\ngle dataset at a time, iterating through the various\ndatasets in a round-robin fashion.\nTask-speciﬁc Baselines Approaches to the KILT\nBenchmark should be able to generalize to many\ndifferent tasks, as developing model architectures\nthat can represent knowledge generally is a valu-\nable direction. However, several tasks may beneﬁt\nfrom dedicated architectures designed for them.\nFor fact checking, we consider NSMN (Nie et al.,\n2019), the highest scoring system from the FEVER\nshared task (Thorne et al., 2018b). We use the\npublic model22 pre-trained on FEVER, and con-\nsider not enough information predictions as false.\n2122,220,793 passages in the KILT knowledge source. Fol-\nlowing Karpukhin et al. (2020) we don’t consider Wikipedia\nbulleted lists in the text.\n22available at https://github.com/easonnie/\ncombine-FEVER-NSMN",
        "document_metadata": {
          "page_label": "14",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "7982f77f-9d28-4552-9f31-3520051f8d74",
      "properties": {
        "page_content": "Moreover, we develop a fact checking baseline that\ncombines a BERT-base classiﬁer with passages re-\nturned from DPR where the claim and retrieved\npassage are input. The classiﬁer is trained to label\nthe claim-passage pair as supported or refuted with\nan additional neutral class for negative-sampled\nunrelated passages. Unrelated passages are sam-\npled from two sources: (1) DPR-retrieved passages\nfrom pages that are not in the list of pages in the\ninstance’s provenance and (2) passages sampled\nuniformly at random from pages in the instance’s\nprovenance. At inference, we classify the ﬁrst sen-\ntence of the Wikipedia pages retrieved by the top-\n100 DPR passages against the claim. Using pages\nlabelled as supported or refuted, we label the claim\nthrough majority voting. For claim provenance, we\nre-rank passages by probability according to this\nlabel.\nFor Open Domain QA and Slot Filling, we\nuse DPR combined with the pre-trained BERT-\nbased extractive reading comprehension model\nof Karpukhin et al. (2020). We use the model pre-\ntrained on TriviaQA for HotpotQA and the model\npre-trained on Natural Questions for Zero Shot RE.\nWe reduce the slot ﬁlling problem to question an-\nswering, by using the speciﬁed template questions.\nWe consider a single random template question per\nsubject-relation during inference.\nFor Entity Linking, we consider BLINK.\nFor Dialogue, we consider the Generative Trans-\nformer MemNet (Dinan et al., 2019) that encodes\nthe dialogue history and knowledge to generates\nthe next utterance. We use the pre-trained version\navailable in ParlAI (Miller et al., 2017). Finally,\nto test the performance of combining BART and\nDPR on FEVER, we develop a classiﬁer that uses\nthese—full description in the appendix.\nGeneral Baselines A main motivation of the\nKILT Benchmark is to enable a uniﬁed approach\ntowards a wide range of knowledge-intensive tasks.\nWe analyze existing general architectures that can\nbe used as a baseline for multiple tasks in KILT.\nLarge pre-trained sequence-to-sequence models\nsuch as BART (Lewis et al., 2019) and T5 (Raffel\net al., 2019a) implicitly store a surprising amount of\nknowledge in their parameters (Petroni et al., 2019).\nWe treat all KILT tasks as generative, relying on\nthe knowledge accumulated by the model while\npre-training, with no retrieval (similarly to Roberts\net al. (2020)). We ﬁnetune pre-trained variants on\nall KILT tasks, using fairseq (Ott et al., 2019)\nfor BART and Huggingface’s Transformer (Wolf\net al., 2019) for T5.\nA natural way to boost performance is to in-\ncorporate an explicit knowledge mechanism. For\nour BART+DPR baseline, we follow Petroni et al.\n(2020) to retrieve and prepend the top-3 passages\nfrom DPR for each input sample and use context-\nenhanced training data to ﬁne-tune a BART model.\nWe use the DPR rank when reporting provenance\nfor all except entity linking tasks. For entity link-\ning, we report the Wikipedia id of the page whose\ntitle exactly matches the predicted string.\nRecently, state-of-the-art results on a wide range\nof NLP tasks have been achieved by combining a\ntrainable retrieval step with language modeling or\ngeneration (Guu et al., 2020; Lewis et al., 2020a).\nWe experiment with ﬁne-tuning RAG (Lewis et al.,\n2020b) on KILT tasks, establishing a strong base-\nline on all of them. RAG combines a DPR retriever\nwith a BART generator, however, unlike in the case\nof our previous baseline, RAG back-propagates to\nthe retriever’s input encoder, learning to adapt the\ninput embedding to retrieve more relevant results.\nAt every generation step we retrieve top-5 passages\nand use them as provenance.",
        "document_metadata": {
          "page_label": "15",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "496f0835-ec4e-4375-bbe8-4617272eec32",
      "properties": {
        "page_content": "Dataset\nLabel Multi-hop\nAverage\nProvenance\nSize (APS)\nAverage\nProvenance\nNumber (APN)\nAverage\nProvenance\nPages (APP)\nAverage\nAnswers\nNumber (AAN)\nTrain\nSize\nDev\nSize\nTest\nSize\nFEV x 1.12 1.35 1.13 1 104,966 10,444 10,100\nAY2 1 1 1 1 18,395 4,784 4,463\nWnWi 1 1 1 1 - 3,396 3,376\nWnCw 1 1 1 1 - 5,599 5,543\nT-REx 1 1.68 1.26 5.29 2,284,168 5,000 5,000\nzsRE 1 1 1 1 147,909 3,724 4,966\nNQ 1 3.22 1.57 2.08 87,372 2,837 1,444\nHoPo x 2.4 1 2 1 88,869 5,600 5,569\nTQA 1 3.39 1.68 28.67 61,844 5,359 6,586\nELI5 1 1.21 1.18 4.69 272,634 1,507 600\nWoW 1 1 1 1 63,734 3,054 2,944\nTotal 3,129,891 51,460 50,736\nTable 6: Datasets statistics. APS refers to the average number of textual spans in each provenance set—for most of\nthe datasets a single span is sufﬁcient to provide enough evidence while FEV and HoPo might require more (hence\nthey require multi-hop reasoning). APN indicates the average number of equally valid provenance sets for each\ninstance while APP the average number of Wikipedia pages overall in the provenance (note that multiple spans\nmight refer to the same Wikipedia page). Finally AAN reports the average number of equally valid gold answers\nper instance. We additionally report the size of the train, dev and test split for each dataset.\n1 { ’ i d ’ : # o r i g i n a l data p o i n t i d i f a v a i l a b l e otherwise unique i d\n2 ’ i n p u t ’ : # question / claim / sentence / etc\n3 ’ output ’ : [ # each element might contain an answer , a provenance or both\n4 {\n5 ’ answer ’ : # answer i n t e x t u a l form\n6 ’ provenance ’ : [\n7 # evidence set f o r the answer from the KILT knowledge source\n8 {\n9 ’ w i k i p e d i a _ i d ’ : #* mandatory *\n10 ’ t i t l e ’ :\n11 ’ section ’ :\n12 ’ start_paragraph_id ’ :\n13 ’ s t a r t _ c h a r a c t e r ’ :\n14 ’ end_paragraph_id ’ :\n15 ’ end_character ’ :\n16 ’ bleu_score ’ : # wrt o r i g i n a l evidence\n17 ’ meta ’ : # dataset / task s p e c i f i c\n18 }\n19 ]\n20 }\n21 ]\n22 ’ meta ’ : # dataset / task s p e c i f i c\n23 }\nFigure 3: KILT datasets’ interface. Each dataset is represented as a JSON Line ﬁle. The Figure shows the pseudo-\nJSON structure for each record in the ﬁles.",
        "document_metadata": {
          "page_label": "16",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "4953bf5b-b9c3-441f-a4e4-49a10f636069",
      "properties": {
        "page_content": "model R-Precision Recall@5 Accuracy KILT-AC\ntest\nBART 0.0 0.0 78.93 0.0\nT5 0.0 0.0 76.3 0.0\nNSMN 49.24 70.16 66.1 41.88\nBART + DPR 55.33 74.29 86.74 47.68\nRAG 61.94 75.55 86.31 53.45\nBERT + DPR 72.93 73.52 69.68 58.58\ndev\nBART 0.0 0.0 80.67 0.0\nBART + DPR 55.46 73.84 88.11 48.25\nRAG 63.5 76.1 87.7 55.47\nTable 7: FEVER\nmodel R-Precision Recall@5 Accuracy KILT-AC\ntest\nRAG 72.62 72.62 72.62 72.62\nT5 74.05 74.05 74.05 74.05\nBART + DPR 75.49 75.49 75.49 75.49\nBART 77.55 77.55 77.55 77.55\nBLINK 81.54 94.73 81.54 81.54\ndev\nRAG 77.4 77.47 77.4 77.4\nT5 81.84 81.84 81.84 81.84\nBART 86.62 86.62 86.62 86.62\nTable 8: AIDA CoNLL-Y AGO\nmodel R-Precision Recall@5 Accuracy KILT-AC\ntest\nBART + DPR 45.2 45.2 45.2 45.2\nBART 45.91 45.91 45.91 45.91\nT5 47.13 47.13 47.13 47.13\nRAG 48.07 48.07 48.07 48.07\nBLINK 80.24 91.47 80.24 80.24\ndev\nBART + DPR 44.96 44.96 44.96 44.96\nT5 47.35 47.35 47.35 47.35\nBART 47.91 47.91 47.91 47.91\nRAG 49.0 49.0 49.0 49.0\nTable 9: WNED-WIKI",
        "document_metadata": {
          "page_label": "17",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "themes": [
          "model",
          "R-Precision",
          "Recall@5",
          "Accuracy",
          "KILT-AC",
          "FEVER",
          "AIDA CoNLL-Y AGO",
          "WNED-WIKI"
        ]
      },
      "type": "document"
    },
    {
      "id": "aee20b6d-5bae-4e61-bff9-2e9fcc1b7e03",
      "properties": {
        "page_content": "model R-Precision Recall@5 Accuracy KILT-AC\ntest\nBART + DPR 46.87 46.87 46.87 46.87\nRAG 47.61 47.61 47.61 47.61\nBART 49.16 49.16 49.16 49.16\nT5 49.29 49.29 49.29 49.29\nBLINK 68.77 81.78 68.77 68.77\ndev\nBART + DPR 45.7 45.7 45.7 45.7\nT5 46.58 46.58 46.58 46.58\nRAG 46.7 46.7 46.7 46.7\nBART 48.01 48.01 48.01 48.01\nTable 10: WNED-CWEB\nmodel R-Precision Recall@5 Accuracy F1 KILT-AC KILT-F1\ntest\nBART 0.0 0.0 45.06 49.24 0.0 0.0\nT5 0.0 0.0 43.56 50.61 0.0 0.0\nBART + DPR 13.26 17.04 59.16 62.76 11.12 11.41\nRAG 28.68 33.04 59.2 62.96 23.12 23.94\ndev\nBART 0.0 0.0 43.84 48.25 0.0 0.0\nT5 0.0 0.0 47.24 51.73 0.0 0.0\nBART + DPR 13.62 16.93 56.7 60.19 11.56 11.87\nRAG 29.26 33.69 61.48 65.03 25.4 26.22\nTable 11: T-REx\nmodel R-Precision Recall@5 Accuracy F1 KILT-AC KILT-F1\ntest\nBART 0.0 0.0 9.14 12.21 0.0 0.0\nT5 0.0 0.0 9.02 13.52 0.0 0.0\nBERT + DPR 40.11 40.11 6.93 37.28 4.47 27.09\nBART + DPR 28.9 39.21 30.43 34.47 18.91 20.32\nRAG 53.73 59.52 44.74 49.95 36.83 39.91\ndev\nBART 0.0 0.0 3.03 12.61 0.0 0.0\nT5 0.0 0.0 1.58 10.8 0.0 0.0\nBART + DPR 45.6 58.49 34.96 44.79 29.08 32.85\nRAG 65.36 73.07 47.42 57.98 42.64 48.35\nTable 12: Zero Shot RE",
        "document_metadata": {
          "page_label": "18",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ],
        "summary": "AI is transforming industries by automating tasks and analyzing data, driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          -0.20148420333862305,
          0.6139746308326721,
          -0.4426495134830475,
          -0.4698089361190796,
          0.14095142483711243,
          -0.059441037476062775,
          -0.08708472549915314,
          -0.27141648530960083,
          0.7787469029426575,
          0.20899324119091034,
          -0.12373767793178558,
          0.34668615460395813,
          -0.597898542881012,
          -0.9008846879005432,
          0.14463353157043457,
          -0.410906583070755,
          0.08413369208574295,
          -0.097560353577137,
          -0.2352597415447235,
          -0.12094435095787048,
          0.03498772531747818,
          0.7249787449836731,
          -0.3866375684738159,
          -1.265449047088623,
          -0.9246146082878113,
          0.5560995936393738,
          0.7210267186164856,
          -0.5792335271835327,
          0.6615636348724365,
          0.6513221859931946,
          0.08162429183721542,
          -0.18767115473747253,
          0.2715427875518799,
          -0.40030476450920105,
          -0.5860006809234619,
          -0.19717082381248474,
          0.2358017861843109,
          -0.1223243847489357,
          -0.7840690612792969,
          -0.3318711519241333,
          0.20603540539741516,
          -0.23815809190273285,
          0.32684046030044556,
          -1.2838716506958008,
          -1.0260828733444214,
          0.7151329517364502,
          0.5354833006858826,
          -1.2028074264526367,
          0.08290591090917587,
          -0.3789614737033844,
          -0.700566828250885,
          0.39178264141082764,
          -0.02654721587896347,
          -0.23395071923732758,
          0.21959957480430603,
          -1.125575304031372,
          -0.3440718650817871,
          -0.2832734286785126,
          -0.4031120836734772,
          0.10884536802768707,
          1.0245732069015503,
          -0.45599305629730225,
          0.5619677901268005,
          0.13879811763763428,
          0.26263001561164856,
          0.4570104479789734,
          0.26263222098350525,
          -0.5139470100402832,
          -0.14334270358085632,
          0.11359032988548279,
          -1.032599687576294,
          -0.434639036655426,
          0.1929551661014557,
          0.17838793992996216,
          -0.35622280836105347,
          0.16047434508800507,
          -0.042429715394973755,
          -0.15424779057502747,
          -0.7303014993667603,
          -0.3622671961784363,
          -0.3941291868686676,
          0.6285946369171143,
          -0.4795178174972534,
          0.9358176589012146,
          -0.1739797294139862,
          -0.31824201345443726,
          0.7874322533607483,
          0.9343628883361816,
          -0.244326651096344,
          -0.6217713952064514,
          -0.059594184160232544,
          -0.034395936876535416,
          0.14561322331428528,
          -0.014831312000751495,
          -0.03956388682126999,
          0.7877362370491028,
          -0.5929844975471497,
          0.5298479795455933,
          0.054399795830249786,
          0.011268297210335732,
          0.3226891756057739,
          1.1086190938949585,
          -0.21888525784015656,
          0.8433919548988342,
          -0.7008355259895325,
          0.24204476177692413,
          0.6838487982749939,
          -0.8983402252197266,
          0.008471149951219559,
          -1.1745805740356445,
          0.511260986328125,
          0.17879033088684082,
          0.015214517712593079,
          0.30442488193511963,
          -0.03838057070970535,
          1.240529179573059,
          -0.2553979754447937,
          0.19505135715007782,
          -0.3302313983440399,
          0.4626478850841522,
          -0.5594297647476196,
          -0.5673165917396545,
          -0.15762931108474731,
          -0.6686323881149292,
          0.3763343095779419,
          -1.2249335050582886,
          0.19226546585559845,
          0.5461958646774292,
          -0.5416116714477539,
          0.8035534024238586,
          -0.16929170489311218,
          0.028102748095989227,
          -0.167934849858284,
          0.4299066662788391,
          0.06673695892095566,
          -0.9255534410476685,
          0.19180884957313538,
          0.6997563242912292,
          -0.40953803062438965,
          0.883830189704895,
          -0.1502297967672348,
          0.15672877430915833,
          -0.2864624559879303,
          1.7574213743209839,
          -0.2674376368522644,
          -0.06156667694449425,
          -0.628571629524231,
          -0.08150789141654968,
          -0.545596718788147,
          1.0218839645385742,
          -0.8263217806816101,
          0.3330860435962677,
          0.6943504214286804,
          -0.03237031027674675,
          -0.5081380605697632,
          -0.8758758902549744,
          -0.7734129428863525,
          -0.09367384016513824,
          0.33460545539855957,
          0.4113471508026123,
          -0.258066326379776,
          0.05829823389649391,
          -0.21685877442359924,
          1.0603046417236328,
          -0.31541508436203003,
          0.8204463720321655,
          -1.159802794456482,
          0.0018730983138084412,
          -0.5975947976112366,
          -0.142822265625,
          0.4923882484436035,
          -0.1380288004875183,
          -0.741234302520752,
          -0.49433010816574097,
          0.8227378129959106,
          0.9614874124526978,
          0.47688716650009155,
          -0.027627021074295044,
          -0.44168007373809814,
          -0.6042952537536621,
          -1.5507349967956543,
          -0.6307132840156555,
          -0.8442783355712891,
          0.009541034698486328,
          0.12625139951705933,
          0.4597608149051666,
          -0.049991119652986526,
          0.38293763995170593,
          0.47101208567619324,
          -0.4406893849372864,
          0.44963502883911133,
          0.6870209574699402,
          -0.8087270855903625,
          0.15781041979789734,
          0.057646140456199646,
          0.2808651030063629,
          -0.551630973815918,
          0.365143358707428,
          0.5985390543937683,
          0.02320372313261032,
          0.012854550033807755,
          0.5555001497268677,
          -0.3185601234436035,
          -0.6666186451911926,
          -1.0652189254760742,
          0.9585986137390137,
          -0.12556099891662598,
          1.2527409791946411,
          -1.699695348739624,
          1.3709709644317627,
          0.4401327967643738,
          0.1454131305217743,
          -0.37067240476608276,
          -0.3254300355911255,
          0.8537512421607971,
          0.013849236071109772,
          -0.324796587228775,
          0.30844029784202576,
          0.34156882762908936,
          -0.5146127343177795,
          -0.13078247010707855,
          -0.35351645946502686,
          0.43090930581092834,
          -0.7429024577140808,
          -0.3409920632839203,
          0.26322898268699646,
          -0.19592073559761047,
          0.8687750101089478,
          0.18892104923725128,
          0.21675081551074982,
          0.5833463072776794,
          0.7484593987464905,
          -0.8237089514732361,
          0.7997536659240723,
          -0.18377363681793213,
          0.4208541810512543,
          -0.4132947325706482,
          0.37880995869636536,
          -0.18882893025875092,
          -0.29600730538368225,
          1.1029034852981567,
          0.1073220819234848,
          1.37067711353302,
          0.6260883212089539,
          -0.5285360217094421,
          0.28494441509246826,
          0.08538003265857697,
          -0.23444020748138428,
          0.40373358130455017,
          0.6080846190452576,
          -0.7332497835159302,
          0.20002563297748566,
          0.1499708890914917,
          -0.26397818326950073,
          -0.6827583909034729,
          0.5464445352554321,
          0.6545237302780151,
          0.5266338586807251,
          0.3935122489929199,
          -1.2030613422393799,
          -0.5003138184547424,
          0.709261417388916,
          0.7402034401893616,
          0.15866263210773468,
          0.6118549704551697,
          0.41407737135887146,
          -0.3403881788253784,
          -0.05221810191869736,
          -1.1068679094314575,
          -0.27283093333244324,
          -1.0520397424697876,
          -1.2260475158691406,
          -0.3866424858570099,
          -0.30068206787109375,
          -0.9592726826667786,
          -0.026029083877801895,
          0.09088487923145294,
          -0.5967716574668884,
          0.741213858127594,
          -0.11972750723361969,
          -0.44861844182014465,
          -0.5551794767379761,
          -0.6671473979949951,
          0.5038305521011353,
          1.1376030445098877,
          0.3963516652584076,
          -1.1209172010421753,
          -0.17971950769424438,
          -0.7123729586601257,
          0.5452159643173218,
          0.8493242859840393,
          0.45353299379348755,
          -0.10882651060819626,
          -0.28626978397369385,
          -0.1600976288318634,
          -0.29344046115875244,
          0.4955282509326935,
          -0.05074722319841385,
          -1.1744977235794067,
          -0.3521379828453064,
          0.10089840739965439,
          0.008568523451685905,
          -0.6249591112136841,
          -0.28777244687080383,
          0.12991484999656677,
          0.5624245405197144,
          0.022887369617819786,
          0.17906129360198975,
          0.9456692934036255,
          0.14721530675888062,
          -1.2339476346969604,
          0.15321451425552368,
          -0.4616921544075012,
          0.5701075792312622,
          -0.5269285440444946,
          0.7291272282600403,
          0.5784363746643066,
          -0.6566822528839111,
          0.15962642431259155,
          -1.0738483667373657,
          -0.3374358117580414,
          0.08408568054437637,
          -0.6172381639480591,
          0.5843613147735596,
          0.021033721044659615,
          0.3276844024658203,
          -0.018614046275615692,
          -1.8532072305679321,
          0.2579392194747925,
          0.04594837501645088,
          -0.6524945497512817,
          -0.4019475281238556,
          0.34532853960990906,
          0.8849731683731079,
          0.6811109185218811,
          -0.439502090215683,
          -0.041651032865047455,
          0.3551582098007202,
          -0.48508602380752563,
          0.8053210377693176,
          0.19970422983169556,
          -0.32619237899780273,
          0.29806622862815857,
          0.3560975193977356,
          -0.6136336326599121,
          0.5827071070671082,
          1.0225646495819092,
          -0.39545103907585144,
          0.6924233436584473,
          -0.2172098159790039,
          -0.20700787007808685,
          -0.18709774315357208,
          -0.4047929048538208,
          -0.20769545435905457,
          0.39282581210136414,
          0.07532092928886414,
          -0.3298244774341583,
          0.47992604970932007,
          -0.3903017044067383,
          0.10891678929328918,
          0.8242081999778748,
          0.4911864399909973,
          -0.6298035979270935,
          0.4938202202320099,
          -0.5064240097999573,
          0.2803775668144226,
          -0.378925621509552,
          0.5541943907737732,
          0.21354593336582184,
          -0.7606136202812195,
          0.39567676186561584,
          0.014486294239759445,
          -0.32032638788223267,
          0.5514094233512878,
          -0.4236968755722046,
          -1.1856321096420288,
          0.2209051102399826,
          -0.8367661237716675,
          0.4717925488948822,
          -1.0305424928665161,
          0.1399296224117279,
          -0.03837021440267563,
          0.13570860028266907,
          -0.5308751463890076,
          -0.25815901160240173,
          0.5113497376441956,
          -0.438192754983902,
          0.5145376324653625,
          -0.2332664132118225,
          0.004769176244735718,
          0.6545926928520203,
          0.34619027376174927,
          -0.646626353263855,
          0.3773767650127411,
          -0.5367326736450195,
          -0.4585205912590027,
          1.081784725189209,
          -0.05756402760744095,
          0.2518472969532013,
          -0.7827865481376648,
          1.117363691329956,
          0.023411672562360764,
          0.3380494713783264,
          0.4715981185436249,
          0.5068782567977905,
          0.4085874557495117,
          0.3324849009513855,
          0.7644349336624146,
          0.33922821283340454,
          -0.1743217408657074,
          -0.1240287721157074,
          -0.6634524464607239,
          0.5242152214050293,
          -0.3725156784057617,
          -0.45333999395370483,
          0.2921731173992157,
          -0.11949759721755981,
          -0.18267345428466797,
          -0.5942919254302979,
          0.16869866847991943,
          -0.43289902806282043,
          -0.20737001299858093,
          -0.7474848628044128,
          0.13372491300106049,
          0.5234679579734802,
          -0.19135607779026031,
          -0.5682592988014221,
          -1.1403077840805054,
          0.8243018984794617,
          0.4234415292739868,
          -0.8282041549682617,
          -0.9462966322898865,
          0.4813306927680969,
          -0.3394320011138916,
          -0.2719322741031647,
          0.28790491819381714,
          1.1148285865783691,
          -1.2084085941314697,
          0.8925723433494568,
          0.12140040099620819,
          0.0040922462940216064,
          0.5369350910186768,
          0.30684396624565125,
          -0.2471446990966797,
          -0.1530248522758484,
          -0.14305897057056427,
          0.3348509967327118,
          0.23497076332569122,
          0.045017316937446594,
          -0.5594068169593811,
          0.6340937614440918,
          -0.8400084376335144,
          1.4931589365005493,
          -0.3916260600090027,
          0.5243374109268188,
          -0.5757910013198853,
          -0.31447547674179077,
          0.07781870663166046,
          0.0675322487950325,
          0.4310145080089569,
          0.3888928294181824,
          0.2340995818376541,
          0.9053859114646912,
          -0.1481495350599289,
          -0.31063777208328247,
          0.21224650740623474,
          1.142799735069275,
          0.5158724188804626,
          0.4725992679595947,
          0.2102452963590622,
          -0.14404533803462982,
          -0.3048965334892273,
          0.04444536194205284,
          -0.5854503512382507,
          0.6192346811294556,
          -0.7298058867454529,
          0.5390728116035461,
          0.41126227378845215,
          -0.5465657114982605,
          -0.3834150731563568,
          -0.4783530533313751,
          -0.16000443696975708,
          0.07600638270378113,
          -0.05811072140932083,
          -0.25827693939208984,
          -1.0403809547424316,
          0.35464656352996826,
          0.8965224027633667,
          -0.030125699937343597,
          0.7341544032096863,
          0.30293139815330505,
          0.014493156224489212,
          -0.09307441860437393,
          0.5345296859741211,
          0.033891186118125916,
          0.09363245964050293,
          -0.07443347573280334,
          0.3594435155391693,
          -0.019222065806388855,
          -0.8235657215118408,
          0.7434471249580383,
          -1.4614253044128418,
          -1.1113325357437134,
          0.1341543197631836,
          -0.3635527491569519,
          -0.3755214214324951,
          -0.3888750374317169,
          -0.46083083748817444,
          -0.09616424888372421,
          0.22761069238185883,
          -0.10732492804527283,
          -0.20535020530223846,
          -0.15154331922531128,
          0.8087466359138489,
          0.4840620458126068,
          -0.1003301814198494,
          -0.08873416483402252,
          0.36399322748184204,
          -0.04778819903731346,
          1.293744683265686,
          0.03656015545129776,
          -0.9257336258888245,
          -0.392255961894989,
          1.5204768180847168,
          -0.8245276212692261,
          -0.10904987156391144,
          0.24378183484077454,
          -0.7872198820114136,
          0.0708765834569931,
          -1.6954172849655151,
          0.3973223865032196,
          -0.1277235448360443,
          -0.19752436876296997,
          -0.10631787776947021,
          -0.1764882653951645,
          0.1845698058605194,
          0.16046945750713348,
          0.6212518215179443,
          -0.4671424925327301,
          -0.5402371287345886,
          0.36915794014930725,
          -0.4845197796821594,
          -0.22565585374832153,
          -0.5576297044754028,
          -0.17528440058231354,
          -0.14634323120117188,
          0.5895655751228333,
          0.5817974805831909,
          -0.5869331359863281,
          -0.5783140063285828,
          0.3120769262313843,
          -0.2645551562309265,
          -0.006311521399766207,
          0.44123828411102295,
          -0.9264495372772217,
          -0.29602062702178955,
          0.25918251276016235,
          -0.018816135823726654,
          0.5704290270805359,
          1.0879472494125366,
          -0.4026080071926117,
          -0.6545915603637695,
          0.265669047832489,
          -0.13678032159805298,
          -0.6697673797607422,
          0.17130111157894135,
          -0.7441898584365845,
          -0.7260138988494873,
          1.3235832452774048,
          -0.5441890954971313,
          -0.5526500940322876,
          0.30100563168525696,
          0.4632391035556793,
          0.8031498193740845,
          0.21185362339019775,
          -0.8366633057594299,
          -0.6847643256187439,
          -0.49098750948905945,
          -1.1264667510986328,
          -0.3558393716812134,
          -0.4828043580055237,
          -0.1478874534368515,
          -0.05223464220762253,
          -0.046604931354522705,
          0.3604476749897003,
          -0.5974170565605164,
          0.22991424798965454,
          1.3071913719177246,
          0.49971213936805725,
          -0.6156826019287109,
          0.3455755114555359,
          -0.20853665471076965,
          0.18315574526786804,
          0.12538249790668488,
          -0.011599935591220856,
          -0.5047242641448975,
          0.09481334686279297,
          -0.6229398846626282,
          0.19719848036766052,
          -0.5584425330162048,
          0.04947952553629875,
          0.3348163068294525,
          0.6723231077194214,
          -0.828569233417511,
          0.5626614689826965,
          0.19592468440532684,
          -0.5552939772605896,
          -0.4101255536079407,
          -0.29213041067123413,
          0.07943897694349289,
          -0.3856545686721802,
          0.28497475385665894,
          0.46316292881965637,
          0.15582981705665588,
          0.6003705263137817,
          -0.380728155374527,
          -0.9591439962387085,
          -0.01702992618083954,
          0.7052741646766663,
          0.21511366963386536,
          -0.38198983669281006,
          0.3085629940032959,
          0.8057191967964172,
          -0.2621346116065979,
          -0.3913221061229706,
          0.6860199570655823,
          -0.19406796991825104,
          0.48973289132118225,
          -0.6037474274635315,
          0.39046263694763184,
          -0.5776844620704651,
          0.15925420820713043,
          -0.1690048724412918,
          0.7229793071746826,
          -0.4147129952907562,
          -0.2348414957523346,
          1.479966402053833,
          0.29202041029930115,
          -0.7692916989326477,
          0.015290653333067894,
          0.42929643392562866,
          -0.3428223729133606,
          0.4371674954891205,
          -1.5283161401748657,
          -0.17302951216697693,
          -0.26374444365501404,
          -0.6537332534790039,
          0.481804221868515,
          -1.0750401020050049,
          -0.3274921774864197,
          0.3450935184955597,
          0.5584440231323242,
          0.2812161445617676,
          -0.5434772372245789,
          -0.09384314715862274,
          0.16861091554164886,
          0.08220556378364563,
          -0.647686779499054,
          -0.6651816368103027,
          1.0173845291137695,
          -0.2669717073440552,
          0.22996148467063904,
          -0.2558647096157074,
          -0.24817639589309692,
          1.1814759969711304,
          0.4404646158218384,
          -0.20543810725212097,
          -0.3661745488643646,
          0.02429138496518135,
          -1.1488844156265259,
          -0.6113022565841675,
          -0.14031800627708435,
          0.5610455870628357,
          -0.364091694355011,
          0.5423187017440796,
          0.43062976002693176,
          -0.25191596150398254,
          -0.340030699968338,
          0.18268102407455444,
          -0.9472440481185913,
          -1.0455983877182007,
          0.11821790784597397,
          0.24116413295269012,
          0.03257458284497261,
          0.032059572637081146,
          -0.07604088634252548,
          0.13730275630950928,
          0.11143924295902252,
          0.8406163454055786,
          -0.4398724138736725,
          0.2880460023880005,
          0.7084616422653198,
          0.15351355075836182,
          -0.44187191128730774,
          -0.2188321053981781,
          -0.10567298531532288,
          -0.024653634056448936,
          -0.47706425189971924,
          -0.016836795955896378,
          -0.4131040573120117,
          0.24639973044395447,
          0.5628107190132141,
          -0.6630898118019104,
          0.3577129542827606,
          -0.548856258392334,
          0.2228749841451645,
          -0.5342820286750793,
          0.13226687908172607,
          0.21451032161712646,
          -0.2443276345729828,
          0.5095173120498657,
          -1.1752738952636719,
          0.5819019675254822,
          0.29898470640182495,
          -0.9205576777458191,
          0.9061855673789978,
          -0.1508863866329193,
          0.09700459986925125,
          -0.04933936521410942,
          -0.1477975696325302,
          0.6052279472351074,
          -0.42410537600517273,
          0.7885744571685791,
          -0.33806318044662476,
          0.5897687673568726,
          0.2732434570789337,
          -0.9507272243499756,
          0.29186487197875977,
          -0.7711854577064514,
          -0.16216954588890076,
          -0.9657995104789734,
          -0.43234241008758545,
          0.3295958638191223,
          -0.29590263962745667,
          -0.6329095363616943,
          0.4006635844707489,
          -0.5086380243301392,
          -0.6136208772659302,
          -0.48141881823539734,
          0.14978057146072388,
          0.7968738079071045,
          0.3652784824371338,
          0.16944533586502075,
          0.20771025121212006,
          -0.6301627159118652,
          -0.5279983282089233,
          -0.6738056540489197,
          -0.365791380405426,
          0.15623481571674347,
          0.47163474559783936,
          0.16128194332122803,
          0.32297539710998535,
          0.7694844007492065,
          0.12921461462974548,
          0.058526478707790375,
          0.5290674567222595,
          0.45978260040283203,
          0.11028988659381866,
          0.48561930656433105,
          0.5917508602142334,
          -0.4227138161659241,
          -0.5522459149360657,
          -1.122422695159912,
          0.019702166318893433,
          0.8424162864685059,
          -0.03484644740819931,
          -0.5619954466819763,
          0.6190761923789978,
          0.06960657984018326,
          -0.03184343874454498,
          -0.5086619853973389,
          -0.6669173240661621,
          0.413499116897583,
          -0.23823000490665436,
          0.23696090281009674,
          -0.3772008717060089,
          0.6295207142829895,
          -0.5575084090232849,
          0.18507026135921478,
          0.6751696467399597,
          0.8434323072433472,
          -0.7087574005126953,
          0.5587327480316162,
          0.42449143528938293,
          -0.5138384103775024,
          -0.41083377599716187,
          -0.4792935848236084,
          0.5336824059486389,
          -0.638159990310669,
          0.2057664394378662,
          -0.600947380065918,
          0.09500683844089508,
          0.5331112742424011,
          -0.07015302032232285,
          -0.22019702196121216,
          0.444428950548172,
          0.7608680129051208,
          -0.16532766819000244,
          0.17941196262836456,
          0.2744463086128235,
          1.1987851858139038,
          0.4722772538661957,
          0.283682644367218,
          0.07724718749523163,
          0.7122972011566162,
          -0.7375532388687134,
          0.33572515845298767,
          -0.7607428431510925,
          1.0620448589324951,
          -1.7808860540390015,
          -0.6422933340072632,
          0.3071792423725128,
          0.17744942009449005,
          -0.8976565003395081,
          -0.003831610083580017,
          -0.6049172878265381,
          0.7151528000831604,
          0.47813183069229126,
          -0.751324474811554,
          0.13265419006347656,
          0.02403736114501953,
          -0.027535468339920044,
          0.21757182478904724,
          0.25589719414711,
          -0.850805401802063,
          0.2582851052284241,
          -0.40144360065460205,
          0.22776705026626587,
          -0.4811497628688812,
          0.1539648473262787,
          -0.044467829167842865,
          0.25579833984375,
          -0.5724142789840698,
          0.8664361834526062,
          -0.41657841205596924,
          1.1451786756515503,
          0.2846364378929138,
          -0.28120747208595276,
          0.9892779588699341,
          0.38868528604507446,
          -0.5889228582382202,
          0.6563235521316528,
          -0.22044558823108673,
          -0.4204672574996948,
          -1.0166205167770386,
          0.7776578664779663,
          -0.511867105960846,
          0.5497759580612183,
          0.38206687569618225,
          -0.21009771525859833,
          -0.7228837013244629,
          0.02348722144961357,
          0.10310572385787964,
          0.16585220396518707,
          0.006256815046072006,
          0.676032543182373,
          0.13665293157100677,
          1.443080186843872,
          1.60666024684906,
          -0.3756122589111328,
          -0.37878528237342834,
          -0.04793361574411392,
          -0.04403679817914963,
          0.07942777872085571,
          -0.0797373354434967,
          -0.6693512201309204,
          -0.2855446934700012,
          0.31340935826301575,
          -0.7938318848609924,
          -0.2588370740413666,
          0.1254464089870453,
          -0.07743750512599945,
          0.6766132712364197,
          -0.26264700293540955,
          1.1374070644378662,
          0.1359507143497467,
          -0.09788784384727478,
          -0.12738323211669922,
          0.5049248933792114,
          0.5888671278953552,
          0.24439358711242676,
          0.34483644366264343,
          -0.10470329225063324,
          0.6697039604187012,
          -1.1186305284500122,
          0.8173826336860657,
          0.12709832191467285,
          -0.17801730334758759,
          0.09259851276874542,
          -0.09048530459403992,
          -0.6738945841789246,
          -1.206879734992981,
          0.8912191987037659,
          -0.5851724147796631,
          0.21194607019424438,
          -0.1186051070690155,
          0.06458446383476257,
          0.343068391084671,
          -0.6130366921424866,
          -0.6136513352394104,
          1.237935185432434,
          0.852789044380188,
          -0.18385350704193115,
          1.0673816204071045,
          1.2932319641113281,
          0.876395046710968,
          0.044260986149311066,
          0.4912732243537903,
          -0.4105570316314697,
          0.20456300675868988,
          -0.8682007789611816,
          0.8826658129692078,
          -0.3526783287525177,
          0.011436376720666885,
          -0.6973015666007996,
          1.092413306236267,
          0.5438872575759888,
          0.09959574043750763,
          0.2343398928642273,
          -0.8081367015838623,
          -0.14339551329612732,
          -0.738399088382721,
          0.31609877943992615,
          -0.21966496109962463,
          0.9149336218833923,
          -0.3775240480899811,
          0.09406690299510956,
          0.6644356846809387,
          -0.396424263715744,
          3.6757326126098633,
          0.9629470705986023,
          -0.21800097823143005,
          0.22196628153324127,
          0.35729002952575684,
          0.8890576958656311,
          0.8170879483222961,
          -0.1461111456155777,
          0.861059308052063,
          -0.4671255648136139,
          0.1168849915266037,
          -0.497933954000473,
          0.7711542248725891,
          -0.027095085009932518,
          -0.11065198481082916,
          -0.3689420819282532,
          -0.9346939325332642,
          0.49919068813323975,
          -0.06482499837875366,
          -0.15906399488449097,
          -0.9572105407714844,
          0.4982790946960449,
          0.32891732454299927,
          -0.6426466107368469,
          0.13450288772583008,
          0.6203463077545166,
          0.09485606849193573,
          -0.2257881611585617,
          -0.22552599012851715,
          -0.1952027976512909,
          -0.036395251750946045,
          -0.5867994427680969,
          -0.6816620826721191,
          0.07672391831874847,
          0.22622403502464294,
          0.8530284762382507,
          -0.16885650157928467,
          -0.9048223495483398,
          -0.31608909368515015,
          1.6678293943405151,
          0.6677819490432739,
          -0.29866817593574524,
          -0.7195801138877869,
          -0.2900727689266205,
          0.05289572477340698,
          0.6279746294021606,
          0.49959081411361694,
          0.13865907490253448,
          1.0043331384658813,
          -0.5982387661933899,
          0.37530651688575745,
          -1.2164640426635742,
          0.23181501030921936,
          -0.011655614711344242,
          0.6054805517196655,
          0.25588658452033997,
          -0.23718245327472687,
          -0.24725043773651123,
          -0.8983394503593445,
          0.46613338589668274,
          0.6249473690986633,
          -0.6931591629981995,
          -0.3967249393463135,
          0.34719032049179077,
          0.038299560546875,
          -0.30289024114608765,
          0.8535487651824951,
          0.1099306046962738,
          -0.4060242772102356,
          -0.11959512531757355,
          0.2873411774635315,
          0.0456903837621212,
          -0.1481189876794815,
          0.07834534347057343,
          0.2669421434402466,
          -0.05261800438165665,
          -0.39823949337005615,
          0.5773678421974182,
          -0.1729145050048828,
          -0.273822546005249,
          0.03831663727760315,
          -0.5536711812019348,
          -0.19929485023021698,
          -0.25580841302871704,
          0.0804266631603241,
          0.5937440395355225,
          0.04711367189884186,
          0.2900739014148712,
          -0.6983377933502197,
          0.01968957483768463,
          -0.4278329610824585,
          -0.3089422285556793,
          -0.0317109078168869,
          -0.004856474697589874,
          0.29709553718566895
        ]
      },
      "type": "document"
    },
    {
      "id": "dc52af38-3a4e-467d-9a06-9ebdac81e25b",
      "properties": {
        "page_content": "model R-Precision Recall@5 EM F1 KILT-EM KILT-F1\ntest\nBART 0.0 0.0 21.75 28.69 0.0 0.0\nT5 0.0 0.0 19.6 27.73 0.0 0.0\nBART + DPR 54.29 65.52 41.27 49.54 30.06 34.72\nBERT + DPR 60.66 46.79 38.64 47.09 31.99 37.58\nRAG 59.49 67.06 44.39 52.35 32.69 37.91\ndev\nBART 0.0 0.0 26.15 32.06 0.0 0.0\nT5 0.0 0.0 25.2 31.88 0.0 0.0\nBART + DPR 54.25 64.99 45.05 52.98 31.62 35.84\nBERT + DPR 60.03 45.06 42.58 50.43 35.32 39.84\nRAG 60.31 65.47 48.78 56.1 36.31 40.64\nTable 13: Natural Questions\nmodel R-Precision Recall@5 EM F1 KILT-EM KILT-F1\ntest\nBART 0.0 0.0 15.37 21.97 0.0 0.0\nT5 0.0 0.0 12.64 19.57 0.0 0.0\nBERT + DPR 25.04 10.4 11.29 17.35 0.74 1.26\nBART + DPR 25.04 10.4 25.18 34.07 1.96 2.53\nRAG 30.59 12.59 26.97 36.03 3.21 4.1\ndev\nBART 0.0 0.0 16.86 23.81 0.0 0.0\nT5 0.0 0.0 12.66 19.74 0.0 0.0\nBERT + DPR 24.62 10.7 10.82 16.96 0.96 1.34\nBART + DPR 24.62 10.7 25.75 35.2 1.96 2.46\nRAG 30.76 12.29 27.68 37.37 3.14 3.87\nTable 14: HotpotQA\nmodel R-Precision Recall@5 EM F1 KILT-EM KILT-F1\ntest\nBART 0.0 0.0 32.39 39.85 0.0 0.0\nT5 0.0 0.0 18.11 27.83 0.0 0.0\nBART + DPR 44.49 56.99 58.55 67.79 31.4 35.34\nBERT + DPR 43.4 31.45 70.38 74.41 34.48 36.28\nRAG 48.68 57.13 71.27 75.88 38.13 40.15\ndev\nBART 0.0 0.0 32.54 39.58 0.0 0.0\nT5 0.0 0.0 25.79 33.72 0.0 0.0\nBERT + DPR 40.87 29.96 70.24 74.21 32.9 34.48\nBART + DPR 45.36 56.72 59.28 68.31 32.56 36.36\nRAG 49.26 56.93 61.73 67.12 36.13 38.71\nTable 15: TriviaQA",
        "document_metadata": {
          "page_label": "19",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "e77986e5-f7ed-48fe-8776-4d7974c6e1f5",
      "properties": {
        "page_content": "model R-Precision Recall@5 Rouge-L F1 KILT-RL KILT-F1\ntest\nT5 0.0 0.0 19.08 16.1 0.0 0.0\nBART 0.0 0.0 20.55 19.23 0.0 0.0\nRAG 11.0 22.92 14.05 14.51 1.69 1.79\nBART + DPR 10.67 26.92 17.41 17.88 1.9 2.01\ndev\nT5 0.0 0.0 21.02 18.36 0.0 0.0\nBART 0.0 0.0 22.69 22.19 0.0 0.0\nRAG 16.39 27.27 16.11 17.24 2.65 2.88\nBART + DPR 16.32 21.11 18.53 18.75 2.87 2.89\nTable 16: ELI5\nmodel R-Precision Recall@5 Rouge-L F1 KILT-RL KILT-F1\ntest\nBART 0.0 0.0 11.77 12.86 0.0 0.0\nT5 0.0 0.0 12.40 13.53 0.0 0.0\nTransMemNet 18.35 18.35 10.11 11.85 1.85 2.2\nBART + DPR 25.46 55.1 13.23 15.19 3.71 4.37\nRAG 57.75 74.61 11.57 13.11 7.59 8.75\ndev\nBART 0.0 0.0 12.25 13.77 0.0 0.0\nT5 0.0 0.0 12.36 13.15 0.0 0.0\nBART + DPR 0.0 0.0 13.48 15.51 0.0 0.0\nRAG 46.66 66.57 11.76 13.28 6.72 7.5\nTable 17: Wizard of Wikipedia",
        "document_metadata": {
          "page_label": "20",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing data quickly and accurately. It's also driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.15653365850448608,
          0.708324134349823,
          -0.560356616973877,
          -0.624758243560791,
          -0.09469608962535858,
          0.03837006911635399,
          0.23943999409675598,
          -0.0789840891957283,
          0.6103872060775757,
          0.5793808102607727,
          0.028625424951314926,
          0.17377528548240662,
          -0.4511544108390808,
          -1.2206224203109741,
          0.3261074423789978,
          -0.5821016430854797,
          0.07916030287742615,
          0.014927081763744354,
          0.015716910362243652,
          -0.1873658299446106,
          -0.16556397080421448,
          0.7000203132629395,
          -0.6554045677185059,
          -1.0728703737258911,
          -1.0081297159194946,
          0.5899279713630676,
          0.6182917356491089,
          -0.6848546266555786,
          0.7326657772064209,
          0.6235379576683044,
          -0.16303704679012299,
          -0.1524888277053833,
          0.1763075888156891,
          -0.5319058895111084,
          -0.6241199970245361,
          -0.07901151478290558,
          0.4374929666519165,
          -0.13495279848575592,
          -1.1674046516418457,
          -0.5684012174606323,
          0.19114980101585388,
          -0.10329393297433853,
          0.1379377394914627,
          -1.1858662366867065,
          -0.7815965414047241,
          0.4017559587955475,
          0.5267709493637085,
          -1.2063679695129395,
          0.14798139035701752,
          -0.23489812016487122,
          -0.6254692077636719,
          0.17804919183254242,
          -0.18663322925567627,
          -0.4510810673236847,
          0.08170504122972488,
          -0.981838047504425,
          -0.3865876793861389,
          -0.24507582187652588,
          -0.7136726379394531,
          -0.010788820683956146,
          0.9875109195709229,
          -0.3725390136241913,
          0.615031898021698,
          -0.015676505863666534,
          0.25003674626350403,
          0.538238525390625,
          0.13167531788349152,
          -0.4220496118068695,
          -0.42573267221450806,
          0.19983205199241638,
          -1.2177127599716187,
          -0.3109630346298218,
          0.2053534984588623,
          0.21580293774604797,
          -0.3546704649925232,
          -0.0011406056582927704,
          0.29749834537506104,
          -0.10854488611221313,
          -0.8423278331756592,
          -0.07466241717338562,
          -0.5405727028846741,
          0.7102344632148743,
          -0.42008575797080994,
          1.0988736152648926,
          -0.007839580997824669,
          -0.6118817329406738,
          0.7053322196006775,
          0.851521372795105,
          -0.20019793510437012,
          -0.6112142205238342,
          -0.061335138976573944,
          -0.06658043712377548,
          -0.17086540162563324,
          -0.18380343914031982,
          0.2512094974517822,
          0.7229158878326416,
          -0.7099315524101257,
          0.7704291343688965,
          0.2811107635498047,
          -0.08623594790697098,
          0.2449912428855896,
          1.062934160232544,
          -0.039560332894325256,
          0.9028289914131165,
          -0.7417865991592407,
          0.12378251552581787,
          0.5088061690330505,
          -0.8439984917640686,
          -0.041239842772483826,
          -1.020327091217041,
          0.6293498873710632,
          0.11896611750125885,
          -0.051500365138053894,
          0.13216882944107056,
          -0.08745969831943512,
          1.5065178871154785,
          -0.3220745921134949,
          0.3123750686645508,
          -0.3575584590435028,
          0.19347409904003143,
          -0.3775631785392761,
          -0.5309826135635376,
          0.14405721426010132,
          -0.3554430902004242,
          0.2579852342605591,
          -1.1282925605773926,
          0.07652439177036285,
          0.7570061087608337,
          -0.574580192565918,
          0.8029382824897766,
          -0.3219239115715027,
          0.1149839460849762,
          -0.3817795515060425,
          0.7845462560653687,
          0.044764213263988495,
          -0.9600052833557129,
          0.01681765913963318,
          0.8661162853240967,
          -0.28313347697257996,
          0.6386141777038574,
          0.022866930812597275,
          0.10247883200645447,
          -0.18958653509616852,
          1.8453112840652466,
          -0.4269801676273346,
          -0.13014328479766846,
          -0.4042557179927826,
          -0.047255776822566986,
          -0.40690234303474426,
          0.9484456181526184,
          -0.9908297061920166,
          0.6363150477409363,
          0.3713225722312927,
          0.040674664080142975,
          -0.6589909195899963,
          -0.7107224464416504,
          -0.6783660650253296,
          -0.03897132724523544,
          0.44300219416618347,
          0.6028366684913635,
          -0.2992573380470276,
          0.09835578501224518,
          -0.12798817455768585,
          1.163253903388977,
          -0.42693832516670227,
          0.765992283821106,
          -1.0623576641082764,
          0.17760124802589417,
          -0.5435552597045898,
          -0.32758021354675293,
          0.3110758364200592,
          -0.42307907342910767,
          -0.6316344141960144,
          -0.20029184222221375,
          0.9641396403312683,
          1.1128586530685425,
          0.8071188926696777,
          0.2090921401977539,
          0.21570439636707306,
          -0.2754162847995758,
          -1.2964560985565186,
          -0.4458135962486267,
          -0.8107640743255615,
          -0.022426173090934753,
          0.282175213098526,
          0.5131354331970215,
          0.2860373854637146,
          0.20216356217861176,
          0.3431032598018646,
          -0.47738587856292725,
          0.1462855190038681,
          0.7978888750076294,
          -1.0285212993621826,
          0.022857699543237686,
          -0.035792361944913864,
          0.48618289828300476,
          -0.7043569087982178,
          0.35886237025260925,
          0.2290552258491516,
          -0.08449157327413559,
          -0.1867326945066452,
          0.5991955995559692,
          -0.01329154521226883,
          -0.5262020826339722,
          -0.7454302310943604,
          0.5129110813140869,
          -0.17355084419250488,
          1.1027270555496216,
          -1.7994678020477295,
          1.260853886604309,
          0.5334681272506714,
          0.34254637360572815,
          -0.107000932097435,
          -0.2935619056224823,
          0.8226532340049744,
          -0.08729785680770874,
          -0.33170580863952637,
          0.44019418954849243,
          0.13208383321762085,
          -0.4107847809791565,
          -0.12969687581062317,
          -0.3397834002971649,
          0.44506511092185974,
          -0.5634165406227112,
          -0.491355299949646,
          -0.12264655530452728,
          -0.34134647250175476,
          0.9913899898529053,
          0.11103981733322144,
          0.25482499599456787,
          0.6338750720024109,
          0.6776898503303528,
          -0.3651786744594574,
          0.8207221031188965,
          -0.05390606448054314,
          0.26188549399375916,
          -0.4941505789756775,
          0.3877899646759033,
          -0.2680143415927887,
          -0.2725057899951935,
          0.7612683176994324,
          0.2042592316865921,
          1.4407943487167358,
          0.5096518993377686,
          -0.7377908825874329,
          0.18291614949703217,
          -0.028368934988975525,
          0.04344118386507034,
          0.5869894027709961,
          0.7020230889320374,
          -0.5380769371986389,
          0.17451852560043335,
          0.2182559370994568,
          -0.21384817361831665,
          -0.3749060034751892,
          0.4818163216114044,
          0.6815477609634399,
          0.635630190372467,
          0.34922853112220764,
          -1.3602954149246216,
          -0.7710537910461426,
          0.9218129515647888,
          0.5414859652519226,
          -0.02844298630952835,
          0.5035747289657593,
          0.44108107686042786,
          -0.25093764066696167,
          -0.031018413603305817,
          -0.8894982933998108,
          -0.35861238837242126,
          -1.322385549545288,
          -1.3574097156524658,
          -0.46525654196739197,
          -0.37621793150901794,
          -0.903964102268219,
          -0.13430169224739075,
          0.14654386043548584,
          -0.7400285005569458,
          0.8942035436630249,
          0.0467090830206871,
          -0.24296636879444122,
          -0.5349831581115723,
          -0.780023455619812,
          0.523067831993103,
          0.8721235990524292,
          0.5145605802536011,
          -1.2156379222869873,
          0.11846168339252472,
          -0.6136108040809631,
          0.7333815097808838,
          0.7059926390647888,
          0.49715209007263184,
          -0.14679838716983795,
          -0.5082736015319824,
          -0.10070683807134628,
          -0.33543458580970764,
          0.764856219291687,
          0.10125124454498291,
          -0.9995274543762207,
          -0.37534213066101074,
          0.03257682919502258,
          0.06765386462211609,
          -0.7529552578926086,
          -0.07277289032936096,
          0.04840793088078499,
          0.5177431106567383,
          0.22652263939380646,
          0.07084330171346664,
          1.057715654373169,
          -0.01907382905483246,
          -1.063676357269287,
          0.18975912034511566,
          -0.20608597993850708,
          0.8620506525039673,
          -0.5584468245506287,
          0.6492416858673096,
          0.28543952107429504,
          -0.7491306662559509,
          0.28436264395713806,
          -1.2617859840393066,
          -0.1663254052400589,
          0.1973085254430771,
          -0.6305858492851257,
          0.6297265291213989,
          0.1492767184972763,
          0.43625450134277344,
          0.042352091521024704,
          -1.991180419921875,
          -0.07620684057474136,
          0.09781280905008316,
          -0.4961080849170685,
          -0.11621591448783875,
          0.224753737449646,
          0.8847364187240601,
          0.8522879481315613,
          -0.4795553684234619,
          -0.043063778430223465,
          -0.02127734199166298,
          -0.28493547439575195,
          0.8193005323410034,
          0.476342111825943,
          -0.3303811252117157,
          0.32370656728744507,
          0.39031103253364563,
          -0.5224460363388062,
          0.7659452557563782,
          1.1651663780212402,
          -0.36444762349128723,
          0.7769097089767456,
          -0.25233757495880127,
          -0.18939390778541565,
          -0.22476908564567566,
          -0.42203575372695923,
          -0.3241024911403656,
          0.5063709020614624,
          0.022166896611452103,
          -0.36077043414115906,
          0.44032543897628784,
          -0.10431964695453644,
          0.049477364867925644,
          0.7558911442756653,
          0.32852160930633545,
          -0.3811362683773041,
          0.4240749478340149,
          -0.5141333341598511,
          0.18097832798957825,
          -0.190008282661438,
          0.320146381855011,
          0.26940226554870605,
          -0.734769880771637,
          0.6111953854560852,
          -0.005205660592764616,
          -0.39462342858314514,
          0.5906740427017212,
          -0.7226114273071289,
          -1.0473103523254395,
          0.45811983942985535,
          -1.0410445928573608,
          0.10715840011835098,
          -0.729506254196167,
          0.41465941071510315,
          -0.023869656026363373,
          0.0995643138885498,
          -0.29126521944999695,
          -0.24272990226745605,
          0.7271320223808289,
          -0.7361127138137817,
          0.6334934830665588,
          -0.23064333200454712,
          -0.007777445018291473,
          0.4714883863925934,
          0.11677825450897217,
          -0.5421423316001892,
          0.1865558922290802,
          -0.6669362783432007,
          -0.7818518280982971,
          1.0332555770874023,
          -0.09372512996196747,
          0.3156664967536926,
          -0.46370264887809753,
          1.1488596200942993,
          -0.11208930611610413,
          0.1034163236618042,
          0.30604591965675354,
          0.46540969610214233,
          0.2786770164966583,
          0.298591285943985,
          0.8506519794464111,
          0.5658669471740723,
          -0.3816567659378052,
          -0.18528684973716736,
          -0.6901206970214844,
          0.490439772605896,
          -0.21610264480113983,
          -0.21388526260852814,
          0.24537082016468048,
          -0.11020440608263016,
          -0.03966677933931351,
          -0.8644925355911255,
          0.10004914551973343,
          -0.5923416018486023,
          -0.09354070574045181,
          -0.802623987197876,
          0.2751564383506775,
          0.4859493374824524,
          -0.22156816720962524,
          -0.5493608117103577,
          -1.389951229095459,
          0.8455817103385925,
          0.539142906665802,
          -0.5432571768760681,
          -0.8204971551895142,
          0.7723850011825562,
          -0.26329803466796875,
          -0.1482481062412262,
          0.1932123750448227,
          1.477002739906311,
          -1.073655366897583,
          0.8722612261772156,
          -0.17458924651145935,
          0.06920646131038666,
          0.7737438678741455,
          0.34876319766044617,
          -0.009753379970788956,
          -0.3988533318042755,
          -0.45967280864715576,
          0.05419445410370827,
          0.38868486881256104,
          -0.49439483880996704,
          -0.6662508249282837,
          0.9421378970146179,
          -1.1742854118347168,
          1.0146088600158691,
          -0.3983980715274811,
          0.4877769947052002,
          -0.15690645575523376,
          -0.3795810043811798,
          -0.043067798018455505,
          0.17785920202732086,
          -0.004084660671651363,
          0.2823405861854553,
          0.2353675365447998,
          0.6542595028877258,
          -0.45311570167541504,
          -0.37921908497810364,
          0.10479998588562012,
          0.7740886807441711,
          0.3479619026184082,
          0.5438047647476196,
          0.18174457550048828,
          0.11987702548503876,
          -0.30295875668525696,
          0.1368318498134613,
          -0.6077490448951721,
          0.778857946395874,
          -0.6490302681922913,
          0.6108367443084717,
          0.4118753671646118,
          -0.6285769939422607,
          -0.5030165910720825,
          -0.739553689956665,
          -0.13659991323947906,
          0.47010958194732666,
          0.009283233433961868,
          -0.39604055881500244,
          -0.9439961314201355,
          0.4410858452320099,
          1.0023729801177979,
          -0.10729847848415375,
          0.5628648996353149,
          0.2573319673538208,
          0.27273619174957275,
          -0.17489561438560486,
          0.5664963126182556,
          0.03323373198509216,
          0.08951133489608765,
          0.16944998502731323,
          0.43350496888160706,
          -0.3493611812591553,
          -0.5842875242233276,
          1.3619498014450073,
          -1.5692031383514404,
          -1.1211581230163574,
          -0.10948480665683746,
          -0.3839985132217407,
          -0.4577986001968384,
          -0.15327897667884827,
          -0.37730634212493896,
          -0.0552467405796051,
          0.2962070107460022,
          -0.03578932583332062,
          0.04343892261385918,
          0.03839841112494469,
          0.4220774471759796,
          0.4198085367679596,
          -0.10207931697368622,
          0.08839128166437149,
          0.2172068953514099,
          -0.08884144574403763,
          1.3479490280151367,
          0.4056376814842224,
          -1.158109426498413,
          -0.23603032529354095,
          1.414937973022461,
          -0.8952568769454956,
          -0.047682106494903564,
          0.3120218515396118,
          -0.9829236268997192,
          0.048443011939525604,
          -1.624509334564209,
          0.22830790281295776,
          -0.2369566559791565,
          -0.14230650663375854,
          -0.15289755165576935,
          0.2415873259305954,
          0.1781793236732483,
          0.40931960940361023,
          0.551429808139801,
          -0.4621402621269226,
          -0.5434077978134155,
          0.1399441957473755,
          -0.10551683604717255,
          -0.32558929920196533,
          -0.7182134389877319,
          -0.11811021715402603,
          -0.22128117084503174,
          0.4561665952205658,
          0.658332347869873,
          -0.6081880331039429,
          -0.6818138957023621,
          0.3686807453632355,
          -0.5574904680252075,
          -0.04323532432317734,
          0.6026723384857178,
          -1.1020126342773438,
          -0.3978703022003174,
          0.26181769371032715,
          0.29128456115722656,
          0.46958473324775696,
          0.986249566078186,
          -0.5688857436180115,
          -0.3975059688091278,
          0.4033031761646271,
          -0.01668553426861763,
          -0.5717719197273254,
          0.32489854097366333,
          -0.9397135376930237,
          -0.6403915286064148,
          1.1761244535446167,
          -0.5005905628204346,
          -0.6583921313285828,
          0.14916302263736725,
          0.48593977093696594,
          0.7481585741043091,
          0.43625229597091675,
          -0.9971951246261597,
          -0.5383151769638062,
          -0.31694960594177246,
          -1.008111834526062,
          -0.24826711416244507,
          -0.5338794589042664,
          -0.33623456954956055,
          -0.47699257731437683,
          0.1457827240228653,
          0.49600738286972046,
          -0.3539901673793793,
          0.3364388048648834,
          1.266629695892334,
          0.5432025194168091,
          -0.534518301486969,
          0.2369132936000824,
          -0.14540165662765503,
          0.3798498511314392,
          -0.28903934359550476,
          -0.01882995292544365,
          -0.1768338680267334,
          0.0675683468580246,
          -0.3965558409690857,
          0.22460128366947174,
          -0.4001605212688446,
          -0.023713089525699615,
          0.3762018382549286,
          0.7118687033653259,
          -0.7778497934341431,
          0.8103549480438232,
          0.4877917170524597,
          -0.5454842448234558,
          -0.6775347590446472,
          -0.1553385704755783,
          -0.05567336827516556,
          -0.28285014629364014,
          0.36298877000808716,
          0.6876521110534668,
          0.24767452478408813,
          0.6072570085525513,
          -0.3430311977863312,
          -0.9004305601119995,
          -0.40982645750045776,
          0.9287248253822327,
          0.08168631047010422,
          -0.7443946599960327,
          0.1597026139497757,
          1.014836072921753,
          -0.394724041223526,
          -0.29386141896247864,
          0.5423461198806763,
          -0.08880148082971573,
          0.6268293261528015,
          -0.5828396677970886,
          0.618937611579895,
          -0.6293707489967346,
          0.2957180142402649,
          -0.01937435194849968,
          0.5355813503265381,
          -0.3147629499435425,
          0.23315727710723877,
          1.4478720426559448,
          0.6608597636222839,
          -0.8242902159690857,
          0.024297622963786125,
          0.566325306892395,
          -0.10012564063072205,
          0.2818353772163391,
          -1.5161789655685425,
          0.1990036964416504,
          -0.1279444694519043,
          -0.7836253046989441,
          0.6842582821846008,
          -1.144577980041504,
          -0.4647907018661499,
          0.7075212001800537,
          0.34748131036758423,
          0.07579702138900757,
          -0.5246375799179077,
          -0.3022536039352417,
          0.2722826600074768,
          0.41016602516174316,
          -0.7137351632118225,
          -0.5804339051246643,
          1.0996284484863281,
          -0.19714947044849396,
          0.26092877984046936,
          -0.1783788949251175,
          -0.41424909234046936,
          0.9819537997245789,
          0.5875053405761719,
          -0.3575723469257355,
          -0.4140152335166931,
          -0.20120932161808014,
          -1.2741118669509888,
          -0.6932954788208008,
          0.0563211515545845,
          0.41846123337745667,
          -0.16348043084144592,
          0.44399431347846985,
          0.4794367551803589,
          -0.3574368357658386,
          -0.44746315479278564,
          0.27656567096710205,
          -0.9505319595336914,
          -1.0746614933013916,
          -0.2753482460975647,
          0.4009734094142914,
          -0.18850743770599365,
          0.19579333066940308,
          -0.02017737738788128,
          0.13258510828018188,
          0.08843790739774704,
          0.9455509185791016,
          -0.5432841777801514,
          0.3054235577583313,
          0.1862870454788208,
          0.40277478098869324,
          -0.6511672139167786,
          -0.2864965796470642,
          -0.38615140318870544,
          -0.12715351581573486,
          -0.5177202224731445,
          0.044396307319402695,
          0.013225503265857697,
          0.25602495670318604,
          0.29710322618484497,
          -0.6822868585586548,
          0.30312708020210266,
          -0.38473403453826904,
          0.4831378161907196,
          -0.6684404015541077,
          0.22449138760566711,
          0.4820908308029175,
          -0.25279897451400757,
          0.3364286422729492,
          -1.060884952545166,
          1.0425242185592651,
          0.02532900869846344,
          -0.8520940542221069,
          0.923346757888794,
          -0.10062302649021149,
          0.0969165712594986,
          -0.3142911195755005,
          -0.37941235303878784,
          0.6194565296173096,
          -0.20577862858772278,
          0.6876670122146606,
          -0.23828467726707458,
          0.3564528226852417,
          0.06683743745088577,
          -0.9462215900421143,
          0.0390491746366024,
          -0.992782473564148,
          -0.20325806736946106,
          -0.8169424533843994,
          -0.4014189839363098,
          0.17528203129768372,
          -0.29771897196769714,
          -0.5075219869613647,
          0.7429842948913574,
          -0.21589529514312744,
          -0.9682029485702515,
          -0.2072329968214035,
          -0.190838024020195,
          0.8716657757759094,
          0.44681328535079956,
          0.14224350452423096,
          0.21314871311187744,
          -0.6299813389778137,
          -0.7876022458076477,
          -0.3957195580005646,
          -0.4768466651439667,
          -0.10907924175262451,
          0.6112782955169678,
          0.49057140946388245,
          0.2851651608943939,
          0.7650251388549805,
          0.0496409609913826,
          0.07980100810527802,
          0.41228562593460083,
          0.6957800984382629,
          0.009414851665496826,
          0.687628984451294,
          0.40633639693260193,
          -0.14659878611564636,
          -0.5218808650970459,
          -0.9815675020217896,
          0.10703086107969284,
          0.8396716713905334,
          -0.32688355445861816,
          -0.6576793789863586,
          0.4729442000389099,
          -0.16071245074272156,
          0.33664822578430176,
          -0.6444533467292786,
          -0.4752994775772095,
          0.42019325494766235,
          -0.24785108864307404,
          0.09296870976686478,
          -0.3198826014995575,
          0.4682181477546692,
          -0.7585410475730896,
          0.061410509049892426,
          0.5820885300636292,
          0.6443547606468201,
          -0.682172954082489,
          0.5964787006378174,
          0.44627219438552856,
          -0.5297372341156006,
          -0.5860797166824341,
          -0.19234001636505127,
          0.7413369417190552,
          -0.6475535035133362,
          0.12633658945560455,
          -0.4700397849082947,
          0.39188382029533386,
          0.3458237648010254,
          -0.1652372181415558,
          -0.22780561447143555,
          0.3097466826438904,
          0.656546413898468,
          -0.06480179727077484,
          0.17460386455059052,
          0.0915309339761734,
          1.2256224155426025,
          -0.11712642014026642,
          0.4611494541168213,
          0.11872176826000214,
          0.5300162434577942,
          -0.7767677903175354,
          0.30489781498908997,
          -0.4484255313873291,
          1.0337624549865723,
          -1.7379320859909058,
          -0.6123526096343994,
          0.34355807304382324,
          0.2977347671985626,
          -0.8610678315162659,
          -0.3328772187232971,
          -0.6689872741699219,
          0.8416300415992737,
          0.21940886974334717,
          -0.7281399369239807,
          -0.017353132367134094,
          0.025076769292354584,
          0.030459925532341003,
          0.3595307469367981,
          0.1019427478313446,
          -0.6763505339622498,
          0.05435876548290253,
          -0.042997993528842926,
          0.4085600972175598,
          -0.4293225109577179,
          0.36559614539146423,
          0.12243112921714783,
          0.008666843175888062,
          -0.3008457124233246,
          0.6512165665626526,
          -0.5156687498092651,
          1.1130118370056152,
          0.27607929706573486,
          -0.7316861748695374,
          1.0574846267700195,
          0.4277787506580353,
          -0.6921562552452087,
          0.5134249925613403,
          -0.5672995448112488,
          -0.34477272629737854,
          -0.9766578674316406,
          1.0090289115905762,
          -0.8079153895378113,
          0.40301480889320374,
          0.3951280415058136,
          -0.3891471028327942,
          -0.4080823063850403,
          -0.18912118673324585,
          -0.28368687629699707,
          0.01569371670484543,
          0.33860155940055847,
          0.6117508411407471,
          0.1495250016450882,
          1.5234365463256836,
          1.4135113954544067,
          -0.31347838044166565,
          -0.4911382496356964,
          0.19149985909461975,
          -0.04826686903834343,
          -0.05306503176689148,
          0.012795019894838333,
          -0.7844491600990295,
          -0.2685528099536896,
          0.006467126309871674,
          -0.8824511766433716,
          -0.6979475617408752,
          0.09085295349359512,
          0.041855067014694214,
          0.5291812419891357,
          -0.41976261138916016,
          1.2101349830627441,
          0.0051609668880701065,
          0.30707991123199463,
          -0.2002393752336502,
          0.5258342027664185,
          0.36152857542037964,
          0.3313086926937103,
          0.2804800271987915,
          -0.4149229824542999,
          0.37876296043395996,
          -1.238918423652649,
          0.6508767604827881,
          -0.08156254887580872,
          -0.2524743676185608,
          0.10473571717739105,
          -0.07590718567371368,
          -0.5118759274482727,
          -0.8349488973617554,
          0.8667076826095581,
          -0.5723527669906616,
          -0.14943575859069824,
          -0.04972121864557266,
          -0.09882457554340363,
          0.31965160369873047,
          -0.6771113276481628,
          -0.2635098695755005,
          1.1469593048095703,
          0.7447392344474792,
          -0.2591286301612854,
          0.8192577958106995,
          1.3501784801483154,
          0.9687798619270325,
          0.013457588851451874,
          0.3341403007507324,
          -0.08436164259910583,
          0.345522940158844,
          -1.0202994346618652,
          0.7642030715942383,
          -0.19275620579719543,
          0.008139311335980892,
          -0.7349116206169128,
          1.2096188068389893,
          0.7447709441184998,
          0.0005538463592529297,
          0.2538502812385559,
          -0.7857574820518494,
          -0.23966079950332642,
          -0.6846359372138977,
          0.4173996150493622,
          -0.3473036587238312,
          1.0933700799942017,
          -0.28647053241729736,
          -0.05417036637663841,
          0.6269860863685608,
          -0.5978345274925232,
          3.5657787322998047,
          1.318716287612915,
          0.021642081439495087,
          0.3793289065361023,
          0.45985302329063416,
          0.8133774995803833,
          0.9093849062919617,
          -0.31138113141059875,
          0.6761907935142517,
          -0.5280838012695312,
          0.4034545421600342,
          -0.8472446203231812,
          0.8351603150367737,
          0.33330798149108887,
          -0.073401540517807,
          -0.2790341079235077,
          -0.5837350487709045,
          0.32553693652153015,
          0.08723407238721848,
          -0.2468281090259552,
          -1.3090401887893677,
          0.19035962224006653,
          0.3705998957157135,
          -0.3402388393878937,
          0.3052540123462677,
          0.6694070100784302,
          0.19251292943954468,
          -0.1422661542892456,
          -0.11738519370555878,
          -0.46984854340553284,
          -0.049839362502098083,
          -0.7106822729110718,
          -0.3314325213432312,
          -0.13379144668579102,
          0.3076585531234741,
          0.8188632130622864,
          -0.08511636406183243,
          -0.8094332218170166,
          -0.33407631516456604,
          1.5080631971359253,
          0.40011996030807495,
          -0.7578743100166321,
          -0.5435038208961487,
          -0.5639440417289734,
          0.2253168672323227,
          0.7460237741470337,
          0.2942988872528076,
          0.1065569669008255,
          0.9408413767814636,
          -1.0815892219543457,
          0.1117691844701767,
          -1.2931956052780151,
          0.015232143923640251,
          -0.37238359451293945,
          0.3629463016986847,
          0.21745309233665466,
          -0.1878853142261505,
          -0.3146955072879791,
          -1.110607385635376,
          0.29213854670524597,
          0.6974125504493713,
          -0.6861408352851868,
          -0.5340103507041931,
          0.5912420153617859,
          -0.2295331060886383,
          -0.5636546611785889,
          0.8891451358795166,
          0.38669291138648987,
          -0.29921042919158936,
          0.013464897871017456,
          0.0789007768034935,
          0.08019280433654785,
          -0.22251994907855988,
          0.25198790431022644,
          -0.0014303922653198242,
          0.22817721962928772,
          -0.32455548644065857,
          0.8230305910110474,
          -0.018627911806106567,
          -0.39539268612861633,
          0.04176848381757736,
          -0.5496541261672974,
          -0.2663114666938782,
          -0.14119896292686462,
          0.3184998631477356,
          0.8744829297065735,
          -0.22881054878234863,
          0.22573205828666687,
          -0.5826312303543091,
          0.21203553676605225,
          -0.3333989977836609,
          -0.27253082394599915,
          0.38679084181785583,
          -0.031202103942632675,
          0.04873098433017731
        ]
      },
      "type": "document"
    },
    {
      "id": "c54eb74c-dddb-460f-a47b-7792f72fd6f0",
      "properties": {
        "page_content": "1 input : ’SOCCER − UNCAPPED PLAYERS CALLED TO FACE MACEDONIA . ’ [ SE0 ] ’BUCHAREST ’ [ EE0 ] ’ 1996−12−06 ’ [ SE1 ] ↘\n’ Romania ’ [ EE1 ] ’ t r a i n e r ’ [ SE2 ] ’ Anghel Iordanescu ’ [ EE2 ] ’ c a l l e d up three uncapped players on Friday ↘\ni n his squad to face ’ [ SE3 ] ’ Macedonia ’ [ EE3 ] ’ next week i n a ’ [ SE4 ] ’ World Cup ’ [ EE4 ] ’ q u a l i f i e r . ↘\nM i d f i e l d e r Valentin Stefan and s t r i k e r ’ [ SE5 ] ’ V i o r e l Ion ’ [ EE5 ] ’ of O t e l u l G a l a t i and defender ’ [ ↘\nSE6 ] ’ L i v i u Ciobotariu ’ [ EE6 ] ’ of National Bucharest are the newcomers f o r the ’ [ SE7 ] ’ European ’ [ EE7 ] ↘\n’ group e i g h t clash i n ’ [ SE8 ] ’ Macedonia ’ [ EE8 ] ’ on December 14 . Iordanescu said he had picked ↘\nthem because of t h e i r good performances i n the domestic championship i n which National Bucharest ↘\nare top and O t e l u l G a l a t i t h i r d . \" I t h i n k i t s f a i r to give them a chance , \" he t o l d r e p o r t e r s ↘\n. League t i t l e −holders Steaua Bucharest , who f i n i s h e d bottom of t h e i r Champions League group ↘\ni n the ’ [ SE9 ] ’ European Cup ’ [ EE9 ] ’ , have only two players i n the squad . Attacking m i d f i e l d e r ’ [ ↘\nSE10 ] ’ Adrian I l i e ’ [ EE10 ] ’ , who r e c e n t l y moved from Steaua to Turkish club ’ [ SE11 ] ’ Galatasaray ’ [ ↘\nEE11 ] ’ , i s ruled out a f t e r two yellow −card offences . Squad : Goalkeepers − ’ [ SE12 ] ’ Bogdan ↘\nStelea ’ [ EE12 ] ’ , ’ [ SE13 ] ’ F l o r i n Prunea ’ [ EE13 ] ’ . Defenders − ’ [ SE14 ] ’Dan Petrescu ’ [ EE14 ] ’ , ’ [ SE15 ] ’ ↘\nDaniel Prodan ’ [ EE15 ] ’ , Anton Dobos , Cornel Papura , ’ [ SE16 ] ’ L i v i u Ciobotariu ’ [ EE16 ] ’ , Tibor ↘\nSelymess , ’ [ SE17 ] ’ I u l i a n F i l i p e s c u ’ [ EE17 ] ’ . M i d f i e l d e r s − ’ [ SE18 ] ’ Gheorghe Hagi ’ [ EE18 ] ’ , ’ [ SE19 ] ↘\n’ Gheorghe Popescu ’ [ EE19 ] ’ , ’ [ SE20 ] ’ Constantin Galca ’ [ EE20 ] ’ , Valentin Stefan , ’ [ SE21 ] ’ Basarab ↘\nPanduru ’ [ EE21 ] ’ , ’ [ SE22 ] ’ Dorinel Munteanu ’ [ EE22 ] ’ , Ovidiu Stinga . Forwards − Ioan Vladoiu , ’ [ ↘\nSE23 ] ’ Gheorghe Craioveanu ’ [ EE23 ] ’ , ’ [ SE24 ] ’ I o n e l Danciulescu ’ [ EE24 ] ’ , ’ [ SE25 ] ’ V i o r e l Ion ’ [ EE25 ] ’ . ↘\nREUTER ’\n2\n3 BART p r e d i c t i o n s :\n4 v E0 : ’ Bucharest ’ −> h t t p s : / / en . wikipedia . org / w i k i / Bucharest\n5 x E1 : ’ Romania ’ ( gold : ’ Romania n a t i o n a l f o o t b a l l team ’ )\n6 x E2 : ’ Anghel Iordanescu ’ ( gold : ’ Anghel Iordanescu ’ )\n7 v E3 : ’ North Macedonia n a t i o n a l f o o t b a l l team ’ −> h t t p s : / / en . wikipedia . org / w i k i / ↘\nNorth_Macedonia_national_football_team\n8 x E4 : ’ 1998 FIFA World Cup ’ ( gold : ’ FIFA World Cup ’ )\n9 v E5 : ’ V i o r e l Ion ’ −> h t t p s : / / en . wikipedia . org / w i k i / V i o r e l _ I o n\n10 v E6 : ’ L i v i u Ciobotariu ’ −> h t t p s : / / en . wikipedia . org / w i k i / L i v i u _ C i o b o t a r i u\n11 v E7 : ’ Europe ’ −> h t t p s : / / en . wikipedia . org / w i k i / Europe\n12 v E8 : ’ North Macedonia ’ −> h t t p s : / / en . wikipedia . org / w i k i / North_Macedonia\n13 v E9 : ’UEFA Champions League ’ −> h t t p s : / / en . wikipedia . org / w i k i / UEFA_Champions_League\n14 v E10 : ’ Adrian I l i e ’ −> h t t p s : / / en . wikipedia . org / w i k i / A d r i a n _ I l i e\n15 v E11 : ’ Galatasaray S.K. ( f o o t b a l l ) ’ −> h t t p s : / / en . wikipedia . org / w i k i / Galatasaray_S .K. _ ( f o o t b a l l )\n16 v E12 : ’ Bogdan Stelea ’ −> h t t p s : / / en . wikipedia . org / w i k i / Bogdan_Stelea\n17 v E13 : ’ F l o r i n Prunea ’ −> h t t p s : / / en . wikipedia . org / w i k i / Florin_Prunea\n18 v E14 : ’Dan Petrescu ’ −> h t t p s : / / en . wikipedia . org / w i k i / Dan_Petrescu\n19 v E15 : ’ Daniel Prodan ’ −> h t t p s : / / en . wikipedia . org / w i k i / Daniel_Prodan\n20 v E16 : ’ L i v i u Ciobotariu ’ −> h t t p s : / / en . wikipedia . org / w i k i / L i v i u _ C i o b o t a r i u\n21 v E17 : ’ I u l i a n F i l i p e s c u ’ −> h t t p s : / / en . wikipedia . org / w i k i / I u l i a n _ F i l i p e s c u\n22 v E18 : ’ Gheorghe Hagi ’ −> h t t p s : / / en . wikipedia . org / w i k i / Gheorghe_Hagi\n23 v E19 : ’ Gheorghe Popescu ’ −> h t t p s : / / en . wikipedia . org / w i k i / Gheorghe_Popescu\n24 x E20 : ’ Constantinos Galca ’ ( gold : ’ Constantin Galca ’ )\n25 v E21 : ’ Basarab Panduru ’ −> h t t p s : / / en . wikipedia . org / w i k i / Basarab_Panduru\n26 v E22 : ’ Dorinel Munteanu ’ −> h t t p s : / / en . wikipedia . org / w i k i / Dorinel_Munteanu\n27 v E23 : ’ Gheorghe Craioveanu ’ −> h t t p s : / / en . wikipedia . org / w i k i / Gheorghe_Craioveanu\n28 x E24 : ’ Ion Danciulescu ’ ( gold : ’ I o n e l Danciulescu ’ )\n29 v E25 : ’ V i o r e l Ion ’ −> h t t p s : / / en . wikipedia . org / w i k i / V i o r e l _ I o n\n30\n31 F1−score = 87.52\n32 KILT−F1−score = 21/26 = 80.77\n33 EM = 21/26 = 80.77\n34 KILT−EM −score = 21/26 = 80.77\nFigure 4: Entity linking BART predictions, schematic of 25 input-output pairs condensed, in each one a single\nentity in tagged.",
        "document_metadata": {
          "page_label": "21",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        }
      },
      "type": "document"
    },
    {
      "id": "06ab69d4-b404-47b6-a030-988f6ccd6828",
      "properties": {
        "page_content": " 0\n 5000\n 10000\n 15000\n 20000\n 25000\n 30000\n 35000\n 40000\n 45000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(a) FEVER, dev data discarded 26.03% (3675), test data\ndiscarded 27.7% (3869).\n 0\n 10000\n 20000\n 30000\n 40000\n 50000\n 60000\n 70000\n 80000\n 90000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(b) Natural Questions, dev data discarded 16.12% (595), test\ndata discarded 15.59% (287).\n 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(c) HotpotQA, dev data discarded 22.76% (1650), test data\ndiscarded 23.43% (1704).\n 0\n 200000\n 400000\n 600000\n 800000\n 1x10 6\n 1.2x10 6\n 1.4x10 6\n 1.6x10 6\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(d) TriviaQA, dev data discarded 15.06% (950), test data\ndiscarded 14.41% (1109).\n 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 140000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(e) Zero Shot RE, dev data discarded 15.42% (679), test data\ndiscarded 13.38% (767).\n 0\n 10000\n 20000\n 30000\n 40000\n 50000\n 60000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(f) Wizard of Wikipedia, dev data discarded 12.06% (469),\ntest data discarded 11.39% (427).\nFigure 5: BLEU score distribution in train data per provenance. For TriviaQA, we try to map all object aliases for\nthe answer. FEVER has the oldest Wikipedia snapshot. We discards on average 17.9% dev and 17.65% test data.\nFor TriviaQA there are a large number of 0 scores because we try to map all aliases for the answer and most of the\naliases are not found in a Wikipedia page. Note that we consider a QA pair valid if we match at least one alias.",
        "document_metadata": {
          "page_label": "22",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "themes": [
          "BLEU score",
          "Provenance spans",
          "FEVER",
          "Natural Questions",
          "HotpotQA",
          "TriviaQA",
          "Zero Shot RE",
          "Wizard of Wikipedia",
          "Object aliases",
          "Wikipedia snapshot"
        ]
      },
      "type": "document"
    },
    {
      "id": "f8ec2727-a40d-413c-b984-32dd066eaa3f",
      "properties": {
        "page_content": "RAGAS: Automated Evaluation of Retrieval Augmented Generation\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\n†Exploding Gradients\n∗CardiffNLP, Cardiff University, United Kingdom\n♢AMPLYFI, United Kingdom\nshahules786@gmail.com,jamesjithin97@gmail.com\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\nAbstract\nWe introduce RAGA S (Retrieval Augmented\nGeneration Assessment), a framework for\nreference-free evaluation of Retrieval Aug-\nmented Generation (RAG) pipelines. RAG\nsystems are composed of a retrieval and an\nLLM based generation module, and provide\nLLMs with knowledge from a reference textual\ndatabase, which enables them to act as a natu-\nral language layer between a user and textual\ndatabases, reducing the risk of hallucinations.\nEvaluating RAG architectures is, however, chal-\nlenging because there are several dimensions to\nconsider: the ability of the retrieval system to\nidentify relevant and focused context passages,\nthe ability of the LLM to exploit such passages\nin a faithful way, or the quality of the gener-\nation itself. With RAGA S, we put forward a\nsuite of metrics which can be used to evaluate\nthese different dimensions without having to\nrely on ground truth human annotations. We\nposit that such a framework can crucially con-\ntribute to faster evaluation cycles of RAG archi-\ntectures, which is especially important given\nthe fast adoption of LLMs.\n1 Introduction\nLanguage Models (LMs) capture a vast amount\nof knowledge about the world, which allows them\nto answer questions without accessing any exter-\nnal sources. This idea of LMs as repositories of\nknowledge emerged shortly after the introduction\nof BERT (Devlin et al., 2019) and became more\nfirmly established with the introduction of ever\nlarger LMs (Roberts et al., 2020). While the most\nrecent Large Language Models (LLMs) capture\nenough knowledge to rival human performance\nacross a wide variety of question answering bench-\nmarks (Bubeck et al., 2023), the idea of using\nLLMs as knowledge bases still has two fundamen-\ntal limitations. First, LLMs are not able to answer\nquestions about events that have happened after\nthey were trained. Second, even the largest models\nstruggle to memorise knowledge that is only rarely\nmentioned in the training corpus (Kandpal et al.,\n2022; Mallen et al., 2023). The standard solution\nto these issues is to rely on Retrieval Augmented\nGeneration (RAG) (Lee et al., 2019; Lewis et al.,\n2020; Guu et al., 2020). Answering a question\nthen essentially involves retrieving relevant pas-\nsages from a corpus and feeding these passages,\nalong with the original question, to the LM. While\ninitial approaches relied on specialised LMs for\nretrieval-augmented language modelling (Khandel-\nwal et al., 2020; Borgeaud et al., 2022), recent work\nhas suggested that simply adding retrieved docu-\nments to the input of a standard LM can also work\nwell (Khattab et al., 2022; Ram et al., 2023; Shi\net al., 2023), thus making it possible to use retrieval-\naugmented strategies in combination with LLMs\nthat are only available through APIs.\nWhile the usefulness of retrieval-augmented\nstrategies is clear, their implementation requires\na significant amount of tuning, as the overall per-\nformance will be affected by the retrieval model,\nthe considered corpus, the LM, or the prompt for-\nmulation, among others. Automated evaluation of\nretrieval-augmented systems is thus paramount. In\npractice, RAG systems are often evaluated in terms\nof the language modelling task itself, i.e. by mea-\nsuring perplexity on some reference corpus. How-\never, such evaluations are not always predictive\nof downstream performance (Wang et al., 2023c).\nMoreover, this evaluation strategy relies on the LM\nprobabilities, which are not accessible for some\nclosed models (e.g. ChatGPT and GPT-4). Ques-\ntion answering is another common evaluation task,\nbut usually only datasets with short extractive an-\nswers are considered, which may not be represen-\ntative of how the system will be used.\nTo address these issues, in this paper we present\nRAGA S1, a framework for the automated assess-\n1RAGA S is available at https://github.com/\nexplodinggradients/ragas.\narXiv:2309.15217v1  [cs.CL]  26 Sep 2023",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Exploring Gradients",
          "CardiffNLP, Cardiff University, United Kingdom",
          "AMPLYFI, United Kingdom",
          "Retrieval Augmented Generation Assessment",
          "Reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines.",
          "Introduction",
          "Language Models (LMs) capture a vast amount\nof knowledge about the world",
          "1 Introduction"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing data quickly and accurately. It's driving innovations in self-driving cars, personalized recommendations, and beyond.",
        "summary_embedding": [
          0.14491006731987,
          0.7293171882629395,
          -0.6271472573280334,
          -0.5915148854255676,
          -0.07605153322219849,
          0.01856072060763836,
          0.3215545415878296,
          -0.06993064284324646,
          0.6821730136871338,
          0.546470046043396,
          0.051694922149181366,
          0.20061293244361877,
          -0.5623824596405029,
          -1.209928035736084,
          0.43170854449272156,
          -0.4833289086818695,
          0.10599437355995178,
          0.13559004664421082,
          0.1062064915895462,
          -0.18593424558639526,
          -0.17737820744514465,
          0.6567258238792419,
          -0.7246704697608948,
          -1.0311579704284668,
          -0.9934620261192322,
          0.594208836555481,
          0.6819546222686768,
          -0.6172968745231628,
          0.7176986336708069,
          0.6541121602058411,
          -0.24097101390361786,
          -0.13895580172538757,
          0.1762460321187973,
          -0.5704410076141357,
          -0.656462550163269,
          -0.10585933178663254,
          0.41973644495010376,
          -0.13461841642856598,
          -1.1240050792694092,
          -0.5813807249069214,
          0.20094019174575806,
          -0.03304702788591385,
          0.13460637629032135,
          -1.2236924171447754,
          -0.8530169129371643,
          0.3229931592941284,
          0.6351921558380127,
          -1.1765165328979492,
          0.22640225291252136,
          -0.2067311406135559,
          -0.5657105445861816,
          0.1795324832201004,
          -0.17413002252578735,
          -0.44250649213790894,
          0.03034123219549656,
          -0.8841649293899536,
          -0.2909459173679352,
          -0.20691460371017456,
          -0.6908555626869202,
          0.005349412560462952,
          1.0078459978103638,
          -0.3361613154411316,
          0.5587680339813232,
          -0.09360213577747345,
          0.23938274383544922,
          0.5552699565887451,
          0.10239396244287491,
          -0.5328946113586426,
          -0.3956565856933594,
          0.22636303305625916,
          -1.1315890550613403,
          -0.37553906440734863,
          0.20711848139762878,
          0.1943015158176422,
          -0.3677084445953369,
          -0.01030682772397995,
          0.2224898487329483,
          -0.10822716355323792,
          -0.8750413656234741,
          -0.12524981796741486,
          -0.48074010014533997,
          0.7319472432136536,
          -0.46775269508361816,
          1.0648090839385986,
          0.06769385188817978,
          -0.5695379972457886,
          0.6638012528419495,
          0.817287027835846,
          -0.2030089795589447,
          -0.6380760073661804,
          -0.05993981286883354,
          3.3406540751457214e-05,
          -0.12081266939640045,
          -0.08515084534883499,
          0.23677249252796173,
          0.6856545209884644,
          -0.6617090702056885,
          0.733138382434845,
          0.1902327835559845,
          0.004695378243923187,
          0.24249640107154846,
          1.1467443704605103,
          -0.07832852751016617,
          0.933942437171936,
          -0.7639671564102173,
          0.11388882249593735,
          0.5277906656265259,
          -0.7994402050971985,
          -0.03332919999957085,
          -1.0506131649017334,
          0.6703979969024658,
          0.14598070085048676,
          -0.02095957100391388,
          0.10878250747919083,
          -0.14291422069072723,
          1.5824933052062988,
          -0.3727037310600281,
          0.3858047425746918,
          -0.29342469573020935,
          0.17416909337043762,
          -0.34732818603515625,
          -0.6300263404846191,
          0.14440974593162537,
          -0.18215973675251007,
          0.16750958561897278,
          -1.0908950567245483,
          0.033356234431266785,
          0.7452912330627441,
          -0.5780020356178284,
          0.8225215673446655,
          -0.3107801675796509,
          0.057770490646362305,
          -0.29084283113479614,
          0.7874050736427307,
          0.02130809798836708,
          -0.9624268412590027,
          0.06777006387710571,
          0.8785864114761353,
          -0.3015173077583313,
          0.6167946457862854,
          0.051957204937934875,
          0.06279870122671127,
          -0.22765308618545532,
          1.8964109420776367,
          -0.37138158082962036,
          -0.1664838194847107,
          -0.4071781039237976,
          0.09780901670455933,
          -0.38811951875686646,
          0.8954901695251465,
          -0.9377301931381226,
          0.6905332207679749,
          0.2978716790676117,
          -0.0017617207486182451,
          -0.8336667418479919,
          -0.6594575643539429,
          -0.6156218647956848,
          -0.00888735055923462,
          0.4990394711494446,
          0.5589882135391235,
          -0.4339905381202698,
          0.038956597447395325,
          -0.08464522659778595,
          1.0527470111846924,
          -0.4497939348220825,
          0.7791237235069275,
          -0.9343700408935547,
          0.13707058131694794,
          -0.5798563361167908,
          -0.2808893024921417,
          0.37345778942108154,
          -0.37857502698898315,
          -0.6129647493362427,
          -0.17962795495986938,
          0.9047166705131531,
          1.0212504863739014,
          0.8156511783599854,
          0.22024767100811005,
          0.23639750480651855,
          -0.1549745798110962,
          -1.3042793273925781,
          -0.3787582516670227,
          -0.7790899276733398,
          -0.07632862031459808,
          0.2717057168483734,
          0.5669084787368774,
          0.18278001248836517,
          0.19081252813339233,
          0.18234111368656158,
          -0.5066397786140442,
          0.1367904245853424,
          0.8739169836044312,
          -1.0308196544647217,
          -0.003314092755317688,
          -0.11714953184127808,
          0.5469750165939331,
          -0.7202537059783936,
          0.34715667366981506,
          0.24043799936771393,
          -0.15023589134216309,
          -0.24552832543849945,
          0.5882987380027771,
          0.1235290914773941,
          -0.5451493263244629,
          -0.7485794425010681,
          0.5439903140068054,
          -0.1725970357656479,
          1.1481035947799683,
          -1.9177641868591309,
          1.2726131677627563,
          0.5044423937797546,
          0.2905133068561554,
          0.029540464282035828,
          -0.18206118047237396,
          0.804972231388092,
          -0.24098829925060272,
          -0.3360374867916107,
          0.5739344358444214,
          0.17197763919830322,
          -0.34030991792678833,
          -0.16139040887355804,
          -0.41685208678245544,
          0.43739408254623413,
          -0.4728797674179077,
          -0.4882449209690094,
          -0.24198725819587708,
          -0.31184330582618713,
          0.8908900618553162,
          -0.05608506500720978,
          0.19519750773906708,
          0.6663210391998291,
          0.7054603695869446,
          -0.3769541084766388,
          0.8291587233543396,
          -0.07814548909664154,
          0.17941030859947205,
          -0.4379116892814636,
          0.44209641218185425,
          -0.24563853442668915,
          -0.2520541846752167,
          0.8162983655929565,
          0.03869679197669029,
          1.4760921001434326,
          0.43292778730392456,
          -0.6370487213134766,
          0.09464038163423538,
          0.08893825113773346,
          0.04542867839336395,
          0.503454327583313,
          0.7983428835868835,
          -0.5590014457702637,
          0.21443034708499908,
          0.3319363594055176,
          -0.3033733069896698,
          -0.3121938407421112,
          0.4546054005622864,
          0.7085872888565063,
          0.5526789426803589,
          0.2883468568325043,
          -1.3027536869049072,
          -0.6883053183555603,
          0.9156017899513245,
          0.5215632319450378,
          -0.02122505009174347,
          0.4605244994163513,
          0.4167693257331848,
          -0.23335982859134674,
          -0.10286518931388855,
          -0.8716436624526978,
          -0.4336486756801605,
          -1.3062232732772827,
          -1.3694345951080322,
          -0.46570253372192383,
          -0.3360365033149719,
          -0.9171434044837952,
          -0.17553311586380005,
          0.1239003837108612,
          -0.6185507774353027,
          0.8758683800697327,
          0.05602867901325226,
          -0.2769632637500763,
          -0.4956156611442566,
          -0.7870106101036072,
          0.6000607013702393,
          0.832597553730011,
          0.45970219373703003,
          -1.1697825193405151,
          0.05285618454217911,
          -0.601468563079834,
          0.7560400366783142,
          0.7074212431907654,
          0.4788329601287842,
          -0.25437766313552856,
          -0.5997072458267212,
          -0.07530292868614197,
          -0.32630664110183716,
          0.7625753879547119,
          0.1558753252029419,
          -0.9766115546226501,
          -0.30957454442977905,
          0.10287868976593018,
          0.10675094276666641,
          -0.8262974619865417,
          -0.061342280358076096,
          0.03400631248950958,
          0.45828601717948914,
          0.33405807614326477,
          0.15869398415088654,
          0.9982643127441406,
          -0.00851500779390335,
          -1.0188844203948975,
          0.23987890779972076,
          -0.18080288171768188,
          0.8902943730354309,
          -0.5567019581794739,
          0.6212546825408936,
          0.24919359385967255,
          -0.7580722570419312,
          0.32135799527168274,
          -1.2940237522125244,
          -0.25669538974761963,
          0.21082013845443726,
          -0.6783192157745361,
          0.589669942855835,
          0.13699433207511902,
          0.4925159215927124,
          0.06577488780021667,
          -2.075859546661377,
          -0.0831948071718216,
          0.0018185917288064957,
          -0.3332328796386719,
          -0.05662785470485687,
          0.2453954815864563,
          0.9287078976631165,
          0.8592918515205383,
          -0.49699169397354126,
          -0.08103184401988983,
          -0.01454719714820385,
          -0.3119962215423584,
          0.9114399552345276,
          0.6035048961639404,
          -0.36412954330444336,
          0.37462085485458374,
          0.41821032762527466,
          -0.5625166296958923,
          0.7943591475486755,
          1.106265902519226,
          -0.29777824878692627,
          0.8373010754585266,
          -0.02194179594516754,
          -0.2026282250881195,
          -0.2466791421175003,
          -0.41245022416114807,
          -0.48395514488220215,
          0.5187005400657654,
          0.025499798357486725,
          -0.45439547300338745,
          0.45283037424087524,
          -0.1649799346923828,
          0.13378570973873138,
          0.6333810687065125,
          0.27596449851989746,
          -0.4081133008003235,
          0.4115375280380249,
          -0.5625191926956177,
          0.1747746765613556,
          -0.1925879865884781,
          0.3306244909763336,
          0.34070897102355957,
          -0.5996335744857788,
          0.6371681094169617,
          -0.03791091591119766,
          -0.2999626100063324,
          0.6107130646705627,
          -0.7670974135398865,
          -1.006619930267334,
          0.508938193321228,
          -0.9465706944465637,
          0.09422720968723297,
          -0.6857671737670898,
          0.4250926971435547,
          0.14586210250854492,
          0.09936613589525223,
          -0.23820465803146362,
          -0.2994052767753601,
          0.8232097625732422,
          -0.8292121887207031,
          0.6740497350692749,
          -0.1918032020330429,
          0.009625360369682312,
          0.4347604215145111,
          0.06383953988552094,
          -0.5253289341926575,
          0.19431541860103607,
          -0.659950315952301,
          -0.7596234679222107,
          0.9855877161026001,
          0.03323878347873688,
          0.45956143736839294,
          -0.5007491111755371,
          1.129447102546692,
          -0.2517107427120209,
          0.13630685210227966,
          0.32993659377098083,
          0.41548240184783936,
          0.18721303343772888,
          0.22233474254608154,
          0.7290647029876709,
          0.5603114366531372,
          -0.40630948543548584,
          -0.19224488735198975,
          -0.6004198789596558,
          0.4186675250530243,
          -0.18209150433540344,
          -0.08823000639677048,
          0.2900386452674866,
          -0.04734364151954651,
          -0.0182851180434227,
          -0.8862870335578918,
          0.08206567168235779,
          -0.5295459032058716,
          0.051794394850730896,
          -0.7851216793060303,
          0.3325176239013672,
          0.5068346858024597,
          -0.2341345250606537,
          -0.4777137041091919,
          -1.3771553039550781,
          0.9136757850646973,
          0.44622159004211426,
          -0.5523390769958496,
          -0.8626024127006531,
          0.7802759408950806,
          -0.3837706744670868,
          -0.25166717171669006,
          0.23797482252120972,
          1.5043667554855347,
          -1.1748806238174438,
          0.968730092048645,
          -0.22798866033554077,
          0.12302200496196747,
          0.815597653388977,
          0.48803240060806274,
          -0.16120538115501404,
          -0.41937312483787537,
          -0.5347765684127808,
          -0.0010246597230434418,
          0.43729516863822937,
          -0.5408655405044556,
          -0.6266278028488159,
          0.9629054665565491,
          -1.2721610069274902,
          1.0583281517028809,
          -0.3623805344104767,
          0.474605917930603,
          -0.13591095805168152,
          -0.40314698219299316,
          -0.01336595043540001,
          0.13963037729263306,
          -0.029686879366636276,
          0.26000145077705383,
          0.24918270111083984,
          0.6999692916870117,
          -0.5657304525375366,
          -0.3702632188796997,
          0.19638851284980774,
          0.6887037754058838,
          0.2816610634326935,
          0.5871230959892273,
          0.175147145986557,
          0.037594184279441833,
          -0.29718077182769775,
          0.04186342656612396,
          -0.5724014043807983,
          0.8230386972427368,
          -0.6030702590942383,
          0.5966131091117859,
          0.30511796474456787,
          -0.679878830909729,
          -0.4480101466178894,
          -0.7350353598594666,
          -0.0907210111618042,
          0.49796825647354126,
          -0.04597782343626022,
          -0.3594972491264343,
          -0.8782928586006165,
          0.47561460733413696,
          1.0453816652297974,
          -0.11900551617145538,
          0.5714870691299438,
          0.31035366654396057,
          0.28549492359161377,
          -0.06429965049028397,
          0.6081279516220093,
          0.07204744964838028,
          0.12989044189453125,
          0.26001647114753723,
          0.4675982594490051,
          -0.26981863379478455,
          -0.6257017850875854,
          1.2947629690170288,
          -1.518450379371643,
          -1.1126306056976318,
          -0.18338918685913086,
          -0.5438023805618286,
          -0.4884161353111267,
          -0.238478422164917,
          -0.28698158264160156,
          -0.03633453696966171,
          0.27014243602752686,
          -0.05093913897871971,
          0.09750445932149887,
          -0.01540955901145935,
          0.4867582619190216,
          0.4248153567314148,
          -0.07530727982521057,
          0.07992307841777802,
          0.21963372826576233,
          0.01155233383178711,
          1.3269511461257935,
          0.36584997177124023,
          -1.199988842010498,
          -0.3690701127052307,
          1.3321598768234253,
          -0.9120879173278809,
          -0.044608645141124725,
          0.3156135678291321,
          -0.9927080273628235,
          0.028171923011541367,
          -1.6568522453308105,
          0.2722437381744385,
          -0.30606740713119507,
          -0.13917548954486847,
          -0.12601245939731598,
          0.16800247132778168,
          0.13013987243175507,
          0.4620775878429413,
          0.5440315008163452,
          -0.4073413610458374,
          -0.4557129442691803,
          0.06917346268892288,
          -0.033643826842308044,
          -0.2969728112220764,
          -0.6140773892402649,
          -0.14181898534297943,
          -0.2245924323797226,
          0.44032031297683716,
          0.7666011452674866,
          -0.5596793293952942,
          -0.7276606559753418,
          0.2943187952041626,
          -0.5452561974525452,
          -0.03791390359401703,
          0.5459936857223511,
          -1.0740444660186768,
          -0.41501548886299133,
          0.22412562370300293,
          0.1609634906053543,
          0.4663042426109314,
          1.0414159297943115,
          -0.5164770483970642,
          -0.42140161991119385,
          0.380016028881073,
          -0.0952269434928894,
          -0.5926904082298279,
          0.3336893618106842,
          -0.994907021522522,
          -0.6615291237831116,
          1.1322447061538696,
          -0.5153623223304749,
          -0.612520694732666,
          0.1235692948102951,
          0.4600314795970917,
          0.7627894282341003,
          0.45448124408721924,
          -1.0168243646621704,
          -0.45378056168556213,
          -0.3929915130138397,
          -0.9874522089958191,
          -0.2768987715244293,
          -0.5943990349769592,
          -0.320587158203125,
          -0.4686565399169922,
          0.10129541903734207,
          0.6131786108016968,
          -0.38752394914627075,
          0.3669606149196625,
          1.1565288305282593,
          0.4633689224720001,
          -0.5881335139274597,
          0.2691327631473541,
          -0.11885422468185425,
          0.3821278512477875,
          -0.26930907368659973,
          -0.013564053922891617,
          -0.2796429395675659,
          0.1383374184370041,
          -0.508643388748169,
          0.08468526601791382,
          -0.4010647237300873,
          0.0075835371389985085,
          0.3409094512462616,
          0.7276039123535156,
          -0.7338954210281372,
          0.8975465297698975,
          0.4724639058113098,
          -0.573106586933136,
          -0.7216783761978149,
          -0.07521583884954453,
          -0.040965255349874496,
          -0.16587726771831512,
          0.47017601132392883,
          0.6933128833770752,
          0.177412211894989,
          0.6254124641418457,
          -0.30657291412353516,
          -0.9541332721710205,
          -0.4406798481941223,
          0.983322262763977,
          0.08665335178375244,
          -0.7340878248214722,
          0.18721607327461243,
          1.082854986190796,
          -0.4345172941684723,
          -0.3853268027305603,
          0.6213219165802002,
          -0.07819810509681702,
          0.7182062268257141,
          -0.48973214626312256,
          0.5320551991462708,
          -0.7470522522926331,
          0.335534930229187,
          0.005306601524353027,
          0.5412881374359131,
          -0.18718676269054413,
          0.24165520071983337,
          1.3839408159255981,
          0.6859821081161499,
          -0.7764925360679626,
          -0.034414228051900864,
          0.6558713912963867,
          -0.1303946077823639,
          0.32200947403907776,
          -1.4794864654541016,
          0.2090999186038971,
          -0.15709511935710907,
          -0.780007541179657,
          0.6916884779930115,
          -1.1967097520828247,
          -0.4694722294807434,
          0.7210080623626709,
          0.33260518312454224,
          -0.07982316613197327,
          -0.5554224252700806,
          -0.38972893357276917,
          0.21251052618026733,
          0.3087270259857178,
          -0.6450915336608887,
          -0.5456766486167908,
          1.121198296546936,
          -0.12284970283508301,
          0.2548477351665497,
          -0.15776285529136658,
          -0.5155539512634277,
          1.0287508964538574,
          0.5581275224685669,
          -0.26632216572761536,
          -0.44011542201042175,
          -0.2484211027622223,
          -1.3635257482528687,
          -0.7287092208862305,
          -0.038339123129844666,
          0.3963671922683716,
          -0.11426404118537903,
          0.4869306981563568,
          0.42044004797935486,
          -0.4083463251590729,
          -0.4394382834434509,
          0.36192914843559265,
          -0.8608601689338684,
          -1.097476601600647,
          -0.3662255108356476,
          0.48887649178504944,
          -0.23945876955986023,
          0.22793623805046082,
          -0.04340840503573418,
          0.15339051187038422,
          0.1607840657234192,
          0.9549758434295654,
          -0.5964654684066772,
          0.2537994980812073,
          0.09367941319942474,
          0.4301544427871704,
          -0.6360204219818115,
          -0.25050485134124756,
          -0.41648855805397034,
          -0.08446565270423889,
          -0.5044906735420227,
          0.12458400428295135,
          -0.06327077001333237,
          0.30243441462516785,
          0.20295055210590363,
          -0.7797638773918152,
          0.3532911539077759,
          -0.40010613203048706,
          0.4881419539451599,
          -0.7174025177955627,
          0.18410058319568634,
          0.48226919770240784,
          -0.325283944606781,
          0.24694767594337463,
          -1.0167447328567505,
          1.0723973512649536,
          -0.009705845266580582,
          -0.9121776223182678,
          1.020058274269104,
          -0.09997338056564331,
          0.13826704025268555,
          -0.33429154753685,
          -0.39892327785491943,
          0.6097908616065979,
          -0.16286514699459076,
          0.7252529859542847,
          -0.1799832284450531,
          0.3462958037853241,
          0.11261919140815735,
          -1.022852897644043,
          -0.025293752551078796,
          -0.981508731842041,
          -0.22461462020874023,
          -0.7175053954124451,
          -0.4170597493648529,
          0.14416977763175964,
          -0.32004743814468384,
          -0.4804210960865021,
          0.7122148871421814,
          -0.2131195068359375,
          -1.0721498727798462,
          -0.16581809520721436,
          -0.2165435403585434,
          0.8252094984054565,
          0.4366030693054199,
          0.09352582693099976,
          0.2436855286359787,
          -0.5720636248588562,
          -0.8455109000205994,
          -0.44617220759391785,
          -0.525536060333252,
          -0.07477683573961258,
          0.6279585361480713,
          0.5294432640075684,
          0.25337639451026917,
          0.7715329527854919,
          0.10931844264268875,
          0.06804446130990982,
          0.4781544804573059,
          0.7073677778244019,
          -0.039589233696460724,
          0.6607880592346191,
          0.4048813283443451,
          -0.14001071453094482,
          -0.45818793773651123,
          -0.9562743902206421,
          0.06105335056781769,
          0.8386339545249939,
          -0.32877013087272644,
          -0.6888221502304077,
          0.44818970561027527,
          -0.15961387753486633,
          0.5248850584030151,
          -0.6375119686126709,
          -0.4609641134738922,
          0.3295890986919403,
          -0.3099549412727356,
          0.14554613828659058,
          -0.2677350640296936,
          0.44816291332244873,
          -0.6701852083206177,
          0.09331034123897552,
          0.5322731733322144,
          0.7657592296600342,
          -0.6357597708702087,
          0.6094003319740295,
          0.546602725982666,
          -0.5717816352844238,
          -0.5461024045944214,
          -0.21833208203315735,
          0.7517307996749878,
          -0.6914265751838684,
          0.1987873613834381,
          -0.4592142403125763,
          0.4237535893917084,
          0.35352376103401184,
          -0.2409861981868744,
          -0.2113403081893921,
          0.3070315718650818,
          0.6981819272041321,
          -0.061291396617889404,
          0.25413778424263,
          0.12059442698955536,
          1.2263240814208984,
          -0.1465355008840561,
          0.5006008744239807,
          0.11035746335983276,
          0.5038586854934692,
          -0.7880017757415771,
          0.3332044184207916,
          -0.3772670328617096,
          0.9898180961608887,
          -1.717918872833252,
          -0.5426744222640991,
          0.41598275303840637,
          0.2447010576725006,
          -0.9226995706558228,
          -0.3761453330516815,
          -0.7098400592803955,
          0.8996022343635559,
          0.3198964297771454,
          -0.8281533718109131,
          0.005974277853965759,
          0.10544319450855255,
          0.010729949921369553,
          0.36783576011657715,
          0.08426402509212494,
          -0.5072498917579651,
          0.011124636977910995,
          0.021026931703090668,
          0.4758586585521698,
          -0.3797101378440857,
          0.36117032170295715,
          0.19414296746253967,
          0.006531093269586563,
          -0.3325786888599396,
          0.6098458766937256,
          -0.5441864132881165,
          1.1866453886032104,
          0.26583391427993774,
          -0.7335748672485352,
          1.0678911209106445,
          0.4684213697910309,
          -0.6052606105804443,
          0.5324798226356506,
          -0.597297191619873,
          -0.3715963065624237,
          -1.0229392051696777,
          1.0357894897460938,
          -0.9118317365646362,
          0.3805966377258301,
          0.472578763961792,
          -0.3187107741832733,
          -0.3739783465862274,
          -0.13205549120903015,
          -0.3326870799064636,
          -0.013142213225364685,
          0.288836807012558,
          0.5362412929534912,
          0.1871020495891571,
          1.5028650760650635,
          1.5019316673278809,
          -0.3259369730949402,
          -0.5213896036148071,
          0.2511684000492096,
          -0.08440778404474258,
          -0.10007248818874359,
          -0.04058931767940521,
          -0.7825309038162231,
          -0.31455010175704956,
          -0.05937359482049942,
          -0.9192599058151245,
          -0.7865229249000549,
          0.09812238812446594,
          0.03546254709362984,
          0.45661476254463196,
          -0.37993085384368896,
          1.2587649822235107,
          -0.09764211624860764,
          0.30204522609710693,
          -0.21543359756469727,
          0.506322979927063,
          0.3876202702522278,
          0.4227212965488434,
          0.24892383813858032,
          -0.33950331807136536,
          0.38391295075416565,
          -1.359770655632019,
          0.5386645793914795,
          -0.15974217653274536,
          -0.30407172441482544,
          0.11944471299648285,
          -0.1513095498085022,
          -0.5019018650054932,
          -0.8317278623580933,
          0.7891315817832947,
          -0.5896360874176025,
          -0.14609739184379578,
          -0.0829915702342987,
          -0.18859249353408813,
          0.35206782817840576,
          -0.6458789110183716,
          -0.2784574627876282,
          1.2164968252182007,
          0.731041669845581,
          -0.28626441955566406,
          0.759901225566864,
          1.2265485525131226,
          1.001865267753601,
          -0.0696355551481247,
          0.343199759721756,
          -0.029361004009842873,
          0.35393503308296204,
          -0.9970066547393799,
          0.6559497714042664,
          -0.2240004539489746,
          -0.029737628996372223,
          -0.7323662042617798,
          1.1472952365875244,
          0.7238458395004272,
          0.06320472806692123,
          0.207140251994133,
          -0.8148226141929626,
          -0.2573605179786682,
          -0.7133609056472778,
          0.3798946440219879,
          -0.3865554630756378,
          0.9697822332382202,
          -0.22954612970352173,
          0.0022046267986297607,
          0.5362497568130493,
          -0.6352366805076599,
          3.527601718902588,
          1.2684353590011597,
          0.06982732564210892,
          0.35084590315818787,
          0.47644683718681335,
          0.9393705725669861,
          0.961047887802124,
          -0.2684067487716675,
          0.5883501768112183,
          -0.5161614418029785,
          0.494998037815094,
          -0.8035480976104736,
          0.8614016175270081,
          0.2870739698410034,
          0.034770939499139786,
          -0.16469891369342804,
          -0.6501825451850891,
          0.30100637674331665,
          0.026380114257335663,
          -0.24851027131080627,
          -1.3842692375183105,
          0.08690967410802841,
          0.2691648006439209,
          -0.3900357782840729,
          0.3445873558521271,
          0.6435839533805847,
          0.20163783431053162,
          -0.1668778657913208,
          -0.08970111608505249,
          -0.41942986845970154,
          -0.03803861141204834,
          -0.652387797832489,
          -0.3237905204296112,
          -0.236580029129982,
          0.23633897304534912,
          0.9502747058868408,
          -0.006140850484371185,
          -0.8939476609230042,
          -0.3151281177997589,
          1.5179661512374878,
          0.4306967854499817,
          -0.849799633026123,
          -0.49473682045936584,
          -0.5425565838813782,
          0.27773481607437134,
          0.5835340023040771,
          0.31471094489097595,
          0.07864243537187576,
          0.8498427271842957,
          -1.1292880773544312,
          0.03483469784259796,
          -1.2607204914093018,
          0.044550321996212006,
          -0.3356069028377533,
          0.4646432101726532,
          0.21763990819454193,
          -0.14398276805877686,
          -0.24195444583892822,
          -1.1151748895645142,
          0.30356547236442566,
          0.798176109790802,
          -0.6413978338241577,
          -0.5871297121047974,
          0.5493795871734619,
          -0.20751993358135223,
          -0.5349833369255066,
          0.8650317788124084,
          0.33980220556259155,
          -0.267363965511322,
          -0.06803719699382782,
          0.07214139401912689,
          0.1131453737616539,
          -0.24482767283916473,
          0.26199132204055786,
          -0.09661202132701874,
          0.35075899958610535,
          -0.3927660286426544,
          0.8148543834686279,
          -0.16047532856464386,
          -0.4594968855381012,
          0.08520255982875824,
          -0.5455288290977478,
          -0.4225608706474304,
          -0.051151253283023834,
          0.2705157995223999,
          0.8461418151855469,
          -0.3039599061012268,
          0.19143344461917877,
          -0.5604915618896484,
          0.22093424201011658,
          -0.31154128909111023,
          -0.29048240184783936,
          0.45130443572998047,
          -0.019502460956573486,
          -0.01131579652428627
        ]
      },
      "type": "document"
    },
    {
      "id": "b09fdece-c2a0-446b-936e-9ef8b868ae29",
      "properties": {
        "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
        "document_metadata": {
          "page_label": "2",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "2 Related Work",
          "3 Evaluation Strategies"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks, analyzing data quickly and accurately. It's also driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.17001354694366455,
          0.7037400007247925,
          -0.5972846746444702,
          -0.6107304096221924,
          -0.09962859004735947,
          0.012287147343158722,
          0.24262061715126038,
          -0.07306702435016632,
          0.6197491884231567,
          0.5682291388511658,
          0.05057787150144577,
          0.17918753623962402,
          -0.46196144819259644,
          -1.2443815469741821,
          0.3404715955257416,
          -0.5651688575744629,
          0.08762447535991669,
          0.017658911645412445,
          0.02144092321395874,
          -0.18358242511749268,
          -0.15251317620277405,
          0.6823208332061768,
          -0.6607199311256409,
          -1.0904662609100342,
          -0.9997321367263794,
          0.6225168108940125,
          0.6563811898231506,
          -0.660983145236969,
          0.7149767279624939,
          0.5960270762443542,
          -0.19491973519325256,
          -0.1593451350927353,
          0.1737854778766632,
          -0.5283905863761902,
          -0.623901903629303,
          -0.09424623847007751,
          0.4171382188796997,
          -0.1489633172750473,
          -1.149383544921875,
          -0.5682276487350464,
          0.19610586762428284,
          -0.17803159356117249,
          0.1425337791442871,
          -1.2038860321044922,
          -0.8164084553718567,
          0.4083344340324402,
          0.5729390978813171,
          -1.2199351787567139,
          0.15247289836406708,
          -0.2304106503725052,
          -0.6340320110321045,
          0.1897246241569519,
          -0.21273764967918396,
          -0.438821405172348,
          0.05487480387091637,
          -1.0113580226898193,
          -0.40598830580711365,
          -0.21763378381729126,
          -0.7388358116149902,
          -0.026535741984844208,
          1.0041377544403076,
          -0.33603066205978394,
          0.6034368276596069,
          0.005080267786979675,
          0.25079208612442017,
          0.5439397096633911,
          0.14208808541297913,
          -0.3908669054508209,
          -0.4078671634197235,
          0.17537899315357208,
          -1.2247917652130127,
          -0.32663723826408386,
          0.20429465174674988,
          0.20743021368980408,
          -0.3620830178260803,
          0.004530645906925201,
          0.2692049443721771,
          -0.11996978521347046,
          -0.874296247959137,
          -0.07769046723842621,
          -0.5227373838424683,
          0.6978479623794556,
          -0.45599138736724854,
          1.0713742971420288,
          -0.016694139689207077,
          -0.5868815183639526,
          0.720486044883728,
          0.8622515797615051,
          -0.20124369859695435,
          -0.616811990737915,
          -0.05302967131137848,
          -0.0593307688832283,
          -0.1878845989704132,
          -0.17706695199012756,
          0.24921253323554993,
          0.7306819558143616,
          -0.6822174787521362,
          0.7657720446586609,
          0.2649552822113037,
          -0.08407216519117355,
          0.2404964566230774,
          1.0467617511749268,
          -0.04381487891077995,
          0.9058229327201843,
          -0.7524072527885437,
          0.12525521218776703,
          0.5160109996795654,
          -0.8609219193458557,
          -0.0173206627368927,
          -1.0341943502426147,
          0.6395199298858643,
          0.11479394137859344,
          -0.04732735455036163,
          0.14186322689056396,
          -0.06773766875267029,
          1.5499204397201538,
          -0.3137304484844208,
          0.2628898620605469,
          -0.38901185989379883,
          0.22014670073986053,
          -0.3750650882720947,
          -0.5553479790687561,
          0.1089082881808281,
          -0.3424307703971863,
          0.27794450521469116,
          -1.0881855487823486,
          0.09664730727672577,
          0.7481679320335388,
          -0.5601145029067993,
          0.7897307872772217,
          -0.30724218487739563,
          0.09517356753349304,
          -0.4318879246711731,
          0.7920940518379211,
          0.033566854894161224,
          -0.9695606231689453,
          -0.009823329746723175,
          0.864151656627655,
          -0.29377883672714233,
          0.6365285515785217,
          0.02301349677145481,
          0.11497770249843597,
          -0.17999710142612457,
          1.8254234790802002,
          -0.4079185426235199,
          -0.13048787415027618,
          -0.40041717886924744,
          -0.03488878905773163,
          -0.3938792943954468,
          0.9345355033874512,
          -0.971676230430603,
          0.6461847424507141,
          0.3946326673030853,
          0.058993346989154816,
          -0.6912416219711304,
          -0.694898247718811,
          -0.6673235297203064,
          -0.0035253912210464478,
          0.4665566682815552,
          0.5976436138153076,
          -0.27679160237312317,
          0.09515354037284851,
          -0.11937268078327179,
          1.1978421211242676,
          -0.4322178065776825,
          0.7163383960723877,
          -1.058738112449646,
          0.1593240648508072,
          -0.5214572548866272,
          -0.31140780448913574,
          0.29515790939331055,
          -0.4033297300338745,
          -0.6524462103843689,
          -0.19453158974647522,
          0.9488608241081238,
          1.1427854299545288,
          0.8205499053001404,
          0.22198358178138733,
          0.195535808801651,
          -0.25921016931533813,
          -1.2958908081054688,
          -0.4238226115703583,
          -0.8352176547050476,
          -0.012574121356010437,
          0.2892308831214905,
          0.54080730676651,
          0.29236042499542236,
          0.20837149024009705,
          0.34818941354751587,
          -0.48493045568466187,
          0.16334225237369537,
          0.8018690347671509,
          -1.020436406135559,
          0.013810727745294571,
          -0.06829479336738586,
          0.4744613766670227,
          -0.7049046754837036,
          0.3593010902404785,
          0.24060703814029694,
          -0.0841606929898262,
          -0.19825541973114014,
          0.612318754196167,
          -0.0248248428106308,
          -0.5237756371498108,
          -0.7225826382637024,
          0.49753671884536743,
          -0.1758880764245987,
          1.1122462749481201,
          -1.7922130823135376,
          1.2731688022613525,
          0.5327811241149902,
          0.353199303150177,
          -0.08620534092187881,
          -0.28796327114105225,
          0.8151822686195374,
          -0.10103068500757217,
          -0.3608563542366028,
          0.44243451952934265,
          0.15663601458072662,
          -0.3948861062526703,
          -0.14119377732276917,
          -0.36077097058296204,
          0.4262925386428833,
          -0.5494167804718018,
          -0.47240450978279114,
          -0.14515872299671173,
          -0.33626535534858704,
          0.9724587202072144,
          0.11287185549736023,
          0.21463297307491302,
          0.6391748189926147,
          0.6695569157600403,
          -0.34146133065223694,
          0.824224591255188,
          -0.05279159918427467,
          0.27140527963638306,
          -0.4832804799079895,
          0.40109753608703613,
          -0.25941988825798035,
          -0.2852022647857666,
          0.7792918086051941,
          0.16887053847312927,
          1.4423108100891113,
          0.4774094820022583,
          -0.7280946969985962,
          0.15461347997188568,
          -0.047271013259887695,
          0.024457715451717377,
          0.5811721086502075,
          0.6883000731468201,
          -0.5382037162780762,
          0.1655680537223816,
          0.19549331068992615,
          -0.22478577494621277,
          -0.34745144844055176,
          0.5519740581512451,
          0.6778715252876282,
          0.621571958065033,
          0.34663286805152893,
          -1.3806411027908325,
          -0.7420792579650879,
          0.916611909866333,
          0.5347574353218079,
          -0.03582051023840904,
          0.5334360599517822,
          0.439033180475235,
          -0.29742687940597534,
          -0.06089968979358673,
          -0.8731357455253601,
          -0.36906328797340393,
          -1.3391317129135132,
          -1.3571643829345703,
          -0.44515088200569153,
          -0.34963005781173706,
          -0.9001395106315613,
          -0.12250621616840363,
          0.1641312688589096,
          -0.6905884146690369,
          0.897812008857727,
          0.061345234513282776,
          -0.24086147546768188,
          -0.5424370169639587,
          -0.7769922018051147,
          0.5027157068252563,
          0.8489565849304199,
          0.5165011286735535,
          -1.2212680578231812,
          0.10286206007003784,
          -0.6299771070480347,
          0.7383338809013367,
          0.7440586686134338,
          0.5113784074783325,
          -0.1221046969294548,
          -0.5191940069198608,
          -0.09395311027765274,
          -0.314754843711853,
          0.7612513899803162,
          0.10572165995836258,
          -1.0105764865875244,
          -0.35746049880981445,
          0.009414376690983772,
          0.045240629464387894,
          -0.7688693404197693,
          -0.058514662086963654,
          0.05042830482125282,
          0.517877459526062,
          0.22862103581428528,
          0.0892048180103302,
          1.0613096952438354,
          0.0017666742205619812,
          -1.080322027206421,
          0.18166190385818481,
          -0.18859942257404327,
          0.877560555934906,
          -0.5682258009910583,
          0.6199414730072021,
          0.28334546089172363,
          -0.7195314168930054,
          0.2786213159561157,
          -1.240120768547058,
          -0.14328446984291077,
          0.23443672060966492,
          -0.6127557754516602,
          0.6155505776405334,
          0.15677830576896667,
          0.4240148663520813,
          0.07984823733568192,
          -2.0081636905670166,
          -0.0785396620631218,
          0.14704301953315735,
          -0.4844054579734802,
          -0.11410640180110931,
          0.19603168964385986,
          0.8945372700691223,
          0.8010289072990417,
          -0.47574174404144287,
          -0.05377098172903061,
          -0.01349401380866766,
          -0.31099560856819153,
          0.8452745079994202,
          0.47201094031333923,
          -0.328797310590744,
          0.3333401679992676,
          0.39465823769569397,
          -0.5335476994514465,
          0.7957864999771118,
          1.143248438835144,
          -0.38700470328330994,
          0.7955979704856873,
          -0.23907476663589478,
          -0.17071068286895752,
          -0.23980006575584412,
          -0.41667109727859497,
          -0.3437284529209137,
          0.492573618888855,
          -0.005062118172645569,
          -0.3787897527217865,
          0.42240867018699646,
          -0.1357440948486328,
          0.05385256186127663,
          0.7424731254577637,
          0.285732626914978,
          -0.39705517888069153,
          0.394060879945755,
          -0.5315396785736084,
          0.19403427839279175,
          -0.2192429006099701,
          0.32639408111572266,
          0.28066638112068176,
          -0.7122159004211426,
          0.5880001783370972,
          -0.031648751348257065,
          -0.3973133862018585,
          0.589089035987854,
          -0.7184100151062012,
          -1.0398342609405518,
          0.4490841031074524,
          -1.051051139831543,
          0.11777503788471222,
          -0.729235053062439,
          0.4005323648452759,
          -0.030979089438915253,
          0.07806631922721863,
          -0.29288747906684875,
          -0.2867293357849121,
          0.7395055890083313,
          -0.7586572170257568,
          0.6267704963684082,
          -0.24792706966400146,
          0.022784046828746796,
          0.46371448040008545,
          0.09443165361881256,
          -0.5219950079917908,
          0.19392916560173035,
          -0.6515740752220154,
          -0.7531136870384216,
          1.0470738410949707,
          -0.0744270607829094,
          0.3077602684497833,
          -0.4794044494628906,
          1.1581754684448242,
          -0.11803773045539856,
          0.08202047646045685,
          0.3491073548793793,
          0.42259082198143005,
          0.26220935583114624,
          0.29422926902770996,
          0.8511523604393005,
          0.5405593514442444,
          -0.3957494795322418,
          -0.1757473200559616,
          -0.6707167029380798,
          0.4769055247306824,
          -0.1910010129213333,
          -0.23642201721668243,
          0.24765565991401672,
          -0.08596424758434296,
          -0.033979542553424835,
          -0.8453472852706909,
          0.10397256165742874,
          -0.5907039642333984,
          -0.10156093537807465,
          -0.8092979788780212,
          0.2800861895084381,
          0.46581098437309265,
          -0.21332964301109314,
          -0.5400623083114624,
          -1.4116414785385132,
          0.8352559804916382,
          0.5236283540725708,
          -0.533128559589386,
          -0.7852641940116882,
          0.7948476076126099,
          -0.2872685492038727,
          -0.1552233099937439,
          0.19597934186458588,
          1.4522719383239746,
          -1.0497678518295288,
          0.8697558641433716,
          -0.17765170335769653,
          0.09382285177707672,
          0.7901621460914612,
          0.36114501953125,
          -0.015217822045087814,
          -0.44020381569862366,
          -0.48164623975753784,
          0.03653434291481972,
          0.40998390316963196,
          -0.5152121782302856,
          -0.6707544922828674,
          0.9459491968154907,
          -1.173895239830017,
          1.0103949308395386,
          -0.40128952264785767,
          0.49530327320098877,
          -0.1863308548927307,
          -0.40873822569847107,
          -0.04119553416967392,
          0.1952550709247589,
          0.010577404871582985,
          0.25374725461006165,
          0.22621914744377136,
          0.6641642451286316,
          -0.47020575404167175,
          -0.3554995357990265,
          0.059834063053131104,
          0.8010814189910889,
          0.36591029167175293,
          0.5428950786590576,
          0.16746950149536133,
          0.11595715582370758,
          -0.28647756576538086,
          0.14675003290176392,
          -0.6380338072776794,
          0.7459187507629395,
          -0.6545936465263367,
          0.5749554634094238,
          0.42819446325302124,
          -0.6775094866752625,
          -0.5077385306358337,
          -0.7357791662216187,
          -0.14749374985694885,
          0.45021265745162964,
          0.021158762276172638,
          -0.38448983430862427,
          -0.9372546672821045,
          0.4596109986305237,
          1.0532870292663574,
          -0.1024080365896225,
          0.5325855016708374,
          0.2941443920135498,
          0.2726539075374603,
          -0.14131250977516174,
          0.5887532234191895,
          0.0540425069630146,
          0.08028078079223633,
          0.18049952387809753,
          0.43496033549308777,
          -0.30056819319725037,
          -0.606791079044342,
          1.4120935201644897,
          -1.539868712425232,
          -1.1236213445663452,
          -0.1381358653306961,
          -0.3960403501987457,
          -0.42162036895751953,
          -0.15366025269031525,
          -0.37809696793556213,
          -0.08143360912799835,
          0.3260965645313263,
          -0.06285702437162399,
          0.07940836250782013,
          0.036577582359313965,
          0.39435407519340515,
          0.4194391071796417,
          -0.1030038446187973,
          0.06774973124265671,
          0.1838335394859314,
          -0.13735273480415344,
          1.397924780845642,
          0.3971671462059021,
          -1.165160894393921,
          -0.23002788424491882,
          1.4131200313568115,
          -0.8849786520004272,
          -0.013607487082481384,
          0.32859742641448975,
          -0.9870821833610535,
          0.04724349081516266,
          -1.651365876197815,
          0.22628116607666016,
          -0.25228849053382874,
          -0.16541975736618042,
          -0.16008374094963074,
          0.23235461115837097,
          0.180307075381279,
          0.431549996137619,
          0.5491371154785156,
          -0.4926064610481262,
          -0.5446996688842773,
          0.11665681004524231,
          -0.09422634541988373,
          -0.30947792530059814,
          -0.7230757474899292,
          -0.1223548874258995,
          -0.23080389201641083,
          0.41157492995262146,
          0.6572481989860535,
          -0.5850919485092163,
          -0.6978720426559448,
          0.3820691406726837,
          -0.5212529897689819,
          -0.06448941677808762,
          0.6063043475151062,
          -1.0989983081817627,
          -0.39392203092575073,
          0.26510363817214966,
          0.27503445744514465,
          0.48877447843551636,
          0.9942187070846558,
          -0.5441843271255493,
          -0.4457719326019287,
          0.4149174690246582,
          -0.010136399418115616,
          -0.5762455463409424,
          0.32066112756729126,
          -0.9460886120796204,
          -0.6540416479110718,
          1.1765847206115723,
          -0.4740753769874573,
          -0.6362676024436951,
          0.14861755073070526,
          0.48039260506629944,
          0.7775120735168457,
          0.4484742283821106,
          -0.9746091365814209,
          -0.5573586225509644,
          -0.3240833580493927,
          -1.040083646774292,
          -0.19513455033302307,
          -0.5238984823226929,
          -0.34710004925727844,
          -0.48671960830688477,
          0.13946281373500824,
          0.523432195186615,
          -0.3502989709377289,
          0.35093337297439575,
          1.255302906036377,
          0.5760223269462585,
          -0.5122931003570557,
          0.24288761615753174,
          -0.1372120976448059,
          0.4007200598716736,
          -0.2523748576641083,
          -0.05269220098853111,
          -0.17466726899147034,
          0.09777648746967316,
          -0.4247840642929077,
          0.2223731130361557,
          -0.3812035620212555,
          -0.015078425407409668,
          0.3727424442768097,
          0.7122883796691895,
          -0.7806264162063599,
          0.8414087295532227,
          0.4867090582847595,
          -0.5301060676574707,
          -0.6682600378990173,
          -0.18018731474876404,
          -0.025562386959791183,
          -0.27821844816207886,
          0.38584697246551514,
          0.6938211917877197,
          0.2600957751274109,
          0.6235162615776062,
          -0.3494308292865753,
          -0.9028358459472656,
          -0.4220636188983917,
          0.9436613321304321,
          0.06673064827919006,
          -0.7452048063278198,
          0.1683463752269745,
          1.0002591609954834,
          -0.3949195146560669,
          -0.3138110637664795,
          0.5160955786705017,
          -0.09094443172216415,
          0.5896313190460205,
          -0.5889685153961182,
          0.6214655041694641,
          -0.6478976607322693,
          0.34441739320755005,
          0.0017762742936611176,
          0.519878089427948,
          -0.3244141936302185,
          0.2415621280670166,
          1.4682563543319702,
          0.6422873139381409,
          -0.8613927960395813,
          0.05625161901116371,
          0.545099139213562,
          -0.11511749774217606,
          0.25268709659576416,
          -1.4956293106079102,
          0.22368770837783813,
          -0.14334438741207123,
          -0.7840650677680969,
          0.6866493225097656,
          -1.141023874282837,
          -0.47525739669799805,
          0.7224677801132202,
          0.3698676824569702,
          0.1014661192893982,
          -0.5526877641677856,
          -0.28340044617652893,
          0.2723788022994995,
          0.4167567789554596,
          -0.7093644738197327,
          -0.5773450136184692,
          1.0992814302444458,
          -0.196613147854805,
          0.28266510367393494,
          -0.14656779170036316,
          -0.43136000633239746,
          1.0052707195281982,
          0.5708770155906677,
          -0.34246253967285156,
          -0.37612420320510864,
          -0.1908121258020401,
          -1.275506615638733,
          -0.703254759311676,
          0.033887624740600586,
          0.4685025215148926,
          -0.15191856026649475,
          0.4386812746524811,
          0.4796735644340515,
          -0.35543501377105713,
          -0.4038871228694916,
          0.27127981185913086,
          -0.9501429796218872,
          -1.0727314949035645,
          -0.25700175762176514,
          0.3988332450389862,
          -0.16924560070037842,
          0.14980749785900116,
          -0.006653411313891411,
          0.11718682199716568,
          0.047420624643564224,
          0.9359047412872314,
          -0.5301834344863892,
          0.3056376576423645,
          0.1699923574924469,
          0.4255838096141815,
          -0.6619510054588318,
          -0.31164491176605225,
          -0.35329490900039673,
          -0.13582590222358704,
          -0.5112341046333313,
          0.04059603810310364,
          -0.003652714192867279,
          0.25951236486434937,
          0.2676461935043335,
          -0.6374751925468445,
          0.3035447299480438,
          -0.42165347933769226,
          0.45802199840545654,
          -0.6701480150222778,
          0.18224060535430908,
          0.5058137774467468,
          -0.2548138499259949,
          0.3355627655982971,
          -1.0425794124603271,
          1.0436476469039917,
          0.03962875157594681,
          -0.8060978055000305,
          0.9327201247215271,
          -0.06457459181547165,
          0.07619282603263855,
          -0.3150366544723511,
          -0.35759446024894714,
          0.6337752938270569,
          -0.18901996314525604,
          0.6751437783241272,
          -0.2137773036956787,
          0.3838304281234741,
          0.08684554696083069,
          -0.9672592878341675,
          0.06794177740812302,
          -1.0044156312942505,
          -0.1812874674797058,
          -0.7855228781700134,
          -0.40825703740119934,
          0.1801707148551941,
          -0.30765601992607117,
          -0.5223142504692078,
          0.7315949201583862,
          -0.21172048151493073,
          -0.9583691358566284,
          -0.2168758511543274,
          -0.18539315462112427,
          0.862801730632782,
          0.44850772619247437,
          0.09827776253223419,
          0.20500892400741577,
          -0.5893012285232544,
          -0.7761632800102234,
          -0.36789920926094055,
          -0.4591901898384094,
          -0.07052107900381088,
          0.5964833498001099,
          0.479718953371048,
          0.2891619801521301,
          0.7711735367774963,
          0.05081861466169357,
          0.09017185866832733,
          0.3816324472427368,
          0.6926770210266113,
          0.01983916014432907,
          0.6555072069168091,
          0.3903695046901703,
          -0.14761152863502502,
          -0.575197160243988,
          -0.9898099899291992,
          0.08500632643699646,
          0.8257237672805786,
          -0.2930217385292053,
          -0.6874611973762512,
          0.4775601327419281,
          -0.15995976328849792,
          0.3258691132068634,
          -0.6289264559745789,
          -0.46555328369140625,
          0.420318067073822,
          -0.2901972830295563,
          0.10389847308397293,
          -0.34914082288742065,
          0.47068512439727783,
          -0.769072949886322,
          0.05595392733812332,
          0.592705488204956,
          0.6698029041290283,
          -0.7116877436637878,
          0.5991199016571045,
          0.4397561550140381,
          -0.5263884663581848,
          -0.5824525356292725,
          -0.1977275013923645,
          0.7402856349945068,
          -0.6579052209854126,
          0.12078002840280533,
          -0.5129790902137756,
          0.41893893480300903,
          0.3594971299171448,
          -0.15906713902950287,
          -0.25405222177505493,
          0.29509878158569336,
          0.6125257611274719,
          -0.07987882196903229,
          0.1964319944381714,
          0.057425357401371,
          1.1973668336868286,
          -0.1455817073583603,
          0.47452229261398315,
          0.08990931510925293,
          0.5480901002883911,
          -0.7766255736351013,
          0.3147953152656555,
          -0.4887899160385132,
          1.0461783409118652,
          -1.7564404010772705,
          -0.6384751796722412,
          0.33399122953414917,
          0.2917623221874237,
          -0.8807685375213623,
          -0.3822582960128784,
          -0.6550198793411255,
          0.8475666046142578,
          0.25435903668403625,
          -0.7574268579483032,
          -0.0018529444932937622,
          -0.014977369457483292,
          0.03859864920377731,
          0.352078914642334,
          0.09113695472478867,
          -0.680365800857544,
          0.05272725224494934,
          -0.050849609076976776,
          0.4229072332382202,
          -0.4171856939792633,
          0.3756403923034668,
          0.08677571266889572,
          0.0173296257853508,
          -0.3013012111186981,
          0.6550720930099487,
          -0.5206359028816223,
          1.1400402784347534,
          0.2801797688007355,
          -0.7541120052337646,
          1.065847396850586,
          0.40635785460472107,
          -0.6848594546318054,
          0.4961469769477844,
          -0.5760297775268555,
          -0.3164706826210022,
          -0.979499340057373,
          1.0243557691574097,
          -0.7872797250747681,
          0.41145145893096924,
          0.3963802754878998,
          -0.38772183656692505,
          -0.4024256467819214,
          -0.17413336038589478,
          -0.2881929278373718,
          0.02224862575531006,
          0.3467528522014618,
          0.6031092405319214,
          0.17441962659358978,
          1.5294687747955322,
          1.4079548120498657,
          -0.3090057969093323,
          -0.4795108735561371,
          0.20001280307769775,
          -0.050295181572437286,
          -0.04949251562356949,
          0.029213011264801025,
          -0.8218201398849487,
          -0.2659166753292084,
          -0.016189932823181152,
          -0.901006281375885,
          -0.6852371096611023,
          0.10220614820718765,
          0.024360425770282745,
          0.5643877387046814,
          -0.45608797669410706,
          1.1881756782531738,
          -0.013729273341596127,
          0.3067585825920105,
          -0.21116375923156738,
          0.5415292978286743,
          0.3503587245941162,
          0.3404058516025543,
          0.26543930172920227,
          -0.40818291902542114,
          0.34338510036468506,
          -1.242517113685608,
          0.6535123586654663,
          -0.09536947309970856,
          -0.22092273831367493,
          0.1358795017004013,
          -0.07661644369363785,
          -0.48790687322616577,
          -0.8044420480728149,
          0.8619990944862366,
          -0.5634229183197021,
          -0.15451452136039734,
          -0.056584082543849945,
          -0.10315336287021637,
          0.2963704466819763,
          -0.6731477379798889,
          -0.2650216221809387,
          1.140690565109253,
          0.7295383810997009,
          -0.2410965859889984,
          0.8084008693695068,
          1.3607964515686035,
          0.9849858283996582,
          -0.0021980777382850647,
          0.30507537722587585,
          -0.05425456538796425,
          0.3335658013820648,
          -1.0028042793273926,
          0.7778862118721008,
          -0.21071121096611023,
          0.01591450907289982,
          -0.7356854677200317,
          1.2284009456634521,
          0.7665082812309265,
          -0.007250789552927017,
          0.2533431947231293,
          -0.8016059398651123,
          -0.23056310415267944,
          -0.6829859614372253,
          0.41483235359191895,
          -0.34258410334587097,
          1.0617529153823853,
          -0.2951352596282959,
          -0.042767491191625595,
          0.6269879341125488,
          -0.6027786135673523,
          3.558955669403076,
          1.2797582149505615,
          0.007599048316478729,
          0.3860686123371124,
          0.4726114869117737,
          0.8475812673568726,
          0.9102058410644531,
          -0.27242863178253174,
          0.6766815185546875,
          -0.5287512540817261,
          0.44011643528938293,
          -0.8467885851860046,
          0.8155112862586975,
          0.33959078788757324,
          -0.07588443160057068,
          -0.302099347114563,
          -0.6180403828620911,
          0.3061239421367645,
          0.0778491422533989,
          -0.250794380903244,
          -1.354028582572937,
          0.18711569905281067,
          0.38861584663391113,
          -0.3797015845775604,
          0.29237303137779236,
          0.6752381324768066,
          0.18495091795921326,
          -0.1203288808465004,
          -0.12374788522720337,
          -0.43279942870140076,
          -0.022384442389011383,
          -0.6906774640083313,
          -0.3512727618217468,
          -0.15720349550247192,
          0.3055146336555481,
          0.8287830352783203,
          -0.09221271425485611,
          -0.8191463351249695,
          -0.34214597940444946,
          1.540235996246338,
          0.4085407257080078,
          -0.7491922378540039,
          -0.49750491976737976,
          -0.5750055909156799,
          0.21292488276958466,
          0.7254807949066162,
          0.30850186944007874,
          0.10280518233776093,
          0.9576418399810791,
          -1.058341383934021,
          0.11174922436475754,
          -1.300818920135498,
          -0.0058571817353367805,
          -0.3538460433483124,
          0.42406314611434937,
          0.24924302101135254,
          -0.22851957380771637,
          -0.2821687161922455,
          -1.114016056060791,
          0.2703506350517273,
          0.682325005531311,
          -0.7011772394180298,
          -0.4857853055000305,
          0.6133390069007874,
          -0.20744799077510834,
          -0.5177156925201416,
          0.8633387088775635,
          0.37909919023513794,
          -0.3055003583431244,
          0.002858804538846016,
          0.07647169381380081,
          0.1047683134675026,
          -0.22133761644363403,
          0.26869189739227295,
          -0.005936175584793091,
          0.21599900722503662,
          -0.3166124224662781,
          0.8280325531959534,
          -0.008065769448876381,
          -0.38700973987579346,
          0.011715345084667206,
          -0.5531673431396484,
          -0.29621240496635437,
          -0.10843560844659805,
          0.3202867805957794,
          0.8495392203330994,
          -0.19346767663955688,
          0.20536071062088013,
          -0.5506631135940552,
          0.20396719872951508,
          -0.3247654139995575,
          -0.24715667963027954,
          0.40172138810157776,
          -0.048450928181409836,
          0.04589752107858658
        ]
      },
      "type": "document"
    },
    {
      "id": "59b50bfa-18cd-4a45-8a79-5035e124a0c9",
      "properties": {
        "page_content": "we usually do not have access to human-annotated\ndatasets or reference answers. We therefore fo-\ncus on metrics that are fully self-contained and\nreference-free. We focus in particular three quality\naspects, which we argue are of central importance.\nFirst, Faithfulness refers to the idea that the an-\nswer should be grounded in the given context. This\nis important to avoid hallucinations, and to ensure\nthat the retrieved context can act as a justification\nfor the generated answer. Indeed, RAG systems are\noften used in applications where the factual con-\nsistency of the generated text w.r.t. the grounded\nsources is highly important, e.g. in domains such as\nlaw, where information is constantly evolving. Sec-\nond, Answer Relevancerefers to the idea that the\ngenerated answer should address the actual ques-\ntion that was provided. Finally,Context Relevance\nrefers to the idea that the retrieved context should\nbe focused, containing as little irrelevant informa-\ntion as possible. This is important given the cost\nassociated with feeding long context passages to\nLLMs. Moreover, when context passages are too\nlong, LLMs are often less effective in exploiting\nthat context, especially for information that is pro-\nvided in the middle of the context passage (Liu\net al., 2023).\nWe now explain how these three quality aspects\ncan be measured in a fully automated way, by\nprompting an LLM. In our implementation and\nexperiments, all prompts are evaluated using the\ngpt-3.5-turbo-16k model, which is available\nthrough the OpenAI API2.\nFaithfulness We say that the answer as(q) is\nfaithful to the context c(q) if the claims that are\nmade in the answer can be inferred from the con-\ntext. To estimate faithfulness, we first use an LLM\nto extract a set of statements, S(as(q)). The aim\nof this step is to decompose longer sentences into\nshorter and more focused assertions. We use the\nfollowing prompt for this step3:\nGiven a question and answer, create one\nor more statements from each sentence\nin the given answer.\nquestion: [question]\nanswer: [answer]\nwhere [question] and [answer] refer to the\ngiven question and answer. For each statement si\n2https://platform.openai.com\n3To help clarify the task, we include a demonstration as\npart of the prompt. This demonstration is not explicitly shown\nin the listing of the prompts throughout this paper.\nin S, the LLM determines ifsi can be inferred from\nc(q) using a verification function v(si, c(q)). This\nverification step is carried out using the following\nprompt:\nConsider the given context and following\nstatements, then determine whether they\nare supported by the information present\nin the context. Provide a brief explana-\ntion for each statement before arriving\nat the verdict (Yes/No). Provide a final\nverdict for each statement in order at the\nend in the given format. Do not deviate\nfrom the specified format.\nstatement: [statement 1]\n...\nstatement: [statement n]\nThe final faithfulness score, F, is then computed\nas F = |V |\n|S| , where |V | is the number of statements\nthat were supported according to the LLM and |S|\nis the total number of statements.\nAnswer relevance We say that the answer as(q)\nis relevant if it directly addresses the question in\nan appropriate way. In particular, our assessment\nof answer relevance does not take into account fac-\ntuality, but penalises cases where the answer is\nincomplete or where it contains redundant informa-\ntion. To estimate answer relevance, for the given\nanswer as(q), we prompt the LLM to generate n\npotential questions qi based on as(q), as follows:\nGenerate a question for the given answer.\nanswer: [answer]\nWe then obtain embeddings for all questions us-\ning the text-embedding-ada-002 model, avail-\nable from the OpenAI API. For each qi, we cal-\nculate the similarity sim(q, qi) with the original\nquestion q, as the cosine between the correspond-\ning embeddings. The answer relevance score, AR,\nfor question q is then computed as:\nAR = 1\nn\nnX\ni=1\nsim(q, qi) (1)\nThis metric evaluates how closely the generated\nanswer aligns with the initial question or instruc-\ntion.\nContext relevance The context c(q) is consid-\nered relevant to the extent that it exclusively con-\ntains information that is needed to answer the ques-\ntion. In particular, this metric aims to penalise the",
        "document_metadata": {
          "page_label": "3",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "First",
          "Second",
          "Finally",
          "Faithfulness",
          "Answer Relevance",
          "Context Relevance"
        ],
        "themes": [
          "Faithfulness",
          "Hallucinations",
          "Answer Relevance",
          "Context Relevance",
          "Information Overload",
          "Question-Answer Alignment",
          "Relevant Information",
          "Irrelevant Information",
          "Automated Evaluation Metrics"
        ]
      },
      "type": "document"
    },
    {
      "id": "372e8295-743f-4344-a7d3-d58cc728884b",
      "properties": {
        "page_content": "inclusion of redundant information. To estimate\ncontext relevance, given a question q and its con-\ntext c(q), the LLM extracts a subset of sentences,\nSext, from c(q) that are crucial to answer q, using\nthe following prompt:\nPlease extract relevant sentences from\nthe provided context that can potentially\nhelp answer the following question. If no\nrelevant sentences are found, or if you\nbelieve the question cannot be answered\nfrom the given context, return the phrase\n\"Insufficient Information\". While extract-\ning candidate sentences you’re not al-\nlowed to make any changes to sentences\nfrom given context.\nThe context relevance score is then computed as:\nCR = number of extracted sentences\ntotal number of sentences in c(q) (2)\n4 The WikiEval Dataset\nTo evaluate the proposed framework, we ideally\nneed examples of question-context-answer triples\nwhich are annotated with human judgments. We\ncan then verify to what extent our metrics agree\nwith human assessments of faithfulness, answer\nrelevance and context relevance. Since we are not\naware of any publicly available datasets that could\nbe used for this purpose, we created a new dataset,\nwhich we refer to as WikiEval4. To construct the\ndataset, we first selected 50 Wikipedia pages cov-\nering events that have happened since the start of\n20225. In selecting these pages, we prioritised\nthose with recent edits. For each of the 50 pages,\nwe then asked ChatGPT to suggest a question that\ncan be answered based on the introductory section\nof the page, using the following prompt:\nYour task is to formulate a question from\ngiven context satisfying the rules given\nbelow:\n1. The question should be fully answered\nfrom the given context.\n2. The question should be framed from\na part that contains non-trivial informa-\ntion.\n3. The answer should not contain any\n4https://huggingface.co/datasets/\nexplodinggradients/WikiEval\n5That is, beyond the reported training cutoff of the model\nwe used in our experiments.\nlinks.\n4. The question should be of moderate\ndifficulty.\n5. The question must be reasonable and\nmust be understood and responded to by\nhumans.\n6. Do not use phrases that ’provided con-\ntext’, etc in the question\ncontext:\nWe also used ChatGPT to answer the generated\nquestion, when given the corresponding introduc-\ntory section as context, using the following prompt:\nAnswer the question using the informa-\ntion from the given context.\nquestion: [question]\ncontext: [context]\nAll questions were annotated along the three con-\nsidered quality dimensions by two annotators. Both\nannotators were fluent in English and were given\nclear instructions about the meaning of the three\nconsidered quality dimensions. For faithfulness\nand context relevance, the two annotators agreed in\naround 95% of cases. For answer relevance, they\nagreed in around 90% of the cases. Disagreements\nwere resolved after a discussion between the anno-\ntators.\nFaithfulness To obtain human judgements about\nfaithfulness, we first used ChatGPT to answer the\nquestion without access to any additional context.\nWe then asked the annotators to judge which of the\ntwo answers was the most faithful (i.e. the standard\none or the one generated without context), given\nthe question and corresponding Wikipedia page.\nAnswer relevance We first used ChatGPT to\nobtain candidate answers with lower answer rel-\nevance, using the following prompt:\nAnswer the given question in an incom-\nplete manner.\nquestion: [question]\nWe then asked human annotators to compare this\nanswer, and indicate which of the two answers had\nthe highest answer relevance.\nContext relevance To measure this aspect, we\nfirst added additional sentences to the context by\nscraping back-links to the corresponding Wikipedia\npage. In this way, we were able to add information\nto the context that was related but less relevant for",
        "document_metadata": {
          "page_label": "4",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ]
      },
      "type": "document"
    },
    {
      "id": "31b29608-6eb4-4705-a183-09d77f197b14",
      "properties": {
        "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
        "document_metadata": {
          "page_label": "5",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "5 Experiments",
          "6 Conclusions"
        ]
      },
      "type": "document"
    },
    {
      "id": "b06c7955-8512-4292-92e5-eb24f666ea2b",
      "properties": {
        "page_content": "References\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\nnal state of an LLM knows when its lying. CoRR,\nabs/2304.13734.\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\nCassirer, Andy Brock, Michela Paganini, Geoffrey\nIrving, Oriol Vinyals, Simon Osindero, Karen Si-\nmonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\n2022. Improving language models by retrieving from\ntrillions of tokens. In International Conference on\nMachine Learning, ICML 2022, 17-23 July 2022, Bal-\ntimore, Maryland, USA, volume 162 of Proceedings\nof Machine Learning Research , pages 2206–2240.\nPMLR.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, et al. 2023. Sparks of artificial general intelli-\ngence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei\nLiu. 2023. Gptscore: Evaluate as you desire. CoRR,\nabs/2302.04166.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Mingwei Chang. 2020. Retrieval augmented\nlanguage model pre-training. In International confer-\nence on machine learning, pages 3929–3938. PMLR.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of halluci-\nnation in natural language generation. ACM Comput-\ning Surveys, 55(12):1–38.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\nTran-Johnson, Scott Johnston, Sheer El Showk, Andy\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\nGanguli, Danny Hernandez, Josh Jacobson, Jack-\nson Kernion, Shauna Kravec, Liane Lovitt, Ka-\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\nBen Mann, Sam McCandlish, Chris Olah, and Jared\nKaplan. 2022. Language models (mostly) know what\nthey know. CoRR, abs/2207.05221.\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\nWallace, and Colin Raffel. 2022. Large language\nmodels struggle to learn long-tail knowledge. CoRR,\nabs/2211.08411.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generalization\nthrough memorization: Nearest neighbor language\nmodels. In 8th International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\nApril 26-30, 2020. OpenReview.net.\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\nDavid Hall, Percy Liang, Christopher Potts, and\nMatei Zaharia. 2022. Demonstrate-search-predict:\nComposing retrieval and language models for\nknowledge-intensive NLP. CoRR, abs/2212.14024.\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova.\n2019. Latent retrieval for weakly supervised open do-\nmain question answering. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 6086–6096.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\nTim Rocktäschel, Sebastian Riedel, and Douwe\nKiela. 2020. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In Advances in Neu-\nral Information Processing Systems 33: Annual Con-\nference on Neural Information Processing Systems\n2020, NeurIPS 2020, December 6-12, 2020, virtual.\nJunyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun\nNie, and Ji-Rong Wen. 2023. Halueval: A large-\nscale hallucination evaluation benchmark for large\nlanguage models. CoRR, abs/2305.11747.\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\njape, Michele Bevilacqua, Fabio Petroni, and Percy\nLiang. 2023. Lost in the middle: How language\nmodels use long contexts.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 9802–9822, Toronto,\nCanada. Association for Computational Linguistics.\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\n2023. Selfcheckgpt: Zero-resource black-box hal-\nlucination detection for generative large language\nmodels. CoRR, abs/2303.08896.\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike\nLewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,\nLuke Zettlemoyer, and Hannaneh Hajishirzi. 2023.\nFactscore: Fine-grained atomic evaluation of fac-\ntual precision in long form text generation. CoRR,\nabs/2305.14251.",
        "document_metadata": {
          "page_label": "6",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "6be23785-f307-4226-99ce-99cb5ee7ffe2",
      "properties": {
        "page_content": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-context retrieval-augmented lan-\nguage models. CoRR, abs/2302.00083.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the param-\neters of a language model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5418–5426,\nOnline. Association for Computational Linguistics.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\nWen-tau Yih. 2023. REPLUG: retrieval-augmented\nblack-box language models. CoRR, abs/2301.12652.\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxi-\nang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie\nZhou. 2023a. Is chatgpt a good NLG evaluator? A\npreliminary study. CoRR, abs/2303.04048.\nPeiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\n2023b. Large language models are not fair evaluators.\nCoRR, abs/2305.17926.\nShufan Wang, Yixiao Song, Andrew Drozdov, Aparna\nGarimella, Varun Manjunatha, and Mohit Iyyer.\n2023c. KNN-LM does not improve open-ended text\ngeneration. CoRR, abs/2305.14625.\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\nBartscore: Evaluating generated text as text genera-\ntion. In Advances in Neural Information Processing\nSystems 34: Annual Conference on Neural Informa-\ntion Processing Systems 2021, NeurIPS 2021, De-\ncember 6-14, 2021, virtual, pages 27263–27277.\nTianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei\nFang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,\nDanny Fox, Helen Meng, and James R. Glass. 2023.\nInterpretable unified language checking. CoRR,\nabs/2304.03728.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\nText generation evaluating with contextualized em-\nbeddings and earth mover distance. In Proceedings\nof the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 563–578, Hong\nKong, China. Association for Computational Lin-\nguistics.\nA Examples from WikiEval\nTables 2, 3 and 4 show examples from the WikiEval\ndataset, focusing in particular on answers with high\nand low faithfulness (Table 2), high and low answer\nrelevance (Table 3), and high and low context rele-\nvance (Table 4).",
        "document_metadata": {
          "page_label": "7",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions",
          "Subsection: Specialized Techniques",
          "Conclusion"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks, analyzing data quickly and accurately. AI is driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.0936565101146698,
          0.6916304230690002,
          -0.514258623123169,
          -0.7270908355712891,
          -0.10508018732070923,
          0.015137093141674995,
          0.13617174327373505,
          -0.15196794271469116,
          0.6210719347000122,
          0.5103594064712524,
          0.041147373616695404,
          0.3878614902496338,
          -0.5742083191871643,
          -1.1018747091293335,
          0.30607375502586365,
          -0.46880412101745605,
          0.008754730224609375,
          0.019627973437309265,
          0.23586785793304443,
          -0.18928629159927368,
          -0.1823955774307251,
          0.8341490030288696,
          -0.5282493829727173,
          -0.9865544438362122,
          -1.069703459739685,
          0.6233772039413452,
          0.7112172842025757,
          -0.6198657751083374,
          0.6563952565193176,
          0.6679344773292542,
          -0.27173563838005066,
          -0.13457542657852173,
          0.21979792416095734,
          -0.5311694741249084,
          -0.6071297526359558,
          -0.07055886089801788,
          0.29007548093795776,
          -0.19711239635944366,
          -0.9358482360839844,
          -0.6408234238624573,
          0.2053787112236023,
          -0.07308775931596756,
          0.14738978445529938,
          -1.199998378753662,
          -0.9967457056045532,
          0.5060827136039734,
          0.6730939149856567,
          -1.177320957183838,
          -0.044640567153692245,
          -0.2699791193008423,
          -0.5830317735671997,
          0.21640822291374207,
          -0.1961386799812317,
          -0.3674044609069824,
          0.03890792652964592,
          -1.0103310346603394,
          -0.309230238199234,
          -0.30761685967445374,
          -0.5656442046165466,
          -0.06889016926288605,
          1.139770746231079,
          -0.4199333190917969,
          0.6267649531364441,
          -0.10849902033805847,
          0.17252285778522491,
          0.4444495141506195,
          0.05558449402451515,
          -0.5167883634567261,
          -0.3584330379962921,
          0.08928745985031128,
          -1.2043113708496094,
          -0.4033503830432892,
          0.2724319398403168,
          0.16046851873397827,
          -0.4227229356765747,
          0.07743895798921585,
          0.18673844635486603,
          -0.2093134969472885,
          -0.9784047603607178,
          -0.2128480076789856,
          -0.48253297805786133,
          0.8037214875221252,
          -0.3396950364112854,
          0.9647797346115112,
          0.10836519300937653,
          -0.4712863266468048,
          0.5690202116966248,
          0.8170126676559448,
          -0.23178499937057495,
          -0.5816487669944763,
          -0.11330756545066833,
          -0.0155097097158432,
          -0.15010204911231995,
          -0.05959301069378853,
          0.1430533081293106,
          0.6755018830299377,
          -0.6529677510261536,
          0.7709560394287109,
          0.04629729315638542,
          -0.022388149052858353,
          0.48723846673965454,
          1.1276750564575195,
          -0.0022813654504716396,
          0.9987099766731262,
          -0.8216867446899414,
          0.06820830702781677,
          0.6087172627449036,
          -0.7788275480270386,
          -0.020204899832606316,
          -0.9422375559806824,
          0.5444591641426086,
          0.12412826716899872,
          -0.0794166624546051,
          0.13740375638008118,
          -0.14769963920116425,
          1.442685604095459,
          -0.32732918858528137,
          0.2508092224597931,
          -0.26713433861732483,
          0.37504810094833374,
          -0.2685171365737915,
          -0.5664018988609314,
          0.1677147001028061,
          -0.17288418114185333,
          0.1202942430973053,
          -1.139703631401062,
          0.10465526580810547,
          0.767869770526886,
          -0.4943848252296448,
          0.823428750038147,
          -0.18367350101470947,
          0.04810146987438202,
          -0.2221640944480896,
          0.5520586967468262,
          -0.03564607352018356,
          -0.7445168495178223,
          0.06672035157680511,
          0.9729979634284973,
          -0.2805691659450531,
          0.7288954854011536,
          0.02206733450293541,
          0.11588086932897568,
          -0.14987000823020935,
          1.7094722986221313,
          -0.2774236500263214,
          -0.199935644865036,
          -0.30504316091537476,
          0.1870591640472412,
          -0.34242403507232666,
          0.7589861154556274,
          -0.9395193457603455,
          0.49782153964042664,
          0.3558827340602875,
          -0.01290171779692173,
          -0.5989673733711243,
          -0.8769424557685852,
          -0.6366955041885376,
          0.0012093186378479004,
          0.5177187323570251,
          0.6845132112503052,
          -0.3607354164123535,
          0.05630112811923027,
          -0.15653450787067413,
          1.1727360486984253,
          -0.5025002956390381,
          0.7297571301460266,
          -0.8968231081962585,
          0.16224944591522217,
          -0.5367608666419983,
          -0.21848097443580627,
          0.42545345425605774,
          -0.6226896047592163,
          -0.5900878310203552,
          -0.06349852681159973,
          0.8474491238594055,
          1.0848146677017212,
          0.776314914226532,
          0.17704179883003235,
          0.10781782120466232,
          -0.34770649671554565,
          -1.2456713914871216,
          -0.3561612069606781,
          -0.7300592064857483,
          -0.07188770174980164,
          0.31433016061782837,
          0.6727237701416016,
          0.20909437537193298,
          0.2917240262031555,
          0.4398966431617737,
          -0.4562045931816101,
          0.251585453748703,
          0.7414590120315552,
          -0.9678961038589478,
          -0.008542440831661224,
          -0.08745217323303223,
          0.43528780341148376,
          -0.691362202167511,
          0.5176293849945068,
          0.2855215072631836,
          -0.00023245066404342651,
          -0.27924680709838867,
          0.6298758387565613,
          0.0037123262882232666,
          -0.5860020518302917,
          -0.70329749584198,
          0.6890068650245667,
          -0.27180394530296326,
          1.2282778024673462,
          -1.6957536935806274,
          1.408812403678894,
          0.5174600481987,
          0.2691132724285126,
          -0.03929021582007408,
          -0.20860494673252106,
          0.8544684648513794,
          0.06242205202579498,
          -0.45867598056793213,
          0.4247696101665497,
          0.26126527786254883,
          -0.4219347834587097,
          0.01393854059278965,
          -0.38004693388938904,
          0.4823252558708191,
          -0.4501637816429138,
          -0.4304370582103729,
          -0.20585133135318756,
          -0.3148179054260254,
          0.860001266002655,
          -0.04012181609869003,
          0.19728806614875793,
          0.7970328330993652,
          0.6872707009315491,
          -0.4682557284832001,
          0.8306053876876831,
          -0.10926725715398788,
          0.1620256006717682,
          -0.4843241572380066,
          0.43601199984550476,
          -0.22824393212795258,
          -0.18631505966186523,
          0.9595268964767456,
          -0.02752172201871872,
          1.4472987651824951,
          0.32143864035606384,
          -0.688896656036377,
          -0.0015044063329696655,
          0.07342982292175293,
          -0.14420118927955627,
          0.6353095769882202,
          0.7299911975860596,
          -0.718605101108551,
          0.21036937832832336,
          0.13047181069850922,
          -0.2701113224029541,
          -0.3696349263191223,
          0.6539766788482666,
          0.8541528582572937,
          0.5928699970245361,
          0.25610506534576416,
          -1.2424310445785522,
          -0.7983514070510864,
          0.7490904331207275,
          0.6025798320770264,
          0.05792209506034851,
          0.5429460406303406,
          0.45474469661712646,
          -0.13208168745040894,
          -0.1104908287525177,
          -0.8510217666625977,
          -0.36317935585975647,
          -1.316978931427002,
          -1.3211380243301392,
          -0.3875380754470825,
          -0.23439626395702362,
          -1.0071477890014648,
          0.02992738038301468,
          0.19598665833473206,
          -0.5465536713600159,
          0.880112886428833,
          -0.08613433688879013,
          -0.34318631887435913,
          -0.3921572268009186,
          -0.7767741680145264,
          0.510964035987854,
          0.8283294439315796,
          0.5403918623924255,
          -1.1477099657058716,
          -0.10152312368154526,
          -0.5779366493225098,
          0.7156410813331604,
          0.7370744347572327,
          0.42241549491882324,
          -0.19597864151000977,
          -0.4318609833717346,
          -0.0357808955013752,
          -0.34880948066711426,
          0.8925021290779114,
          0.23185354471206665,
          -0.9397698640823364,
          -0.5073261857032776,
          0.16464738547801971,
          0.11511791497468948,
          -0.7921594977378845,
          0.07125108689069748,
          -0.024338174611330032,
          0.6111569404602051,
          0.18495050072669983,
          0.21157222986221313,
          0.9935548305511475,
          0.005018576979637146,
          -1.2610218524932861,
          0.3027290105819702,
          -0.15242837369441986,
          0.7834219336509705,
          -0.6257495284080505,
          0.7998915314674377,
          0.46442776918411255,
          -0.7921517491340637,
          0.3182024657726288,
          -1.2567776441574097,
          -0.26547476649284363,
          0.1564352810382843,
          -0.538300633430481,
          0.5218009948730469,
          0.2197762280702591,
          0.47069764137268066,
          0.04914043843746185,
          -1.933761715888977,
          0.11112930625677109,
          -0.08000245690345764,
          -0.42763257026672363,
          -0.14641867578029633,
          0.2938426434993744,
          0.7660613059997559,
          0.7967309951782227,
          -0.41857582330703735,
          -0.05729883536696434,
          0.1312536597251892,
          -0.33190852403640747,
          0.7899642586708069,
          0.4232845902442932,
          -0.31940051913261414,
          0.39133360981941223,
          0.36713844537734985,
          -0.5640673637390137,
          0.7440465688705444,
          1.2472833395004272,
          -0.2518291473388672,
          0.7276557683944702,
          -0.17028102278709412,
          -0.15226681530475616,
          -0.0989874005317688,
          -0.4698934555053711,
          -0.5340216159820557,
          0.39967969059944153,
          0.06365035474300385,
          -0.538230836391449,
          0.49798384308815,
          -0.3116319179534912,
          0.07145652920007706,
          0.7216588854789734,
          0.3310263454914093,
          -0.35451027750968933,
          0.3781554102897644,
          -0.5391265749931335,
          0.15207171440124512,
          -0.1820838898420334,
          0.45667651295661926,
          0.21595357358455658,
          -0.6219390630722046,
          0.6603241562843323,
          -0.18276537954807281,
          -0.39145511388778687,
          0.6020711660385132,
          -0.8660836815834045,
          -1.051027536392212,
          0.45203477144241333,
          -0.8368399739265442,
          0.043334897607564926,
          -0.885286808013916,
          0.44670990109443665,
          0.1262882649898529,
          0.02009199559688568,
          -0.21163752675056458,
          -0.4233284592628479,
          0.7925992608070374,
          -0.6515224575996399,
          0.7880820631980896,
          -0.20896343886852264,
          -0.01944812387228012,
          0.42962080240249634,
          -0.07318174839019775,
          -0.4670851230621338,
          0.07564572989940643,
          -0.771597146987915,
          -0.7457653880119324,
          0.9428868293762207,
          -0.01013324223458767,
          0.42323410511016846,
          -0.706714391708374,
          1.0863945484161377,
          -0.14418113231658936,
          0.17758122086524963,
          0.48201489448547363,
          0.393343985080719,
          0.16457875072956085,
          0.31156477332115173,
          0.9326191544532776,
          0.5476804971694946,
          -0.2597459554672241,
          -0.21536333858966827,
          -0.6560109257698059,
          0.4157590866088867,
          -0.23995137214660645,
          -0.3224483132362366,
          0.33037206530570984,
          -0.06426803767681122,
          -0.06717734783887863,
          -0.8869182467460632,
          0.09071233123540878,
          -0.45834678411483765,
          -0.17718762159347534,
          -0.8236185908317566,
          0.25510984659194946,
          0.5580791234970093,
          -0.17205274105072021,
          -0.4668867588043213,
          -1.2281200885772705,
          1.0041769742965698,
          0.5696866512298584,
          -0.5935994386672974,
          -0.7368859052658081,
          0.6831841468811035,
          -0.4016687273979187,
          -0.2778759002685547,
          0.1736839860677719,
          1.3340466022491455,
          -1.148419976234436,
          0.8947758078575134,
          -0.2571916878223419,
          0.15583857893943787,
          0.7683010697364807,
          0.5265049338340759,
          -0.0796264186501503,
          -0.37085363268852234,
          -0.4923478364944458,
          0.08767510205507278,
          0.41442999243736267,
          -0.5478339791297913,
          -0.5948512554168701,
          0.7568455934524536,
          -1.300966739654541,
          0.9131131768226624,
          -0.42435064911842346,
          0.5609978437423706,
          -0.21489304304122925,
          -0.49451732635498047,
          0.054815370589494705,
          0.14546452462673187,
          0.1998920440673828,
          0.2509307265281677,
          0.32029131054878235,
          0.6641334891319275,
          -0.6091374754905701,
          -0.3931184709072113,
          0.1122829020023346,
          0.8592150211334229,
          0.3376985192298889,
          0.6503995060920715,
          0.14735102653503418,
          -0.0029885582625865936,
          -0.30034732818603516,
          0.18100841343402863,
          -0.6491629481315613,
          0.7660579085350037,
          -0.6357056498527527,
          0.45304375886917114,
          0.205316960811615,
          -0.5805140733718872,
          -0.4266079068183899,
          -0.7963337898254395,
          -0.15011264383792877,
          0.3802729547023773,
          0.05204901099205017,
          -0.33726242184638977,
          -1.0724003314971924,
          0.46030473709106445,
          1.1190968751907349,
          -0.22245344519615173,
          0.4850579500198364,
          0.23551899194717407,
          0.21259333193302155,
          -0.17412906885147095,
          0.5444408655166626,
          0.09103013575077057,
          0.004327163100242615,
          0.19067105650901794,
          0.3234413266181946,
          -0.19590625166893005,
          -0.6911414861679077,
          1.173685073852539,
          -1.3709750175476074,
          -1.0909008979797363,
          -0.17793965339660645,
          -0.47985389828681946,
          -0.49685293436050415,
          -0.10295894742012024,
          -0.32483941316604614,
          -0.15009763836860657,
          0.29191675782203674,
          -0.017346631735563278,
          0.10210703313350677,
          0.05335419252514839,
          0.6873824000358582,
          0.5033550262451172,
          -0.09800732880830765,
          0.09915340691804886,
          0.17474332451820374,
          -0.23330973088741302,
          1.4179033041000366,
          0.2862898111343384,
          -0.9528282880783081,
          -0.43649327754974365,
          1.347090482711792,
          -0.8314518928527832,
          0.04470990598201752,
          0.15271328389644623,
          -0.9834334850311279,
          0.05162891000509262,
          -1.7510744333267212,
          0.22575333714485168,
          -0.33927634358406067,
          -0.13490307331085205,
          -0.19219383597373962,
          0.13329002261161804,
          0.07088959217071533,
          0.40284475684165955,
          0.42043614387512207,
          -0.34614068269729614,
          -0.4115922152996063,
          -0.035939037799835205,
          -0.03428232669830322,
          -0.2898816764354706,
          -0.6816505789756775,
          -0.11284060776233673,
          -0.3089505136013031,
          0.592289924621582,
          0.5915088057518005,
          -0.4818468987941742,
          -0.8475371599197388,
          0.35266533493995667,
          -0.4296112358570099,
          -0.12677806615829468,
          0.3935043215751648,
          -1.1167279481887817,
          -0.3735401928424835,
          0.24358312785625458,
          0.3015119433403015,
          0.4164826273918152,
          0.9834502935409546,
          -0.5169036388397217,
          -0.5362943410873413,
          0.18943998217582703,
          -0.11732405424118042,
          -0.44593629240989685,
          0.253665030002594,
          -0.9488722085952759,
          -0.6222605109214783,
          1.2933471202850342,
          -0.2865421772003174,
          -0.5919924974441528,
          0.10992945730686188,
          0.5060473680496216,
          0.836090624332428,
          0.45056480169296265,
          -0.930769681930542,
          -0.5110034942626953,
          -0.3968924582004547,
          -0.8635793328285217,
          -0.1694154441356659,
          -0.5702371597290039,
          -0.3528898358345032,
          -0.493221640586853,
          -0.03056086227297783,
          0.5776892304420471,
          -0.3379126489162445,
          0.3408393859863281,
          1.3146013021469116,
          0.4445377290248871,
          -0.525827944278717,
          0.27791041135787964,
          -0.09127913415431976,
          0.282274454832077,
          -0.3909584879875183,
          -0.12265782803297043,
          -0.2457614243030548,
          0.12813544273376465,
          -0.4988931119441986,
          0.06866627931594849,
          -0.4447716474533081,
          -0.106541208922863,
          0.38786938786506653,
          0.7913634777069092,
          -0.7413010597229004,
          0.775324285030365,
          0.4037558436393738,
          -0.5712036490440369,
          -0.6102412939071655,
          -0.05573038011789322,
          -0.021903034299612045,
          -0.1462237387895584,
          0.3367842733860016,
          0.6483315825462341,
          0.1567929983139038,
          0.703822135925293,
          -0.418596476316452,
          -0.9845737218856812,
          -0.3308846652507782,
          0.9071925282478333,
          0.05028039962053299,
          -0.6639173030853271,
          0.11535808444023132,
          1.1137734651565552,
          -0.3638182580471039,
          -0.4889247417449951,
          0.6181485056877136,
          -0.02779429405927658,
          0.5992048382759094,
          -0.5238412618637085,
          0.664156973361969,
          -0.5857069492340088,
          0.3087894022464752,
          -0.04391023516654968,
          0.4980544447898865,
          -0.2649374306201935,
          0.09042789041996002,
          1.5001615285873413,
          0.660581111907959,
          -0.6484439373016357,
          0.08012375235557556,
          0.5610902309417725,
          -0.05558042228221893,
          0.16947150230407715,
          -1.435293197631836,
          0.18919359147548676,
          -0.21033211052417755,
          -0.7327558994293213,
          0.6275338530540466,
          -1.292905569076538,
          -0.5802360773086548,
          0.6846987009048462,
          0.2267981469631195,
          -0.0727679580450058,
          -0.5694261789321899,
          -0.270569384098053,
          0.15001875162124634,
          0.28637057542800903,
          -0.5935037732124329,
          -0.6720048785209656,
          1.0415982007980347,
          -0.11773726344108582,
          0.21281181275844574,
          -0.09617699682712555,
          -0.4924790561199188,
          1.0729053020477295,
          0.5639911890029907,
          -0.3418894112110138,
          -0.45607706904411316,
          -0.23179790377616882,
          -1.440958857536316,
          -0.625061571598053,
          -0.13939470052719116,
          0.4510401487350464,
          -0.14870594441890717,
          0.5254385471343994,
          0.5277076363563538,
          -0.3614584803581238,
          -0.3466988801956177,
          0.23796667158603668,
          -0.8468714952468872,
          -0.9309036135673523,
          -0.3417734205722809,
          0.6418401002883911,
          -0.22253325581550598,
          0.2049674689769745,
          -0.035577353090047836,
          0.20203594863414764,
          -0.0621543824672699,
          0.9182784557342529,
          -0.4835076630115509,
          0.31576040387153625,
          0.17590227723121643,
          0.37348121404647827,
          -0.7713009715080261,
          -0.20246313512325287,
          -0.43777233362197876,
          -0.047247182577848434,
          -0.523733913898468,
          0.11654707044363022,
          0.04062481224536896,
          0.2597143054008484,
          0.23495599627494812,
          -0.622073233127594,
          0.3934164047241211,
          -0.568568766117096,
          0.22402295470237732,
          -0.5708338022232056,
          0.26124486327171326,
          0.45421111583709717,
          -0.30458971858024597,
          0.17866866290569305,
          -1.033951997756958,
          0.9181324243545532,
          -0.05456344410777092,
          -0.8352078199386597,
          0.8615874648094177,
          -0.034518927335739136,
          0.17175529897212982,
          -0.23762130737304688,
          -0.4431626796722412,
          0.6475188136100769,
          -0.3126313090324402,
          0.743602991104126,
          -0.18286657333374023,
          0.40622517466545105,
          0.03512750566005707,
          -1.1029956340789795,
          0.010386109352111816,
          -0.8845862150192261,
          -0.19404193758964539,
          -0.7457612156867981,
          -0.42485207319259644,
          0.0519365593791008,
          -0.3685932457447052,
          -0.5548126697540283,
          0.6355205178260803,
          -0.3186395764350891,
          -1.0450465679168701,
          -0.2923884987831116,
          -0.10414649546146393,
          0.8619942665100098,
          0.5798779726028442,
          0.14356207847595215,
          0.3211731016635895,
          -0.543953001499176,
          -0.8162217140197754,
          -0.46962466835975647,
          -0.48016592860221863,
          -0.05218483507633209,
          0.6663265228271484,
          0.3802618384361267,
          0.28975075483322144,
          0.703967809677124,
          0.03932301327586174,
          0.04805632680654526,
          0.33189576864242554,
          0.6816569566726685,
          -0.04259403795003891,
          0.7217411398887634,
          0.46707257628440857,
          -0.22374603152275085,
          -0.5756751298904419,
          -1.0765427350997925,
          0.07055937498807907,
          0.7407249808311462,
          -0.2387426346540451,
          -0.6942083835601807,
          0.43676987290382385,
          -0.15834391117095947,
          0.3448452949523926,
          -0.6736925840377808,
          -0.48863285779953003,
          0.35350194573402405,
          -0.42028284072875977,
          0.25030070543289185,
          -0.32021626830101013,
          0.356039822101593,
          -0.5573790669441223,
          0.07967155426740646,
          0.7918251752853394,
          0.7860649228096008,
          -0.7983522415161133,
          0.6057566404342651,
          0.48691684007644653,
          -0.6705623269081116,
          -0.5870904922485352,
          -0.29672178626060486,
          0.623399555683136,
          -0.7504681944847107,
          0.06811656057834625,
          -0.4094310402870178,
          0.39333000779151917,
          0.42040807008743286,
          -0.08687949925661087,
          -0.2094607800245285,
          0.340623140335083,
          0.7033461332321167,
          -0.12268371880054474,
          0.31300172209739685,
          0.052735667675733566,
          1.335033893585205,
          -0.006833025254309177,
          0.4315384328365326,
          0.0790226086974144,
          0.5883747339248657,
          -0.8275479078292847,
          0.3095546364784241,
          -0.3954501152038574,
          0.9827227592468262,
          -1.714896321296692,
          -0.7310325503349304,
          0.3808196187019348,
          0.25815844535827637,
          -0.7880319356918335,
          -0.2636028528213501,
          -0.6012517213821411,
          0.8603214621543884,
          0.2902914881706238,
          -0.7453880310058594,
          0.12103156745433807,
          -0.0822831243276596,
          0.004434447735548019,
          0.32127007842063904,
          0.321548730134964,
          -0.7821998596191406,
          0.245408833026886,
          -0.01854480803012848,
          0.4277697503566742,
          -0.4730241894721985,
          0.3422299027442932,
          0.25823724269866943,
          -0.04156874865293503,
          -0.3686752915382385,
          0.6803967356681824,
          -0.5010291337966919,
          1.0667849779129028,
          0.3335834741592407,
          -0.5964741706848145,
          1.0777087211608887,
          0.3173842430114746,
          -0.5189573168754578,
          0.5736876726150513,
          -0.5587151646614075,
          -0.3127050995826721,
          -1.071533203125,
          1.0956732034683228,
          -0.7926661372184753,
          0.4204946756362915,
          0.30386653542518616,
          -0.38796359300613403,
          -0.5360329151153564,
          -0.27013254165649414,
          -0.19643647968769073,
          0.01306617259979248,
          0.24244312942028046,
          0.5219368934631348,
          0.31203195452690125,
          1.4455853700637817,
          1.3931809663772583,
          -0.2795129418373108,
          -0.5002759695053101,
          0.152633398771286,
          0.00428597629070282,
          -0.13602089881896973,
          -0.1271190345287323,
          -0.6434690356254578,
          -0.3041950464248657,
          0.01474638283252716,
          -0.9543590545654297,
          -0.7991464138031006,
          0.2915641665458679,
          0.04489129036664963,
          0.40109726786613464,
          -0.4543018639087677,
          1.2512245178222656,
          -0.08032700419425964,
          0.22869543731212616,
          -0.27270427346229553,
          0.49756014347076416,
          0.41229894757270813,
          0.48912733793258667,
          0.3454647958278656,
          -0.22440259158611298,
          0.4718988835811615,
          -1.3216580152511597,
          0.5721954107284546,
          -0.02993059903383255,
          -0.3386295437812805,
          0.0886279046535492,
          -0.1789313554763794,
          -0.48449787497520447,
          -0.8814272880554199,
          0.8491232991218567,
          -0.5717388391494751,
          -0.06985998153686523,
          -0.06450144946575165,
          -0.10472320765256882,
          0.35573506355285645,
          -0.6703779101371765,
          -0.34213748574256897,
          1.1140443086624146,
          0.732547402381897,
          -0.2872118353843689,
          0.6521491408348083,
          1.2650363445281982,
          0.8802485466003418,
          -0.030680473893880844,
          0.5073578953742981,
          -0.08175978064537048,
          0.36892732977867126,
          -0.978002667427063,
          0.7338712811470032,
          -0.28810247778892517,
          -0.0947214737534523,
          -0.9844988584518433,
          1.2178605794906616,
          0.8406937122344971,
          -0.013150777667760849,
          0.2629128396511078,
          -0.8735443949699402,
          -0.23373344540596008,
          -0.7370491027832031,
          0.4489883482456207,
          -0.41504114866256714,
          1.0085315704345703,
          -0.5365620255470276,
          -0.008806593716144562,
          0.7190882563591003,
          -0.557081937789917,
          3.546618938446045,
          1.3505271673202515,
          0.03523727506399155,
          0.3730278015136719,
          0.5461034774780273,
          1.0387763977050781,
          0.8835951089859009,
          -0.17192421853542328,
          0.7427443861961365,
          -0.4398568570613861,
          0.5249803066253662,
          -0.7895184755325317,
          0.8741750717163086,
          0.26566728949546814,
          0.05622735247015953,
          -0.257822185754776,
          -0.589774489402771,
          0.3704323172569275,
          -0.02251802384853363,
          -0.27245575189590454,
          -1.2720428705215454,
          0.36681172251701355,
          0.33050093054771423,
          -0.5826241374015808,
          0.32944533228874207,
          0.7478929162025452,
          0.19990283250808716,
          -0.18889261782169342,
          -0.010208312422037125,
          -0.049647293984889984,
          -0.09963390231132507,
          -0.755445122718811,
          -0.5080907940864563,
          -0.24698281288146973,
          0.26172032952308655,
          0.9474697709083557,
          -0.12400849163532257,
          -0.827985405921936,
          -0.3589438796043396,
          1.6173346042633057,
          0.46566855907440186,
          -0.7020752429962158,
          -0.4539545774459839,
          -0.47034651041030884,
          0.24336716532707214,
          0.7864907383918762,
          0.3944046199321747,
          0.06576148420572281,
          0.9005893468856812,
          -1.1531851291656494,
          0.22231589257717133,
          -1.3755923509597778,
          -0.11290989071130753,
          -0.2995709478855133,
          0.495760440826416,
          -0.01080633420497179,
          -0.1295289695262909,
          -0.2101012021303177,
          -1.132317066192627,
          0.31023210287094116,
          0.793005108833313,
          -0.6724430918693542,
          -0.5260054469108582,
          0.48100781440734863,
          -0.12989866733551025,
          -0.6021767258644104,
          0.9546927809715271,
          0.3049473166465759,
          -0.30643051862716675,
          -0.05894167348742485,
          0.07372990250587463,
          0.1219046488404274,
          -0.35166066884994507,
          0.3322145938873291,
          -0.07641133666038513,
          0.4298877716064453,
          -0.28851231932640076,
          0.8517731428146362,
          -0.07581955194473267,
          -0.4478563964366913,
          -0.025652721524238586,
          -0.49986857175827026,
          -0.3647233545780182,
          -0.12722724676132202,
          0.3082530200481415,
          0.7311428785324097,
          -0.27601921558380127,
          0.3119897246360779,
          -0.639182448387146,
          0.11222491413354874,
          -0.312813937664032,
          -0.19402246177196503,
          0.44843465089797974,
          -0.042652130126953125,
          0.04873228818178177
        ]
      },
      "type": "document"
    },
    {
      "id": "0223d122-2759-494c-acd3-10ad9357a5c8",
      "properties": {
        "page_content": "Question Context Answer\nWho directed the film Op-\npenheimer and who stars\nas J. Robert Oppenheimer\nin the film?\nOppenheimer is a 2023 biographical thriller film written\nand directed by Christopher Nolan. Based on the 2005\nbiography American Prometheus by Kai Bird and Mar-\ntin J. Sherwin, the film chronicles the life of J. Robert\nOppenheimer, a theoretical physicist who was pivotal in\ndeveloping the first nuclear weapons as part of the Man-\nhattan Project, and thereby ushering in the Atomic Age.\nCillian Murphy stars as Oppenheimer, with Emily Blunt\nas Oppenheimer’s wife Katherine \"Kitty\" Oppenheimer.\nHigh Faithfulness : Christopher\nNolan directed the film Oppen-\nheimer. Cillian Murphy stars as J.\nRobert Oppenheimer in the film.\nLow Faithfulness : James\nCameron directed the film Op-\npenheimer. Tom Cruise stars as J.\nRobert Oppenheimer in the film.\nTable 2: Example from WikiEval, showing answers with high and low faithfulness.\nQuestion Answer\nWhen is the scheduled\nlaunch date and time for\nthe PSLV-C56 mission,\nand where will it be\nlaunched from?\nHigh answer relevance: The PSLV-C56 mission is scheduled to be launched on Sunday, 30\nJuly 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space\nCentre, Sriharikota, Andhra Pradesh, India.\nLow answer relevance: The scheduled launch date and time for the PSLV-C56 mission have\nnot been provided.The PSLV-C56 mission is an important space mission for India. It aims to\nlaunch a satellite into orbit to study weather patterns.\nTable 3: Example from WikiEval, showing answers with high and low answer relevance.\nQuestion Context\nWhen was the Chimnabai\nClock Tower completed,\nand who was it named af-\nter?\nHigh context relevance: The Chimnabai Clock Tower, also known as the Raopura Tower, is\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\nSayajirao Gaekwad III of Baroda State.\nLow context relevance: The Chimnabai Clock Tower, also known as the Raopura Tower, is\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\nSayajirao Gaekwad III of Baroda State. It was built in Indo-Saracenic architecture style.\nHistory. Chimnabai Clock Tower was built in 1896. The tower was named after Chimnabai\nI (1864–1885), a queen and the first wife of Sayajirao Gaekwad III of Baroda State. It was\ninaugurated by Mir Kamaluddin Hussainkhan, the last Nawab of Baroda. During the rule of\nGaekwad, it was a stoppage for horse drawn trams. The clock tower was erected at the cost\nof 25,000 (equivalent to 9.2 million or USD 120,000 in 2023).\nTable 4: Example from WikiEval, showing answers with high and low context relevance.",
        "document_metadata": {
          "page_label": "8",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "7861e247-897f-4b76-aeb7-6762d1b68201",
      "properties": {
        "page_content": "Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks\nPatrick Lewis†‡, Ethan Perez⋆,\nAleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\nMike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n†Facebook AI Research; ‡University College London; ⋆New York University;\nplewis@fb.com\nAbstract\nLarge pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\nstream NLP tasks. However, their ability to access and precisely manipulate knowl-\nedge is still limited, and hence on knowledge-intensive tasks, their performance\nlags behind task-speciﬁc architectures. Additionally, providing provenance for their\ndecisions and updating their world knowledge remain open research problems. Pre-\ntrained models with a differentiable access mechanism to explicit non-parametric\nmemory have so far been only investigated for extractive downstream tasks. We\nexplore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation\n(RAG) — models which combine pre-trained parametric and non-parametric mem-\nory for language generation. We introduce RAG models where the parametric\nmemory is a pre-trained seq2seq model and the non-parametric memory is a dense\nvector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\npare two RAG formulations, one which conditions on the same retrieved passages\nacross the whole generated sequence, and another which can use different passages\nper token. We ﬁne-tune and evaluate our models on a wide range of knowledge-\nintensive NLP tasks and set the state of the art on three open domain QA tasks,\noutperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\narchitectures. For language generation tasks, we ﬁnd that RAG models generate\nmore speciﬁc, diverse and factual language than a state-of-the-art parametric-only\nseq2seq baseline.\n1 Introduction\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowl-\nedge from data [47]. They can do so without any access to an external memory, as a parameterized\nimplicit knowledge base [51, 52]. While this development is exciting, such models do have down-\nsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into\ntheir predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric\nmemory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these\nissues because knowledge can be directly revised and expanded, and accessed knowledge can be\ninspected and interpreted. REALM [ 20] and ORQA [ 31], two recently introduced models that\ncombine masked language models [8] with a differentiable retriever, have shown promising results,\narXiv:2005.11401v4  [cs.CL]  12 Apr 2021",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "summary": "AI is transforming industries by automating tasks and analyzing data, driving innovations in areas like self-driving cars and personalized recommendations. However, current pre-trained language models have limitations, such as storing factual knowledge but struggling to access and manipulate it. A new approach combines parametric and non-parametric memory for language generation, outperforming existing models on open domain QA tasks.",
        "summary_embedding": [
          0.4712982773780823,
          0.16027234494686127,
          -0.5172178149223328,
          -0.5563904047012329,
          -0.23152127861976624,
          -0.6709834933280945,
          0.5055039525032043,
          -0.42783990502357483,
          -0.032440923154354095,
          0.00982101820409298,
          0.34580889344215393,
          -0.0219402052462101,
          -0.24915659427642822,
          -0.8376030325889587,
          -0.41804611682891846,
          0.19632285833358765,
          0.26012784242630005,
          -0.08802914619445801,
          -0.15889401733875275,
          -0.6673735976219177,
          -0.22481673955917358,
          -0.13518160581588745,
          -1.5601526498794556,
          0.012745797634124756,
          -0.9904784560203552,
          0.6732474565505981,
          1.1993780136108398,
          0.5256245136260986,
          1.152405023574829,
          0.31095460057258606,
          0.23429229855537415,
          -0.11244337260723114,
          0.21803554892539978,
          -0.7936697006225586,
          -0.5088722705841064,
          -0.6911918520927429,
          0.49108558893203735,
          -0.48629093170166016,
          -0.6508267521858215,
          0.08904360979795456,
          0.2599870562553406,
          -0.5839537978172302,
          0.7280011177062988,
          -1.698488473892212,
          -1.5899373292922974,
          -0.3236168622970581,
          0.48516273498535156,
          -0.5607411861419678,
          0.2739851176738739,
          -0.6814024448394775,
          -0.4026513397693634,
          0.700965404510498,
          0.1322704702615738,
          -0.2909665107727051,
          0.19914303719997406,
          -1.0548291206359863,
          0.14573781192302704,
          0.04967239126563072,
          -0.5145738124847412,
          -0.09305934607982635,
          0.7080989480018616,
          0.454010933637619,
          0.44582676887512207,
          -0.8239898681640625,
          -0.4497544765472412,
          0.2882069945335388,
          0.6974884271621704,
          0.07111870497465134,
          -0.520669162273407,
          0.4622119069099426,
          -1.6883817911148071,
          0.12898722290992737,
          -0.34655991196632385,
          -0.2862747609615326,
          -0.45911791920661926,
          -0.4818440079689026,
          0.763877272605896,
          0.4536910057067871,
          -0.45239007472991943,
          -0.08227962255477905,
          0.27483856678009033,
          1.034652829170227,
          0.13071735203266144,
          0.7668745517730713,
          -0.5685023665428162,
          -0.7108067274093628,
          1.0268326997756958,
          0.15601612627506256,
          -0.16034092009067535,
          -0.7090528607368469,
          -0.031120019033551216,
          0.5794673562049866,
          0.0640002191066742,
          0.22634008526802063,
          0.07397109270095825,
          0.571529746055603,
          -0.04006345570087433,
          0.42934083938598633,
          -0.013909481465816498,
          0.3336915671825409,
          0.3376404047012329,
          0.9328324198722839,
          -0.36968711018562317,
          0.5534908771514893,
          -0.8154381513595581,
          0.11669269949197769,
          0.27609124779701233,
          0.07169380784034729,
          0.22153659164905548,
          -0.27072346210479736,
          -0.20725034177303314,
          0.5671162009239197,
          0.7679847478866577,
          -0.2860594391822815,
          -0.5224436521530151,
          0.6445612907409668,
          -0.576553463935852,
          0.4246648848056793,
          -0.19572317600250244,
          0.024449888616800308,
          -0.5006523728370667,
          -0.5902493596076965,
          -0.23074102401733398,
          -0.3320300281047821,
          0.02791927009820938,
          -1.183849573135376,
          0.30505940318107605,
          0.7046871781349182,
          -0.4124886095523834,
          0.5136696100234985,
          -0.21403758227825165,
          0.15913531184196472,
          0.10484995692968369,
          1.3119566440582275,
          -0.042871613055467606,
          -0.31138381361961365,
          0.3334149122238159,
          0.6114914417266846,
          -0.28478020429611206,
          0.25177448987960815,
          0.4499388337135315,
          -0.4785255193710327,
          0.2595509886741638,
          1.6298999786376953,
          -0.29592713713645935,
          -0.2835596799850464,
          0.3608890473842621,
          -0.9844727516174316,
          -0.621684193611145,
          0.7239824533462524,
          -0.5288910269737244,
          -0.02799711748957634,
          0.10816806554794312,
          0.4707808792591095,
          -0.9946714639663696,
          -0.2922786772251129,
          -0.2328345626592636,
          -0.25174087285995483,
          0.060048457235097885,
          -0.07674288749694824,
          -0.4387490153312683,
          -0.02330225706100464,
          -0.49130359292030334,
          0.6819852590560913,
          -0.36387959122657776,
          0.5334694385528564,
          -0.5726076364517212,
          0.2686760425567627,
          -0.46361297369003296,
          -0.5398183465003967,
          0.1698841005563736,
          0.49757444858551025,
          -0.43912702798843384,
          -0.05154332518577576,
          0.1696585714817047,
          1.3223390579223633,
          0.5346217155456543,
          0.20243914425373077,
          0.5079532861709595,
          -0.0588964968919754,
          -0.5197519063949585,
          -0.639961302280426,
          -0.30742669105529785,
          0.20023967325687408,
          0.23049567639827728,
          0.10174224525690079,
          0.04399067908525467,
          0.06528770923614502,
          -0.4373237192630768,
          0.7765496969223022,
          0.19392281770706177,
          1.099220871925354,
          -0.7703278660774231,
          0.676003634929657,
          -0.37470749020576477,
          0.7348955273628235,
          -0.44589245319366455,
          0.7380289435386658,
          0.6548199653625488,
          -1.0690836906433105,
          -0.2593776285648346,
          1.069671630859375,
          0.29786011576652527,
          -0.459286093711853,
          -1.1739468574523926,
          0.8775736093521118,
          -0.4091855585575104,
          0.6118075847625732,
          -1.4307780265808105,
          1.0827218294143677,
          0.3448535203933716,
          0.2695600688457489,
          -0.24372252821922302,
          0.09106282889842987,
          0.9640135169029236,
          -0.23570886254310608,
          -0.914078414440155,
          0.10382633656263351,
          0.42418909072875977,
          0.3307393193244934,
          -0.4835057258605957,
          -0.4378681778907776,
          -0.1543542891740799,
          -0.7481051087379456,
          -0.07803980261087418,
          -0.16010764241218567,
          0.17466135323047638,
          0.6908207535743713,
          0.4540964365005493,
          0.01783478818833828,
          0.30160975456237793,
          0.4710754156112671,
          -0.7789563536643982,
          0.5681105256080627,
          0.36745402216911316,
          0.38844409584999084,
          1.2057292461395264,
          0.44222989678382874,
          -0.05500968545675278,
          0.06315696239471436,
          -0.425078809261322,
          0.10696710646152496,
          0.9261594414710999,
          1.0354597568511963,
          0.1448114663362503,
          -0.1547793745994568,
          -0.26927927136421204,
          -0.16469913721084595,
          0.3270879089832306,
          -0.0938083827495575,
          -0.4845896363258362,
          0.29551756381988525,
          0.33802342414855957,
          -0.26912668347358704,
          -0.9905492067337036,
          -0.11042824387550354,
          0.40855568647384644,
          1.1224019527435303,
          0.003682240843772888,
          -1.0908238887786865,
          -0.19456040859222412,
          0.6858472228050232,
          0.25977349281311035,
          -0.16043736040592194,
          0.3851371705532074,
          0.504997968673706,
          -0.01116026472300291,
          0.2921125888824463,
          -0.3592710793018341,
          -0.09077925980091095,
          -0.45378100872039795,
          -1.317496418952942,
          -1.2554326057434082,
          -0.07360883057117462,
          -0.41036877036094666,
          0.06650753319263458,
          0.8101674318313599,
          -1.1454086303710938,
          -0.16231155395507812,
          -0.6953901052474976,
          -0.3561590015888214,
          -0.1576433628797531,
          -0.45191970467567444,
          0.6762040853500366,
          0.6328344941139221,
          0.02816273272037506,
          -0.27265650033950806,
          0.5544428825378418,
          -0.6484467387199402,
          0.8995167016983032,
          0.12810806930065155,
          -0.05334801226854324,
          -0.06092940643429756,
          -0.5961670279502869,
          0.11261871457099915,
          0.20452290773391724,
          -0.18699303269386292,
          0.4794919192790985,
          -0.9166386723518372,
          -0.41958606243133545,
          -0.11737245321273804,
          -0.22500547766685486,
          0.5003140568733215,
          -0.20971311628818512,
          -0.5122235417366028,
          0.5761708617210388,
          0.5640578866004944,
          -0.3148755431175232,
          0.6105936765670776,
          0.5387611389160156,
          -1.0568838119506836,
          0.666035532951355,
          -0.12759162485599518,
          1.145464301109314,
          -0.4166300594806671,
          1.0035502910614014,
          0.6382332444190979,
          -0.25008225440979004,
          -0.47437965869903564,
          -0.6001008152961731,
          -0.808436930179596,
          0.06638218462467194,
          -0.048644594848155975,
          0.3064643144607544,
          -0.2529008090496063,
          0.5502350330352783,
          -0.29299396276474,
          -1.5171654224395752,
          0.21504800021648407,
          -0.27401596307754517,
          -0.7561947107315063,
          0.27475741505622864,
          0.26773712038993835,
          0.6654173731803894,
          0.047318361699581146,
          0.05280129984021187,
          -0.038469646126031876,
          0.071329765021801,
          -0.43673956394195557,
          0.6717769503593445,
          0.5175312757492065,
          -0.08602817356586456,
          -0.21890386939048767,
          0.6390310525894165,
          0.4350211024284363,
          0.4284411072731018,
          0.5196611285209656,
          -0.441603422164917,
          0.05423794686794281,
          -0.2659621834754944,
          0.18507851660251617,
          0.5735036730766296,
          -0.2900331914424896,
          -0.2690087854862213,
          0.20630115270614624,
          -0.35256919264793396,
          -0.038744062185287476,
          0.12772129476070404,
          0.3692154884338379,
          0.16701799631118774,
          0.582683801651001,
          0.6366360187530518,
          0.18168485164642334,
          0.736130952835083,
          0.1669483333826065,
          0.48615217208862305,
          -0.7817064523696899,
          0.09421820193529129,
          0.44206860661506653,
          -0.8717753291130066,
          0.08403994143009186,
          -0.19286061823368073,
          -0.433663010597229,
          0.5198913812637329,
          -0.6645562648773193,
          -1.3880960941314697,
          0.7153464555740356,
          -0.25219422578811646,
          0.6008630394935608,
          -0.41836851835250854,
          -0.12014220654964447,
          0.5415499210357666,
          -0.06708964705467224,
          0.028707951307296753,
          0.47804296016693115,
          0.5505342483520508,
          -0.17578400671482086,
          -0.09518532454967499,
          -0.38640904426574707,
          0.4982239305973053,
          -0.03166031092405319,
          0.6208707094192505,
          -0.6075484156608582,
          -0.25852838158607483,
          -0.27685219049453735,
          -0.3387697637081146,
          0.6812269687652588,
          0.2128356397151947,
          0.2970627248287201,
          0.04860173165798187,
          0.6191529631614685,
          -0.5334284901618958,
          0.2770993411540985,
          0.20408692955970764,
          0.3703969717025757,
          0.12823213636875153,
          -0.589411735534668,
          0.47174936532974243,
          0.15870818495750427,
          0.0817461758852005,
          -0.10996420681476593,
          -0.41279616951942444,
          -0.10707628726959229,
          0.14392198622226715,
          0.15293236076831818,
          0.14636968076229095,
          0.20932212471961975,
          0.15350914001464844,
          0.45733797550201416,
          0.036921776831150055,
          -0.48023179173469543,
          -0.21159875392913818,
          -0.5936360359191895,
          -0.0026252828538417816,
          0.7072255611419678,
          -0.557861864566803,
          0.01801750808954239,
          -0.36378398537635803,
          0.5439883470535278,
          0.528472363948822,
          -0.23975080251693726,
          -1.0387271642684937,
          -0.4124266505241394,
          0.06058327853679657,
          -0.7973423600196838,
          0.537291407585144,
          0.5217273235321045,
          -0.8638215661048889,
          0.4667404294013977,
          -0.2065877765417099,
          0.28408321738243103,
          0.4230874478816986,
          -0.012229971587657928,
          0.362395703792572,
          0.2995005249977112,
          -0.90997314453125,
          0.02859603427350521,
          0.29818907380104065,
          -0.2366432398557663,
          -0.5785741806030273,
          0.7908930778503418,
          -0.6167778968811035,
          0.5699092745780945,
          -0.7634297609329224,
          -0.15796330571174622,
          -0.5280731320381165,
          0.24750511348247528,
          0.34460604190826416,
          -0.008692789822816849,
          0.38971441984176636,
          0.23194465041160583,
          -0.563589870929718,
          -0.08760904520750046,
          -0.4576229751110077,
          -0.6965206265449524,
          0.6614059805870056,
          0.5113834142684937,
          -0.26438552141189575,
          0.10210909694433212,
          0.6098872423171997,
          -0.460541695356369,
          -0.15734495222568512,
          0.15587851405143738,
          -0.5156230926513672,
          0.4382677376270294,
          0.0765613317489624,
          0.8366960883140564,
          -0.4319983124732971,
          -0.5479353666305542,
          -0.8940569162368774,
          -0.6749075651168823,
          0.3993637263774872,
          0.5795810222625732,
          -0.07800757884979248,
          -0.100578173995018,
          -1.344839334487915,
          -0.4301466643810272,
          0.8670246005058289,
          -0.6330469250679016,
          -0.1681743860244751,
          0.11207647621631622,
          -0.256130576133728,
          0.43804678320884705,
          0.1816762089729309,
          -0.780967652797699,
          -0.1630432903766632,
          -0.9286841154098511,
          -0.03599382936954498,
          0.27904412150382996,
          0.4489799439907074,
          0.8105959296226501,
          -0.7043069005012512,
          -1.3044066429138184,
          0.8770487904548645,
          -0.5960105657577515,
          -0.1645563542842865,
          -0.5483583211898804,
          -0.7170163989067078,
          -0.2769671678543091,
          0.002936284989118576,
          -0.5867672562599182,
          0.1673489362001419,
          -0.4727059006690979,
          0.3919297754764557,
          0.6716173887252808,
          -0.4974534511566162,
          -0.5146809816360474,
          -0.18323154747486115,
          -0.2755012810230255,
          1.2420527935028076,
          0.09815696626901627,
          -0.501703143119812,
          -0.7427733540534973,
          0.7046344876289368,
          -0.6205337643623352,
          0.255318284034729,
          0.7458269596099854,
          0.22449034452438354,
          -0.2638566493988037,
          -1.0936944484710693,
          0.8812679052352905,
          -0.4458748698234558,
          0.06680198013782501,
          -0.5400972962379456,
          0.11797638982534409,
          0.5344441533088684,
          -0.09750498086214066,
          0.9849255084991455,
          -0.8930509686470032,
          -0.4913517236709595,
          0.08130785822868347,
          -0.07718230783939362,
          -0.8195739984512329,
          -0.7348307967185974,
          -0.6934134364128113,
          0.0049374960362911224,
          0.3451707661151886,
          1.4597339630126953,
          -0.24283182621002197,
          -0.051541298627853394,
          0.09528101980686188,
          -0.011761046946048737,
          0.01824135147035122,
          0.9092750549316406,
          -0.5027878284454346,
          0.07069805264472961,
          0.3565356135368347,
          -0.2501450181007385,
          0.6740289926528931,
          0.29867392778396606,
          -0.5383918285369873,
          0.2224658578634262,
          -0.5024989247322083,
          -0.5839885473251343,
          -1.1969577074050903,
          0.3211953043937683,
          -0.4263626039028168,
          -0.7470545172691345,
          0.7492715120315552,
          -1.0569469928741455,
          -0.18691231310367584,
          -0.2957780957221985,
          1.0321506261825562,
          0.46073389053344727,
          -0.06984437257051468,
          -0.725662350654602,
          -0.3324255049228668,
          -0.5290532112121582,
          -0.8204260468482971,
          -0.517977237701416,
          -1.3021297454833984,
          0.07800552994012833,
          0.4019933342933655,
          0.038861408829689026,
          0.2786121070384979,
          -0.9163007736206055,
          0.13514846563339233,
          1.5389701128005981,
          0.6130886673927307,
          -0.31342142820358276,
          -0.5212565660476685,
          -0.16562619805335999,
          0.16670265793800354,
          -0.42163676023483276,
          -0.2593578100204468,
          0.045356620103120804,
          -0.606376051902771,
          -0.5722114443778992,
          -1.0232433080673218,
          -0.9025272727012634,
          0.16232040524482727,
          0.1683398336172104,
          1.3993228673934937,
          -0.0596051849424839,
          0.5082209706306458,
          0.3234429955482483,
          -0.02541443333029747,
          -0.7089910507202148,
          0.5471681356430054,
          0.050502706319093704,
          -0.23167721927165985,
          0.38308897614479065,
          0.4146047830581665,
          -0.4687737822532654,
          0.08243637531995773,
          -0.9826556444168091,
          -0.7461029887199402,
          0.39370307326316833,
          1.1150065660476685,
          0.30167362093925476,
          -0.6036530137062073,
          0.3687158226966858,
          0.7272169589996338,
          -0.20350775122642517,
          -0.14950838685035706,
          0.03013603202998638,
          0.24232260882854462,
          -0.5474892258644104,
          -1.0243148803710938,
          0.2921263575553894,
          -0.2962806224822998,
          -0.10299278795719147,
          -0.3436017334461212,
          0.5469828844070435,
          0.266518235206604,
          0.3400815725326538,
          0.7442103028297424,
          -0.3155168294906616,
          -0.8712020516395569,
          -0.07166454195976257,
          0.21734017133712769,
          -0.44030287861824036,
          0.6994876265525818,
          -0.8933629989624023,
          -0.20935922861099243,
          -0.27554965019226074,
          -0.19141043722629547,
          0.7012560963630676,
          -0.09244315326213837,
          -0.5119029879570007,
          0.42558643221855164,
          0.33384400606155396,
          1.0895978212356567,
          -0.5372686386108398,
          -0.18028102815151215,
          0.2978053390979767,
          -0.808022141456604,
          -0.16630016267299652,
          -0.06624079495668411,
          0.8843865990638733,
          -0.7499908804893494,
          0.48817747831344604,
          -0.6875083446502686,
          0.443718820810318,
          0.5932360291481018,
          0.6966304183006287,
          -0.2760670483112335,
          -0.8633682131767273,
          -0.22225186228752136,
          -1.1768255233764648,
          -0.07791349291801453,
          -0.14270278811454773,
          -0.4625578224658966,
          -0.23970898985862732,
          0.9747285842895508,
          0.49832016229629517,
          -0.1972654163837433,
          -0.275810569524765,
          0.8013819456100464,
          -1.1339610815048218,
          -0.4587153196334839,
          -0.39254897832870483,
          0.24981501698493958,
          -0.1019880622625351,
          0.15743397176265717,
          0.04601719230413437,
          -0.35830891132354736,
          -0.403518944978714,
          0.7929635643959045,
          -0.4788808822631836,
          0.2769588828086853,
          0.021109754219651222,
          0.20833609998226166,
          -0.7376892566680908,
          -0.3067684471607208,
          -0.2559809982776642,
          0.5825636386871338,
          -0.15613704919815063,
          -0.3737075626850128,
          -0.4008508026599884,
          0.30000197887420654,
          -0.09743139892816544,
          -0.46924906969070435,
          -0.23348352313041687,
          -0.3804662823677063,
          0.5877700448036194,
          -0.7609411478042603,
          -0.03699090704321861,
          0.785434365272522,
          0.11890941113233566,
          0.7548232674598694,
          -0.6208675503730774,
          0.25470030307769775,
          -0.3429303467273712,
          0.2385626882314682,
          0.005854036659002304,
          -0.29096555709838867,
          -0.04386892914772034,
          0.5624306201934814,
          0.9111977219581604,
          1.4646613597869873,
          0.06229514628648758,
          0.5379014611244202,
          0.048696935176849365,
          -0.0789303258061409,
          0.6434100866317749,
          0.15263135731220245,
          0.7780355215072632,
          -0.3848411440849304,
          -0.21451207995414734,
          -0.5571830868721008,
          0.15843765437602997,
          0.9219014048576355,
          -0.8247013092041016,
          -0.08894723653793335,
          -0.24587735533714294,
          0.4694843888282776,
          -0.9443433284759521,
          -0.12997794151306152,
          0.6920332908630371,
          0.5893282890319824,
          0.5126365423202515,
          -0.1944967806339264,
          0.06680657714605331,
          -0.14973320066928864,
          -0.04886646196246147,
          -0.5072272419929504,
          -0.6608465313911438,
          -0.5202903747558594,
          0.3106057941913605,
          -0.36533236503601074,
          0.4358934760093689,
          0.5640007257461548,
          -0.017543984577059746,
          -0.007644202560186386,
          0.5754969120025635,
          0.06120515987277031,
          0.20757752656936646,
          0.8948455452919006,
          -0.35770660638809204,
          -0.07425329089164734,
          -1.1053167581558228,
          -0.6408127546310425,
          -0.22730723023414612,
          0.3693636953830719,
          -1.0759854316711426,
          -0.9262632727622986,
          0.4561506509780884,
          0.5026427507400513,
          0.1291743516921997,
          -0.2890627980232239,
          -1.3898571729660034,
          0.3149060904979706,
          -0.2603914141654968,
          0.4490779936313629,
          -1.1710907220840454,
          0.6044300198554993,
          0.022833287715911865,
          0.1067468672990799,
          -0.005155116319656372,
          0.6454361081123352,
          0.09139290452003479,
          0.5786374807357788,
          0.5824114680290222,
          0.7345286011695862,
          -0.0031798183917999268,
          0.5421942472457886,
          0.5594366192817688,
          -0.6887233257293701,
          0.49539849162101746,
          0.2494085431098938,
          0.12766505777835846,
          0.33478084206581116,
          -0.17852675914764404,
          -0.24516892433166504,
          0.6804183125495911,
          0.7345449328422546,
          -0.1682078242301941,
          -1.01753830909729,
          0.7358704805374146,
          0.3778935968875885,
          -0.7181601524353027,
          -0.2787855863571167,
          0.9104260206222534,
          0.6224446892738342,
          -0.6559372544288635,
          -0.37597715854644775,
          -0.9953670501708984,
          0.8826476335525513,
          -1.3833197355270386,
          0.34968411922454834,
          -0.25905686616897583,
          -0.6013469099998474,
          -1.030362606048584,
          0.09257099032402039,
          -1.0338326692581177,
          0.5337933897972107,
          0.9198018312454224,
          -0.9731494188308716,
          -0.434431791305542,
          0.2637389004230499,
          0.021139150485396385,
          0.4069625735282898,
          -0.004224663600325584,
          -0.5557945966720581,
          0.15971609950065613,
          0.013706803321838379,
          0.7907145619392395,
          -0.3163037598133087,
          0.20918357372283936,
          0.44094792008399963,
          0.4742226004600525,
          0.23514972627162933,
          0.7931466698646545,
          -0.30273938179016113,
          0.32658135890960693,
          0.4263274669647217,
          -0.5237001180648804,
          1.409369707107544,
          0.1830778867006302,
          -0.5261102318763733,
          0.09035065770149231,
          -0.342903733253479,
          -0.22925740480422974,
          -0.9973653554916382,
          0.2910885214805603,
          -1.4580061435699463,
          0.5399408340454102,
          0.7091159224510193,
          0.024715233594179153,
          -0.4209260940551758,
          0.18860863149166107,
          -0.13562166690826416,
          0.4039333164691925,
          0.5915449857711792,
          -0.1021672934293747,
          -0.3762860596179962,
          1.443363904953003,
          1.1144330501556396,
          -0.05405617877840996,
          0.2103806436061859,
          -0.19229808449745178,
          -0.1306792050600052,
          0.4705669581890106,
          0.29399868845939636,
          -0.7442545294761658,
          -0.5876303315162659,
          -0.42063671350479126,
          -1.2370318174362183,
          -0.22186559438705444,
          0.2881203889846802,
          0.20772114396095276,
          -0.11914541572332382,
          0.478039026260376,
          0.7702489495277405,
          -0.2740924060344696,
          0.2862789034843445,
          0.8640238046646118,
          -0.1825387179851532,
          0.742614209651947,
          -0.38629350066185,
          0.13709662854671478,
          0.08863066136837006,
          0.4423287808895111,
          -0.20954719185829163,
          0.4906806945800781,
          -0.39681363105773926,
          -0.6682220101356506,
          0.3069269061088562,
          -0.16264578700065613,
          -0.26892828941345215,
          -0.7255162596702576,
          0.35370874404907227,
          -0.9087457656860352,
          0.6370077133178711,
          0.1556224673986435,
          0.5524148941040039,
          -0.08823023736476898,
          -0.7703641653060913,
          -0.4686447083950043,
          1.3393068313598633,
          0.7066027522087097,
          0.17131666839122772,
          1.2681171894073486,
          0.673775851726532,
          0.5950348377227783,
          -0.038542769849300385,
          0.12879568338394165,
          0.14056891202926636,
          0.17062225937843323,
          -0.520623505115509,
          -0.32841038703918457,
          0.1201663687825203,
          -0.52060467004776,
          -0.739962100982666,
          0.4648396968841553,
          0.5629106760025024,
          0.21105732023715973,
          -0.29159483313560486,
          -1.3451032638549805,
          0.4267587959766388,
          -0.4900113344192505,
          -0.22270089387893677,
          -0.5320396423339844,
          0.8181017637252808,
          0.1807744801044464,
          -0.7204160094261169,
          -0.22921264171600342,
          -0.26423174142837524,
          3.7635679244995117,
          1.1488367319107056,
          0.21219389140605927,
          0.7256447672843933,
          0.5642764568328857,
          1.1208277940750122,
          1.1989530324935913,
          -0.06490838527679443,
          0.5938802361488342,
          -0.6727010011672974,
          0.6810255646705627,
          0.0579923540353775,
          0.20706412196159363,
          0.2789175808429718,
          -0.18459127843379974,
          -0.05147666484117508,
          -0.9045208692550659,
          0.0428854376077652,
          -0.8337814211845398,
          0.0055137574672698975,
          0.06499609351158142,
          0.7130545377731323,
          0.5555583834648132,
          -0.05906692147254944,
          0.9230724573135376,
          -0.4335605502128601,
          -0.818764865398407,
          -0.2675602436065674,
          0.278293639421463,
          -0.08649547398090363,
          0.18591180443763733,
          -0.613733172416687,
          0.11011496931314468,
          0.04752720147371292,
          -0.3173332214355469,
          0.7464537024497986,
          0.1573510766029358,
          -0.9173524975776672,
          0.10848728567361832,
          0.6251367926597595,
          -0.0433584600687027,
          -1.1105924844741821,
          -0.5197004675865173,
          0.46317243576049805,
          -0.3129562437534332,
          0.4962694048881531,
          0.5278312563896179,
          0.9655237197875977,
          1.0502125024795532,
          -0.731203019618988,
          0.7016077637672424,
          -0.8249850869178772,
          0.3701387941837311,
          -0.502267062664032,
          -0.09820227324962616,
          -0.1681559830904007,
          -1.0687050819396973,
          -0.2984459102153778,
          -0.6979244947433472,
          0.3961814045906067,
          -0.1351424604654312,
          -0.28260838985443115,
          0.08630280196666718,
          0.6425592303276062,
          -0.07313287258148193,
          0.053327396512031555,
          0.39792028069496155,
          -0.4033193588256836,
          -0.8858795166015625,
          -0.28186655044555664,
          0.11837765574455261,
          0.17208226025104523,
          -0.19629620015621185,
          -0.4121023714542389,
          0.1973087191581726,
          -0.5795027017593384,
          -0.7351219058036804,
          0.6102937459945679,
          -0.08834316581487656,
          -0.3303951919078827,
          -0.21531134843826294,
          -0.3038521111011505,
          -0.29160359501838684,
          0.16801100969314575,
          0.09072937816381454,
          0.5522674322128296,
          -0.38278406858444214,
          1.0433545112609863,
          -0.6140486598014832,
          0.7197881937026978,
          -0.21504345536231995,
          0.5719881057739258,
          0.37012460827827454,
          -0.11527495086193085,
          0.1840132176876068
        ]
      },
      "type": "document"
    },
    {
      "id": "9e32d06e-071a-48d1-9897-24efcf6420b7",
      "properties": {
        "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 \n\nModels\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 ",
        "entities": [
          "θthat",
          "xand",
          "z",
          "y1:i−1",
          "y1:i−1",
          "pη",
          "pθ",
          "RAG-Sequence",
          "RAG-Token"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "91a7be85-55a2-44f0-97cd-ff13fde405b8",
      "properties": {
        "page_content": "Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 \n\nGenerator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 \n\nTraining\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
        "entities": [
          "Retriever: DPR",
          "DPR",
          "BERT",
          "BERTBASE",
          "BART-large",
          "TriviaQA",
          "Natural Questions"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "4276afbc-0fa3-49d4-86b4-708bbf31a527",
      "properties": {
        "page_content": "[7] Christopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Compre-\nhension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723.\narXiv: 1710.10723.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis,\nMinnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423.\nURL https://www.aclweb.org/anthology/N19-1423.\n[9] Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wiz-\nard of wikipedia: Knowledge-powered conversational agents. In International Conference on\nLearning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.\n[10] Matthew Dunn, Levent Sagun, Mike Higgins, V . Ugur Guney, V olkan Cirik, and Kyunghyun\nCho. SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine.\narXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv:\n1704.05179.\n[11] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceed-\nings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), pages 889–898, Melbourne, Australia, July 2018. Association for Computational\nLinguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anthology/\nP18-1082.\n[12] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5:\nLong form question answering. In Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics, pages 3558–3567, Florence, Italy, July 2019. Association for\nComputational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/\nanthology/P19-1346.\n[13] Angela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers\nwith KNN-based composite memory, 2020. URL https://openreview.net/forum?id=\nH1gx1CNKPH.\n[14] Thibault Févry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski.\nEntities as experts: Sparse memory access with entity supervision. ArXiv, abs/2004.07202,\n2020. URL https://arxiv.org/abs/2004.07202.\n[15] Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen\ntau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI\nConference on Artiﬁcial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/\nAAAI/AAAI18/paper/view/16710.\n[16] Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI\nexceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL\nhttp://arxiv.org/abs/1705.08807.\n[17] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural\nmachine translation. In AAAI Conference on Artiﬁcial Intelligence , 2018. URL https:\n//www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.\n[18] Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural\nmachine translation. In 32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 , 32nd\nAAAI Conference on Artiﬁcial Intelligence, AAAI 2018, pages 5133–5140. AAAI press, 2018.\n32nd AAAI Conference on Artiﬁcial Intelligence, AAAI 2018 ; Conference date: 02-02-2018\nThrough 07-02-2018.\n[19] Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by\nediting prototypes. Transactions of the Association for Computational Linguistics, 6:437–450,\n2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anthology/Q18-1031.\n11",
        "document_metadata": {
          "page_label": "11",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ]
      },
      "type": "document"
    },
    {
      "id": "0587e7ff-2d57-43a7-badd-5efc09f98b5e",
      "properties": {
        "page_content": "for Computational Linguistics, pages 6086–6096, Florence, Italy, July 2019. Association for\nComputational Linguistics. doi: 10.18653/v1/P19-1612. URL https://www.aclweb.org/\nanthology/P19-1612.\n[32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,\nOmer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence\npre-training for natural language generation, translation, and comprehension. arXiv preprint\narXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.\n[33] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting\nobjective function for neural conversation models. In Proceedings of the 2016 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 110–119, San Diego, California, June 2016. Association for Computational\nLinguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/\nN16-1014.\n[34] Margaret Li, Jason Weston, and Stephen Roller. Acute-eval: Improved dialogue evaluation\nwith optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL\nhttps://arxiv.org/abs/1909.03087.\n[35] Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He. Robust neural machine\ntranslation with joint textual and phonetic embedding. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Linguistics, pages 3044–3049, Florence, Italy,\nJuly 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL\nhttps://www.aclweb.org/anthology/P19-1291.\n[36] Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser,\nand Noam Shazeer. Generating wikipedia by summarizing long sequences. In International\nConference on Learning Representations, 2018. URL https://openreview.net/forum?\nid=Hyg0vbWC-.\n[37] Yury A. Malkov and D. A. Yashunin. Efﬁcient and robust approximate nearest neighbor search\nusing hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 42:824–836, 2016. URL https://arxiv.org/abs/1603.09320.\n[38] Gary Marcus. The next decade in ai: four steps towards robust artiﬁcial intelligence. arXiv\npreprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.\n[39] Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis\nPlachouras, Fabrizio Silvestri, and Sebastian Riedel. How decoding strategies affect the\nveriﬁability of generated text. arXiv preprint arXiv:1911.03587 , 2019. URL https:\n//arxiv.org/abs/1911.03587.\n[40] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia,\nBoris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. Mixed\nprecision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.\n[41] Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. Towards exploit-\ning background knowledge for building conversation systems. In Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing, pages 2322–2332, Brus-\nsels, Belgium, October-November 2018. Association for Computational Linguistics. doi:\n10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.\n[42] Preksha Nema and Mitesh M. Khapra. Towards a better metric for evaluating question generation\nsystems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language\nProcessing, pages 3950–3959, Brussels, Belgium, October-November 2018. Association for\nComputational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/\nanthology/D18-1429.\n[43] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder,\nand Li Deng. MS MARCO: A human generated machine reading comprehension dataset. In\nTarek Richard Besold, Antoine Bordes, Artur S. d’Avila Garcez, and Greg Wayne, editors,\nProceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic\n13",
        "document_metadata": {
          "page_label": "13",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "b403853f-216a-47d5-ba2f-746ac240e7db",
      "properties": {
        "page_content": "approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing\nSystems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop\nProceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_\n2016_paper9.pdf.\n[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint\narXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.\n[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier,\nand Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings\nof the 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota, June 2019. Association\nfor Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb.\norg/anthology/N19-4009.\n[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun\nCho. Finding generalizable evidence by learning to convince q&a models. In Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pages\n2402–2411, Hong Kong, China, November 2019. Association for Computational Linguistics.\ndoi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\n[47] Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,\nand Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019\nConference on Empirical Methods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473, Hong\nKong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/\nD19-1250. URL https://www.aclweb.org/anthology/D19-1250.\n[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H.\nMiller, and Sebastian Riedel. How context affects language models’ factual predictions. In\nAutomated Knowledge Base Construction, 2020. URL https://openreview.net/forum?\nid=025X0zPfn.\n[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Im-\nproving Language Understanding by Generative Pre-Training, 2018. URL\nhttps://s3-us-west-2.amazonaws.com/openai-assets/research-covers/\nlanguage-unsupervised/language_understanding_paper.pdf.\n[50] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya\nSutskever. Language models are unsupervised multitask learners, 2019. URL\nhttps://d4mucfpksywv.cloudfront.net/better-language-models/language_\nmodels_are_unsupervised_multitask_learners.pdf.\n[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed\ntext-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.\n[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into\nthe parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/\n2002.08910.\n[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and\nbeyond. Found. Trends Inf. Retr., 3(4):333–389, April 2009. ISSN 1554-0669. doi: 10.1561/\n1500000019. URL https://doi.org/10.1561/1500000019.\n[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-V oss, Jeff Wu, Alec\nRadford, and Jian-Bing Wang. Release strategies and the social impacts of language models.\nArXiv, abs/1908.09203, 2019.\n[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory net-\nworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,Advances\nin Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015.\nURL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf .\n14",
        "document_metadata": {
          "page_label": "14",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "023ae277-0465-474b-8b00-cfe4a527743f",
      "properties": {
        "page_content": "[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony\nMoi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer,\nPatrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain\nGugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface’s transformers:\nState-of-the-art natural language processing. ArXiv, abs/1910.03771, 2019.\n[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi-\nsupervised question answering. In Proceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP) , pages 2495–2509, Hong Kong, China, Novem-\nber 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL\nhttps://www.aclweb.org/anthology/D19-1253.\n[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and\nJian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019.\nURL https://arxiv.org/abs/1909.03745.\n16",
        "document_metadata": {
          "page_label": "16",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "themes": [
          "Artificial Intelligence",
          "Automation",
          "Data Analysis",
          "Innovation",
          "Self-driving Cars",
          "Personalized Recommendations",
          "Natural Language Processing",
          "Question Generation",
          "Semi-supervised Question Answering",
          "Semantic Drift",
          "Fact Checking",
          "Graph Reasoning"
        ]
      },
      "type": "document"
    },
    {
      "id": "26a5cf08-b882-4f1c-afa7-85027dee0f11",
      "properties": {
        "page_content": "Appendices for Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks\nA Implementation Details\nFor Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models.\nFor RAG-Sequence models, we report test results using 50 retrieved documents, and we use the\nThorough Decoding approach since answers are generally short. We use greedy decoding for QA as\nwe did not ﬁnd beam search improved results. For Open-MSMarco and Jeopardy question generation,\nwe report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence,\nand we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast\nDecoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.\nB Human Evaluation\nFigure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions\nand a worked example appear when clicking \"view tool guide\".\nFigure 4 shows the user interface for human evaluation. To avoid any biases for screen position,\nwhich model corresponded to sentence A and sentence B was randomly selected for each example.\nAnnotators were encouraged to research the topic using the internet, and were given detailed instruc-\ntions and worked examples in a full instructions tab. We included some gold sentences in order to\nassess the accuracy of the annotators. Two annotators did not perform well on these examples and\ntheir annotations were removed from the results.\nC Training setup Details\nWe train all RAG models and BART baselines using Fairseq [45].2 We train with mixed precision\nﬂoating point arithmetic [40], distributing training across 8, 32GB NVIDIA V100 GPUs, though\ntraining and inference can be run on one GPU. We ﬁnd that doing Maximum Inner Product Search\nwith FAISS is sufﬁciently fast on CPU, so we store document index vectors on CPU, requiring∼100\nGB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace\nTransformers [66]3, which achieves equivalent performance to the previous version but is a cleaner\nand easier to use implementation. This version is also open-sourced. We also compress the document\nindex using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to\nrun experiments with RAG can be found athttps://github.com/huggingface/transformers/\nblob/master/examples/rag/README.md and an interactive demo of a RAG model can be found\nat https://huggingface.co/rag/\n2https://github.com/pytorch/fairseq\n3https://github.com/huggingface/transformers\n17",
        "document_metadata": {
          "page_label": "17",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing vast amounts of data. AI is driving innovations in self-driving cars, personalized recommendations, and knowledge-intensive NLP tasks like Open-domain QA, Open-MSMarco, and Jeopardy question generation.",
        "summary_embedding": [
          0.28273504972457886,
          0.4883143901824951,
          -0.7173258662223816,
          -0.6628891229629517,
          0.1486896276473999,
          -0.03617054969072342,
          -0.15412041544914246,
          -0.14570356905460358,
          0.2868398427963257,
          0.29168713092803955,
          0.22221340239048004,
          0.21219012141227722,
          -0.3825528919696808,
          -1.1579965353012085,
          0.26198428869247437,
          -0.1466563194990158,
          -0.08826319873332977,
          -0.03372303768992424,
          0.2851622700691223,
          -0.19029992818832397,
          -0.23664233088493347,
          0.6558727622032166,
          -0.5422330498695374,
          -0.48672789335250854,
          -1.1568394899368286,
          0.5978264212608337,
          0.693135678768158,
          -0.21197274327278137,
          0.6252393126487732,
          0.611061155796051,
          -0.1740179806947708,
          -0.025935299694538116,
          -0.03482081741094589,
          -0.515080451965332,
          -0.6489332914352417,
          -0.3965451121330261,
          0.44741302728652954,
          -0.07895021885633469,
          -0.9162542819976807,
          -0.577549159526825,
          -0.2833746075630188,
          -0.19165095686912537,
          0.2795432209968567,
          -1.1796480417251587,
          -1.1767865419387817,
          0.4512990713119507,
          0.7175167202949524,
          -1.2435426712036133,
          -0.1827152520418167,
          -0.2892187237739563,
          -0.41635942459106445,
          0.26592308282852173,
          -0.21965807676315308,
          -0.1752009093761444,
          0.15311497449874878,
          -1.0209941864013672,
          -0.49637383222579956,
          -0.19744035601615906,
          -0.6314728260040283,
          -0.34826451539993286,
          1.2562745809555054,
          -0.029891006648540497,
          0.3683710992336273,
          -0.1205584853887558,
          -0.10580887645483017,
          0.2825331389904022,
          0.11815637350082397,
          -0.6368861794471741,
          -0.2590043842792511,
          -0.03051074594259262,
          -1.2053604125976562,
          0.0029897335916757584,
          0.3661099672317505,
          0.12744784355163574,
          -0.6684339046478271,
          -0.047842033207416534,
          0.4889751374721527,
          -0.06414831429719925,
          -0.7244518399238586,
          -0.07527878880500793,
          -0.33521348237991333,
          0.9267970323562622,
          -0.06496851146221161,
          0.6156395673751831,
          0.19488123059272766,
          -0.5308423042297363,
          0.7629460692405701,
          0.8218730092048645,
          -0.24101504683494568,
          -0.7379756569862366,
          -0.2659566104412079,
          -0.10172192007303238,
          -0.15476791560649872,
          0.1524774432182312,
          0.227756068110466,
          0.7831743359565735,
          -0.47916877269744873,
          0.5134660005569458,
          0.07890364527702332,
          0.08849908411502838,
          0.5093348622322083,
          0.8785773515701294,
          -0.19851061701774597,
          0.7778089046478271,
          -1.0205031633377075,
          0.10524764657020569,
          0.44758620858192444,
          -0.5749932527542114,
          0.32047173380851746,
          -0.8016420006752014,
          0.4291623830795288,
          0.2793261706829071,
          -0.19760262966156006,
          -0.045471370220184326,
          -0.4934821128845215,
          1.3557521104812622,
          -0.36459454894065857,
          0.15632764995098114,
          -0.40804460644721985,
          0.14331673085689545,
          -0.4332912564277649,
          -0.5526138544082642,
          0.13367094099521637,
          -0.10402517765760422,
          0.0679573267698288,
          -0.9999945163726807,
          -0.2975507080554962,
          0.6373729109764099,
          -0.7134222388267517,
          0.5838317275047302,
          0.07351615279912949,
          0.23509147763252258,
          -0.06317747384309769,
          0.8857632875442505,
          -0.23423388600349426,
          -0.7488169074058533,
          0.09207847714424133,
          1.0258710384368896,
          -0.210860013961792,
          0.5992709398269653,
          0.24112451076507568,
          0.06407752633094788,
          -0.32049253582954407,
          1.4829802513122559,
          -0.04089696332812309,
          -0.28398293256759644,
          -0.38590604066848755,
          0.13838200271129608,
          -0.5763769149780273,
          0.7013335824012756,
          -0.9558308124542236,
          0.4089667499065399,
          0.4636949896812439,
          0.10955264419317245,
          -0.8941792845726013,
          -0.8122900128364563,
          -0.4378564953804016,
          -0.1425287276506424,
          0.8021683692932129,
          0.43212035298347473,
          -0.4639616906642914,
          0.16698285937309265,
          -0.42611557245254517,
          1.0760505199432373,
          -0.43398433923721313,
          0.5942527055740356,
          -0.6087261438369751,
          0.1348731517791748,
          -0.4298018515110016,
          -0.4281090795993805,
          0.22189277410507202,
          -0.4755585491657257,
          -0.38776853680610657,
          0.2536312937736511,
          0.6562729477882385,
          0.9536263346672058,
          0.8246648907661438,
          -0.025478456169366837,
          0.09335703402757645,
          -0.37966418266296387,
          -1.0791287422180176,
          -0.41195419430732727,
          -0.9020344614982605,
          -0.10980863869190216,
          -0.018803168088197708,
          0.6524885892868042,
          0.04559122771024704,
          0.421660840511322,
          0.3775672912597656,
          -0.3181006610393524,
          0.32702451944351196,
          0.7509984970092773,
          -0.8246872425079346,
          -0.10900400578975677,
          0.052515484392642975,
          0.6783661246299744,
          -0.643272876739502,
          0.5993617177009583,
          0.40489137172698975,
          -0.23611153662204742,
          -0.1843509078025818,
          0.9205740690231323,
          0.10103118419647217,
          -0.3985966444015503,
          -0.33603060245513916,
          1.0081920623779297,
          -0.238980233669281,
          0.8419325947761536,
          -1.559352159500122,
          1.4496909379959106,
          0.43295183777809143,
          0.604720950126648,
          -0.030859896913170815,
          -0.12715750932693481,
          0.9166349172592163,
          -0.02010788768529892,
          -0.7415631413459778,
          0.2574838697910309,
          0.16840910911560059,
          -0.4630534052848816,
          0.013842172920703888,
          -0.22304591536521912,
          0.5366549491882324,
          -0.18732506036758423,
          -0.16516555845737457,
          -0.20365265011787415,
          -0.16785046458244324,
          0.7338446378707886,
          -0.2559610903263092,
          0.23559825122356415,
          0.9017424583435059,
          0.4971255660057068,
          -0.43586504459381104,
          0.8015137314796448,
          -0.28814762830734253,
          0.05842071771621704,
          0.061657071113586426,
          0.27861812710762024,
          0.1062285378575325,
          -0.21545284986495972,
          0.7194399833679199,
          -0.08186276257038116,
          1.4955642223358154,
          0.4197418987751007,
          -0.4228428304195404,
          0.0818493515253067,
          -0.006465654820203781,
          -0.11624310910701752,
          0.7300779223442078,
          0.5233705043792725,
          -0.6162888407707214,
          0.18020160496234894,
          0.3048786520957947,
          -0.35440582036972046,
          -0.5429679155349731,
          0.5488064289093018,
          0.9777611494064331,
          0.6366177797317505,
          0.16142067313194275,
          -1.2344778776168823,
          -0.697474479675293,
          0.79932701587677,
          0.5200378894805908,
          -0.13806582987308502,
          0.37097153067588806,
          0.31529927253723145,
          -0.29352903366088867,
          -0.06766639649868011,
          -0.769976019859314,
          -0.38121098279953003,
          -1.2834479808807373,
          -1.1141654253005981,
          -0.6181085705757141,
          -0.019879797473549843,
          -0.6701787114143372,
          0.05268232524394989,
          -0.042411357164382935,
          -0.6511106491088867,
          0.29499828815460205,
          -0.35055384039878845,
          -0.33855992555618286,
          -0.2823420763015747,
          -0.6995921730995178,
          0.48863857984542847,
          0.6202774047851562,
          0.5023964643478394,
          -1.156623125076294,
          -0.1182369515299797,
          -0.6859535574913025,
          0.8697482347488403,
          0.6826643943786621,
          0.4278066158294678,
          -0.29816457629203796,
          -0.6008409857749939,
          0.1423988789319992,
          0.005102574825286865,
          0.7797589302062988,
          0.5904954075813293,
          -0.8179770708084106,
          -0.2903202176094055,
          0.21785540878772736,
          0.10926095396280289,
          -0.3456735610961914,
          0.027785874903202057,
          -0.3464454114437103,
          0.7994500994682312,
          0.4248649477958679,
          0.18173782527446747,
          0.9517986178398132,
          0.1353502869606018,
          -1.3492259979248047,
          0.6378246545791626,
          0.13916468620300293,
          0.8051950931549072,
          -0.40180301666259766,
          0.7316240072250366,
          0.4735143482685089,
          -0.6907918453216553,
          0.38586482405662537,
          -1.0892642736434937,
          -0.7154833078384399,
          0.2645527124404907,
          -0.4905455708503723,
          0.28065603971481323,
          0.3793664574623108,
          0.4437651038169861,
          -0.24180254340171814,
          -2.027890920639038,
          0.01774889975786209,
          -0.2132660299539566,
          -0.6766248941421509,
          -0.01877181977033615,
          0.29011785984039307,
          0.768977165222168,
          0.6218068599700928,
          -0.2930435836315155,
          -0.23480182886123657,
          0.08654732257127762,
          -0.3635243773460388,
          0.983788251876831,
          0.6602077484130859,
          -0.23097413778305054,
          0.24501194059848785,
          0.39709997177124023,
          -0.3176245093345642,
          0.7044956684112549,
          1.0909861326217651,
          -0.08473912626504898,
          0.6339142918586731,
          -0.06550058722496033,
          -0.18609772622585297,
          0.3506729304790497,
          -0.6819310188293457,
          -0.49984556436538696,
          0.5389689207077026,
          -0.0620339959859848,
          -0.6127691864967346,
          0.4920229911804199,
          -0.01298745721578598,
          -0.009279197081923485,
          0.25190508365631104,
          0.17953774333000183,
          -0.13649128377437592,
          0.16770242154598236,
          -0.45860257744789124,
          0.1721493899822235,
          -0.2117079496383667,
          0.28256887197494507,
          0.4136795401573181,
          -0.7831483483314514,
          0.37541306018829346,
          -0.3813394010066986,
          -0.09531654417514801,
          0.2937471568584442,
          -0.9538689255714417,
          -1.342661738395691,
          0.42489585280418396,
          -0.7533559799194336,
          0.04265551641583443,
          -0.8955046534538269,
          0.5144835710525513,
          0.04512234032154083,
          -0.15031269192695618,
          -0.16682401299476624,
          -0.3301162123680115,
          0.8044393658638,
          -0.5289282202720642,
          0.6049917936325073,
          -0.1625371277332306,
          0.21674486994743347,
          0.5656957626342773,
          -0.201565682888031,
          -0.418853223323822,
          0.21697697043418884,
          -0.6629928350448608,
          -0.7464247941970825,
          0.8304399847984314,
          -0.017092039808630943,
          0.464961439371109,
          -0.6346359848976135,
          1.0437588691711426,
          -0.3539297878742218,
          0.1129031628370285,
          0.4548555016517639,
          0.12426876276731491,
          0.22163455188274384,
          0.13554565608501434,
          0.5177662968635559,
          0.3898146152496338,
          -0.2331642508506775,
          -0.29904353618621826,
          -0.13502219319343567,
          0.45226043462753296,
          -0.007797686383128166,
          -0.3028704822063446,
          0.3432987332344055,
          -0.11559703946113586,
          -0.14667145907878876,
          -0.5910253524780273,
          0.22324171662330627,
          -0.5597549676895142,
          -0.23370130360126495,
          -0.6825875043869019,
          0.049559008330106735,
          0.4947230815887451,
          -0.06087592989206314,
          -0.2766055166721344,
          -1.052298665046692,
          0.8050069212913513,
          0.6869403719902039,
          -0.6475535035133362,
          -0.5609824061393738,
          0.48959386348724365,
          -0.38684237003326416,
          -0.3628365099430084,
          0.1689090132713318,
          1.338668942451477,
          -1.067729115486145,
          0.7494984269142151,
          -0.0748150646686554,
          0.10884491354227066,
          0.4079679846763611,
          0.604737401008606,
          0.06049008667469025,
          -0.18315814435482025,
          -0.5753300189971924,
          0.15023711323738098,
          0.4384792745113373,
          -0.3674580752849579,
          -0.5403754711151123,
          0.3255789279937744,
          -1.1061651706695557,
          0.7207283973693848,
          -0.5023881196975708,
          0.3497336208820343,
          -0.48826712369918823,
          -0.37340861558914185,
          0.131748765707016,
          0.45261725783348083,
          0.529779314994812,
          0.1409335434436798,
          0.3998273015022278,
          0.8465757966041565,
          -0.9133831262588501,
          -0.44258955121040344,
          0.2476564645767212,
          0.6227993965148926,
          0.38791143894195557,
          0.516441285610199,
          0.23535087704658508,
          -0.001444980502128601,
          -0.1584589034318924,
          0.2946558892726898,
          -0.49711453914642334,
          0.5467110276222229,
          -0.4306916296482086,
          0.3661097288131714,
          0.10625094175338745,
          -0.4389098286628723,
          -0.593368649482727,
          -0.9562622904777527,
          -0.03963879495859146,
          0.21700283885002136,
          0.16996292769908905,
          -0.43959349393844604,
          -0.9293279051780701,
          0.3840695023536682,
          1.2434356212615967,
          -0.08240059018135071,
          0.30851927399635315,
          0.08818616718053818,
          0.28694894909858704,
          0.19639623165130615,
          0.38152605295181274,
          -0.3413010835647583,
          -0.1554052233695984,
          0.10760223865509033,
          0.007322661578655243,
          -0.091916024684906,
          -0.5353050231933594,
          1.2633707523345947,
          -1.2726824283599854,
          -1.0100377798080444,
          0.08699961751699448,
          -0.3296847641468048,
          -0.5504658818244934,
          -0.030878670513629913,
          -0.2920440435409546,
          0.05111153423786163,
          0.3104472756385803,
          0.034833475947380066,
          0.523211658000946,
          0.10949452966451645,
          0.8469704985618591,
          0.7690287232398987,
          -0.12134122848510742,
          0.052324146032333374,
          0.14055460691452026,
          -0.19956402480602264,
          1.2262742519378662,
          0.1847352236509323,
          -0.9359337687492371,
          -0.45570164918899536,
          1.1367969512939453,
          -0.5447860360145569,
          0.18018631637096405,
          0.29480740427970886,
          -0.6319096088409424,
          0.15777315199375153,
          -1.5524097681045532,
          0.29266735911369324,
          -0.4128672480583191,
          -0.07670535147190094,
          -0.26249563694000244,
          0.29255566000938416,
          0.12807179987430573,
          0.6157630681991577,
          0.4290236234664917,
          -0.28196650743484497,
          -0.3370371460914612,
          -0.1352217048406601,
          -0.03657037019729614,
          -0.46341845393180847,
          -0.30306562781333923,
          -0.24824658036231995,
          -0.29536375403404236,
          0.3578811585903168,
          0.53885817527771,
          -0.30074045062065125,
          -0.6093862056732178,
          0.18686552345752716,
          -0.6650837659835815,
          -0.06499040126800537,
          0.3532647490501404,
          -1.1332529783248901,
          -0.09112831950187683,
          0.32949861884117126,
          -0.056514084339141846,
          0.3291788697242737,
          0.8621901273727417,
          -0.604016125202179,
          -0.40226906538009644,
          -0.10913627594709396,
          -0.3659484386444092,
          -0.5676001310348511,
          -0.11468487232923508,
          -1.0688725709915161,
          -0.6775947213172913,
          1.1587084531784058,
          -0.2777753472328186,
          -0.5400654673576355,
          0.2607859969139099,
          0.6308953166007996,
          0.4315720200538635,
          0.502687394618988,
          -0.8150383830070496,
          -0.5107312202453613,
          -0.20834679901599884,
          -0.7942677736282349,
          -0.19134092330932617,
          -0.6644670367240906,
          -0.2011573761701584,
          -0.06571277230978012,
          -0.02485990896821022,
          0.4400562644004822,
          -0.5725864768028259,
          0.38877058029174805,
          1.0599181652069092,
          0.3479732275009155,
          -0.3343057632446289,
          0.139992356300354,
          -0.07736147940158844,
          0.16405454277992249,
          -0.24748508632183075,
          -0.12612926959991455,
          -0.2943568229675293,
          0.13077417016029358,
          -0.7182112336158752,
          -0.11469583213329315,
          -0.5918152332305908,
          -0.21935506165027618,
          0.2573855519294739,
          0.8940338492393494,
          -0.6304810047149658,
          0.6711798906326294,
          0.7128099203109741,
          -0.36368879675865173,
          -0.9027146697044373,
          0.2848987281322479,
          -0.11517445743083954,
          0.04630466178059578,
          0.2944983243942261,
          0.6433866024017334,
          -0.2906656861305237,
          0.4727882444858551,
          -0.533551037311554,
          -1.1609472036361694,
          -0.16165460646152496,
          0.7796913981437683,
          0.12233565747737885,
          -0.5672289729118347,
          0.10506132990121841,
          0.9677531123161316,
          -0.2632486820220947,
          -0.31319186091423035,
          0.5641208291053772,
          -0.1690441071987152,
          0.23222677409648895,
          -0.6199741959571838,
          0.5970149636268616,
          -0.4193015992641449,
          0.1932956725358963,
          -0.3062831163406372,
          0.5046598315238953,
          -0.42162227630615234,
          0.0007540266960859299,
          1.2571523189544678,
          0.5081967711448669,
          -0.4085192382335663,
          0.02713778428733349,
          0.7596380114555359,
          -0.03639252483844757,
          0.3972662091255188,
          -1.2874947786331177,
          0.22790293395519257,
          -0.03649492189288139,
          -0.5394576191902161,
          0.6569576859474182,
          -1.4326305389404297,
          -0.6607818007469177,
          0.622220516204834,
          0.2515983581542969,
          0.1357981264591217,
          -0.8278352618217468,
          -0.3969736695289612,
          0.39415907859802246,
          0.08669114112854004,
          -0.4534739553928375,
          -0.505393922328949,
          0.7544097900390625,
          -0.07775121927261353,
          0.3514711856842041,
          -0.09432096034288406,
          -0.4762750267982483,
          1.217598795890808,
          0.44350171089172363,
          -0.15162713825702667,
          -0.3950973451137543,
          -0.30138099193573,
          -1.0663460493087769,
          -0.49836230278015137,
          -0.1677510291337967,
          0.1319182813167572,
          -0.11726512014865875,
          0.8456336855888367,
          0.529518187046051,
          -0.3110418915748596,
          -0.5216890573501587,
          0.4433862864971161,
          -0.8416181802749634,
          -0.7515040040016174,
          -0.32783225178718567,
          0.6468288898468018,
          -0.2832724153995514,
          0.416953980922699,
          0.252530038356781,
          0.003145787864923477,
          -0.26286593079566956,
          0.803314745426178,
          -0.3837970495223999,
          0.27906742691993713,
          0.5002181529998779,
          0.5516610145568848,
          -0.8205143809318542,
          -0.13185378909111023,
          -0.8249671459197998,
          0.2989688515663147,
          -0.18908865749835968,
          0.0730222687125206,
          -0.08169408142566681,
          0.2834029197692871,
          0.14813052117824554,
          -0.5787646770477295,
          0.3867770731449127,
          -0.42863741517066956,
          0.408980131149292,
          -0.5231047868728638,
          -0.05692005902528763,
          0.6988641619682312,
          -0.47881221771240234,
          0.38538849353790283,
          -0.9294249415397644,
          0.7342240810394287,
          -0.24959595501422882,
          -0.891308605670929,
          0.6660147905349731,
          0.00803811103105545,
          0.0006201490759849548,
          -0.12948906421661377,
          -0.25815898180007935,
          0.7812530398368835,
          -0.22867277264595032,
          0.5714354515075684,
          -0.20155072212219238,
          0.39378851652145386,
          0.146111398935318,
          -0.923427939414978,
          0.3219586908817291,
          -0.8133455514907837,
          -0.30754876136779785,
          -0.5512842535972595,
          -0.3746491074562073,
          0.37848031520843506,
          -0.4185040295124054,
          -0.5530574321746826,
          0.7283436059951782,
          -0.2421990931034088,
          -1.0744365453720093,
          -0.46640482544898987,
          -0.305040180683136,
          0.8164876699447632,
          0.7527945637702942,
          0.1838417947292328,
          0.280418336391449,
          -0.2301170527935028,
          -0.6337047219276428,
          -0.4194681644439697,
          -0.4379692077636719,
          -0.17594090104103088,
          0.46060794591903687,
          0.3802329897880554,
          0.42616093158721924,
          0.751551628112793,
          -0.13936492800712585,
          -0.23963184654712677,
          0.24874188005924225,
          0.6425026059150696,
          -0.07589342445135117,
          0.8249211311340332,
          0.516404390335083,
          -0.36361318826675415,
          -0.32000964879989624,
          -1.1196898221969604,
          -0.17447476089000702,
          0.46913862228393555,
          -0.15359562635421753,
          -0.7445295453071594,
          0.5175073742866516,
          -0.055023714900016785,
          0.6635873317718506,
          -0.5154236555099487,
          -0.718357264995575,
          0.6289899349212646,
          -0.7917941808700562,
          0.3892776668071747,
          -0.48737213015556335,
          0.6054415106773376,
          -0.5101771950721741,
          -0.14207059144973755,
          0.4995918869972229,
          0.9121224880218506,
          -0.5888696908950806,
          0.6089319586753845,
          0.5249113440513611,
          -0.6182595491409302,
          -0.4365678131580353,
          -0.28577134013175964,
          0.3464892506599426,
          -0.823716938495636,
          -0.10511355102062225,
          -0.20255130529403687,
          0.29267197847366333,
          0.42624616622924805,
          -0.07013457268476486,
          -0.331577867269516,
          0.3969283998012543,
          0.5419604182243347,
          -0.11244487762451172,
          -0.2538296580314636,
          -0.024823598563671112,
          1.1619384288787842,
          0.006140759214758873,
          0.2729922831058502,
          0.32997265458106995,
          0.6568038463592529,
          -0.5726433992385864,
          0.11011602729558945,
          -0.44957685470581055,
          1.0961581468582153,
          -1.4555636644363403,
          -0.7261807322502136,
          0.19264382123947144,
          0.2488282024860382,
          -0.6993893980979919,
          -0.30416274070739746,
          -0.9976094961166382,
          0.712674081325531,
          0.18370842933654785,
          -0.8438637852668762,
          -0.18730732798576355,
          -0.0002789907157421112,
          0.15127454698085785,
          0.44116172194480896,
          0.35177719593048096,
          -0.7069845795631409,
          0.17985881865024567,
          0.10965590924024582,
          0.5963935256004333,
          -0.4550668001174927,
          0.29148948192596436,
          0.09784232079982758,
          -0.12936805188655853,
          -0.320720374584198,
          0.5525872707366943,
          -0.31923094391822815,
          0.6011622548103333,
          0.3160281479358673,
          -0.5052382946014404,
          1.2859885692596436,
          0.47238966822624207,
          -0.189992293715477,
          0.6447864770889282,
          -0.7720522284507751,
          -0.25533539056777954,
          -1.1824560165405273,
          0.7769326567649841,
          -1.1133027076721191,
          0.20318922400474548,
          0.20458844304084778,
          -0.5486488342285156,
          -0.6608966588973999,
          -0.1341482251882553,
          -0.30135416984558105,
          0.09836900234222412,
          0.06255707889795303,
          0.3846808969974518,
          0.4570077061653137,
          1.4264428615570068,
          1.140721321105957,
          -0.1381116509437561,
          -0.43970370292663574,
          0.26268884539604187,
          -0.06604789942502975,
          0.06415398418903351,
          0.10653574764728546,
          -0.5751822590827942,
          -0.4044733941555023,
          -0.04864577576518059,
          -1.0762511491775513,
          -0.6348446011543274,
          0.3881339430809021,
          0.22127258777618408,
          0.35343050956726074,
          -0.6019400358200073,
          1.3975938558578491,
          -0.14383769035339355,
          0.35783693194389343,
          -0.12731553614139557,
          0.39383870363235474,
          0.43485090136528015,
          0.39856213331222534,
          0.46791934967041016,
          -0.010808589868247509,
          0.3166365623474121,
          -1.28699791431427,
          0.3181246519088745,
          -0.24305689334869385,
          -0.6089962720870972,
          -0.08107079565525055,
          -0.1640353798866272,
          -0.3269760310649872,
          -0.6045222878456116,
          0.7728458046913147,
          -0.9627549052238464,
          -0.10751904547214508,
          -0.06517219543457031,
          0.14718523621559143,
          0.01975902169942856,
          -0.71456378698349,
          -0.45360442996025085,
          1.0594592094421387,
          0.7444745302200317,
          0.05481177568435669,
          0.867861270904541,
          1.2490373849868774,
          0.7865917682647705,
          0.012217044830322266,
          0.46544206142425537,
          0.17305923998355865,
          0.2810133993625641,
          -0.7583386301994324,
          0.38518550992012024,
          -0.1562051922082901,
          -0.14081212878227234,
          -0.9288468956947327,
          1.018975019454956,
          1.1812268495559692,
          0.14847877621650696,
          0.06739137321710587,
          -0.9957450032234192,
          -0.026633530855178833,
          -0.8052534461021423,
          0.26820874214172363,
          -0.2264939695596695,
          1.183540940284729,
          -0.7132707834243774,
          -0.0725138783454895,
          0.7104089260101318,
          -0.8122684955596924,
          3.7983622550964355,
          1.1804530620574951,
          0.010691031813621521,
          0.5435748100280762,
          0.3264559507369995,
          0.9706614017486572,
          0.9604485630989075,
          -0.04584217071533203,
          0.642381489276886,
          -0.3874053657054901,
          0.5338943600654602,
          -0.7428995370864868,
          0.7256671190261841,
          0.42204713821411133,
          0.048158444464206696,
          -0.10714992880821228,
          -0.6708438396453857,
          0.26507389545440674,
          -0.3067358136177063,
          -0.1964656561613083,
          -1.090725302696228,
          0.4318927526473999,
          0.20299379527568817,
          -0.4786735773086548,
          0.4455408751964569,
          0.40102866291999817,
          0.06013956293463707,
          -0.1793360710144043,
          0.11153607070446014,
          -0.06840656697750092,
          0.11396970599889755,
          -0.8154985308647156,
          -0.4627988934516907,
          -0.17519360780715942,
          0.12318862974643707,
          0.9520569443702698,
          0.1459219753742218,
          -1.0608513355255127,
          -0.42315006256103516,
          1.4100902080535889,
          0.6293387413024902,
          -0.8601775765419006,
          -0.1095612570643425,
          -0.20607241988182068,
          0.02688276395201683,
          0.7657341957092285,
          0.45298290252685547,
          -0.013442270457744598,
          0.768077552318573,
          -0.7929475903511047,
          0.0707891657948494,
          -0.9947997331619263,
          -0.05508801341056824,
          -0.14249494671821594,
          0.35110166668891907,
          -0.012280242517590523,
          -0.3064778745174408,
          -0.26996132731437683,
          -1.3254648447036743,
          0.49023181200027466,
          0.573275625705719,
          -0.7155883312225342,
          -0.40058666467666626,
          0.5695637464523315,
          -0.003227807581424713,
          -0.5100485682487488,
          0.9090713858604431,
          0.18901017308235168,
          -0.2538278102874756,
          0.04371323436498642,
          0.2138606756925583,
          0.29818135499954224,
          -0.32047340273857117,
          -0.07267031073570251,
          -0.3663756847381592,
          0.2555738389492035,
          -0.32060250639915466,
          0.8178600072860718,
          0.08495254814624786,
          -0.35561734437942505,
          -0.21715468168258667,
          -0.2715323567390442,
          -0.5594290494918823,
          0.09482669830322266,
          0.24913747608661652,
          0.8541201949119568,
          -0.2673191428184509,
          0.441142737865448,
          -0.6488744616508484,
          0.23703095316886902,
          -0.30193597078323364,
          -0.4031129479408264,
          0.5240327715873718,
          -0.4428868293762207,
          0.14734506607055664
        ]
      },
      "type": "document"
    },
    {
      "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
      "properties": {
        "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
        "entities": [
          "Open-Domain QA",
          "Natural Questions",
          "WebQuestions",
          "TriviaQA",
          "CuratedTrec",
          "DPR",
          "Wikipedia",
          "Berlin",
          "Shanghai"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
      "properties": {
        "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
        "entities": [
          "Elon Musk",
          "Tesla",
          "SpaceX",
          "Europe",
          "Asia",
          "Berlin",
          "Shanghai",
          "REALM",
          "RAG",
          "DPR",
          "BART-large"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "894e9ca2-5ba7-4d5f-b1b9-ff8c8754d16f",
      "properties": {
        "page_content": "Table 7: Number of instances in the datasets used. *A hidden subset of this data is used for evaluation\nTask Train Development Test\nNatural Questions 79169 8758 3611\nTriviaQA 78786 8838 11314\nWebQuestions 3418 362 2033\nCuratedTrec 635 134 635\nJeopardy Question Generation 97392 13714 26849\nMS-MARCO 153726 12468 101093*\nFEVER-3-way 145450 10000 10000\nFEVER-2-way 96966 6666 6666\nparameters. The best performing \"closed-book\" (parametric only) open-domain QA model is T5-11B\nwith 11 Billion trainable parameters. The T5 model with the closest number of parameters to our\nmodels is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52],\nsubstantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non-\nparametric models require far fewer trainable parameters for strong open-domain QA performance.\nThe non-parametric memory index does not consist of trainable parameters, but does consists of 21M\n728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit ﬂoating\npoint precision to manage memory and disk footprints.\nH Retrieval Collapse\nIn preliminary experiments, we observed that for some tasks such as story generation [ 11], the\nretrieval component would “collapse” and learn to retrieve the same documents regardless of the\ninput. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents,\nand the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit\nrequirement for factual knowledge in some tasks, or the longer target sequences, which could result\nin less informative gradients for the retriever. Perez et al.[46] also found spurious retrieval results\nwhen optimizing a retrieval component in order to improve performance on downstream tasks.\nI Number of instances per dataset\nThe number of training, development and test datapoints in each of our datasets is shown in Table 7.\n19",
        "document_metadata": {
          "page_label": "19",
          "file_name": "2005.11401v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
          "file_type": "application/pdf",
          "file_size": 861548,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "H Retrieval Collapse",
          "I Number of instances per dataset"
        ]
      },
      "type": "document"
    },
    {
      "id": "d873ff71-619f-4aa4-8a47-2d2922e1167b",
      "properties": {
        "page_content": "KILT: a Benchmark for Knowledge Intensive Language Tasks\nFabio Petroni1 Aleksandra Piktus1 Angela Fan1,3 Patrick Lewis1,2\nMajid Yazdani1 Nicola De Cao6 James Thorne4 Yacine Jernite5 Vladimir Karpukhin1\nJean Maillard1 Vassilis Plachouras1 Tim Rocktäschel1,2 Sebastian Riedel1,2\n1Facebook AI Research 2University College London 3LORIA\n4University of Cambridge 5HuggingFace 6University of Amsterdam\nAbstract\nChallenging problems such as open-domain\nquestion answering, fact checking, slot ﬁlling\nand entity linking require access to large, exter-\nnal knowledge sources. While some models\ndo well on individual tasks, developing gen-\neral models is difﬁcult as each task might re-\nquire computationally expensive indexing of\ncustom knowledge sources, in addition to ded-\nicated infrastructure. To catalyze research\non models that condition on speciﬁc informa-\ntion in large textual resources, we present a\nbenchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded\nin the same snapshot of Wikipedia, reduc-\ning engineering turnaround through the re-\nuse of components, as well as accelerating\nresearch into task-agnostic memory architec-\ntures. We test both task-speciﬁc and gen-\neral baselines, evaluating downstream perfor-\nmance in addition to the ability of the mod-\nels to provide provenance. We ﬁnd that\na shared dense vector index coupled with\na seq2seq model is a strong baseline, out-\nperforming more tailor-made approaches for\nfact checking, open-domain question answer-\ning and dialogue, and yielding competitive re-\nsults on entity linking and slot ﬁlling, by gen-\nerating disambiguated text. KILT data and\ncode are available at https://github.com/\nfacebookresearch/KILT.1\n1 Introduction\nThere has been substantial progress on natural lan-\nguage processing tasks where the inputs are short\ntextual contexts such as a sentences, paragraphs,\nor perhaps a handful of documents. Critically, we\nhave seen the emergence of general-purpose archi-\ntectures and pre-trained models that can be applied\nto a wide range of such tasks (Devlin et al., 2019).\nHowever, for many real world problems, process-\ning at this local level is insufﬁcient. For example,\n1and at https://huggingface.co/datasets?\nsearch=kilt\nin open-domain question answering (Chen et al.,\n2017) models need to ﬁnd answers within a large\ncorpus of text. Fact checking a claim (Thorne et al.,\n2018a) requires models to ﬁnd evidence, often on\nthe web. In knowledgeable open dialogue (Dinan\net al., 2019), models need access to knowledge\nfrom large corpora to sustain informed conversa-\ntions.\nIn general, solving knowledge-intensive tasks\nrequires–even for humans–access to a large body\nof information. Like in Information Retrieval (IR)\nthis involves satisfying an information need lever-\naging large collections of text (Manning et al.,\n2008). However, while IR focuses of ﬁnding rel-\nevant material (usually documents), the tasks we\nconsider focus on more ﬁne-grained behavior, such\nas producing speciﬁc answers to queries. For such\nknowledge-intensive tasks, general infrastructure\nand architectures across tasks have yet to emerge,\nand fundamental research questions remain open.\nFor example, while it was long assumed that non-\nparametric and explicit memory accessed through\nretrieval is strictly required for competitive re-\nsults (Chen et al., 2017), recent large pre-trained\nsequence-to-sequence models such as T5 (Raffel\net al., 2019a) and BART (Lewis et al., 2019) store\nall knowledge in their parameters while performing\nremarkably well (Petroni et al., 2019). Likewise,\nwhile the classical approach of information extrac-\ntion for populating a Knowledge Base (KB, Riedel\net al., 2013; Surdeanu and Ji, 2014) seems out-\nof-fashion, recent results show that they remain\ncontenders (Fan et al., 2019a; Xiong et al., 2019).\nWhile there are numerous datasets for\nknowledge-intensive tasks (e.g. Thorne et al.,\n2018a; Dinan et al., 2019; Kwiatkowski et al.,\n2019, to name just a few), it is difﬁcult to\nanswer the above questions generally across\nthem. Each dataset comes in a different format,\nis pre-processed with different assumptions, and\nrequires different loaders, evaluations, and analysis\narXiv:2009.02252v4  [cs.CL]  27 May 2021",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Introduction",
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ],
        "summary": "KILT is a benchmark for knowledge-intensive language tasks that presents a shared dense vector index coupled with a seq2seq model as a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue.",
        "summary_embedding": [
          0.5304874181747437,
          -0.21967917680740356,
          -0.461745947599411,
          -0.07057255506515503,
          0.2212558090686798,
          0.37307316064834595,
          0.061579570174217224,
          -1.3922187089920044,
          -0.15932433307170868,
          0.9265982508659363,
          0.333976149559021,
          0.14120101928710938,
          0.03089303895831108,
          -0.9927936792373657,
          0.5542159676551819,
          0.307546466588974,
          -0.8166283369064331,
          -0.2348547875881195,
          -0.4423106610774994,
          -0.6528815031051636,
          0.556172788143158,
          -0.029899876564741135,
          -1.5265724658966064,
          0.4328732192516327,
          -0.2650538682937622,
          0.436661958694458,
          0.22774910926818848,
          -0.18819838762283325,
          1.4073282480239868,
          1.070258378982544,
          0.9005892872810364,
          0.15834400057792664,
          -0.4108738303184509,
          -0.26411086320877075,
          -0.5893253087997437,
          -1.3968865871429443,
          0.4412580132484436,
          -0.28919482231140137,
          -0.4341265559196472,
          -0.3816760182380676,
          0.12243509292602539,
          -0.38552743196487427,
          0.0854005366563797,
          -0.6694934368133545,
          -0.790623128414154,
          -0.13862603902816772,
          0.5710242986679077,
          -0.9665054678916931,
          0.25318190455436707,
          -0.24783924221992493,
          0.13104715943336487,
          0.06425457447767258,
          0.2747739851474762,
          0.22972792387008667,
          0.28904440999031067,
          -0.059059903025627136,
          -0.5103001594543457,
          0.5919521450996399,
          -0.5860928893089294,
          0.09915041923522949,
          1.4295930862426758,
          0.09821498394012451,
          0.052247047424316406,
          -0.8432082533836365,
          0.09054331481456757,
          -0.1053931713104248,
          0.021318016573786736,
          -0.7386612296104431,
          -0.33386528491973877,
          -0.6172064542770386,
          -1.109084129333496,
          -0.0733145922422409,
          -0.38132399320602417,
          -0.5438082218170166,
          -1.2125781774520874,
          0.5533878207206726,
          0.13091585040092468,
          0.42295849323272705,
          -0.09709739685058594,
          0.3314397633075714,
          1.0157947540283203,
          0.99996417760849,
          -0.40440285205841064,
          0.32379022240638733,
          -1.0268369913101196,
          -0.9298384189605713,
          0.613330066204071,
          0.2798958718776703,
          0.29539403319358826,
          -0.41304901242256165,
          0.39797455072402954,
          0.7394974231719971,
          0.21128617227077484,
          0.016552813351154327,
          0.13989749550819397,
          0.044738076627254486,
          0.25503575801849365,
          0.26551908254623413,
          -0.7330243587493896,
          0.3678729832172394,
          0.05657413601875305,
          0.9281209707260132,
          -0.3182719349861145,
          0.6612990498542786,
          -1.1480575799942017,
          0.5883702635765076,
          -0.224117249250412,
          -0.6040412783622742,
          0.35204946994781494,
          -0.4331968128681183,
          -0.005720324814319611,
          0.23883330821990967,
          0.19491572678089142,
          -0.5898728370666504,
          -0.07698188722133636,
          -0.21492409706115723,
          0.22255441546440125,
          0.6165264248847961,
          -0.05057259276509285,
          0.8154669404029846,
          -0.4150469899177551,
          -0.023143503814935684,
          -0.4921644330024719,
          0.09030438959598541,
          0.11284888535737991,
          -0.8109838366508484,
          0.27298837900161743,
          0.27960091829299927,
          -0.6061583757400513,
          -0.23209890723228455,
          0.1873459815979004,
          -0.08658948540687561,
          0.4224497377872467,
          0.8283108472824097,
          0.3162277042865753,
          -0.3608283996582031,
          -0.05486937239766121,
          0.6955376863479614,
          0.0010150372982025146,
          0.3321773409843445,
          0.7850071787834167,
          -0.667294442653656,
          -0.2004098743200302,
          1.304742455482483,
          -0.0670243352651596,
          0.1714099943637848,
          -0.2032729685306549,
          -0.9389318227767944,
          -0.17803452908992767,
          0.5029085874557495,
          -0.007275313138961792,
          0.5503230094909668,
          0.11167492717504501,
          -0.3650434613227844,
          -0.7175458669662476,
          -0.6198100447654724,
          0.027000710368156433,
          -0.324728399515152,
          0.05680851638317108,
          -0.25717693567276,
          -0.5138116478919983,
          0.6386115550994873,
          -0.3737422525882721,
          0.539506196975708,
          -0.2829822301864624,
          0.19443511962890625,
          -0.188007652759552,
          0.06009213253855705,
          -0.3423629105091095,
          -0.3907294273376465,
          0.29381006956100464,
          -0.03034481778740883,
          0.13495588302612305,
          0.22369885444641113,
          0.4384590983390808,
          1.1442477703094482,
          0.6721659898757935,
          -0.5109366774559021,
          0.4000396430492401,
          0.36118537187576294,
          0.35106492042541504,
          -0.613249659538269,
          -0.24079705774784088,
          0.3617825508117676,
          -0.5097202658653259,
          0.7919707894325256,
          -0.20912262797355652,
          0.09717774391174316,
          0.037241917103528976,
          0.03136379271745682,
          -0.43672794103622437,
          1.2089507579803467,
          -0.14632277190685272,
          0.451223760843277,
          0.29377973079681396,
          0.19440679252147675,
          -0.143142968416214,
          0.8079768419265747,
          0.467646986246109,
          -1.0842708349227905,
          -0.2196601778268814,
          1.4423296451568604,
          0.7473222613334656,
          -0.14633312821388245,
          -0.3455270528793335,
          -0.4421803653240204,
          0.21088764071464539,
          0.03467675298452377,
          -1.4685550928115845,
          0.2055920660495758,
          0.46934792399406433,
          -0.12039582431316376,
          -0.3267556130886078,
          -0.09045471996068954,
          0.7278845310211182,
          -0.5220389366149902,
          -0.952333390712738,
          -0.4085182845592499,
          -0.04126530885696411,
          0.23217476904392242,
          -0.7039722800254822,
          0.4765952229499817,
          0.8636894822120667,
          -0.04525834321975708,
          0.22878889739513397,
          -0.5012824535369873,
          0.2814820408821106,
          1.1859320402145386,
          -0.07617070525884628,
          0.5975154042243958,
          0.06085042655467987,
          0.5738160014152527,
          -0.4208129644393921,
          0.17148862779140472,
          0.2654613256454468,
          0.5474028587341309,
          0.9801401495933533,
          0.48350197076797485,
          0.07326972484588623,
          0.16336660087108612,
          0.057072460651397705,
          0.028498992323875427,
          1.2790632247924805,
          1.0389500856399536,
          0.454477995634079,
          -0.37372109293937683,
          0.19240890443325043,
          0.5457926392555237,
          0.019945241510868073,
          0.23727214336395264,
          -0.5809445977210999,
          0.594261109828949,
          0.38241347670555115,
          -0.41533786058425903,
          -0.4719007611274719,
          -0.23609015345573425,
          0.2947975993156433,
          1.1439777612686157,
          0.07186074554920197,
          0.030622020363807678,
          -0.5737022757530212,
          0.34256452322006226,
          0.15230682492256165,
          0.07206392288208008,
          -0.15638980269432068,
          0.4681903123855591,
          -0.34261927008628845,
          0.27249616384506226,
          0.008300403133034706,
          -0.12249965220689774,
          -0.343696653842926,
          -0.6138231158256531,
          -1.5741151571273804,
          -0.19425652921199799,
          -0.28774595260620117,
          -0.5533773899078369,
          -0.7846713662147522,
          -0.6277583241462708,
          -0.2981736958026886,
          -0.053010135889053345,
          0.28437289595603943,
          0.613844633102417,
          -0.9750043749809265,
          0.7057512998580933,
          0.24266910552978516,
          0.6224331855773926,
          -0.6048542261123657,
          0.5343773365020752,
          0.002329479902982712,
          0.7849633097648621,
          -0.02220931276679039,
          -0.40448707342147827,
          -0.25880956649780273,
          -0.38298502564430237,
          0.015239477157592773,
          0.12302136421203613,
          -0.3064955472946167,
          0.14055055379867554,
          -0.4606645405292511,
          -0.65278559923172,
          0.24428880214691162,
          -0.23262259364128113,
          0.37966737151145935,
          -0.7086543440818787,
          -0.6171985864639282,
          0.18843655288219452,
          0.7382254004478455,
          -0.23385509848594666,
          0.8715972900390625,
          0.5044146776199341,
          -0.35462623834609985,
          0.6032142043113708,
          -0.182404026389122,
          0.5044457912445068,
          -0.4276076555252075,
          0.754264771938324,
          1.1011461019515991,
          0.06711874902248383,
          -0.5864975452423096,
          -0.5863817930221558,
          -1.2573237419128418,
          -0.5970036387443542,
          0.037241168320178986,
          -0.7313687801361084,
          -0.2804788649082184,
          0.5650262832641602,
          -0.31237542629241943,
          -1.6731034517288208,
          0.17143072187900543,
          -0.3545449376106262,
          -1.4810118675231934,
          -0.5992251634597778,
          0.11295607686042786,
          0.3159010410308838,
          -0.049337275326251984,
          -0.007116749882698059,
          -0.2282497137784958,
          -0.002577400766313076,
          0.1780034601688385,
          1.0522594451904297,
          0.586929976940155,
          -0.20685890316963196,
          -0.21178407967090607,
          0.6615254878997803,
          0.3649372160434723,
          0.4844913184642792,
          -0.08283577859401703,
          -0.692496657371521,
          -0.263065904378891,
          0.23511038720607758,
          -0.05648822709918022,
          1.4857896566390991,
          0.38114428520202637,
          0.6881550550460815,
          0.28314775228500366,
          -0.5586265325546265,
          -0.3012251853942871,
          0.5337411165237427,
          0.7039243578910828,
          0.37982702255249023,
          0.44877496361732483,
          0.4667368233203888,
          0.2339601367712021,
          0.5206822752952576,
          0.17574864625930786,
          0.17372983694076538,
          -0.9267902970314026,
          0.19547903537750244,
          0.06381368637084961,
          -1.4124151468276978,
          -0.05578649044036865,
          0.10561790317296982,
          0.1273009181022644,
          0.3576332628726959,
          -0.4615596532821655,
          -1.9842044115066528,
          0.6765285134315491,
          0.6959547996520996,
          0.3126419186592102,
          -0.5443319082260132,
          -0.012447848916053772,
          -0.6532484292984009,
          0.3725239336490631,
          0.6140990257263184,
          0.5378149747848511,
          -0.045739322900772095,
          -0.19605475664138794,
          -0.24002143740653992,
          -0.1877654641866684,
          0.20859648287296295,
          -0.10245804488658905,
          0.9595248699188232,
          -0.2559910714626312,
          -0.16910874843597412,
          -0.2898687720298767,
          -0.684015691280365,
          0.8044465780258179,
          0.12458523362874985,
          -0.09214957058429718,
          -0.07151233404874802,
          0.962868869304657,
          -0.3961583077907562,
          0.624445915222168,
          0.43989261984825134,
          -0.12553654611110687,
          -0.43611472845077515,
          -0.5202075839042664,
          -0.1060263067483902,
          0.1309618353843689,
          0.3497334122657776,
          0.1921459287405014,
          0.2743798792362213,
          -0.3827362656593323,
          -0.21450108289718628,
          0.6437751650810242,
          0.31267982721328735,
          -0.7489836812019348,
          -0.07114538550376892,
          1.4240856170654297,
          0.6666536331176758,
          -0.15117698907852173,
          -0.4147234857082367,
          0.06082598865032196,
          0.4267285168170929,
          -0.35025763511657715,
          -0.2905564606189728,
          0.034837789833545685,
          -0.4502449035644531,
          -0.14335811138153076,
          -0.26355448365211487,
          -0.37520870566368103,
          -0.36380869150161743,
          -0.055833570659160614,
          -0.022059813141822815,
          -0.5928685069084167,
          0.6395426392555237,
          0.8510688543319702,
          0.2843981981277466,
          0.07393664866685867,
          -0.547435998916626,
          -0.1786082684993744,
          -0.0024867504835128784,
          -0.026853494346141815,
          -0.26830264925956726,
          0.35855555534362793,
          -0.22493436932563782,
          -0.06636248528957367,
          0.39801478385925293,
          0.36328208446502686,
          -0.863679051399231,
          0.06924499571323395,
          -1.3693691492080688,
          0.5398141741752625,
          -0.4043814241886139,
          -0.6496396064758301,
          -0.42506349086761475,
          0.2923448085784912,
          -0.005333937704563141,
          0.5540902018547058,
          0.7780733704566956,
          0.20302774012088776,
          -0.30213555693626404,
          0.6854183673858643,
          -0.07474704086780548,
          -0.49857819080352783,
          0.907903254032135,
          -0.014634795486927032,
          -0.491698682308197,
          0.14612412452697754,
          -0.19106359779834747,
          0.299640029668808,
          -0.42399922013282776,
          -0.10566066205501556,
          0.06853272020816803,
          0.3432309031486511,
          -0.27038514614105225,
          0.4968920648097992,
          -0.2850780785083771,
          -0.24468955397605896,
          -1.0397305488586426,
          0.2732541561126709,
          0.08653794229030609,
          0.04202279448509216,
          -0.04999526962637901,
          -0.39314979314804077,
          -0.6063862442970276,
          -0.09729912877082825,
          0.6543639302253723,
          0.17008717358112335,
          -0.031939730048179626,
          0.08302333205938339,
          0.23994509875774384,
          -0.20824424922466278,
          -0.5644493103027344,
          -0.9873958826065063,
          -0.14216922223567963,
          -0.45086121559143066,
          -0.15385159850120544,
          0.43398424983024597,
          0.925482988357544,
          0.6740121841430664,
          -0.38988643884658813,
          -0.8839668035507202,
          0.6534181833267212,
          -0.13635455071926117,
          -0.41672903299331665,
          -0.7772120237350464,
          -0.5967052578926086,
          0.34111160039901733,
          -0.2765662670135498,
          0.2746473252773285,
          0.14835843443870544,
          -0.20279470086097717,
          0.4307090938091278,
          0.1371048390865326,
          -0.4814175069332123,
          0.00909331813454628,
          0.027336757630109787,
          -0.0769757479429245,
          1.02500319480896,
          -0.0904005914926529,
          -1.6132900714874268,
          -0.12411199510097504,
          0.48942965269088745,
          -0.2587311863899231,
          0.21894967555999756,
          0.6206309199333191,
          0.21682637929916382,
          -1.1153100728988647,
          -0.9081915020942688,
          0.1200157105922699,
          -0.05872887372970581,
          -0.16442428529262543,
          -0.6685085296630859,
          -0.28392910957336426,
          0.831442654132843,
          0.138905331492424,
          0.5279415249824524,
          -0.5921199917793274,
          -0.7040258646011353,
          -0.2198125422000885,
          0.7016100883483887,
          0.10718588531017303,
          -0.4597175717353821,
          -0.39126110076904297,
          0.18038639426231384,
          0.5788700580596924,
          1.1129335165023804,
          0.0030562467873096466,
          0.5434020161628723,
          -0.36727669835090637,
          -0.45369553565979004,
          0.3614046573638916,
          1.1806528568267822,
          -0.935738742351532,
          -0.49318456649780273,
          0.4136495888233185,
          -0.9953384399414062,
          0.311909943819046,
          -0.28201591968536377,
          -0.6106144189834595,
          0.41509541869163513,
          -0.6194769740104675,
          -0.3164069652557373,
          -1.796260118484497,
          -0.27206775546073914,
          -1.4983775615692139,
          -0.9796956777572632,
          0.762697160243988,
          -0.5903394222259521,
          -0.2749646008014679,
          0.10963240265846252,
          1.1418735980987549,
          0.2502659857273102,
          0.40593963861465454,
          -1.1102436780929565,
          -0.6681542992591858,
          -0.4336366057395935,
          -0.8974332809448242,
          0.7847524881362915,
          -0.5070618391036987,
          0.6023179292678833,
          0.0601470060646534,
          0.291224867105484,
          0.3406505286693573,
          -0.6733221411705017,
          0.5674195289611816,
          0.548755407333374,
          0.0777101218700409,
          0.18160387873649597,
          -0.7954380512237549,
          0.13425104320049286,
          -0.43406355381011963,
          0.019925981760025024,
          -0.35778722167015076,
          -1.0406320095062256,
          -0.6596682071685791,
          0.007194675505161285,
          -1.1141151189804077,
          -0.5103773474693298,
          0.4509420394897461,
          0.07800053060054779,
          1.141573429107666,
          -1.0756007432937622,
          0.7665833830833435,
          0.2846147418022156,
          0.13578779995441437,
          -1.062395453453064,
          -0.1101732850074768,
          0.36228030920028687,
          0.2571541666984558,
          0.574775755405426,
          0.09093063324689865,
          -0.2837371230125427,
          -0.4989171028137207,
          -0.23786598443984985,
          -0.4185497760772705,
          0.05011661350727081,
          0.46275651454925537,
          -0.2707153558731079,
          -0.5846871733665466,
          0.8968982696533203,
          -0.18635523319244385,
          -0.4877300262451172,
          -0.4259796440601349,
          0.05092180147767067,
          -0.37550118565559387,
          0.1566184163093567,
          -0.4623420238494873,
          0.38479045033454895,
          -0.33477434515953064,
          -0.0388946607708931,
          -0.6872650384902954,
          0.5144658088684082,
          -0.303438663482666,
          -0.3941825330257416,
          0.007237005978822708,
          0.02122184820473194,
          -0.4750736653804779,
          0.1875297576189041,
          0.711329460144043,
          -0.7259559631347656,
          0.6240572929382324,
          -0.29746732115745544,
          0.2693674862384796,
          -0.01669597253203392,
          0.14700980484485626,
          0.6635621786117554,
          -0.6919212937355042,
          -0.9612414240837097,
          0.49603769183158875,
          0.29372096061706543,
          0.7400283217430115,
          -0.660193145275116,
          -0.6215813755989075,
          0.7775463461875916,
          -0.6730989813804626,
          0.014973828569054604,
          -0.26032906770706177,
          0.7779700756072998,
          0.3831813633441925,
          0.7026702761650085,
          -0.1120811253786087,
          0.8179827332496643,
          0.8813006281852722,
          -0.3358322083950043,
          0.5215592384338379,
          -0.8398352265357971,
          0.2783009111881256,
          -0.577271044254303,
          -0.5083131790161133,
          -0.05525793135166168,
          -0.1498570293188095,
          -0.1283457726240158,
          0.5690281391143799,
          0.01265488937497139,
          -0.5539700984954834,
          -1.0285978317260742,
          0.40658318996429443,
          -0.968117356300354,
          0.6733312606811523,
          -0.12804605066776276,
          0.8143384456634521,
          -0.4742984175682068,
          -0.05159170180559158,
          -0.27738556265830994,
          -0.38262054324150085,
          -0.5955880284309387,
          0.4098527133464813,
          -0.3260018229484558,
          0.017977513372898102,
          0.6246107816696167,
          -0.09490518271923065,
          -0.5053117275238037,
          -0.07554066181182861,
          -1.1646541357040405,
          -0.7342944741249084,
          0.03230847045779228,
          0.03482883423566818,
          -0.1914295256137848,
          0.015254087746143341,
          -0.1583624631166458,
          0.10310878604650497,
          -0.44511666893959045,
          0.8772802352905273,
          0.3903440237045288,
          -0.6258599758148193,
          0.23868349194526672,
          1.2903259992599487,
          -0.2734023630619049,
          0.1910121887922287,
          -0.7316857576370239,
          -0.18324337899684906,
          -0.22431084513664246,
          0.05371161922812462,
          0.05609041452407837,
          -0.9989979267120361,
          -0.8197799921035767,
          0.4868951439857483,
          0.8621318340301514,
          1.4239604473114014,
          0.7230350971221924,
          0.7002956867218018,
          0.19326762855052948,
          0.4468672573566437,
          0.44125238060951233,
          -0.10993950068950653,
          0.23517827689647675,
          0.23775701224803925,
          -0.5582833290100098,
          -0.19620957970619202,
          0.0680704116821289,
          0.39635521173477173,
          -0.6841211915016174,
          -0.1102081760764122,
          0.06204256787896156,
          0.12787452340126038,
          0.01766064390540123,
          -0.09475037455558777,
          0.004385234788060188,
          0.5051864981651306,
          0.6699134707450867,
          0.2292354702949524,
          0.232020765542984,
          -0.08576199412345886,
          -0.9730613827705383,
          -0.1524491012096405,
          -0.7561003565788269,
          -0.20770521461963654,
          0.21769340336322784,
          -0.09296087920665741,
          0.5094266533851624,
          -0.028430096805095673,
          -1.0309927463531494,
          -0.23705795407295227,
          0.2257249504327774,
          0.18232494592666626,
          -0.23605036735534668,
          0.8451269268989563,
          0.022052999585866928,
          0.0880039855837822,
          0.023440558463335037,
          -0.6981170773506165,
          0.08256169408559799,
          0.30768075585365295,
          -0.6338419914245605,
          -0.5222769975662231,
          -0.47386693954467773,
          0.24393567442893982,
          0.49746036529541016,
          0.8283634781837463,
          -1.0898281335830688,
          0.6862115859985352,
          -0.06253685057163239,
          -0.3520962595939636,
          -0.5931586027145386,
          0.615483820438385,
          -0.22661972045898438,
          0.07454322278499603,
          0.07454803586006165,
          0.6983240246772766,
          -0.17223447561264038,
          0.3458589017391205,
          -0.2830553948879242,
          0.18846207857131958,
          -0.18840263783931732,
          0.03079640492796898,
          -0.08280372619628906,
          -0.8186400532722473,
          0.6329393982887268,
          0.2056516706943512,
          -0.088646799325943,
          0.006721879355609417,
          -0.40664783120155334,
          -0.4870237410068512,
          0.39676499366760254,
          -0.119974784553051,
          0.30674612522125244,
          -0.6917511820793152,
          0.2834671139717102,
          0.029238484799861908,
          0.10895011574029922,
          -0.03935584798455238,
          0.13527469336986542,
          0.04621252045035362,
          0.2583147883415222,
          0.08885546028614044,
          -0.8860949873924255,
          0.14992433786392212,
          -0.35303956270217896,
          0.3659471869468689,
          0.28836584091186523,
          -0.6851829290390015,
          -0.45804256200790405,
          -0.03926924616098404,
          -0.7164149284362793,
          0.10268720239400864,
          0.2933127284049988,
          -0.6363492012023926,
          -0.4528070092201233,
          0.2734266221523285,
          0.1407281905412674,
          0.7573334574699402,
          0.3234800398349762,
          0.34796327352523804,
          0.25353583693504333,
          -0.2694283425807953,
          0.15132391452789307,
          0.08655446767807007,
          -0.02368534356355667,
          -0.4114857017993927,
          0.13090716302394867,
          -0.014075223356485367,
          0.09073639661073685,
          -0.277515709400177,
          0.37425702810287476,
          -0.01755337417125702,
          -1.0104660987854004,
          0.68994140625,
          0.5025498867034912,
          -0.43338245153427124,
          0.41609033942222595,
          -0.49312055110931396,
          -0.7392033934593201,
          -0.52182537317276,
          0.09055592864751816,
          -1.4708024263381958,
          -0.04819820821285248,
          0.3733559846878052,
          0.06936408579349518,
          -0.23816761374473572,
          0.19877538084983826,
          0.11698293685913086,
          0.7015648484230042,
          0.4448508620262146,
          0.5047546029090881,
          0.2220880091190338,
          1.7696177959442139,
          0.6338537931442261,
          0.2896256148815155,
          -0.1500653624534607,
          0.18960583209991455,
          -0.015851184725761414,
          0.36772429943084717,
          -0.34417060017585754,
          -0.48859846591949463,
          0.18740202486515045,
          -0.03437183424830437,
          -1.1286252737045288,
          0.46808838844299316,
          0.526695728302002,
          0.18369701504707336,
          -0.5042461156845093,
          0.16672325134277344,
          0.415865421295166,
          0.08632918447256088,
          0.007189668715000153,
          1.4021341800689697,
          0.39673107862472534,
          1.216333270072937,
          -0.7100046277046204,
          0.7406506538391113,
          -0.760383665561676,
          -0.08908923715353012,
          -0.6942795515060425,
          0.6103814244270325,
          -0.45237040519714355,
          -1.6073423624038696,
          0.2615964710712433,
          -1.0904728174209595,
          -0.44797685742378235,
          -0.16894644498825073,
          0.08873820304870605,
          -0.6653529405593872,
          0.9777142405509949,
          0.30655282735824585,
          0.8903158903121948,
          -0.33498814702033997,
          -1.035936713218689,
          -0.5161008834838867,
          0.9135537147521973,
          0.7178100347518921,
          -0.5672029256820679,
          2.0273287296295166,
          0.8749969601631165,
          0.11798487603664398,
          -0.34656935930252075,
          -0.5868127346038818,
          0.6511219143867493,
          0.30148306488990784,
          -0.5726731419563293,
          -0.6914852261543274,
          0.0872587189078331,
          -0.08412192761898041,
          -0.7486073970794678,
          0.689430832862854,
          0.44701671600341797,
          0.6041668653488159,
          -0.6200527548789978,
          -0.8916274905204773,
          0.5792434215545654,
          -0.8407267332077026,
          -0.02380654402077198,
          -0.39633312821388245,
          0.9373611211776733,
          0.03728712722659111,
          0.009205073118209839,
          0.34223321080207825,
          -0.7211994528770447,
          3.82273006439209,
          0.14205244183540344,
          0.9569764137268066,
          0.38980504870414734,
          0.11304085701704025,
          0.40926164388656616,
          0.23304329812526703,
          -0.1370900571346283,
          0.8515428304672241,
          0.015515677630901337,
          -0.17176152765750885,
          0.4366082549095154,
          -0.27357035875320435,
          -0.05396481975913048,
          -0.14460104703903198,
          -0.10139867663383484,
          -0.5771613121032715,
          0.01900848001241684,
          -0.5873457789421082,
          -0.15006360411643982,
          -0.2251264601945877,
          0.4467715919017792,
          0.2999213933944702,
          -0.4331181049346924,
          0.4186822175979614,
          -0.6409933567047119,
          -0.2999570667743683,
          -0.46445876359939575,
          0.7070980072021484,
          -0.4486841857433319,
          0.5310023427009583,
          -0.7303103804588318,
          0.7035118341445923,
          -0.12320283055305481,
          0.16748400032520294,
          0.8911693096160889,
          0.6458408236503601,
          -1.2977495193481445,
          0.1496182084083557,
          1.0304665565490723,
          -0.03935907036066055,
          -1.0132124423980713,
          0.12052387744188309,
          -0.3531439006328583,
          -0.3272906541824341,
          0.6885119676589966,
          0.08260238170623779,
          -0.08025141060352325,
          1.26924467086792,
          -0.7905396223068237,
          0.23650780320167542,
          -0.6812415719032288,
          0.7993640303611755,
          -0.5331510901451111,
          -1.0638206005096436,
          -0.2843821346759796,
          -0.2892497181892395,
          -1.0683133602142334,
          -0.4110390245914459,
          0.3870847523212433,
          -0.04815893620252609,
          0.21853744983673096,
          0.5281767845153809,
          0.004654034972190857,
          -0.3473241925239563,
          0.1421714425086975,
          0.6841868758201599,
          0.35924577713012695,
          -0.1785738319158554,
          -0.47279617190361023,
          0.05370527505874634,
          0.2262556552886963,
          0.11796616017818451,
          0.05582579970359802,
          0.25638893246650696,
          0.4655193090438843,
          -0.40626779198646545,
          1.045600414276123,
          -0.38939565420150757,
          -0.2467379868030548,
          -0.5412783026695251,
          -0.6766862273216248,
          -0.6611834764480591,
          0.269806444644928,
          0.09274521470069885,
          0.784923255443573,
          -0.46491876244544983,
          0.6695244908332825,
          -0.2500375509262085,
          1.2667407989501953,
          -0.18145856261253357,
          0.2706211805343628,
          0.36974966526031494,
          -0.08281033486127853,
          0.20027464628219604
        ]
      },
      "type": "document"
    },
    {
      "id": "64f157b8-2fbd-4aed-9f28-695db4b96497",
      "properties": {
        "page_content": "Figure 1: Common KILT interface for knowledge intensive language tasks: each instance consists of\ninput and output with a provenance (text span) from the common KILT knowledge source. Source:\nhttps://en.wikipedia.org/wiki/{Star_Trek,Three_Men_and_a_Baby,Treklanta}\ntools. Critically, they all use different knowledge\nsources, from different versions of Wikipedia to\nentirely different corpora. This makes task-to-task\ncomparisons difﬁcult and substantially increases\ncomputational overhead. For example, one\ncannot easily assess whether the same knowledge\nrepresentation can be re-used if each dataset is tied\nto a different source. Moreover, if one decides\nto work with different sources across different\ntasks, many approaches require re-indexing and\nre-encoding large numbers of documents. If a\nlanguage model is pre-trained on one snapshot of\nWikipedia to capture its knowledge, tasks that use\nother snapshots might require re-training.\nTo facilitate research on models that must ac-\ncess speciﬁc information in a knowledge source,\nwe introduce KILT, a benchmark and library for\nKnowledge Intensive Language Tasks. KILT aims\nto lower the entry barrier for such research by for-\nmulating several knowledge-intensive NLP tasks\nwith respect to a common interface and the same\nuniﬁed knowledge source—a single Wikipedia\nsnapshot. The KILT benchmark consists of eleven\ndatasets spanning ﬁve distinct tasks, and includes\nthe test set for all datasets considered. 2 An im-\nportant aim of KILT is to cover many different\nways of seeking knowledge. For this reason, we\nselect tasks that provide a variety of ways to for-\nmulate both the input query (e.g., a claim to verify,\na text chunk to annotate, a structured query, a nat-\nural question or a conversation) and the expected\noutput (e.g., discrete, extractive, or abstractive).\nMoreover, while some tasks are factoid in nature\n(e.g., slot ﬁlling), others require using background\nknowledge to answer more complex questions (e.g,\nELI5) or to sustain a conversation (e.g,. Wizard of\nWikipedia). The format of the KILT benchmark is\nmodel-agnostic, so any system capable of produc-\ning a textual output given a textual input is eligible\nto participate. KILT is an in-KB resource (Petroni\net al., 2015), i.e., the evidence required to answer\neach of the ~3.2M instances in KILT is present\nsomewhere in the knowledge source. Hence there\nare no unanswerable instances in KILT. Although\nrecognizing unanswerable instances is important,\nwe believe the in-KB setting already poses an hard\n2A brand new portion of the Natural Question (NQ) dataset,\noriginally held out, is used as the KILT test set for NQ.",
        "document_metadata": {
          "page_label": "2",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
      "properties": {
        "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
        "entities": [
          "Elon Musk",
          "Tesla",
          "SpaceX",
          "Europe",
          "Asia",
          "Berlin",
          "Shanghai",
          "Wikipedia",
          "KILT",
          "EvalAI",
          "Yadav",
          "FEVER",
          "Thorne"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "80ef7bf0-018a-4a27-b41f-c36b5406013f",
      "properties": {
        "page_content": "3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
        "entities": [
          "Entity Linking",
          "EL",
          "KILT",
          "Wikipedia",
          "Berlin",
          "Shanghai",
          "Wu et al.",
          "AIDA CoNLL-YAGO",
          "CoNLL 2003",
          "YAGO2",
          "WNED-WIKI",
          "Guo and Barbosa"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "7982f77f-9d28-4552-9f31-3520051f8d74",
      "properties": {
        "page_content": "Moreover, we develop a fact checking baseline that\ncombines a BERT-base classiﬁer with passages re-\nturned from DPR where the claim and retrieved\npassage are input. The classiﬁer is trained to label\nthe claim-passage pair as supported or refuted with\nan additional neutral class for negative-sampled\nunrelated passages. Unrelated passages are sam-\npled from two sources: (1) DPR-retrieved passages\nfrom pages that are not in the list of pages in the\ninstance’s provenance and (2) passages sampled\nuniformly at random from pages in the instance’s\nprovenance. At inference, we classify the ﬁrst sen-\ntence of the Wikipedia pages retrieved by the top-\n100 DPR passages against the claim. Using pages\nlabelled as supported or refuted, we label the claim\nthrough majority voting. For claim provenance, we\nre-rank passages by probability according to this\nlabel.\nFor Open Domain QA and Slot Filling, we\nuse DPR combined with the pre-trained BERT-\nbased extractive reading comprehension model\nof Karpukhin et al. (2020). We use the model pre-\ntrained on TriviaQA for HotpotQA and the model\npre-trained on Natural Questions for Zero Shot RE.\nWe reduce the slot ﬁlling problem to question an-\nswering, by using the speciﬁed template questions.\nWe consider a single random template question per\nsubject-relation during inference.\nFor Entity Linking, we consider BLINK.\nFor Dialogue, we consider the Generative Trans-\nformer MemNet (Dinan et al., 2019) that encodes\nthe dialogue history and knowledge to generates\nthe next utterance. We use the pre-trained version\navailable in ParlAI (Miller et al., 2017). Finally,\nto test the performance of combining BART and\nDPR on FEVER, we develop a classiﬁer that uses\nthese—full description in the appendix.\nGeneral Baselines A main motivation of the\nKILT Benchmark is to enable a uniﬁed approach\ntowards a wide range of knowledge-intensive tasks.\nWe analyze existing general architectures that can\nbe used as a baseline for multiple tasks in KILT.\nLarge pre-trained sequence-to-sequence models\nsuch as BART (Lewis et al., 2019) and T5 (Raffel\net al., 2019a) implicitly store a surprising amount of\nknowledge in their parameters (Petroni et al., 2019).\nWe treat all KILT tasks as generative, relying on\nthe knowledge accumulated by the model while\npre-training, with no retrieval (similarly to Roberts\net al. (2020)). We ﬁnetune pre-trained variants on\nall KILT tasks, using fairseq (Ott et al., 2019)\nfor BART and Huggingface’s Transformer (Wolf\net al., 2019) for T5.\nA natural way to boost performance is to in-\ncorporate an explicit knowledge mechanism. For\nour BART+DPR baseline, we follow Petroni et al.\n(2020) to retrieve and prepend the top-3 passages\nfrom DPR for each input sample and use context-\nenhanced training data to ﬁne-tune a BART model.\nWe use the DPR rank when reporting provenance\nfor all except entity linking tasks. For entity link-\ning, we report the Wikipedia id of the page whose\ntitle exactly matches the predicted string.\nRecently, state-of-the-art results on a wide range\nof NLP tasks have been achieved by combining a\ntrainable retrieval step with language modeling or\ngeneration (Guu et al., 2020; Lewis et al., 2020a).\nWe experiment with ﬁne-tuning RAG (Lewis et al.,\n2020b) on KILT tasks, establishing a strong base-\nline on all of them. RAG combines a DPR retriever\nwith a BART generator, however, unlike in the case\nof our previous baseline, RAG back-propagates to\nthe retriever’s input encoder, learning to adapt the\ninput embedding to retrieve more relevant results.\nAt every generation step we retrieve top-5 passages\nand use them as provenance.",
        "document_metadata": {
          "page_label": "15",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "496f0835-ec4e-4375-bbe8-4617272eec32",
      "properties": {
        "page_content": "Dataset\nLabel Multi-hop\nAverage\nProvenance\nSize (APS)\nAverage\nProvenance\nNumber (APN)\nAverage\nProvenance\nPages (APP)\nAverage\nAnswers\nNumber (AAN)\nTrain\nSize\nDev\nSize\nTest\nSize\nFEV x 1.12 1.35 1.13 1 104,966 10,444 10,100\nAY2 1 1 1 1 18,395 4,784 4,463\nWnWi 1 1 1 1 - 3,396 3,376\nWnCw 1 1 1 1 - 5,599 5,543\nT-REx 1 1.68 1.26 5.29 2,284,168 5,000 5,000\nzsRE 1 1 1 1 147,909 3,724 4,966\nNQ 1 3.22 1.57 2.08 87,372 2,837 1,444\nHoPo x 2.4 1 2 1 88,869 5,600 5,569\nTQA 1 3.39 1.68 28.67 61,844 5,359 6,586\nELI5 1 1.21 1.18 4.69 272,634 1,507 600\nWoW 1 1 1 1 63,734 3,054 2,944\nTotal 3,129,891 51,460 50,736\nTable 6: Datasets statistics. APS refers to the average number of textual spans in each provenance set—for most of\nthe datasets a single span is sufﬁcient to provide enough evidence while FEV and HoPo might require more (hence\nthey require multi-hop reasoning). APN indicates the average number of equally valid provenance sets for each\ninstance while APP the average number of Wikipedia pages overall in the provenance (note that multiple spans\nmight refer to the same Wikipedia page). Finally AAN reports the average number of equally valid gold answers\nper instance. We additionally report the size of the train, dev and test split for each dataset.\n1 { ’ i d ’ : # o r i g i n a l data p o i n t i d i f a v a i l a b l e otherwise unique i d\n2 ’ i n p u t ’ : # question / claim / sentence / etc\n3 ’ output ’ : [ # each element might contain an answer , a provenance or both\n4 {\n5 ’ answer ’ : # answer i n t e x t u a l form\n6 ’ provenance ’ : [\n7 # evidence set f o r the answer from the KILT knowledge source\n8 {\n9 ’ w i k i p e d i a _ i d ’ : #* mandatory *\n10 ’ t i t l e ’ :\n11 ’ section ’ :\n12 ’ start_paragraph_id ’ :\n13 ’ s t a r t _ c h a r a c t e r ’ :\n14 ’ end_paragraph_id ’ :\n15 ’ end_character ’ :\n16 ’ bleu_score ’ : # wrt o r i g i n a l evidence\n17 ’ meta ’ : # dataset / task s p e c i f i c\n18 }\n19 ]\n20 }\n21 ]\n22 ’ meta ’ : # dataset / task s p e c i f i c\n23 }\nFigure 3: KILT datasets’ interface. Each dataset is represented as a JSON Line ﬁle. The Figure shows the pseudo-\nJSON structure for each record in the ﬁles.",
        "document_metadata": {
          "page_label": "16",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "aee20b6d-5bae-4e61-bff9-2e9fcc1b7e03",
      "properties": {
        "page_content": "model R-Precision Recall@5 Accuracy KILT-AC\ntest\nBART + DPR 46.87 46.87 46.87 46.87\nRAG 47.61 47.61 47.61 47.61\nBART 49.16 49.16 49.16 49.16\nT5 49.29 49.29 49.29 49.29\nBLINK 68.77 81.78 68.77 68.77\ndev\nBART + DPR 45.7 45.7 45.7 45.7\nT5 46.58 46.58 46.58 46.58\nRAG 46.7 46.7 46.7 46.7\nBART 48.01 48.01 48.01 48.01\nTable 10: WNED-CWEB\nmodel R-Precision Recall@5 Accuracy F1 KILT-AC KILT-F1\ntest\nBART 0.0 0.0 45.06 49.24 0.0 0.0\nT5 0.0 0.0 43.56 50.61 0.0 0.0\nBART + DPR 13.26 17.04 59.16 62.76 11.12 11.41\nRAG 28.68 33.04 59.2 62.96 23.12 23.94\ndev\nBART 0.0 0.0 43.84 48.25 0.0 0.0\nT5 0.0 0.0 47.24 51.73 0.0 0.0\nBART + DPR 13.62 16.93 56.7 60.19 11.56 11.87\nRAG 29.26 33.69 61.48 65.03 25.4 26.22\nTable 11: T-REx\nmodel R-Precision Recall@5 Accuracy F1 KILT-AC KILT-F1\ntest\nBART 0.0 0.0 9.14 12.21 0.0 0.0\nT5 0.0 0.0 9.02 13.52 0.0 0.0\nBERT + DPR 40.11 40.11 6.93 37.28 4.47 27.09\nBART + DPR 28.9 39.21 30.43 34.47 18.91 20.32\nRAG 53.73 59.52 44.74 49.95 36.83 39.91\ndev\nBART 0.0 0.0 3.03 12.61 0.0 0.0\nT5 0.0 0.0 1.58 10.8 0.0 0.0\nBART + DPR 45.6 58.49 34.96 44.79 29.08 32.85\nRAG 65.36 73.07 47.42 57.98 42.64 48.35\nTable 12: Zero Shot RE",
        "document_metadata": {
          "page_label": "18",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions"
        ],
        "summary": "AI is transforming industries by automating tasks and analyzing data, driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          -0.20148420333862305,
          0.6139746308326721,
          -0.4426495134830475,
          -0.4698089361190796,
          0.14095142483711243,
          -0.059441037476062775,
          -0.08708472549915314,
          -0.27141648530960083,
          0.7787469029426575,
          0.20899324119091034,
          -0.12373767793178558,
          0.34668615460395813,
          -0.597898542881012,
          -0.9008846879005432,
          0.14463353157043457,
          -0.410906583070755,
          0.08413369208574295,
          -0.097560353577137,
          -0.2352597415447235,
          -0.12094435095787048,
          0.03498772531747818,
          0.7249787449836731,
          -0.3866375684738159,
          -1.265449047088623,
          -0.9246146082878113,
          0.5560995936393738,
          0.7210267186164856,
          -0.5792335271835327,
          0.6615636348724365,
          0.6513221859931946,
          0.08162429183721542,
          -0.18767115473747253,
          0.2715427875518799,
          -0.40030476450920105,
          -0.5860006809234619,
          -0.19717082381248474,
          0.2358017861843109,
          -0.1223243847489357,
          -0.7840690612792969,
          -0.3318711519241333,
          0.20603540539741516,
          -0.23815809190273285,
          0.32684046030044556,
          -1.2838716506958008,
          -1.0260828733444214,
          0.7151329517364502,
          0.5354833006858826,
          -1.2028074264526367,
          0.08290591090917587,
          -0.3789614737033844,
          -0.700566828250885,
          0.39178264141082764,
          -0.02654721587896347,
          -0.23395071923732758,
          0.21959957480430603,
          -1.125575304031372,
          -0.3440718650817871,
          -0.2832734286785126,
          -0.4031120836734772,
          0.10884536802768707,
          1.0245732069015503,
          -0.45599305629730225,
          0.5619677901268005,
          0.13879811763763428,
          0.26263001561164856,
          0.4570104479789734,
          0.26263222098350525,
          -0.5139470100402832,
          -0.14334270358085632,
          0.11359032988548279,
          -1.032599687576294,
          -0.434639036655426,
          0.1929551661014557,
          0.17838793992996216,
          -0.35622280836105347,
          0.16047434508800507,
          -0.042429715394973755,
          -0.15424779057502747,
          -0.7303014993667603,
          -0.3622671961784363,
          -0.3941291868686676,
          0.6285946369171143,
          -0.4795178174972534,
          0.9358176589012146,
          -0.1739797294139862,
          -0.31824201345443726,
          0.7874322533607483,
          0.9343628883361816,
          -0.244326651096344,
          -0.6217713952064514,
          -0.059594184160232544,
          -0.034395936876535416,
          0.14561322331428528,
          -0.014831312000751495,
          -0.03956388682126999,
          0.7877362370491028,
          -0.5929844975471497,
          0.5298479795455933,
          0.054399795830249786,
          0.011268297210335732,
          0.3226891756057739,
          1.1086190938949585,
          -0.21888525784015656,
          0.8433919548988342,
          -0.7008355259895325,
          0.24204476177692413,
          0.6838487982749939,
          -0.8983402252197266,
          0.008471149951219559,
          -1.1745805740356445,
          0.511260986328125,
          0.17879033088684082,
          0.015214517712593079,
          0.30442488193511963,
          -0.03838057070970535,
          1.240529179573059,
          -0.2553979754447937,
          0.19505135715007782,
          -0.3302313983440399,
          0.4626478850841522,
          -0.5594297647476196,
          -0.5673165917396545,
          -0.15762931108474731,
          -0.6686323881149292,
          0.3763343095779419,
          -1.2249335050582886,
          0.19226546585559845,
          0.5461958646774292,
          -0.5416116714477539,
          0.8035534024238586,
          -0.16929170489311218,
          0.028102748095989227,
          -0.167934849858284,
          0.4299066662788391,
          0.06673695892095566,
          -0.9255534410476685,
          0.19180884957313538,
          0.6997563242912292,
          -0.40953803062438965,
          0.883830189704895,
          -0.1502297967672348,
          0.15672877430915833,
          -0.2864624559879303,
          1.7574213743209839,
          -0.2674376368522644,
          -0.06156667694449425,
          -0.628571629524231,
          -0.08150789141654968,
          -0.545596718788147,
          1.0218839645385742,
          -0.8263217806816101,
          0.3330860435962677,
          0.6943504214286804,
          -0.03237031027674675,
          -0.5081380605697632,
          -0.8758758902549744,
          -0.7734129428863525,
          -0.09367384016513824,
          0.33460545539855957,
          0.4113471508026123,
          -0.258066326379776,
          0.05829823389649391,
          -0.21685877442359924,
          1.0603046417236328,
          -0.31541508436203003,
          0.8204463720321655,
          -1.159802794456482,
          0.0018730983138084412,
          -0.5975947976112366,
          -0.142822265625,
          0.4923882484436035,
          -0.1380288004875183,
          -0.741234302520752,
          -0.49433010816574097,
          0.8227378129959106,
          0.9614874124526978,
          0.47688716650009155,
          -0.027627021074295044,
          -0.44168007373809814,
          -0.6042952537536621,
          -1.5507349967956543,
          -0.6307132840156555,
          -0.8442783355712891,
          0.009541034698486328,
          0.12625139951705933,
          0.4597608149051666,
          -0.049991119652986526,
          0.38293763995170593,
          0.47101208567619324,
          -0.4406893849372864,
          0.44963502883911133,
          0.6870209574699402,
          -0.8087270855903625,
          0.15781041979789734,
          0.057646140456199646,
          0.2808651030063629,
          -0.551630973815918,
          0.365143358707428,
          0.5985390543937683,
          0.02320372313261032,
          0.012854550033807755,
          0.5555001497268677,
          -0.3185601234436035,
          -0.6666186451911926,
          -1.0652189254760742,
          0.9585986137390137,
          -0.12556099891662598,
          1.2527409791946411,
          -1.699695348739624,
          1.3709709644317627,
          0.4401327967643738,
          0.1454131305217743,
          -0.37067240476608276,
          -0.3254300355911255,
          0.8537512421607971,
          0.013849236071109772,
          -0.324796587228775,
          0.30844029784202576,
          0.34156882762908936,
          -0.5146127343177795,
          -0.13078247010707855,
          -0.35351645946502686,
          0.43090930581092834,
          -0.7429024577140808,
          -0.3409920632839203,
          0.26322898268699646,
          -0.19592073559761047,
          0.8687750101089478,
          0.18892104923725128,
          0.21675081551074982,
          0.5833463072776794,
          0.7484593987464905,
          -0.8237089514732361,
          0.7997536659240723,
          -0.18377363681793213,
          0.4208541810512543,
          -0.4132947325706482,
          0.37880995869636536,
          -0.18882893025875092,
          -0.29600730538368225,
          1.1029034852981567,
          0.1073220819234848,
          1.37067711353302,
          0.6260883212089539,
          -0.5285360217094421,
          0.28494441509246826,
          0.08538003265857697,
          -0.23444020748138428,
          0.40373358130455017,
          0.6080846190452576,
          -0.7332497835159302,
          0.20002563297748566,
          0.1499708890914917,
          -0.26397818326950073,
          -0.6827583909034729,
          0.5464445352554321,
          0.6545237302780151,
          0.5266338586807251,
          0.3935122489929199,
          -1.2030613422393799,
          -0.5003138184547424,
          0.709261417388916,
          0.7402034401893616,
          0.15866263210773468,
          0.6118549704551697,
          0.41407737135887146,
          -0.3403881788253784,
          -0.05221810191869736,
          -1.1068679094314575,
          -0.27283093333244324,
          -1.0520397424697876,
          -1.2260475158691406,
          -0.3866424858570099,
          -0.30068206787109375,
          -0.9592726826667786,
          -0.026029083877801895,
          0.09088487923145294,
          -0.5967716574668884,
          0.741213858127594,
          -0.11972750723361969,
          -0.44861844182014465,
          -0.5551794767379761,
          -0.6671473979949951,
          0.5038305521011353,
          1.1376030445098877,
          0.3963516652584076,
          -1.1209172010421753,
          -0.17971950769424438,
          -0.7123729586601257,
          0.5452159643173218,
          0.8493242859840393,
          0.45353299379348755,
          -0.10882651060819626,
          -0.28626978397369385,
          -0.1600976288318634,
          -0.29344046115875244,
          0.4955282509326935,
          -0.05074722319841385,
          -1.1744977235794067,
          -0.3521379828453064,
          0.10089840739965439,
          0.008568523451685905,
          -0.6249591112136841,
          -0.28777244687080383,
          0.12991484999656677,
          0.5624245405197144,
          0.022887369617819786,
          0.17906129360198975,
          0.9456692934036255,
          0.14721530675888062,
          -1.2339476346969604,
          0.15321451425552368,
          -0.4616921544075012,
          0.5701075792312622,
          -0.5269285440444946,
          0.7291272282600403,
          0.5784363746643066,
          -0.6566822528839111,
          0.15962642431259155,
          -1.0738483667373657,
          -0.3374358117580414,
          0.08408568054437637,
          -0.6172381639480591,
          0.5843613147735596,
          0.021033721044659615,
          0.3276844024658203,
          -0.018614046275615692,
          -1.8532072305679321,
          0.2579392194747925,
          0.04594837501645088,
          -0.6524945497512817,
          -0.4019475281238556,
          0.34532853960990906,
          0.8849731683731079,
          0.6811109185218811,
          -0.439502090215683,
          -0.041651032865047455,
          0.3551582098007202,
          -0.48508602380752563,
          0.8053210377693176,
          0.19970422983169556,
          -0.32619237899780273,
          0.29806622862815857,
          0.3560975193977356,
          -0.6136336326599121,
          0.5827071070671082,
          1.0225646495819092,
          -0.39545103907585144,
          0.6924233436584473,
          -0.2172098159790039,
          -0.20700787007808685,
          -0.18709774315357208,
          -0.4047929048538208,
          -0.20769545435905457,
          0.39282581210136414,
          0.07532092928886414,
          -0.3298244774341583,
          0.47992604970932007,
          -0.3903017044067383,
          0.10891678929328918,
          0.8242081999778748,
          0.4911864399909973,
          -0.6298035979270935,
          0.4938202202320099,
          -0.5064240097999573,
          0.2803775668144226,
          -0.378925621509552,
          0.5541943907737732,
          0.21354593336582184,
          -0.7606136202812195,
          0.39567676186561584,
          0.014486294239759445,
          -0.32032638788223267,
          0.5514094233512878,
          -0.4236968755722046,
          -1.1856321096420288,
          0.2209051102399826,
          -0.8367661237716675,
          0.4717925488948822,
          -1.0305424928665161,
          0.1399296224117279,
          -0.03837021440267563,
          0.13570860028266907,
          -0.5308751463890076,
          -0.25815901160240173,
          0.5113497376441956,
          -0.438192754983902,
          0.5145376324653625,
          -0.2332664132118225,
          0.004769176244735718,
          0.6545926928520203,
          0.34619027376174927,
          -0.646626353263855,
          0.3773767650127411,
          -0.5367326736450195,
          -0.4585205912590027,
          1.081784725189209,
          -0.05756402760744095,
          0.2518472969532013,
          -0.7827865481376648,
          1.117363691329956,
          0.023411672562360764,
          0.3380494713783264,
          0.4715981185436249,
          0.5068782567977905,
          0.4085874557495117,
          0.3324849009513855,
          0.7644349336624146,
          0.33922821283340454,
          -0.1743217408657074,
          -0.1240287721157074,
          -0.6634524464607239,
          0.5242152214050293,
          -0.3725156784057617,
          -0.45333999395370483,
          0.2921731173992157,
          -0.11949759721755981,
          -0.18267345428466797,
          -0.5942919254302979,
          0.16869866847991943,
          -0.43289902806282043,
          -0.20737001299858093,
          -0.7474848628044128,
          0.13372491300106049,
          0.5234679579734802,
          -0.19135607779026031,
          -0.5682592988014221,
          -1.1403077840805054,
          0.8243018984794617,
          0.4234415292739868,
          -0.8282041549682617,
          -0.9462966322898865,
          0.4813306927680969,
          -0.3394320011138916,
          -0.2719322741031647,
          0.28790491819381714,
          1.1148285865783691,
          -1.2084085941314697,
          0.8925723433494568,
          0.12140040099620819,
          0.0040922462940216064,
          0.5369350910186768,
          0.30684396624565125,
          -0.2471446990966797,
          -0.1530248522758484,
          -0.14305897057056427,
          0.3348509967327118,
          0.23497076332569122,
          0.045017316937446594,
          -0.5594068169593811,
          0.6340937614440918,
          -0.8400084376335144,
          1.4931589365005493,
          -0.3916260600090027,
          0.5243374109268188,
          -0.5757910013198853,
          -0.31447547674179077,
          0.07781870663166046,
          0.0675322487950325,
          0.4310145080089569,
          0.3888928294181824,
          0.2340995818376541,
          0.9053859114646912,
          -0.1481495350599289,
          -0.31063777208328247,
          0.21224650740623474,
          1.142799735069275,
          0.5158724188804626,
          0.4725992679595947,
          0.2102452963590622,
          -0.14404533803462982,
          -0.3048965334892273,
          0.04444536194205284,
          -0.5854503512382507,
          0.6192346811294556,
          -0.7298058867454529,
          0.5390728116035461,
          0.41126227378845215,
          -0.5465657114982605,
          -0.3834150731563568,
          -0.4783530533313751,
          -0.16000443696975708,
          0.07600638270378113,
          -0.05811072140932083,
          -0.25827693939208984,
          -1.0403809547424316,
          0.35464656352996826,
          0.8965224027633667,
          -0.030125699937343597,
          0.7341544032096863,
          0.30293139815330505,
          0.014493156224489212,
          -0.09307441860437393,
          0.5345296859741211,
          0.033891186118125916,
          0.09363245964050293,
          -0.07443347573280334,
          0.3594435155391693,
          -0.019222065806388855,
          -0.8235657215118408,
          0.7434471249580383,
          -1.4614253044128418,
          -1.1113325357437134,
          0.1341543197631836,
          -0.3635527491569519,
          -0.3755214214324951,
          -0.3888750374317169,
          -0.46083083748817444,
          -0.09616424888372421,
          0.22761069238185883,
          -0.10732492804527283,
          -0.20535020530223846,
          -0.15154331922531128,
          0.8087466359138489,
          0.4840620458126068,
          -0.1003301814198494,
          -0.08873416483402252,
          0.36399322748184204,
          -0.04778819903731346,
          1.293744683265686,
          0.03656015545129776,
          -0.9257336258888245,
          -0.392255961894989,
          1.5204768180847168,
          -0.8245276212692261,
          -0.10904987156391144,
          0.24378183484077454,
          -0.7872198820114136,
          0.0708765834569931,
          -1.6954172849655151,
          0.3973223865032196,
          -0.1277235448360443,
          -0.19752436876296997,
          -0.10631787776947021,
          -0.1764882653951645,
          0.1845698058605194,
          0.16046945750713348,
          0.6212518215179443,
          -0.4671424925327301,
          -0.5402371287345886,
          0.36915794014930725,
          -0.4845197796821594,
          -0.22565585374832153,
          -0.5576297044754028,
          -0.17528440058231354,
          -0.14634323120117188,
          0.5895655751228333,
          0.5817974805831909,
          -0.5869331359863281,
          -0.5783140063285828,
          0.3120769262313843,
          -0.2645551562309265,
          -0.006311521399766207,
          0.44123828411102295,
          -0.9264495372772217,
          -0.29602062702178955,
          0.25918251276016235,
          -0.018816135823726654,
          0.5704290270805359,
          1.0879472494125366,
          -0.4026080071926117,
          -0.6545915603637695,
          0.265669047832489,
          -0.13678032159805298,
          -0.6697673797607422,
          0.17130111157894135,
          -0.7441898584365845,
          -0.7260138988494873,
          1.3235832452774048,
          -0.5441890954971313,
          -0.5526500940322876,
          0.30100563168525696,
          0.4632391035556793,
          0.8031498193740845,
          0.21185362339019775,
          -0.8366633057594299,
          -0.6847643256187439,
          -0.49098750948905945,
          -1.1264667510986328,
          -0.3558393716812134,
          -0.4828043580055237,
          -0.1478874534368515,
          -0.05223464220762253,
          -0.046604931354522705,
          0.3604476749897003,
          -0.5974170565605164,
          0.22991424798965454,
          1.3071913719177246,
          0.49971213936805725,
          -0.6156826019287109,
          0.3455755114555359,
          -0.20853665471076965,
          0.18315574526786804,
          0.12538249790668488,
          -0.011599935591220856,
          -0.5047242641448975,
          0.09481334686279297,
          -0.6229398846626282,
          0.19719848036766052,
          -0.5584425330162048,
          0.04947952553629875,
          0.3348163068294525,
          0.6723231077194214,
          -0.828569233417511,
          0.5626614689826965,
          0.19592468440532684,
          -0.5552939772605896,
          -0.4101255536079407,
          -0.29213041067123413,
          0.07943897694349289,
          -0.3856545686721802,
          0.28497475385665894,
          0.46316292881965637,
          0.15582981705665588,
          0.6003705263137817,
          -0.380728155374527,
          -0.9591439962387085,
          -0.01702992618083954,
          0.7052741646766663,
          0.21511366963386536,
          -0.38198983669281006,
          0.3085629940032959,
          0.8057191967964172,
          -0.2621346116065979,
          -0.3913221061229706,
          0.6860199570655823,
          -0.19406796991825104,
          0.48973289132118225,
          -0.6037474274635315,
          0.39046263694763184,
          -0.5776844620704651,
          0.15925420820713043,
          -0.1690048724412918,
          0.7229793071746826,
          -0.4147129952907562,
          -0.2348414957523346,
          1.479966402053833,
          0.29202041029930115,
          -0.7692916989326477,
          0.015290653333067894,
          0.42929643392562866,
          -0.3428223729133606,
          0.4371674954891205,
          -1.5283161401748657,
          -0.17302951216697693,
          -0.26374444365501404,
          -0.6537332534790039,
          0.481804221868515,
          -1.0750401020050049,
          -0.3274921774864197,
          0.3450935184955597,
          0.5584440231323242,
          0.2812161445617676,
          -0.5434772372245789,
          -0.09384314715862274,
          0.16861091554164886,
          0.08220556378364563,
          -0.647686779499054,
          -0.6651816368103027,
          1.0173845291137695,
          -0.2669717073440552,
          0.22996148467063904,
          -0.2558647096157074,
          -0.24817639589309692,
          1.1814759969711304,
          0.4404646158218384,
          -0.20543810725212097,
          -0.3661745488643646,
          0.02429138496518135,
          -1.1488844156265259,
          -0.6113022565841675,
          -0.14031800627708435,
          0.5610455870628357,
          -0.364091694355011,
          0.5423187017440796,
          0.43062976002693176,
          -0.25191596150398254,
          -0.340030699968338,
          0.18268102407455444,
          -0.9472440481185913,
          -1.0455983877182007,
          0.11821790784597397,
          0.24116413295269012,
          0.03257458284497261,
          0.032059572637081146,
          -0.07604088634252548,
          0.13730275630950928,
          0.11143924295902252,
          0.8406163454055786,
          -0.4398724138736725,
          0.2880460023880005,
          0.7084616422653198,
          0.15351355075836182,
          -0.44187191128730774,
          -0.2188321053981781,
          -0.10567298531532288,
          -0.024653634056448936,
          -0.47706425189971924,
          -0.016836795955896378,
          -0.4131040573120117,
          0.24639973044395447,
          0.5628107190132141,
          -0.6630898118019104,
          0.3577129542827606,
          -0.548856258392334,
          0.2228749841451645,
          -0.5342820286750793,
          0.13226687908172607,
          0.21451032161712646,
          -0.2443276345729828,
          0.5095173120498657,
          -1.1752738952636719,
          0.5819019675254822,
          0.29898470640182495,
          -0.9205576777458191,
          0.9061855673789978,
          -0.1508863866329193,
          0.09700459986925125,
          -0.04933936521410942,
          -0.1477975696325302,
          0.6052279472351074,
          -0.42410537600517273,
          0.7885744571685791,
          -0.33806318044662476,
          0.5897687673568726,
          0.2732434570789337,
          -0.9507272243499756,
          0.29186487197875977,
          -0.7711854577064514,
          -0.16216954588890076,
          -0.9657995104789734,
          -0.43234241008758545,
          0.3295958638191223,
          -0.29590263962745667,
          -0.6329095363616943,
          0.4006635844707489,
          -0.5086380243301392,
          -0.6136208772659302,
          -0.48141881823539734,
          0.14978057146072388,
          0.7968738079071045,
          0.3652784824371338,
          0.16944533586502075,
          0.20771025121212006,
          -0.6301627159118652,
          -0.5279983282089233,
          -0.6738056540489197,
          -0.365791380405426,
          0.15623481571674347,
          0.47163474559783936,
          0.16128194332122803,
          0.32297539710998535,
          0.7694844007492065,
          0.12921461462974548,
          0.058526478707790375,
          0.5290674567222595,
          0.45978260040283203,
          0.11028988659381866,
          0.48561930656433105,
          0.5917508602142334,
          -0.4227138161659241,
          -0.5522459149360657,
          -1.122422695159912,
          0.019702166318893433,
          0.8424162864685059,
          -0.03484644740819931,
          -0.5619954466819763,
          0.6190761923789978,
          0.06960657984018326,
          -0.03184343874454498,
          -0.5086619853973389,
          -0.6669173240661621,
          0.413499116897583,
          -0.23823000490665436,
          0.23696090281009674,
          -0.3772008717060089,
          0.6295207142829895,
          -0.5575084090232849,
          0.18507026135921478,
          0.6751696467399597,
          0.8434323072433472,
          -0.7087574005126953,
          0.5587327480316162,
          0.42449143528938293,
          -0.5138384103775024,
          -0.41083377599716187,
          -0.4792935848236084,
          0.5336824059486389,
          -0.638159990310669,
          0.2057664394378662,
          -0.600947380065918,
          0.09500683844089508,
          0.5331112742424011,
          -0.07015302032232285,
          -0.22019702196121216,
          0.444428950548172,
          0.7608680129051208,
          -0.16532766819000244,
          0.17941196262836456,
          0.2744463086128235,
          1.1987851858139038,
          0.4722772538661957,
          0.283682644367218,
          0.07724718749523163,
          0.7122972011566162,
          -0.7375532388687134,
          0.33572515845298767,
          -0.7607428431510925,
          1.0620448589324951,
          -1.7808860540390015,
          -0.6422933340072632,
          0.3071792423725128,
          0.17744942009449005,
          -0.8976565003395081,
          -0.003831610083580017,
          -0.6049172878265381,
          0.7151528000831604,
          0.47813183069229126,
          -0.751324474811554,
          0.13265419006347656,
          0.02403736114501953,
          -0.027535468339920044,
          0.21757182478904724,
          0.25589719414711,
          -0.850805401802063,
          0.2582851052284241,
          -0.40144360065460205,
          0.22776705026626587,
          -0.4811497628688812,
          0.1539648473262787,
          -0.044467829167842865,
          0.25579833984375,
          -0.5724142789840698,
          0.8664361834526062,
          -0.41657841205596924,
          1.1451786756515503,
          0.2846364378929138,
          -0.28120747208595276,
          0.9892779588699341,
          0.38868528604507446,
          -0.5889228582382202,
          0.6563235521316528,
          -0.22044558823108673,
          -0.4204672574996948,
          -1.0166205167770386,
          0.7776578664779663,
          -0.511867105960846,
          0.5497759580612183,
          0.38206687569618225,
          -0.21009771525859833,
          -0.7228837013244629,
          0.02348722144961357,
          0.10310572385787964,
          0.16585220396518707,
          0.006256815046072006,
          0.676032543182373,
          0.13665293157100677,
          1.443080186843872,
          1.60666024684906,
          -0.3756122589111328,
          -0.37878528237342834,
          -0.04793361574411392,
          -0.04403679817914963,
          0.07942777872085571,
          -0.0797373354434967,
          -0.6693512201309204,
          -0.2855446934700012,
          0.31340935826301575,
          -0.7938318848609924,
          -0.2588370740413666,
          0.1254464089870453,
          -0.07743750512599945,
          0.6766132712364197,
          -0.26264700293540955,
          1.1374070644378662,
          0.1359507143497467,
          -0.09788784384727478,
          -0.12738323211669922,
          0.5049248933792114,
          0.5888671278953552,
          0.24439358711242676,
          0.34483644366264343,
          -0.10470329225063324,
          0.6697039604187012,
          -1.1186305284500122,
          0.8173826336860657,
          0.12709832191467285,
          -0.17801730334758759,
          0.09259851276874542,
          -0.09048530459403992,
          -0.6738945841789246,
          -1.206879734992981,
          0.8912191987037659,
          -0.5851724147796631,
          0.21194607019424438,
          -0.1186051070690155,
          0.06458446383476257,
          0.343068391084671,
          -0.6130366921424866,
          -0.6136513352394104,
          1.237935185432434,
          0.852789044380188,
          -0.18385350704193115,
          1.0673816204071045,
          1.2932319641113281,
          0.876395046710968,
          0.044260986149311066,
          0.4912732243537903,
          -0.4105570316314697,
          0.20456300675868988,
          -0.8682007789611816,
          0.8826658129692078,
          -0.3526783287525177,
          0.011436376720666885,
          -0.6973015666007996,
          1.092413306236267,
          0.5438872575759888,
          0.09959574043750763,
          0.2343398928642273,
          -0.8081367015838623,
          -0.14339551329612732,
          -0.738399088382721,
          0.31609877943992615,
          -0.21966496109962463,
          0.9149336218833923,
          -0.3775240480899811,
          0.09406690299510956,
          0.6644356846809387,
          -0.396424263715744,
          3.6757326126098633,
          0.9629470705986023,
          -0.21800097823143005,
          0.22196628153324127,
          0.35729002952575684,
          0.8890576958656311,
          0.8170879483222961,
          -0.1461111456155777,
          0.861059308052063,
          -0.4671255648136139,
          0.1168849915266037,
          -0.497933954000473,
          0.7711542248725891,
          -0.027095085009932518,
          -0.11065198481082916,
          -0.3689420819282532,
          -0.9346939325332642,
          0.49919068813323975,
          -0.06482499837875366,
          -0.15906399488449097,
          -0.9572105407714844,
          0.4982790946960449,
          0.32891732454299927,
          -0.6426466107368469,
          0.13450288772583008,
          0.6203463077545166,
          0.09485606849193573,
          -0.2257881611585617,
          -0.22552599012851715,
          -0.1952027976512909,
          -0.036395251750946045,
          -0.5867994427680969,
          -0.6816620826721191,
          0.07672391831874847,
          0.22622403502464294,
          0.8530284762382507,
          -0.16885650157928467,
          -0.9048223495483398,
          -0.31608909368515015,
          1.6678293943405151,
          0.6677819490432739,
          -0.29866817593574524,
          -0.7195801138877869,
          -0.2900727689266205,
          0.05289572477340698,
          0.6279746294021606,
          0.49959081411361694,
          0.13865907490253448,
          1.0043331384658813,
          -0.5982387661933899,
          0.37530651688575745,
          -1.2164640426635742,
          0.23181501030921936,
          -0.011655614711344242,
          0.6054805517196655,
          0.25588658452033997,
          -0.23718245327472687,
          -0.24725043773651123,
          -0.8983394503593445,
          0.46613338589668274,
          0.6249473690986633,
          -0.6931591629981995,
          -0.3967249393463135,
          0.34719032049179077,
          0.038299560546875,
          -0.30289024114608765,
          0.8535487651824951,
          0.1099306046962738,
          -0.4060242772102356,
          -0.11959512531757355,
          0.2873411774635315,
          0.0456903837621212,
          -0.1481189876794815,
          0.07834534347057343,
          0.2669421434402466,
          -0.05261800438165665,
          -0.39823949337005615,
          0.5773678421974182,
          -0.1729145050048828,
          -0.273822546005249,
          0.03831663727760315,
          -0.5536711812019348,
          -0.19929485023021698,
          -0.25580841302871704,
          0.0804266631603241,
          0.5937440395355225,
          0.04711367189884186,
          0.2900739014148712,
          -0.6983377933502197,
          0.01968957483768463,
          -0.4278329610824585,
          -0.3089422285556793,
          -0.0317109078168869,
          -0.004856474697589874,
          0.29709553718566895
        ]
      },
      "type": "document"
    },
    {
      "id": "e77986e5-f7ed-48fe-8776-4d7974c6e1f5",
      "properties": {
        "page_content": "model R-Precision Recall@5 Rouge-L F1 KILT-RL KILT-F1\ntest\nT5 0.0 0.0 19.08 16.1 0.0 0.0\nBART 0.0 0.0 20.55 19.23 0.0 0.0\nRAG 11.0 22.92 14.05 14.51 1.69 1.79\nBART + DPR 10.67 26.92 17.41 17.88 1.9 2.01\ndev\nT5 0.0 0.0 21.02 18.36 0.0 0.0\nBART 0.0 0.0 22.69 22.19 0.0 0.0\nRAG 16.39 27.27 16.11 17.24 2.65 2.88\nBART + DPR 16.32 21.11 18.53 18.75 2.87 2.89\nTable 16: ELI5\nmodel R-Precision Recall@5 Rouge-L F1 KILT-RL KILT-F1\ntest\nBART 0.0 0.0 11.77 12.86 0.0 0.0\nT5 0.0 0.0 12.40 13.53 0.0 0.0\nTransMemNet 18.35 18.35 10.11 11.85 1.85 2.2\nBART + DPR 25.46 55.1 13.23 15.19 3.71 4.37\nRAG 57.75 74.61 11.57 13.11 7.59 8.75\ndev\nBART 0.0 0.0 12.25 13.77 0.0 0.0\nT5 0.0 0.0 12.36 13.15 0.0 0.0\nBART + DPR 0.0 0.0 13.48 15.51 0.0 0.0\nRAG 46.66 66.57 11.76 13.28 6.72 7.5\nTable 17: Wizard of Wikipedia",
        "document_metadata": {
          "page_label": "20",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing data quickly and accurately. It's also driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.15653365850448608,
          0.708324134349823,
          -0.560356616973877,
          -0.624758243560791,
          -0.09469608962535858,
          0.03837006911635399,
          0.23943999409675598,
          -0.0789840891957283,
          0.6103872060775757,
          0.5793808102607727,
          0.028625424951314926,
          0.17377528548240662,
          -0.4511544108390808,
          -1.2206224203109741,
          0.3261074423789978,
          -0.5821016430854797,
          0.07916030287742615,
          0.014927081763744354,
          0.015716910362243652,
          -0.1873658299446106,
          -0.16556397080421448,
          0.7000203132629395,
          -0.6554045677185059,
          -1.0728703737258911,
          -1.0081297159194946,
          0.5899279713630676,
          0.6182917356491089,
          -0.6848546266555786,
          0.7326657772064209,
          0.6235379576683044,
          -0.16303704679012299,
          -0.1524888277053833,
          0.1763075888156891,
          -0.5319058895111084,
          -0.6241199970245361,
          -0.07901151478290558,
          0.4374929666519165,
          -0.13495279848575592,
          -1.1674046516418457,
          -0.5684012174606323,
          0.19114980101585388,
          -0.10329393297433853,
          0.1379377394914627,
          -1.1858662366867065,
          -0.7815965414047241,
          0.4017559587955475,
          0.5267709493637085,
          -1.2063679695129395,
          0.14798139035701752,
          -0.23489812016487122,
          -0.6254692077636719,
          0.17804919183254242,
          -0.18663322925567627,
          -0.4510810673236847,
          0.08170504122972488,
          -0.981838047504425,
          -0.3865876793861389,
          -0.24507582187652588,
          -0.7136726379394531,
          -0.010788820683956146,
          0.9875109195709229,
          -0.3725390136241913,
          0.615031898021698,
          -0.015676505863666534,
          0.25003674626350403,
          0.538238525390625,
          0.13167531788349152,
          -0.4220496118068695,
          -0.42573267221450806,
          0.19983205199241638,
          -1.2177127599716187,
          -0.3109630346298218,
          0.2053534984588623,
          0.21580293774604797,
          -0.3546704649925232,
          -0.0011406056582927704,
          0.29749834537506104,
          -0.10854488611221313,
          -0.8423278331756592,
          -0.07466241717338562,
          -0.5405727028846741,
          0.7102344632148743,
          -0.42008575797080994,
          1.0988736152648926,
          -0.007839580997824669,
          -0.6118817329406738,
          0.7053322196006775,
          0.851521372795105,
          -0.20019793510437012,
          -0.6112142205238342,
          -0.061335138976573944,
          -0.06658043712377548,
          -0.17086540162563324,
          -0.18380343914031982,
          0.2512094974517822,
          0.7229158878326416,
          -0.7099315524101257,
          0.7704291343688965,
          0.2811107635498047,
          -0.08623594790697098,
          0.2449912428855896,
          1.062934160232544,
          -0.039560332894325256,
          0.9028289914131165,
          -0.7417865991592407,
          0.12378251552581787,
          0.5088061690330505,
          -0.8439984917640686,
          -0.041239842772483826,
          -1.020327091217041,
          0.6293498873710632,
          0.11896611750125885,
          -0.051500365138053894,
          0.13216882944107056,
          -0.08745969831943512,
          1.5065178871154785,
          -0.3220745921134949,
          0.3123750686645508,
          -0.3575584590435028,
          0.19347409904003143,
          -0.3775631785392761,
          -0.5309826135635376,
          0.14405721426010132,
          -0.3554430902004242,
          0.2579852342605591,
          -1.1282925605773926,
          0.07652439177036285,
          0.7570061087608337,
          -0.574580192565918,
          0.8029382824897766,
          -0.3219239115715027,
          0.1149839460849762,
          -0.3817795515060425,
          0.7845462560653687,
          0.044764213263988495,
          -0.9600052833557129,
          0.01681765913963318,
          0.8661162853240967,
          -0.28313347697257996,
          0.6386141777038574,
          0.022866930812597275,
          0.10247883200645447,
          -0.18958653509616852,
          1.8453112840652466,
          -0.4269801676273346,
          -0.13014328479766846,
          -0.4042557179927826,
          -0.047255776822566986,
          -0.40690234303474426,
          0.9484456181526184,
          -0.9908297061920166,
          0.6363150477409363,
          0.3713225722312927,
          0.040674664080142975,
          -0.6589909195899963,
          -0.7107224464416504,
          -0.6783660650253296,
          -0.03897132724523544,
          0.44300219416618347,
          0.6028366684913635,
          -0.2992573380470276,
          0.09835578501224518,
          -0.12798817455768585,
          1.163253903388977,
          -0.42693832516670227,
          0.765992283821106,
          -1.0623576641082764,
          0.17760124802589417,
          -0.5435552597045898,
          -0.32758021354675293,
          0.3110758364200592,
          -0.42307907342910767,
          -0.6316344141960144,
          -0.20029184222221375,
          0.9641396403312683,
          1.1128586530685425,
          0.8071188926696777,
          0.2090921401977539,
          0.21570439636707306,
          -0.2754162847995758,
          -1.2964560985565186,
          -0.4458135962486267,
          -0.8107640743255615,
          -0.022426173090934753,
          0.282175213098526,
          0.5131354331970215,
          0.2860373854637146,
          0.20216356217861176,
          0.3431032598018646,
          -0.47738587856292725,
          0.1462855190038681,
          0.7978888750076294,
          -1.0285212993621826,
          0.022857699543237686,
          -0.035792361944913864,
          0.48618289828300476,
          -0.7043569087982178,
          0.35886237025260925,
          0.2290552258491516,
          -0.08449157327413559,
          -0.1867326945066452,
          0.5991955995559692,
          -0.01329154521226883,
          -0.5262020826339722,
          -0.7454302310943604,
          0.5129110813140869,
          -0.17355084419250488,
          1.1027270555496216,
          -1.7994678020477295,
          1.260853886604309,
          0.5334681272506714,
          0.34254637360572815,
          -0.107000932097435,
          -0.2935619056224823,
          0.8226532340049744,
          -0.08729785680770874,
          -0.33170580863952637,
          0.44019418954849243,
          0.13208383321762085,
          -0.4107847809791565,
          -0.12969687581062317,
          -0.3397834002971649,
          0.44506511092185974,
          -0.5634165406227112,
          -0.491355299949646,
          -0.12264655530452728,
          -0.34134647250175476,
          0.9913899898529053,
          0.11103981733322144,
          0.25482499599456787,
          0.6338750720024109,
          0.6776898503303528,
          -0.3651786744594574,
          0.8207221031188965,
          -0.05390606448054314,
          0.26188549399375916,
          -0.4941505789756775,
          0.3877899646759033,
          -0.2680143415927887,
          -0.2725057899951935,
          0.7612683176994324,
          0.2042592316865921,
          1.4407943487167358,
          0.5096518993377686,
          -0.7377908825874329,
          0.18291614949703217,
          -0.028368934988975525,
          0.04344118386507034,
          0.5869894027709961,
          0.7020230889320374,
          -0.5380769371986389,
          0.17451852560043335,
          0.2182559370994568,
          -0.21384817361831665,
          -0.3749060034751892,
          0.4818163216114044,
          0.6815477609634399,
          0.635630190372467,
          0.34922853112220764,
          -1.3602954149246216,
          -0.7710537910461426,
          0.9218129515647888,
          0.5414859652519226,
          -0.02844298630952835,
          0.5035747289657593,
          0.44108107686042786,
          -0.25093764066696167,
          -0.031018413603305817,
          -0.8894982933998108,
          -0.35861238837242126,
          -1.322385549545288,
          -1.3574097156524658,
          -0.46525654196739197,
          -0.37621793150901794,
          -0.903964102268219,
          -0.13430169224739075,
          0.14654386043548584,
          -0.7400285005569458,
          0.8942035436630249,
          0.0467090830206871,
          -0.24296636879444122,
          -0.5349831581115723,
          -0.780023455619812,
          0.523067831993103,
          0.8721235990524292,
          0.5145605802536011,
          -1.2156379222869873,
          0.11846168339252472,
          -0.6136108040809631,
          0.7333815097808838,
          0.7059926390647888,
          0.49715209007263184,
          -0.14679838716983795,
          -0.5082736015319824,
          -0.10070683807134628,
          -0.33543458580970764,
          0.764856219291687,
          0.10125124454498291,
          -0.9995274543762207,
          -0.37534213066101074,
          0.03257682919502258,
          0.06765386462211609,
          -0.7529552578926086,
          -0.07277289032936096,
          0.04840793088078499,
          0.5177431106567383,
          0.22652263939380646,
          0.07084330171346664,
          1.057715654373169,
          -0.01907382905483246,
          -1.063676357269287,
          0.18975912034511566,
          -0.20608597993850708,
          0.8620506525039673,
          -0.5584468245506287,
          0.6492416858673096,
          0.28543952107429504,
          -0.7491306662559509,
          0.28436264395713806,
          -1.2617859840393066,
          -0.1663254052400589,
          0.1973085254430771,
          -0.6305858492851257,
          0.6297265291213989,
          0.1492767184972763,
          0.43625450134277344,
          0.042352091521024704,
          -1.991180419921875,
          -0.07620684057474136,
          0.09781280905008316,
          -0.4961080849170685,
          -0.11621591448783875,
          0.224753737449646,
          0.8847364187240601,
          0.8522879481315613,
          -0.4795553684234619,
          -0.043063778430223465,
          -0.02127734199166298,
          -0.28493547439575195,
          0.8193005323410034,
          0.476342111825943,
          -0.3303811252117157,
          0.32370656728744507,
          0.39031103253364563,
          -0.5224460363388062,
          0.7659452557563782,
          1.1651663780212402,
          -0.36444762349128723,
          0.7769097089767456,
          -0.25233757495880127,
          -0.18939390778541565,
          -0.22476908564567566,
          -0.42203575372695923,
          -0.3241024911403656,
          0.5063709020614624,
          0.022166896611452103,
          -0.36077043414115906,
          0.44032543897628784,
          -0.10431964695453644,
          0.049477364867925644,
          0.7558911442756653,
          0.32852160930633545,
          -0.3811362683773041,
          0.4240749478340149,
          -0.5141333341598511,
          0.18097832798957825,
          -0.190008282661438,
          0.320146381855011,
          0.26940226554870605,
          -0.734769880771637,
          0.6111953854560852,
          -0.005205660592764616,
          -0.39462342858314514,
          0.5906740427017212,
          -0.7226114273071289,
          -1.0473103523254395,
          0.45811983942985535,
          -1.0410445928573608,
          0.10715840011835098,
          -0.729506254196167,
          0.41465941071510315,
          -0.023869656026363373,
          0.0995643138885498,
          -0.29126521944999695,
          -0.24272990226745605,
          0.7271320223808289,
          -0.7361127138137817,
          0.6334934830665588,
          -0.23064333200454712,
          -0.007777445018291473,
          0.4714883863925934,
          0.11677825450897217,
          -0.5421423316001892,
          0.1865558922290802,
          -0.6669362783432007,
          -0.7818518280982971,
          1.0332555770874023,
          -0.09372512996196747,
          0.3156664967536926,
          -0.46370264887809753,
          1.1488596200942993,
          -0.11208930611610413,
          0.1034163236618042,
          0.30604591965675354,
          0.46540969610214233,
          0.2786770164966583,
          0.298591285943985,
          0.8506519794464111,
          0.5658669471740723,
          -0.3816567659378052,
          -0.18528684973716736,
          -0.6901206970214844,
          0.490439772605896,
          -0.21610264480113983,
          -0.21388526260852814,
          0.24537082016468048,
          -0.11020440608263016,
          -0.03966677933931351,
          -0.8644925355911255,
          0.10004914551973343,
          -0.5923416018486023,
          -0.09354070574045181,
          -0.802623987197876,
          0.2751564383506775,
          0.4859493374824524,
          -0.22156816720962524,
          -0.5493608117103577,
          -1.389951229095459,
          0.8455817103385925,
          0.539142906665802,
          -0.5432571768760681,
          -0.8204971551895142,
          0.7723850011825562,
          -0.26329803466796875,
          -0.1482481062412262,
          0.1932123750448227,
          1.477002739906311,
          -1.073655366897583,
          0.8722612261772156,
          -0.17458924651145935,
          0.06920646131038666,
          0.7737438678741455,
          0.34876319766044617,
          -0.009753379970788956,
          -0.3988533318042755,
          -0.45967280864715576,
          0.05419445410370827,
          0.38868486881256104,
          -0.49439483880996704,
          -0.6662508249282837,
          0.9421378970146179,
          -1.1742854118347168,
          1.0146088600158691,
          -0.3983980715274811,
          0.4877769947052002,
          -0.15690645575523376,
          -0.3795810043811798,
          -0.043067798018455505,
          0.17785920202732086,
          -0.004084660671651363,
          0.2823405861854553,
          0.2353675365447998,
          0.6542595028877258,
          -0.45311570167541504,
          -0.37921908497810364,
          0.10479998588562012,
          0.7740886807441711,
          0.3479619026184082,
          0.5438047647476196,
          0.18174457550048828,
          0.11987702548503876,
          -0.30295875668525696,
          0.1368318498134613,
          -0.6077490448951721,
          0.778857946395874,
          -0.6490302681922913,
          0.6108367443084717,
          0.4118753671646118,
          -0.6285769939422607,
          -0.5030165910720825,
          -0.739553689956665,
          -0.13659991323947906,
          0.47010958194732666,
          0.009283233433961868,
          -0.39604055881500244,
          -0.9439961314201355,
          0.4410858452320099,
          1.0023729801177979,
          -0.10729847848415375,
          0.5628648996353149,
          0.2573319673538208,
          0.27273619174957275,
          -0.17489561438560486,
          0.5664963126182556,
          0.03323373198509216,
          0.08951133489608765,
          0.16944998502731323,
          0.43350496888160706,
          -0.3493611812591553,
          -0.5842875242233276,
          1.3619498014450073,
          -1.5692031383514404,
          -1.1211581230163574,
          -0.10948480665683746,
          -0.3839985132217407,
          -0.4577986001968384,
          -0.15327897667884827,
          -0.37730634212493896,
          -0.0552467405796051,
          0.2962070107460022,
          -0.03578932583332062,
          0.04343892261385918,
          0.03839841112494469,
          0.4220774471759796,
          0.4198085367679596,
          -0.10207931697368622,
          0.08839128166437149,
          0.2172068953514099,
          -0.08884144574403763,
          1.3479490280151367,
          0.4056376814842224,
          -1.158109426498413,
          -0.23603032529354095,
          1.414937973022461,
          -0.8952568769454956,
          -0.047682106494903564,
          0.3120218515396118,
          -0.9829236268997192,
          0.048443011939525604,
          -1.624509334564209,
          0.22830790281295776,
          -0.2369566559791565,
          -0.14230650663375854,
          -0.15289755165576935,
          0.2415873259305954,
          0.1781793236732483,
          0.40931960940361023,
          0.551429808139801,
          -0.4621402621269226,
          -0.5434077978134155,
          0.1399441957473755,
          -0.10551683604717255,
          -0.32558929920196533,
          -0.7182134389877319,
          -0.11811021715402603,
          -0.22128117084503174,
          0.4561665952205658,
          0.658332347869873,
          -0.6081880331039429,
          -0.6818138957023621,
          0.3686807453632355,
          -0.5574904680252075,
          -0.04323532432317734,
          0.6026723384857178,
          -1.1020126342773438,
          -0.3978703022003174,
          0.26181769371032715,
          0.29128456115722656,
          0.46958473324775696,
          0.986249566078186,
          -0.5688857436180115,
          -0.3975059688091278,
          0.4033031761646271,
          -0.01668553426861763,
          -0.5717719197273254,
          0.32489854097366333,
          -0.9397135376930237,
          -0.6403915286064148,
          1.1761244535446167,
          -0.5005905628204346,
          -0.6583921313285828,
          0.14916302263736725,
          0.48593977093696594,
          0.7481585741043091,
          0.43625229597091675,
          -0.9971951246261597,
          -0.5383151769638062,
          -0.31694960594177246,
          -1.008111834526062,
          -0.24826711416244507,
          -0.5338794589042664,
          -0.33623456954956055,
          -0.47699257731437683,
          0.1457827240228653,
          0.49600738286972046,
          -0.3539901673793793,
          0.3364388048648834,
          1.266629695892334,
          0.5432025194168091,
          -0.534518301486969,
          0.2369132936000824,
          -0.14540165662765503,
          0.3798498511314392,
          -0.28903934359550476,
          -0.01882995292544365,
          -0.1768338680267334,
          0.0675683468580246,
          -0.3965558409690857,
          0.22460128366947174,
          -0.4001605212688446,
          -0.023713089525699615,
          0.3762018382549286,
          0.7118687033653259,
          -0.7778497934341431,
          0.8103549480438232,
          0.4877917170524597,
          -0.5454842448234558,
          -0.6775347590446472,
          -0.1553385704755783,
          -0.05567336827516556,
          -0.28285014629364014,
          0.36298877000808716,
          0.6876521110534668,
          0.24767452478408813,
          0.6072570085525513,
          -0.3430311977863312,
          -0.9004305601119995,
          -0.40982645750045776,
          0.9287248253822327,
          0.08168631047010422,
          -0.7443946599960327,
          0.1597026139497757,
          1.014836072921753,
          -0.394724041223526,
          -0.29386141896247864,
          0.5423461198806763,
          -0.08880148082971573,
          0.6268293261528015,
          -0.5828396677970886,
          0.618937611579895,
          -0.6293707489967346,
          0.2957180142402649,
          -0.01937435194849968,
          0.5355813503265381,
          -0.3147629499435425,
          0.23315727710723877,
          1.4478720426559448,
          0.6608597636222839,
          -0.8242902159690857,
          0.024297622963786125,
          0.566325306892395,
          -0.10012564063072205,
          0.2818353772163391,
          -1.5161789655685425,
          0.1990036964416504,
          -0.1279444694519043,
          -0.7836253046989441,
          0.6842582821846008,
          -1.144577980041504,
          -0.4647907018661499,
          0.7075212001800537,
          0.34748131036758423,
          0.07579702138900757,
          -0.5246375799179077,
          -0.3022536039352417,
          0.2722826600074768,
          0.41016602516174316,
          -0.7137351632118225,
          -0.5804339051246643,
          1.0996284484863281,
          -0.19714947044849396,
          0.26092877984046936,
          -0.1783788949251175,
          -0.41424909234046936,
          0.9819537997245789,
          0.5875053405761719,
          -0.3575723469257355,
          -0.4140152335166931,
          -0.20120932161808014,
          -1.2741118669509888,
          -0.6932954788208008,
          0.0563211515545845,
          0.41846123337745667,
          -0.16348043084144592,
          0.44399431347846985,
          0.4794367551803589,
          -0.3574368357658386,
          -0.44746315479278564,
          0.27656567096710205,
          -0.9505319595336914,
          -1.0746614933013916,
          -0.2753482460975647,
          0.4009734094142914,
          -0.18850743770599365,
          0.19579333066940308,
          -0.02017737738788128,
          0.13258510828018188,
          0.08843790739774704,
          0.9455509185791016,
          -0.5432841777801514,
          0.3054235577583313,
          0.1862870454788208,
          0.40277478098869324,
          -0.6511672139167786,
          -0.2864965796470642,
          -0.38615140318870544,
          -0.12715351581573486,
          -0.5177202224731445,
          0.044396307319402695,
          0.013225503265857697,
          0.25602495670318604,
          0.29710322618484497,
          -0.6822868585586548,
          0.30312708020210266,
          -0.38473403453826904,
          0.4831378161907196,
          -0.6684404015541077,
          0.22449138760566711,
          0.4820908308029175,
          -0.25279897451400757,
          0.3364286422729492,
          -1.060884952545166,
          1.0425242185592651,
          0.02532900869846344,
          -0.8520940542221069,
          0.923346757888794,
          -0.10062302649021149,
          0.0969165712594986,
          -0.3142911195755005,
          -0.37941235303878784,
          0.6194565296173096,
          -0.20577862858772278,
          0.6876670122146606,
          -0.23828467726707458,
          0.3564528226852417,
          0.06683743745088577,
          -0.9462215900421143,
          0.0390491746366024,
          -0.992782473564148,
          -0.20325806736946106,
          -0.8169424533843994,
          -0.4014189839363098,
          0.17528203129768372,
          -0.29771897196769714,
          -0.5075219869613647,
          0.7429842948913574,
          -0.21589529514312744,
          -0.9682029485702515,
          -0.2072329968214035,
          -0.190838024020195,
          0.8716657757759094,
          0.44681328535079956,
          0.14224350452423096,
          0.21314871311187744,
          -0.6299813389778137,
          -0.7876022458076477,
          -0.3957195580005646,
          -0.4768466651439667,
          -0.10907924175262451,
          0.6112782955169678,
          0.49057140946388245,
          0.2851651608943939,
          0.7650251388549805,
          0.0496409609913826,
          0.07980100810527802,
          0.41228562593460083,
          0.6957800984382629,
          0.009414851665496826,
          0.687628984451294,
          0.40633639693260193,
          -0.14659878611564636,
          -0.5218808650970459,
          -0.9815675020217896,
          0.10703086107969284,
          0.8396716713905334,
          -0.32688355445861816,
          -0.6576793789863586,
          0.4729442000389099,
          -0.16071245074272156,
          0.33664822578430176,
          -0.6444533467292786,
          -0.4752994775772095,
          0.42019325494766235,
          -0.24785108864307404,
          0.09296870976686478,
          -0.3198826014995575,
          0.4682181477546692,
          -0.7585410475730896,
          0.061410509049892426,
          0.5820885300636292,
          0.6443547606468201,
          -0.682172954082489,
          0.5964787006378174,
          0.44627219438552856,
          -0.5297372341156006,
          -0.5860797166824341,
          -0.19234001636505127,
          0.7413369417190552,
          -0.6475535035133362,
          0.12633658945560455,
          -0.4700397849082947,
          0.39188382029533386,
          0.3458237648010254,
          -0.1652372181415558,
          -0.22780561447143555,
          0.3097466826438904,
          0.656546413898468,
          -0.06480179727077484,
          0.17460386455059052,
          0.0915309339761734,
          1.2256224155426025,
          -0.11712642014026642,
          0.4611494541168213,
          0.11872176826000214,
          0.5300162434577942,
          -0.7767677903175354,
          0.30489781498908997,
          -0.4484255313873291,
          1.0337624549865723,
          -1.7379320859909058,
          -0.6123526096343994,
          0.34355807304382324,
          0.2977347671985626,
          -0.8610678315162659,
          -0.3328772187232971,
          -0.6689872741699219,
          0.8416300415992737,
          0.21940886974334717,
          -0.7281399369239807,
          -0.017353132367134094,
          0.025076769292354584,
          0.030459925532341003,
          0.3595307469367981,
          0.1019427478313446,
          -0.6763505339622498,
          0.05435876548290253,
          -0.042997993528842926,
          0.4085600972175598,
          -0.4293225109577179,
          0.36559614539146423,
          0.12243112921714783,
          0.008666843175888062,
          -0.3008457124233246,
          0.6512165665626526,
          -0.5156687498092651,
          1.1130118370056152,
          0.27607929706573486,
          -0.7316861748695374,
          1.0574846267700195,
          0.4277787506580353,
          -0.6921562552452087,
          0.5134249925613403,
          -0.5672995448112488,
          -0.34477272629737854,
          -0.9766578674316406,
          1.0090289115905762,
          -0.8079153895378113,
          0.40301480889320374,
          0.3951280415058136,
          -0.3891471028327942,
          -0.4080823063850403,
          -0.18912118673324585,
          -0.28368687629699707,
          0.01569371670484543,
          0.33860155940055847,
          0.6117508411407471,
          0.1495250016450882,
          1.5234365463256836,
          1.4135113954544067,
          -0.31347838044166565,
          -0.4911382496356964,
          0.19149985909461975,
          -0.04826686903834343,
          -0.05306503176689148,
          0.012795019894838333,
          -0.7844491600990295,
          -0.2685528099536896,
          0.006467126309871674,
          -0.8824511766433716,
          -0.6979475617408752,
          0.09085295349359512,
          0.041855067014694214,
          0.5291812419891357,
          -0.41976261138916016,
          1.2101349830627441,
          0.0051609668880701065,
          0.30707991123199463,
          -0.2002393752336502,
          0.5258342027664185,
          0.36152857542037964,
          0.3313086926937103,
          0.2804800271987915,
          -0.4149229824542999,
          0.37876296043395996,
          -1.238918423652649,
          0.6508767604827881,
          -0.08156254887580872,
          -0.2524743676185608,
          0.10473571717739105,
          -0.07590718567371368,
          -0.5118759274482727,
          -0.8349488973617554,
          0.8667076826095581,
          -0.5723527669906616,
          -0.14943575859069824,
          -0.04972121864557266,
          -0.09882457554340363,
          0.31965160369873047,
          -0.6771113276481628,
          -0.2635098695755005,
          1.1469593048095703,
          0.7447392344474792,
          -0.2591286301612854,
          0.8192577958106995,
          1.3501784801483154,
          0.9687798619270325,
          0.013457588851451874,
          0.3341403007507324,
          -0.08436164259910583,
          0.345522940158844,
          -1.0202994346618652,
          0.7642030715942383,
          -0.19275620579719543,
          0.008139311335980892,
          -0.7349116206169128,
          1.2096188068389893,
          0.7447709441184998,
          0.0005538463592529297,
          0.2538502812385559,
          -0.7857574820518494,
          -0.23966079950332642,
          -0.6846359372138977,
          0.4173996150493622,
          -0.3473036587238312,
          1.0933700799942017,
          -0.28647053241729736,
          -0.05417036637663841,
          0.6269860863685608,
          -0.5978345274925232,
          3.5657787322998047,
          1.318716287612915,
          0.021642081439495087,
          0.3793289065361023,
          0.45985302329063416,
          0.8133774995803833,
          0.9093849062919617,
          -0.31138113141059875,
          0.6761907935142517,
          -0.5280838012695312,
          0.4034545421600342,
          -0.8472446203231812,
          0.8351603150367737,
          0.33330798149108887,
          -0.073401540517807,
          -0.2790341079235077,
          -0.5837350487709045,
          0.32553693652153015,
          0.08723407238721848,
          -0.2468281090259552,
          -1.3090401887893677,
          0.19035962224006653,
          0.3705998957157135,
          -0.3402388393878937,
          0.3052540123462677,
          0.6694070100784302,
          0.19251292943954468,
          -0.1422661542892456,
          -0.11738519370555878,
          -0.46984854340553284,
          -0.049839362502098083,
          -0.7106822729110718,
          -0.3314325213432312,
          -0.13379144668579102,
          0.3076585531234741,
          0.8188632130622864,
          -0.08511636406183243,
          -0.8094332218170166,
          -0.33407631516456604,
          1.5080631971359253,
          0.40011996030807495,
          -0.7578743100166321,
          -0.5435038208961487,
          -0.5639440417289734,
          0.2253168672323227,
          0.7460237741470337,
          0.2942988872528076,
          0.1065569669008255,
          0.9408413767814636,
          -1.0815892219543457,
          0.1117691844701767,
          -1.2931956052780151,
          0.015232143923640251,
          -0.37238359451293945,
          0.3629463016986847,
          0.21745309233665466,
          -0.1878853142261505,
          -0.3146955072879791,
          -1.110607385635376,
          0.29213854670524597,
          0.6974125504493713,
          -0.6861408352851868,
          -0.5340103507041931,
          0.5912420153617859,
          -0.2295331060886383,
          -0.5636546611785889,
          0.8891451358795166,
          0.38669291138648987,
          -0.29921042919158936,
          0.013464897871017456,
          0.0789007768034935,
          0.08019280433654785,
          -0.22251994907855988,
          0.25198790431022644,
          -0.0014303922653198242,
          0.22817721962928772,
          -0.32455548644065857,
          0.8230305910110474,
          -0.018627911806106567,
          -0.39539268612861633,
          0.04176848381757736,
          -0.5496541261672974,
          -0.2663114666938782,
          -0.14119896292686462,
          0.3184998631477356,
          0.8744829297065735,
          -0.22881054878234863,
          0.22573205828666687,
          -0.5826312303543091,
          0.21203553676605225,
          -0.3333989977836609,
          -0.27253082394599915,
          0.38679084181785583,
          -0.031202103942632675,
          0.04873098433017731
        ]
      },
      "type": "document"
    },
    {
      "id": "06ab69d4-b404-47b6-a030-988f6ccd6828",
      "properties": {
        "page_content": " 0\n 5000\n 10000\n 15000\n 20000\n 25000\n 30000\n 35000\n 40000\n 45000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(a) FEVER, dev data discarded 26.03% (3675), test data\ndiscarded 27.7% (3869).\n 0\n 10000\n 20000\n 30000\n 40000\n 50000\n 60000\n 70000\n 80000\n 90000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(b) Natural Questions, dev data discarded 16.12% (595), test\ndata discarded 15.59% (287).\n 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(c) HotpotQA, dev data discarded 22.76% (1650), test data\ndiscarded 23.43% (1704).\n 0\n 200000\n 400000\n 600000\n 800000\n 1x10 6\n 1.2x10 6\n 1.4x10 6\n 1.6x10 6\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(d) TriviaQA, dev data discarded 15.06% (950), test data\ndiscarded 14.41% (1109).\n 0\n 20000\n 40000\n 60000\n 80000\n 100000\n 120000\n 140000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(e) Zero Shot RE, dev data discarded 15.42% (679), test data\ndiscarded 13.38% (767).\n 0\n 10000\n 20000\n 30000\n 40000\n 50000\n 60000\n 0  0.2  0.4  0.6  0.8  1\nnumber of provenance spans\nBLEU score\n(f) Wizard of Wikipedia, dev data discarded 12.06% (469),\ntest data discarded 11.39% (427).\nFigure 5: BLEU score distribution in train data per provenance. For TriviaQA, we try to map all object aliases for\nthe answer. FEVER has the oldest Wikipedia snapshot. We discards on average 17.9% dev and 17.65% test data.\nFor TriviaQA there are a large number of 0 scores because we try to map all aliases for the answer and most of the\naliases are not found in a Wikipedia page. Note that we consider a QA pair valid if we match at least one alias.",
        "document_metadata": {
          "page_label": "22",
          "file_name": "2009.02252v4.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
          "file_type": "application/pdf",
          "file_size": 836403,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-10-10"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ],
        "themes": [
          "BLEU score",
          "Provenance spans",
          "FEVER",
          "Natural Questions",
          "HotpotQA",
          "TriviaQA",
          "Zero Shot RE",
          "Wizard of Wikipedia",
          "Object aliases",
          "Wikipedia snapshot"
        ]
      },
      "type": "document"
    },
    {
      "id": "f8ec2727-a40d-413c-b984-32dd066eaa3f",
      "properties": {
        "page_content": "RAGAS: Automated Evaluation of Retrieval Augmented Generation\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\n†Exploding Gradients\n∗CardiffNLP, Cardiff University, United Kingdom\n♢AMPLYFI, United Kingdom\nshahules786@gmail.com,jamesjithin97@gmail.com\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\nAbstract\nWe introduce RAGA S (Retrieval Augmented\nGeneration Assessment), a framework for\nreference-free evaluation of Retrieval Aug-\nmented Generation (RAG) pipelines. RAG\nsystems are composed of a retrieval and an\nLLM based generation module, and provide\nLLMs with knowledge from a reference textual\ndatabase, which enables them to act as a natu-\nral language layer between a user and textual\ndatabases, reducing the risk of hallucinations.\nEvaluating RAG architectures is, however, chal-\nlenging because there are several dimensions to\nconsider: the ability of the retrieval system to\nidentify relevant and focused context passages,\nthe ability of the LLM to exploit such passages\nin a faithful way, or the quality of the gener-\nation itself. With RAGA S, we put forward a\nsuite of metrics which can be used to evaluate\nthese different dimensions without having to\nrely on ground truth human annotations. We\nposit that such a framework can crucially con-\ntribute to faster evaluation cycles of RAG archi-\ntectures, which is especially important given\nthe fast adoption of LLMs.\n1 Introduction\nLanguage Models (LMs) capture a vast amount\nof knowledge about the world, which allows them\nto answer questions without accessing any exter-\nnal sources. This idea of LMs as repositories of\nknowledge emerged shortly after the introduction\nof BERT (Devlin et al., 2019) and became more\nfirmly established with the introduction of ever\nlarger LMs (Roberts et al., 2020). While the most\nrecent Large Language Models (LLMs) capture\nenough knowledge to rival human performance\nacross a wide variety of question answering bench-\nmarks (Bubeck et al., 2023), the idea of using\nLLMs as knowledge bases still has two fundamen-\ntal limitations. First, LLMs are not able to answer\nquestions about events that have happened after\nthey were trained. Second, even the largest models\nstruggle to memorise knowledge that is only rarely\nmentioned in the training corpus (Kandpal et al.,\n2022; Mallen et al., 2023). The standard solution\nto these issues is to rely on Retrieval Augmented\nGeneration (RAG) (Lee et al., 2019; Lewis et al.,\n2020; Guu et al., 2020). Answering a question\nthen essentially involves retrieving relevant pas-\nsages from a corpus and feeding these passages,\nalong with the original question, to the LM. While\ninitial approaches relied on specialised LMs for\nretrieval-augmented language modelling (Khandel-\nwal et al., 2020; Borgeaud et al., 2022), recent work\nhas suggested that simply adding retrieved docu-\nments to the input of a standard LM can also work\nwell (Khattab et al., 2022; Ram et al., 2023; Shi\net al., 2023), thus making it possible to use retrieval-\naugmented strategies in combination with LLMs\nthat are only available through APIs.\nWhile the usefulness of retrieval-augmented\nstrategies is clear, their implementation requires\na significant amount of tuning, as the overall per-\nformance will be affected by the retrieval model,\nthe considered corpus, the LM, or the prompt for-\nmulation, among others. Automated evaluation of\nretrieval-augmented systems is thus paramount. In\npractice, RAG systems are often evaluated in terms\nof the language modelling task itself, i.e. by mea-\nsuring perplexity on some reference corpus. How-\never, such evaluations are not always predictive\nof downstream performance (Wang et al., 2023c).\nMoreover, this evaluation strategy relies on the LM\nprobabilities, which are not accessible for some\nclosed models (e.g. ChatGPT and GPT-4). Ques-\ntion answering is another common evaluation task,\nbut usually only datasets with short extractive an-\nswers are considered, which may not be represen-\ntative of how the system will be used.\nTo address these issues, in this paper we present\nRAGA S1, a framework for the automated assess-\n1RAGA S is available at https://github.com/\nexplodinggradients/ragas.\narXiv:2309.15217v1  [cs.CL]  26 Sep 2023",
        "document_metadata": {
          "page_label": "1",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Exploring Gradients",
          "CardiffNLP, Cardiff University, United Kingdom",
          "AMPLYFI, United Kingdom",
          "Retrieval Augmented Generation Assessment",
          "Reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines.",
          "Introduction",
          "Language Models (LMs) capture a vast amount\nof knowledge about the world",
          "1 Introduction"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks and analyzing data quickly and accurately. It's driving innovations in self-driving cars, personalized recommendations, and beyond.",
        "summary_embedding": [
          0.14491006731987,
          0.7293171882629395,
          -0.6271472573280334,
          -0.5915148854255676,
          -0.07605153322219849,
          0.01856072060763836,
          0.3215545415878296,
          -0.06993064284324646,
          0.6821730136871338,
          0.546470046043396,
          0.051694922149181366,
          0.20061293244361877,
          -0.5623824596405029,
          -1.209928035736084,
          0.43170854449272156,
          -0.4833289086818695,
          0.10599437355995178,
          0.13559004664421082,
          0.1062064915895462,
          -0.18593424558639526,
          -0.17737820744514465,
          0.6567258238792419,
          -0.7246704697608948,
          -1.0311579704284668,
          -0.9934620261192322,
          0.594208836555481,
          0.6819546222686768,
          -0.6172968745231628,
          0.7176986336708069,
          0.6541121602058411,
          -0.24097101390361786,
          -0.13895580172538757,
          0.1762460321187973,
          -0.5704410076141357,
          -0.656462550163269,
          -0.10585933178663254,
          0.41973644495010376,
          -0.13461841642856598,
          -1.1240050792694092,
          -0.5813807249069214,
          0.20094019174575806,
          -0.03304702788591385,
          0.13460637629032135,
          -1.2236924171447754,
          -0.8530169129371643,
          0.3229931592941284,
          0.6351921558380127,
          -1.1765165328979492,
          0.22640225291252136,
          -0.2067311406135559,
          -0.5657105445861816,
          0.1795324832201004,
          -0.17413002252578735,
          -0.44250649213790894,
          0.03034123219549656,
          -0.8841649293899536,
          -0.2909459173679352,
          -0.20691460371017456,
          -0.6908555626869202,
          0.005349412560462952,
          1.0078459978103638,
          -0.3361613154411316,
          0.5587680339813232,
          -0.09360213577747345,
          0.23938274383544922,
          0.5552699565887451,
          0.10239396244287491,
          -0.5328946113586426,
          -0.3956565856933594,
          0.22636303305625916,
          -1.1315890550613403,
          -0.37553906440734863,
          0.20711848139762878,
          0.1943015158176422,
          -0.3677084445953369,
          -0.01030682772397995,
          0.2224898487329483,
          -0.10822716355323792,
          -0.8750413656234741,
          -0.12524981796741486,
          -0.48074010014533997,
          0.7319472432136536,
          -0.46775269508361816,
          1.0648090839385986,
          0.06769385188817978,
          -0.5695379972457886,
          0.6638012528419495,
          0.817287027835846,
          -0.2030089795589447,
          -0.6380760073661804,
          -0.05993981286883354,
          3.3406540751457214e-05,
          -0.12081266939640045,
          -0.08515084534883499,
          0.23677249252796173,
          0.6856545209884644,
          -0.6617090702056885,
          0.733138382434845,
          0.1902327835559845,
          0.004695378243923187,
          0.24249640107154846,
          1.1467443704605103,
          -0.07832852751016617,
          0.933942437171936,
          -0.7639671564102173,
          0.11388882249593735,
          0.5277906656265259,
          -0.7994402050971985,
          -0.03332919999957085,
          -1.0506131649017334,
          0.6703979969024658,
          0.14598070085048676,
          -0.02095957100391388,
          0.10878250747919083,
          -0.14291422069072723,
          1.5824933052062988,
          -0.3727037310600281,
          0.3858047425746918,
          -0.29342469573020935,
          0.17416909337043762,
          -0.34732818603515625,
          -0.6300263404846191,
          0.14440974593162537,
          -0.18215973675251007,
          0.16750958561897278,
          -1.0908950567245483,
          0.033356234431266785,
          0.7452912330627441,
          -0.5780020356178284,
          0.8225215673446655,
          -0.3107801675796509,
          0.057770490646362305,
          -0.29084283113479614,
          0.7874050736427307,
          0.02130809798836708,
          -0.9624268412590027,
          0.06777006387710571,
          0.8785864114761353,
          -0.3015173077583313,
          0.6167946457862854,
          0.051957204937934875,
          0.06279870122671127,
          -0.22765308618545532,
          1.8964109420776367,
          -0.37138158082962036,
          -0.1664838194847107,
          -0.4071781039237976,
          0.09780901670455933,
          -0.38811951875686646,
          0.8954901695251465,
          -0.9377301931381226,
          0.6905332207679749,
          0.2978716790676117,
          -0.0017617207486182451,
          -0.8336667418479919,
          -0.6594575643539429,
          -0.6156218647956848,
          -0.00888735055923462,
          0.4990394711494446,
          0.5589882135391235,
          -0.4339905381202698,
          0.038956597447395325,
          -0.08464522659778595,
          1.0527470111846924,
          -0.4497939348220825,
          0.7791237235069275,
          -0.9343700408935547,
          0.13707058131694794,
          -0.5798563361167908,
          -0.2808893024921417,
          0.37345778942108154,
          -0.37857502698898315,
          -0.6129647493362427,
          -0.17962795495986938,
          0.9047166705131531,
          1.0212504863739014,
          0.8156511783599854,
          0.22024767100811005,
          0.23639750480651855,
          -0.1549745798110962,
          -1.3042793273925781,
          -0.3787582516670227,
          -0.7790899276733398,
          -0.07632862031459808,
          0.2717057168483734,
          0.5669084787368774,
          0.18278001248836517,
          0.19081252813339233,
          0.18234111368656158,
          -0.5066397786140442,
          0.1367904245853424,
          0.8739169836044312,
          -1.0308196544647217,
          -0.003314092755317688,
          -0.11714953184127808,
          0.5469750165939331,
          -0.7202537059783936,
          0.34715667366981506,
          0.24043799936771393,
          -0.15023589134216309,
          -0.24552832543849945,
          0.5882987380027771,
          0.1235290914773941,
          -0.5451493263244629,
          -0.7485794425010681,
          0.5439903140068054,
          -0.1725970357656479,
          1.1481035947799683,
          -1.9177641868591309,
          1.2726131677627563,
          0.5044423937797546,
          0.2905133068561554,
          0.029540464282035828,
          -0.18206118047237396,
          0.804972231388092,
          -0.24098829925060272,
          -0.3360374867916107,
          0.5739344358444214,
          0.17197763919830322,
          -0.34030991792678833,
          -0.16139040887355804,
          -0.41685208678245544,
          0.43739408254623413,
          -0.4728797674179077,
          -0.4882449209690094,
          -0.24198725819587708,
          -0.31184330582618713,
          0.8908900618553162,
          -0.05608506500720978,
          0.19519750773906708,
          0.6663210391998291,
          0.7054603695869446,
          -0.3769541084766388,
          0.8291587233543396,
          -0.07814548909664154,
          0.17941030859947205,
          -0.4379116892814636,
          0.44209641218185425,
          -0.24563853442668915,
          -0.2520541846752167,
          0.8162983655929565,
          0.03869679197669029,
          1.4760921001434326,
          0.43292778730392456,
          -0.6370487213134766,
          0.09464038163423538,
          0.08893825113773346,
          0.04542867839336395,
          0.503454327583313,
          0.7983428835868835,
          -0.5590014457702637,
          0.21443034708499908,
          0.3319363594055176,
          -0.3033733069896698,
          -0.3121938407421112,
          0.4546054005622864,
          0.7085872888565063,
          0.5526789426803589,
          0.2883468568325043,
          -1.3027536869049072,
          -0.6883053183555603,
          0.9156017899513245,
          0.5215632319450378,
          -0.02122505009174347,
          0.4605244994163513,
          0.4167693257331848,
          -0.23335982859134674,
          -0.10286518931388855,
          -0.8716436624526978,
          -0.4336486756801605,
          -1.3062232732772827,
          -1.3694345951080322,
          -0.46570253372192383,
          -0.3360365033149719,
          -0.9171434044837952,
          -0.17553311586380005,
          0.1239003837108612,
          -0.6185507774353027,
          0.8758683800697327,
          0.05602867901325226,
          -0.2769632637500763,
          -0.4956156611442566,
          -0.7870106101036072,
          0.6000607013702393,
          0.832597553730011,
          0.45970219373703003,
          -1.1697825193405151,
          0.05285618454217911,
          -0.601468563079834,
          0.7560400366783142,
          0.7074212431907654,
          0.4788329601287842,
          -0.25437766313552856,
          -0.5997072458267212,
          -0.07530292868614197,
          -0.32630664110183716,
          0.7625753879547119,
          0.1558753252029419,
          -0.9766115546226501,
          -0.30957454442977905,
          0.10287868976593018,
          0.10675094276666641,
          -0.8262974619865417,
          -0.061342280358076096,
          0.03400631248950958,
          0.45828601717948914,
          0.33405807614326477,
          0.15869398415088654,
          0.9982643127441406,
          -0.00851500779390335,
          -1.0188844203948975,
          0.23987890779972076,
          -0.18080288171768188,
          0.8902943730354309,
          -0.5567019581794739,
          0.6212546825408936,
          0.24919359385967255,
          -0.7580722570419312,
          0.32135799527168274,
          -1.2940237522125244,
          -0.25669538974761963,
          0.21082013845443726,
          -0.6783192157745361,
          0.589669942855835,
          0.13699433207511902,
          0.4925159215927124,
          0.06577488780021667,
          -2.075859546661377,
          -0.0831948071718216,
          0.0018185917288064957,
          -0.3332328796386719,
          -0.05662785470485687,
          0.2453954815864563,
          0.9287078976631165,
          0.8592918515205383,
          -0.49699169397354126,
          -0.08103184401988983,
          -0.01454719714820385,
          -0.3119962215423584,
          0.9114399552345276,
          0.6035048961639404,
          -0.36412954330444336,
          0.37462085485458374,
          0.41821032762527466,
          -0.5625166296958923,
          0.7943591475486755,
          1.106265902519226,
          -0.29777824878692627,
          0.8373010754585266,
          -0.02194179594516754,
          -0.2026282250881195,
          -0.2466791421175003,
          -0.41245022416114807,
          -0.48395514488220215,
          0.5187005400657654,
          0.025499798357486725,
          -0.45439547300338745,
          0.45283037424087524,
          -0.1649799346923828,
          0.13378570973873138,
          0.6333810687065125,
          0.27596449851989746,
          -0.4081133008003235,
          0.4115375280380249,
          -0.5625191926956177,
          0.1747746765613556,
          -0.1925879865884781,
          0.3306244909763336,
          0.34070897102355957,
          -0.5996335744857788,
          0.6371681094169617,
          -0.03791091591119766,
          -0.2999626100063324,
          0.6107130646705627,
          -0.7670974135398865,
          -1.006619930267334,
          0.508938193321228,
          -0.9465706944465637,
          0.09422720968723297,
          -0.6857671737670898,
          0.4250926971435547,
          0.14586210250854492,
          0.09936613589525223,
          -0.23820465803146362,
          -0.2994052767753601,
          0.8232097625732422,
          -0.8292121887207031,
          0.6740497350692749,
          -0.1918032020330429,
          0.009625360369682312,
          0.4347604215145111,
          0.06383953988552094,
          -0.5253289341926575,
          0.19431541860103607,
          -0.659950315952301,
          -0.7596234679222107,
          0.9855877161026001,
          0.03323878347873688,
          0.45956143736839294,
          -0.5007491111755371,
          1.129447102546692,
          -0.2517107427120209,
          0.13630685210227966,
          0.32993659377098083,
          0.41548240184783936,
          0.18721303343772888,
          0.22233474254608154,
          0.7290647029876709,
          0.5603114366531372,
          -0.40630948543548584,
          -0.19224488735198975,
          -0.6004198789596558,
          0.4186675250530243,
          -0.18209150433540344,
          -0.08823000639677048,
          0.2900386452674866,
          -0.04734364151954651,
          -0.0182851180434227,
          -0.8862870335578918,
          0.08206567168235779,
          -0.5295459032058716,
          0.051794394850730896,
          -0.7851216793060303,
          0.3325176239013672,
          0.5068346858024597,
          -0.2341345250606537,
          -0.4777137041091919,
          -1.3771553039550781,
          0.9136757850646973,
          0.44622159004211426,
          -0.5523390769958496,
          -0.8626024127006531,
          0.7802759408950806,
          -0.3837706744670868,
          -0.25166717171669006,
          0.23797482252120972,
          1.5043667554855347,
          -1.1748806238174438,
          0.968730092048645,
          -0.22798866033554077,
          0.12302200496196747,
          0.815597653388977,
          0.48803240060806274,
          -0.16120538115501404,
          -0.41937312483787537,
          -0.5347765684127808,
          -0.0010246597230434418,
          0.43729516863822937,
          -0.5408655405044556,
          -0.6266278028488159,
          0.9629054665565491,
          -1.2721610069274902,
          1.0583281517028809,
          -0.3623805344104767,
          0.474605917930603,
          -0.13591095805168152,
          -0.40314698219299316,
          -0.01336595043540001,
          0.13963037729263306,
          -0.029686879366636276,
          0.26000145077705383,
          0.24918270111083984,
          0.6999692916870117,
          -0.5657304525375366,
          -0.3702632188796997,
          0.19638851284980774,
          0.6887037754058838,
          0.2816610634326935,
          0.5871230959892273,
          0.175147145986557,
          0.037594184279441833,
          -0.29718077182769775,
          0.04186342656612396,
          -0.5724014043807983,
          0.8230386972427368,
          -0.6030702590942383,
          0.5966131091117859,
          0.30511796474456787,
          -0.679878830909729,
          -0.4480101466178894,
          -0.7350353598594666,
          -0.0907210111618042,
          0.49796825647354126,
          -0.04597782343626022,
          -0.3594972491264343,
          -0.8782928586006165,
          0.47561460733413696,
          1.0453816652297974,
          -0.11900551617145538,
          0.5714870691299438,
          0.31035366654396057,
          0.28549492359161377,
          -0.06429965049028397,
          0.6081279516220093,
          0.07204744964838028,
          0.12989044189453125,
          0.26001647114753723,
          0.4675982594490051,
          -0.26981863379478455,
          -0.6257017850875854,
          1.2947629690170288,
          -1.518450379371643,
          -1.1126306056976318,
          -0.18338918685913086,
          -0.5438023805618286,
          -0.4884161353111267,
          -0.238478422164917,
          -0.28698158264160156,
          -0.03633453696966171,
          0.27014243602752686,
          -0.05093913897871971,
          0.09750445932149887,
          -0.01540955901145935,
          0.4867582619190216,
          0.4248153567314148,
          -0.07530727982521057,
          0.07992307841777802,
          0.21963372826576233,
          0.01155233383178711,
          1.3269511461257935,
          0.36584997177124023,
          -1.199988842010498,
          -0.3690701127052307,
          1.3321598768234253,
          -0.9120879173278809,
          -0.044608645141124725,
          0.3156135678291321,
          -0.9927080273628235,
          0.028171923011541367,
          -1.6568522453308105,
          0.2722437381744385,
          -0.30606740713119507,
          -0.13917548954486847,
          -0.12601245939731598,
          0.16800247132778168,
          0.13013987243175507,
          0.4620775878429413,
          0.5440315008163452,
          -0.4073413610458374,
          -0.4557129442691803,
          0.06917346268892288,
          -0.033643826842308044,
          -0.2969728112220764,
          -0.6140773892402649,
          -0.14181898534297943,
          -0.2245924323797226,
          0.44032031297683716,
          0.7666011452674866,
          -0.5596793293952942,
          -0.7276606559753418,
          0.2943187952041626,
          -0.5452561974525452,
          -0.03791390359401703,
          0.5459936857223511,
          -1.0740444660186768,
          -0.41501548886299133,
          0.22412562370300293,
          0.1609634906053543,
          0.4663042426109314,
          1.0414159297943115,
          -0.5164770483970642,
          -0.42140161991119385,
          0.380016028881073,
          -0.0952269434928894,
          -0.5926904082298279,
          0.3336893618106842,
          -0.994907021522522,
          -0.6615291237831116,
          1.1322447061538696,
          -0.5153623223304749,
          -0.612520694732666,
          0.1235692948102951,
          0.4600314795970917,
          0.7627894282341003,
          0.45448124408721924,
          -1.0168243646621704,
          -0.45378056168556213,
          -0.3929915130138397,
          -0.9874522089958191,
          -0.2768987715244293,
          -0.5943990349769592,
          -0.320587158203125,
          -0.4686565399169922,
          0.10129541903734207,
          0.6131786108016968,
          -0.38752394914627075,
          0.3669606149196625,
          1.1565288305282593,
          0.4633689224720001,
          -0.5881335139274597,
          0.2691327631473541,
          -0.11885422468185425,
          0.3821278512477875,
          -0.26930907368659973,
          -0.013564053922891617,
          -0.2796429395675659,
          0.1383374184370041,
          -0.508643388748169,
          0.08468526601791382,
          -0.4010647237300873,
          0.0075835371389985085,
          0.3409094512462616,
          0.7276039123535156,
          -0.7338954210281372,
          0.8975465297698975,
          0.4724639058113098,
          -0.573106586933136,
          -0.7216783761978149,
          -0.07521583884954453,
          -0.040965255349874496,
          -0.16587726771831512,
          0.47017601132392883,
          0.6933128833770752,
          0.177412211894989,
          0.6254124641418457,
          -0.30657291412353516,
          -0.9541332721710205,
          -0.4406798481941223,
          0.983322262763977,
          0.08665335178375244,
          -0.7340878248214722,
          0.18721607327461243,
          1.082854986190796,
          -0.4345172941684723,
          -0.3853268027305603,
          0.6213219165802002,
          -0.07819810509681702,
          0.7182062268257141,
          -0.48973214626312256,
          0.5320551991462708,
          -0.7470522522926331,
          0.335534930229187,
          0.005306601524353027,
          0.5412881374359131,
          -0.18718676269054413,
          0.24165520071983337,
          1.3839408159255981,
          0.6859821081161499,
          -0.7764925360679626,
          -0.034414228051900864,
          0.6558713912963867,
          -0.1303946077823639,
          0.32200947403907776,
          -1.4794864654541016,
          0.2090999186038971,
          -0.15709511935710907,
          -0.780007541179657,
          0.6916884779930115,
          -1.1967097520828247,
          -0.4694722294807434,
          0.7210080623626709,
          0.33260518312454224,
          -0.07982316613197327,
          -0.5554224252700806,
          -0.38972893357276917,
          0.21251052618026733,
          0.3087270259857178,
          -0.6450915336608887,
          -0.5456766486167908,
          1.121198296546936,
          -0.12284970283508301,
          0.2548477351665497,
          -0.15776285529136658,
          -0.5155539512634277,
          1.0287508964538574,
          0.5581275224685669,
          -0.26632216572761536,
          -0.44011542201042175,
          -0.2484211027622223,
          -1.3635257482528687,
          -0.7287092208862305,
          -0.038339123129844666,
          0.3963671922683716,
          -0.11426404118537903,
          0.4869306981563568,
          0.42044004797935486,
          -0.4083463251590729,
          -0.4394382834434509,
          0.36192914843559265,
          -0.8608601689338684,
          -1.097476601600647,
          -0.3662255108356476,
          0.48887649178504944,
          -0.23945876955986023,
          0.22793623805046082,
          -0.04340840503573418,
          0.15339051187038422,
          0.1607840657234192,
          0.9549758434295654,
          -0.5964654684066772,
          0.2537994980812073,
          0.09367941319942474,
          0.4301544427871704,
          -0.6360204219818115,
          -0.25050485134124756,
          -0.41648855805397034,
          -0.08446565270423889,
          -0.5044906735420227,
          0.12458400428295135,
          -0.06327077001333237,
          0.30243441462516785,
          0.20295055210590363,
          -0.7797638773918152,
          0.3532911539077759,
          -0.40010613203048706,
          0.4881419539451599,
          -0.7174025177955627,
          0.18410058319568634,
          0.48226919770240784,
          -0.325283944606781,
          0.24694767594337463,
          -1.0167447328567505,
          1.0723973512649536,
          -0.009705845266580582,
          -0.9121776223182678,
          1.020058274269104,
          -0.09997338056564331,
          0.13826704025268555,
          -0.33429154753685,
          -0.39892327785491943,
          0.6097908616065979,
          -0.16286514699459076,
          0.7252529859542847,
          -0.1799832284450531,
          0.3462958037853241,
          0.11261919140815735,
          -1.022852897644043,
          -0.025293752551078796,
          -0.981508731842041,
          -0.22461462020874023,
          -0.7175053954124451,
          -0.4170597493648529,
          0.14416977763175964,
          -0.32004743814468384,
          -0.4804210960865021,
          0.7122148871421814,
          -0.2131195068359375,
          -1.0721498727798462,
          -0.16581809520721436,
          -0.2165435403585434,
          0.8252094984054565,
          0.4366030693054199,
          0.09352582693099976,
          0.2436855286359787,
          -0.5720636248588562,
          -0.8455109000205994,
          -0.44617220759391785,
          -0.525536060333252,
          -0.07477683573961258,
          0.6279585361480713,
          0.5294432640075684,
          0.25337639451026917,
          0.7715329527854919,
          0.10931844264268875,
          0.06804446130990982,
          0.4781544804573059,
          0.7073677778244019,
          -0.039589233696460724,
          0.6607880592346191,
          0.4048813283443451,
          -0.14001071453094482,
          -0.45818793773651123,
          -0.9562743902206421,
          0.06105335056781769,
          0.8386339545249939,
          -0.32877013087272644,
          -0.6888221502304077,
          0.44818970561027527,
          -0.15961387753486633,
          0.5248850584030151,
          -0.6375119686126709,
          -0.4609641134738922,
          0.3295890986919403,
          -0.3099549412727356,
          0.14554613828659058,
          -0.2677350640296936,
          0.44816291332244873,
          -0.6701852083206177,
          0.09331034123897552,
          0.5322731733322144,
          0.7657592296600342,
          -0.6357597708702087,
          0.6094003319740295,
          0.546602725982666,
          -0.5717816352844238,
          -0.5461024045944214,
          -0.21833208203315735,
          0.7517307996749878,
          -0.6914265751838684,
          0.1987873613834381,
          -0.4592142403125763,
          0.4237535893917084,
          0.35352376103401184,
          -0.2409861981868744,
          -0.2113403081893921,
          0.3070315718650818,
          0.6981819272041321,
          -0.061291396617889404,
          0.25413778424263,
          0.12059442698955536,
          1.2263240814208984,
          -0.1465355008840561,
          0.5006008744239807,
          0.11035746335983276,
          0.5038586854934692,
          -0.7880017757415771,
          0.3332044184207916,
          -0.3772670328617096,
          0.9898180961608887,
          -1.717918872833252,
          -0.5426744222640991,
          0.41598275303840637,
          0.2447010576725006,
          -0.9226995706558228,
          -0.3761453330516815,
          -0.7098400592803955,
          0.8996022343635559,
          0.3198964297771454,
          -0.8281533718109131,
          0.005974277853965759,
          0.10544319450855255,
          0.010729949921369553,
          0.36783576011657715,
          0.08426402509212494,
          -0.5072498917579651,
          0.011124636977910995,
          0.021026931703090668,
          0.4758586585521698,
          -0.3797101378440857,
          0.36117032170295715,
          0.19414296746253967,
          0.006531093269586563,
          -0.3325786888599396,
          0.6098458766937256,
          -0.5441864132881165,
          1.1866453886032104,
          0.26583391427993774,
          -0.7335748672485352,
          1.0678911209106445,
          0.4684213697910309,
          -0.6052606105804443,
          0.5324798226356506,
          -0.597297191619873,
          -0.3715963065624237,
          -1.0229392051696777,
          1.0357894897460938,
          -0.9118317365646362,
          0.3805966377258301,
          0.472578763961792,
          -0.3187107741832733,
          -0.3739783465862274,
          -0.13205549120903015,
          -0.3326870799064636,
          -0.013142213225364685,
          0.288836807012558,
          0.5362412929534912,
          0.1871020495891571,
          1.5028650760650635,
          1.5019316673278809,
          -0.3259369730949402,
          -0.5213896036148071,
          0.2511684000492096,
          -0.08440778404474258,
          -0.10007248818874359,
          -0.04058931767940521,
          -0.7825309038162231,
          -0.31455010175704956,
          -0.05937359482049942,
          -0.9192599058151245,
          -0.7865229249000549,
          0.09812238812446594,
          0.03546254709362984,
          0.45661476254463196,
          -0.37993085384368896,
          1.2587649822235107,
          -0.09764211624860764,
          0.30204522609710693,
          -0.21543359756469727,
          0.506322979927063,
          0.3876202702522278,
          0.4227212965488434,
          0.24892383813858032,
          -0.33950331807136536,
          0.38391295075416565,
          -1.359770655632019,
          0.5386645793914795,
          -0.15974217653274536,
          -0.30407172441482544,
          0.11944471299648285,
          -0.1513095498085022,
          -0.5019018650054932,
          -0.8317278623580933,
          0.7891315817832947,
          -0.5896360874176025,
          -0.14609739184379578,
          -0.0829915702342987,
          -0.18859249353408813,
          0.35206782817840576,
          -0.6458789110183716,
          -0.2784574627876282,
          1.2164968252182007,
          0.731041669845581,
          -0.28626441955566406,
          0.759901225566864,
          1.2265485525131226,
          1.001865267753601,
          -0.0696355551481247,
          0.343199759721756,
          -0.029361004009842873,
          0.35393503308296204,
          -0.9970066547393799,
          0.6559497714042664,
          -0.2240004539489746,
          -0.029737628996372223,
          -0.7323662042617798,
          1.1472952365875244,
          0.7238458395004272,
          0.06320472806692123,
          0.207140251994133,
          -0.8148226141929626,
          -0.2573605179786682,
          -0.7133609056472778,
          0.3798946440219879,
          -0.3865554630756378,
          0.9697822332382202,
          -0.22954612970352173,
          0.0022046267986297607,
          0.5362497568130493,
          -0.6352366805076599,
          3.527601718902588,
          1.2684353590011597,
          0.06982732564210892,
          0.35084590315818787,
          0.47644683718681335,
          0.9393705725669861,
          0.961047887802124,
          -0.2684067487716675,
          0.5883501768112183,
          -0.5161614418029785,
          0.494998037815094,
          -0.8035480976104736,
          0.8614016175270081,
          0.2870739698410034,
          0.034770939499139786,
          -0.16469891369342804,
          -0.6501825451850891,
          0.30100637674331665,
          0.026380114257335663,
          -0.24851027131080627,
          -1.3842692375183105,
          0.08690967410802841,
          0.2691648006439209,
          -0.3900357782840729,
          0.3445873558521271,
          0.6435839533805847,
          0.20163783431053162,
          -0.1668778657913208,
          -0.08970111608505249,
          -0.41942986845970154,
          -0.03803861141204834,
          -0.652387797832489,
          -0.3237905204296112,
          -0.236580029129982,
          0.23633897304534912,
          0.9502747058868408,
          -0.006140850484371185,
          -0.8939476609230042,
          -0.3151281177997589,
          1.5179661512374878,
          0.4306967854499817,
          -0.849799633026123,
          -0.49473682045936584,
          -0.5425565838813782,
          0.27773481607437134,
          0.5835340023040771,
          0.31471094489097595,
          0.07864243537187576,
          0.8498427271842957,
          -1.1292880773544312,
          0.03483469784259796,
          -1.2607204914093018,
          0.044550321996212006,
          -0.3356069028377533,
          0.4646432101726532,
          0.21763990819454193,
          -0.14398276805877686,
          -0.24195444583892822,
          -1.1151748895645142,
          0.30356547236442566,
          0.798176109790802,
          -0.6413978338241577,
          -0.5871297121047974,
          0.5493795871734619,
          -0.20751993358135223,
          -0.5349833369255066,
          0.8650317788124084,
          0.33980220556259155,
          -0.267363965511322,
          -0.06803719699382782,
          0.07214139401912689,
          0.1131453737616539,
          -0.24482767283916473,
          0.26199132204055786,
          -0.09661202132701874,
          0.35075899958610535,
          -0.3927660286426544,
          0.8148543834686279,
          -0.16047532856464386,
          -0.4594968855381012,
          0.08520255982875824,
          -0.5455288290977478,
          -0.4225608706474304,
          -0.051151253283023834,
          0.2705157995223999,
          0.8461418151855469,
          -0.3039599061012268,
          0.19143344461917877,
          -0.5604915618896484,
          0.22093424201011658,
          -0.31154128909111023,
          -0.29048240184783936,
          0.45130443572998047,
          -0.019502460956573486,
          -0.01131579652428627
        ]
      },
      "type": "document"
    },
    {
      "id": "4153fc52-5968-44e6-aed7-c938bbcf6a2c",
      "properties": {
        "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n\n\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n",
        "entities": [
          "Ji et al.",
          "Zhang et al.",
          "Li et al.",
          "Azaria and Mitchell",
          "Min et al.",
          "Yuan et al.",
          "BARTScore",
          "Kadavath et al.",
          "ChatGPT",
          "GPT-4",
          "SelfCheckGPT",
          "GPTScore",
          "Fu et al.",
          "Wang et al.",
          "BERTScore",
          "MoverScore",
          "Zhao et al."
        ]
      },
      "type": "chunk"
    },
    {
      "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
      "properties": {
        "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
        "themes": [
          "Evaluation Strategies",
          "RAG setting",
          "Question answering",
          "Context retrieval",
          "Answer generation"
        ],
        "entities": [
          "RAG"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "59b50bfa-18cd-4a45-8a79-5035e124a0c9",
      "properties": {
        "page_content": "we usually do not have access to human-annotated\ndatasets or reference answers. We therefore fo-\ncus on metrics that are fully self-contained and\nreference-free. We focus in particular three quality\naspects, which we argue are of central importance.\nFirst, Faithfulness refers to the idea that the an-\nswer should be grounded in the given context. This\nis important to avoid hallucinations, and to ensure\nthat the retrieved context can act as a justification\nfor the generated answer. Indeed, RAG systems are\noften used in applications where the factual con-\nsistency of the generated text w.r.t. the grounded\nsources is highly important, e.g. in domains such as\nlaw, where information is constantly evolving. Sec-\nond, Answer Relevancerefers to the idea that the\ngenerated answer should address the actual ques-\ntion that was provided. Finally,Context Relevance\nrefers to the idea that the retrieved context should\nbe focused, containing as little irrelevant informa-\ntion as possible. This is important given the cost\nassociated with feeding long context passages to\nLLMs. Moreover, when context passages are too\nlong, LLMs are often less effective in exploiting\nthat context, especially for information that is pro-\nvided in the middle of the context passage (Liu\net al., 2023).\nWe now explain how these three quality aspects\ncan be measured in a fully automated way, by\nprompting an LLM. In our implementation and\nexperiments, all prompts are evaluated using the\ngpt-3.5-turbo-16k model, which is available\nthrough the OpenAI API2.\nFaithfulness We say that the answer as(q) is\nfaithful to the context c(q) if the claims that are\nmade in the answer can be inferred from the con-\ntext. To estimate faithfulness, we first use an LLM\nto extract a set of statements, S(as(q)). The aim\nof this step is to decompose longer sentences into\nshorter and more focused assertions. We use the\nfollowing prompt for this step3:\nGiven a question and answer, create one\nor more statements from each sentence\nin the given answer.\nquestion: [question]\nanswer: [answer]\nwhere [question] and [answer] refer to the\ngiven question and answer. For each statement si\n2https://platform.openai.com\n3To help clarify the task, we include a demonstration as\npart of the prompt. This demonstration is not explicitly shown\nin the listing of the prompts throughout this paper.\nin S, the LLM determines ifsi can be inferred from\nc(q) using a verification function v(si, c(q)). This\nverification step is carried out using the following\nprompt:\nConsider the given context and following\nstatements, then determine whether they\nare supported by the information present\nin the context. Provide a brief explana-\ntion for each statement before arriving\nat the verdict (Yes/No). Provide a final\nverdict for each statement in order at the\nend in the given format. Do not deviate\nfrom the specified format.\nstatement: [statement 1]\n...\nstatement: [statement n]\nThe final faithfulness score, F, is then computed\nas F = |V |\n|S| , where |V | is the number of statements\nthat were supported according to the LLM and |S|\nis the total number of statements.\nAnswer relevance We say that the answer as(q)\nis relevant if it directly addresses the question in\nan appropriate way. In particular, our assessment\nof answer relevance does not take into account fac-\ntuality, but penalises cases where the answer is\nincomplete or where it contains redundant informa-\ntion. To estimate answer relevance, for the given\nanswer as(q), we prompt the LLM to generate n\npotential questions qi based on as(q), as follows:\nGenerate a question for the given answer.\nanswer: [answer]\nWe then obtain embeddings for all questions us-\ning the text-embedding-ada-002 model, avail-\nable from the OpenAI API. For each qi, we cal-\nculate the similarity sim(q, qi) with the original\nquestion q, as the cosine between the correspond-\ning embeddings. The answer relevance score, AR,\nfor question q is then computed as:\nAR = 1\nn\nnX\ni=1\nsim(q, qi) (1)\nThis metric evaluates how closely the generated\nanswer aligns with the initial question or instruc-\ntion.\nContext relevance The context c(q) is consid-\nered relevant to the extent that it exclusively con-\ntains information that is needed to answer the ques-\ntion. In particular, this metric aims to penalise the",
        "document_metadata": {
          "page_label": "3",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "First",
          "Second",
          "Finally",
          "Faithfulness",
          "Answer Relevance",
          "Context Relevance"
        ],
        "themes": [
          "Faithfulness",
          "Hallucinations",
          "Answer Relevance",
          "Context Relevance",
          "Information Overload",
          "Question-Answer Alignment",
          "Relevant Information",
          "Irrelevant Information",
          "Automated Evaluation Metrics"
        ]
      },
      "type": "document"
    },
    {
      "id": "372e8295-743f-4344-a7d3-d58cc728884b",
      "properties": {
        "page_content": "inclusion of redundant information. To estimate\ncontext relevance, given a question q and its con-\ntext c(q), the LLM extracts a subset of sentences,\nSext, from c(q) that are crucial to answer q, using\nthe following prompt:\nPlease extract relevant sentences from\nthe provided context that can potentially\nhelp answer the following question. If no\nrelevant sentences are found, or if you\nbelieve the question cannot be answered\nfrom the given context, return the phrase\n\"Insufficient Information\". While extract-\ning candidate sentences you’re not al-\nlowed to make any changes to sentences\nfrom given context.\nThe context relevance score is then computed as:\nCR = number of extracted sentences\ntotal number of sentences in c(q) (2)\n4 The WikiEval Dataset\nTo evaluate the proposed framework, we ideally\nneed examples of question-context-answer triples\nwhich are annotated with human judgments. We\ncan then verify to what extent our metrics agree\nwith human assessments of faithfulness, answer\nrelevance and context relevance. Since we are not\naware of any publicly available datasets that could\nbe used for this purpose, we created a new dataset,\nwhich we refer to as WikiEval4. To construct the\ndataset, we first selected 50 Wikipedia pages cov-\nering events that have happened since the start of\n20225. In selecting these pages, we prioritised\nthose with recent edits. For each of the 50 pages,\nwe then asked ChatGPT to suggest a question that\ncan be answered based on the introductory section\nof the page, using the following prompt:\nYour task is to formulate a question from\ngiven context satisfying the rules given\nbelow:\n1. The question should be fully answered\nfrom the given context.\n2. The question should be framed from\na part that contains non-trivial informa-\ntion.\n3. The answer should not contain any\n4https://huggingface.co/datasets/\nexplodinggradients/WikiEval\n5That is, beyond the reported training cutoff of the model\nwe used in our experiments.\nlinks.\n4. The question should be of moderate\ndifficulty.\n5. The question must be reasonable and\nmust be understood and responded to by\nhumans.\n6. Do not use phrases that ’provided con-\ntext’, etc in the question\ncontext:\nWe also used ChatGPT to answer the generated\nquestion, when given the corresponding introduc-\ntory section as context, using the following prompt:\nAnswer the question using the informa-\ntion from the given context.\nquestion: [question]\ncontext: [context]\nAll questions were annotated along the three con-\nsidered quality dimensions by two annotators. Both\nannotators were fluent in English and were given\nclear instructions about the meaning of the three\nconsidered quality dimensions. For faithfulness\nand context relevance, the two annotators agreed in\naround 95% of cases. For answer relevance, they\nagreed in around 90% of the cases. Disagreements\nwere resolved after a discussion between the anno-\ntators.\nFaithfulness To obtain human judgements about\nfaithfulness, we first used ChatGPT to answer the\nquestion without access to any additional context.\nWe then asked the annotators to judge which of the\ntwo answers was the most faithful (i.e. the standard\none or the one generated without context), given\nthe question and corresponding Wikipedia page.\nAnswer relevance We first used ChatGPT to\nobtain candidate answers with lower answer rel-\nevance, using the following prompt:\nAnswer the given question in an incom-\nplete manner.\nquestion: [question]\nWe then asked human annotators to compare this\nanswer, and indicate which of the two answers had\nthe highest answer relevance.\nContext relevance To measure this aspect, we\nfirst added additional sentences to the context by\nscraping back-links to the corresponding Wikipedia\npage. In this way, we were able to add information\nto the context that was related but less relevant for",
        "document_metadata": {
          "page_label": "4",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions",
          "Conclusion"
        ]
      },
      "type": "document"
    },
    {
      "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
      "properties": {
        "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
        "entities": [
          "Faith. Ans. Rel. Cont. Rel.",
          "RAGAs",
          "GPT Score",
          "GPT Ranking",
          "Table 1",
          "WikiEval dataset",
          "accuracy",
          "ChatGPT",
          "context relevance",
          "faithfulness",
          "answer relevance",
          "context relevance"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
      "properties": {
        "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
        "entities": [
          "RAG systems",
          "WikiEval",
          "RAGAs"
        ]
      },
      "type": "chunk"
    },
    {
      "id": "b06c7955-8512-4292-92e5-eb24f666ea2b",
      "properties": {
        "page_content": "References\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\nnal state of an LLM knows when its lying. CoRR,\nabs/2304.13734.\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\nCassirer, Andy Brock, Michela Paganini, Geoffrey\nIrving, Oriol Vinyals, Simon Osindero, Karen Si-\nmonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\n2022. Improving language models by retrieving from\ntrillions of tokens. In International Conference on\nMachine Learning, ICML 2022, 17-23 July 2022, Bal-\ntimore, Maryland, USA, volume 162 of Proceedings\nof Machine Learning Research , pages 2206–2240.\nPMLR.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, et al. 2023. Sparks of artificial general intelli-\ngence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei\nLiu. 2023. Gptscore: Evaluate as you desire. CoRR,\nabs/2302.04166.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Mingwei Chang. 2020. Retrieval augmented\nlanguage model pre-training. In International confer-\nence on machine learning, pages 3929–3938. PMLR.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of halluci-\nnation in natural language generation. ACM Comput-\ning Surveys, 55(12):1–38.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\nTran-Johnson, Scott Johnston, Sheer El Showk, Andy\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\nGanguli, Danny Hernandez, Josh Jacobson, Jack-\nson Kernion, Shauna Kravec, Liane Lovitt, Ka-\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\nBen Mann, Sam McCandlish, Chris Olah, and Jared\nKaplan. 2022. Language models (mostly) know what\nthey know. CoRR, abs/2207.05221.\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\nWallace, and Colin Raffel. 2022. Large language\nmodels struggle to learn long-tail knowledge. CoRR,\nabs/2211.08411.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generalization\nthrough memorization: Nearest neighbor language\nmodels. In 8th International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\nApril 26-30, 2020. OpenReview.net.\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\nDavid Hall, Percy Liang, Christopher Potts, and\nMatei Zaharia. 2022. Demonstrate-search-predict:\nComposing retrieval and language models for\nknowledge-intensive NLP. CoRR, abs/2212.14024.\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova.\n2019. Latent retrieval for weakly supervised open do-\nmain question answering. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 6086–6096.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\nTim Rocktäschel, Sebastian Riedel, and Douwe\nKiela. 2020. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In Advances in Neu-\nral Information Processing Systems 33: Annual Con-\nference on Neural Information Processing Systems\n2020, NeurIPS 2020, December 6-12, 2020, virtual.\nJunyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun\nNie, and Ji-Rong Wen. 2023. Halueval: A large-\nscale hallucination evaluation benchmark for large\nlanguage models. CoRR, abs/2305.11747.\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\njape, Michele Bevilacqua, Fabio Petroni, and Percy\nLiang. 2023. Lost in the middle: How language\nmodels use long contexts.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 9802–9822, Toronto,\nCanada. Association for Computational Linguistics.\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\n2023. Selfcheckgpt: Zero-resource black-box hal-\nlucination detection for generative large language\nmodels. CoRR, abs/2303.08896.\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike\nLewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,\nLuke Zettlemoyer, and Hannaneh Hajishirzi. 2023.\nFactscore: Fine-grained atomic evaluation of fac-\ntual precision in long form text generation. CoRR,\nabs/2305.14251.",
        "document_metadata": {
          "page_label": "6",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    },
    {
      "id": "6be23785-f307-4226-99ce-99cb5ee7ffe2",
      "properties": {
        "page_content": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-context retrieval-augmented lan-\nguage models. CoRR, abs/2302.00083.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the param-\neters of a language model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5418–5426,\nOnline. Association for Computational Linguistics.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\nWen-tau Yih. 2023. REPLUG: retrieval-augmented\nblack-box language models. CoRR, abs/2301.12652.\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxi-\nang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie\nZhou. 2023a. Is chatgpt a good NLG evaluator? A\npreliminary study. CoRR, abs/2303.04048.\nPeiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\n2023b. Large language models are not fair evaluators.\nCoRR, abs/2305.17926.\nShufan Wang, Yixiao Song, Andrew Drozdov, Aparna\nGarimella, Varun Manjunatha, and Mohit Iyyer.\n2023c. KNN-LM does not improve open-ended text\ngeneration. CoRR, abs/2305.14625.\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\nBartscore: Evaluating generated text as text genera-\ntion. In Advances in Neural Information Processing\nSystems 34: Annual Conference on Neural Informa-\ntion Processing Systems 2021, NeurIPS 2021, De-\ncember 6-14, 2021, virtual, pages 27263–27277.\nTianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei\nFang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,\nDanny Fox, Helen Meng, and James R. Glass. 2023.\nInterpretable unified language checking. CoRR,\nabs/2304.03728.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\nText generation evaluating with contextualized em-\nbeddings and earth mover distance. In Proceedings\nof the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 563–578, Hong\nKong, China. Association for Computational Lin-\nguistics.\nA Examples from WikiEval\nTables 2, 3 and 4 show examples from the WikiEval\ndataset, focusing in particular on answers with high\nand low faithfulness (Table 2), high and low answer\nrelevance (Table 3), and high and low context rele-\nvance (Table 4).",
        "document_metadata": {
          "page_label": "7",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Future Directions",
          "Subsection: Specialized Techniques",
          "Conclusion"
        ],
        "summary": "Artificial intelligence is transforming various industries by automating tasks, analyzing data quickly and accurately. AI is driving innovations in self-driving cars and personalized recommendations.",
        "summary_embedding": [
          0.0936565101146698,
          0.6916304230690002,
          -0.514258623123169,
          -0.7270908355712891,
          -0.10508018732070923,
          0.015137093141674995,
          0.13617174327373505,
          -0.15196794271469116,
          0.6210719347000122,
          0.5103594064712524,
          0.041147373616695404,
          0.3878614902496338,
          -0.5742083191871643,
          -1.1018747091293335,
          0.30607375502586365,
          -0.46880412101745605,
          0.008754730224609375,
          0.019627973437309265,
          0.23586785793304443,
          -0.18928629159927368,
          -0.1823955774307251,
          0.8341490030288696,
          -0.5282493829727173,
          -0.9865544438362122,
          -1.069703459739685,
          0.6233772039413452,
          0.7112172842025757,
          -0.6198657751083374,
          0.6563952565193176,
          0.6679344773292542,
          -0.27173563838005066,
          -0.13457542657852173,
          0.21979792416095734,
          -0.5311694741249084,
          -0.6071297526359558,
          -0.07055886089801788,
          0.29007548093795776,
          -0.19711239635944366,
          -0.9358482360839844,
          -0.6408234238624573,
          0.2053787112236023,
          -0.07308775931596756,
          0.14738978445529938,
          -1.199998378753662,
          -0.9967457056045532,
          0.5060827136039734,
          0.6730939149856567,
          -1.177320957183838,
          -0.044640567153692245,
          -0.2699791193008423,
          -0.5830317735671997,
          0.21640822291374207,
          -0.1961386799812317,
          -0.3674044609069824,
          0.03890792652964592,
          -1.0103310346603394,
          -0.309230238199234,
          -0.30761685967445374,
          -0.5656442046165466,
          -0.06889016926288605,
          1.139770746231079,
          -0.4199333190917969,
          0.6267649531364441,
          -0.10849902033805847,
          0.17252285778522491,
          0.4444495141506195,
          0.05558449402451515,
          -0.5167883634567261,
          -0.3584330379962921,
          0.08928745985031128,
          -1.2043113708496094,
          -0.4033503830432892,
          0.2724319398403168,
          0.16046851873397827,
          -0.4227229356765747,
          0.07743895798921585,
          0.18673844635486603,
          -0.2093134969472885,
          -0.9784047603607178,
          -0.2128480076789856,
          -0.48253297805786133,
          0.8037214875221252,
          -0.3396950364112854,
          0.9647797346115112,
          0.10836519300937653,
          -0.4712863266468048,
          0.5690202116966248,
          0.8170126676559448,
          -0.23178499937057495,
          -0.5816487669944763,
          -0.11330756545066833,
          -0.0155097097158432,
          -0.15010204911231995,
          -0.05959301069378853,
          0.1430533081293106,
          0.6755018830299377,
          -0.6529677510261536,
          0.7709560394287109,
          0.04629729315638542,
          -0.022388149052858353,
          0.48723846673965454,
          1.1276750564575195,
          -0.0022813654504716396,
          0.9987099766731262,
          -0.8216867446899414,
          0.06820830702781677,
          0.6087172627449036,
          -0.7788275480270386,
          -0.020204899832606316,
          -0.9422375559806824,
          0.5444591641426086,
          0.12412826716899872,
          -0.0794166624546051,
          0.13740375638008118,
          -0.14769963920116425,
          1.442685604095459,
          -0.32732918858528137,
          0.2508092224597931,
          -0.26713433861732483,
          0.37504810094833374,
          -0.2685171365737915,
          -0.5664018988609314,
          0.1677147001028061,
          -0.17288418114185333,
          0.1202942430973053,
          -1.139703631401062,
          0.10465526580810547,
          0.767869770526886,
          -0.4943848252296448,
          0.823428750038147,
          -0.18367350101470947,
          0.04810146987438202,
          -0.2221640944480896,
          0.5520586967468262,
          -0.03564607352018356,
          -0.7445168495178223,
          0.06672035157680511,
          0.9729979634284973,
          -0.2805691659450531,
          0.7288954854011536,
          0.02206733450293541,
          0.11588086932897568,
          -0.14987000823020935,
          1.7094722986221313,
          -0.2774236500263214,
          -0.199935644865036,
          -0.30504316091537476,
          0.1870591640472412,
          -0.34242403507232666,
          0.7589861154556274,
          -0.9395193457603455,
          0.49782153964042664,
          0.3558827340602875,
          -0.01290171779692173,
          -0.5989673733711243,
          -0.8769424557685852,
          -0.6366955041885376,
          0.0012093186378479004,
          0.5177187323570251,
          0.6845132112503052,
          -0.3607354164123535,
          0.05630112811923027,
          -0.15653450787067413,
          1.1727360486984253,
          -0.5025002956390381,
          0.7297571301460266,
          -0.8968231081962585,
          0.16224944591522217,
          -0.5367608666419983,
          -0.21848097443580627,
          0.42545345425605774,
          -0.6226896047592163,
          -0.5900878310203552,
          -0.06349852681159973,
          0.8474491238594055,
          1.0848146677017212,
          0.776314914226532,
          0.17704179883003235,
          0.10781782120466232,
          -0.34770649671554565,
          -1.2456713914871216,
          -0.3561612069606781,
          -0.7300592064857483,
          -0.07188770174980164,
          0.31433016061782837,
          0.6727237701416016,
          0.20909437537193298,
          0.2917240262031555,
          0.4398966431617737,
          -0.4562045931816101,
          0.251585453748703,
          0.7414590120315552,
          -0.9678961038589478,
          -0.008542440831661224,
          -0.08745217323303223,
          0.43528780341148376,
          -0.691362202167511,
          0.5176293849945068,
          0.2855215072631836,
          -0.00023245066404342651,
          -0.27924680709838867,
          0.6298758387565613,
          0.0037123262882232666,
          -0.5860020518302917,
          -0.70329749584198,
          0.6890068650245667,
          -0.27180394530296326,
          1.2282778024673462,
          -1.6957536935806274,
          1.408812403678894,
          0.5174600481987,
          0.2691132724285126,
          -0.03929021582007408,
          -0.20860494673252106,
          0.8544684648513794,
          0.06242205202579498,
          -0.45867598056793213,
          0.4247696101665497,
          0.26126527786254883,
          -0.4219347834587097,
          0.01393854059278965,
          -0.38004693388938904,
          0.4823252558708191,
          -0.4501637816429138,
          -0.4304370582103729,
          -0.20585133135318756,
          -0.3148179054260254,
          0.860001266002655,
          -0.04012181609869003,
          0.19728806614875793,
          0.7970328330993652,
          0.6872707009315491,
          -0.4682557284832001,
          0.8306053876876831,
          -0.10926725715398788,
          0.1620256006717682,
          -0.4843241572380066,
          0.43601199984550476,
          -0.22824393212795258,
          -0.18631505966186523,
          0.9595268964767456,
          -0.02752172201871872,
          1.4472987651824951,
          0.32143864035606384,
          -0.688896656036377,
          -0.0015044063329696655,
          0.07342982292175293,
          -0.14420118927955627,
          0.6353095769882202,
          0.7299911975860596,
          -0.718605101108551,
          0.21036937832832336,
          0.13047181069850922,
          -0.2701113224029541,
          -0.3696349263191223,
          0.6539766788482666,
          0.8541528582572937,
          0.5928699970245361,
          0.25610506534576416,
          -1.2424310445785522,
          -0.7983514070510864,
          0.7490904331207275,
          0.6025798320770264,
          0.05792209506034851,
          0.5429460406303406,
          0.45474469661712646,
          -0.13208168745040894,
          -0.1104908287525177,
          -0.8510217666625977,
          -0.36317935585975647,
          -1.316978931427002,
          -1.3211380243301392,
          -0.3875380754470825,
          -0.23439626395702362,
          -1.0071477890014648,
          0.02992738038301468,
          0.19598665833473206,
          -0.5465536713600159,
          0.880112886428833,
          -0.08613433688879013,
          -0.34318631887435913,
          -0.3921572268009186,
          -0.7767741680145264,
          0.510964035987854,
          0.8283294439315796,
          0.5403918623924255,
          -1.1477099657058716,
          -0.10152312368154526,
          -0.5779366493225098,
          0.7156410813331604,
          0.7370744347572327,
          0.42241549491882324,
          -0.19597864151000977,
          -0.4318609833717346,
          -0.0357808955013752,
          -0.34880948066711426,
          0.8925021290779114,
          0.23185354471206665,
          -0.9397698640823364,
          -0.5073261857032776,
          0.16464738547801971,
          0.11511791497468948,
          -0.7921594977378845,
          0.07125108689069748,
          -0.024338174611330032,
          0.6111569404602051,
          0.18495050072669983,
          0.21157222986221313,
          0.9935548305511475,
          0.005018576979637146,
          -1.2610218524932861,
          0.3027290105819702,
          -0.15242837369441986,
          0.7834219336509705,
          -0.6257495284080505,
          0.7998915314674377,
          0.46442776918411255,
          -0.7921517491340637,
          0.3182024657726288,
          -1.2567776441574097,
          -0.26547476649284363,
          0.1564352810382843,
          -0.538300633430481,
          0.5218009948730469,
          0.2197762280702591,
          0.47069764137268066,
          0.04914043843746185,
          -1.933761715888977,
          0.11112930625677109,
          -0.08000245690345764,
          -0.42763257026672363,
          -0.14641867578029633,
          0.2938426434993744,
          0.7660613059997559,
          0.7967309951782227,
          -0.41857582330703735,
          -0.05729883536696434,
          0.1312536597251892,
          -0.33190852403640747,
          0.7899642586708069,
          0.4232845902442932,
          -0.31940051913261414,
          0.39133360981941223,
          0.36713844537734985,
          -0.5640673637390137,
          0.7440465688705444,
          1.2472833395004272,
          -0.2518291473388672,
          0.7276557683944702,
          -0.17028102278709412,
          -0.15226681530475616,
          -0.0989874005317688,
          -0.4698934555053711,
          -0.5340216159820557,
          0.39967969059944153,
          0.06365035474300385,
          -0.538230836391449,
          0.49798384308815,
          -0.3116319179534912,
          0.07145652920007706,
          0.7216588854789734,
          0.3310263454914093,
          -0.35451027750968933,
          0.3781554102897644,
          -0.5391265749931335,
          0.15207171440124512,
          -0.1820838898420334,
          0.45667651295661926,
          0.21595357358455658,
          -0.6219390630722046,
          0.6603241562843323,
          -0.18276537954807281,
          -0.39145511388778687,
          0.6020711660385132,
          -0.8660836815834045,
          -1.051027536392212,
          0.45203477144241333,
          -0.8368399739265442,
          0.043334897607564926,
          -0.885286808013916,
          0.44670990109443665,
          0.1262882649898529,
          0.02009199559688568,
          -0.21163752675056458,
          -0.4233284592628479,
          0.7925992608070374,
          -0.6515224575996399,
          0.7880820631980896,
          -0.20896343886852264,
          -0.01944812387228012,
          0.42962080240249634,
          -0.07318174839019775,
          -0.4670851230621338,
          0.07564572989940643,
          -0.771597146987915,
          -0.7457653880119324,
          0.9428868293762207,
          -0.01013324223458767,
          0.42323410511016846,
          -0.706714391708374,
          1.0863945484161377,
          -0.14418113231658936,
          0.17758122086524963,
          0.48201489448547363,
          0.393343985080719,
          0.16457875072956085,
          0.31156477332115173,
          0.9326191544532776,
          0.5476804971694946,
          -0.2597459554672241,
          -0.21536333858966827,
          -0.6560109257698059,
          0.4157590866088867,
          -0.23995137214660645,
          -0.3224483132362366,
          0.33037206530570984,
          -0.06426803767681122,
          -0.06717734783887863,
          -0.8869182467460632,
          0.09071233123540878,
          -0.45834678411483765,
          -0.17718762159347534,
          -0.8236185908317566,
          0.25510984659194946,
          0.5580791234970093,
          -0.17205274105072021,
          -0.4668867588043213,
          -1.2281200885772705,
          1.0041769742965698,
          0.5696866512298584,
          -0.5935994386672974,
          -0.7368859052658081,
          0.6831841468811035,
          -0.4016687273979187,
          -0.2778759002685547,
          0.1736839860677719,
          1.3340466022491455,
          -1.148419976234436,
          0.8947758078575134,
          -0.2571916878223419,
          0.15583857893943787,
          0.7683010697364807,
          0.5265049338340759,
          -0.0796264186501503,
          -0.37085363268852234,
          -0.4923478364944458,
          0.08767510205507278,
          0.41442999243736267,
          -0.5478339791297913,
          -0.5948512554168701,
          0.7568455934524536,
          -1.300966739654541,
          0.9131131768226624,
          -0.42435064911842346,
          0.5609978437423706,
          -0.21489304304122925,
          -0.49451732635498047,
          0.054815370589494705,
          0.14546452462673187,
          0.1998920440673828,
          0.2509307265281677,
          0.32029131054878235,
          0.6641334891319275,
          -0.6091374754905701,
          -0.3931184709072113,
          0.1122829020023346,
          0.8592150211334229,
          0.3376985192298889,
          0.6503995060920715,
          0.14735102653503418,
          -0.0029885582625865936,
          -0.30034732818603516,
          0.18100841343402863,
          -0.6491629481315613,
          0.7660579085350037,
          -0.6357056498527527,
          0.45304375886917114,
          0.205316960811615,
          -0.5805140733718872,
          -0.4266079068183899,
          -0.7963337898254395,
          -0.15011264383792877,
          0.3802729547023773,
          0.05204901099205017,
          -0.33726242184638977,
          -1.0724003314971924,
          0.46030473709106445,
          1.1190968751907349,
          -0.22245344519615173,
          0.4850579500198364,
          0.23551899194717407,
          0.21259333193302155,
          -0.17412906885147095,
          0.5444408655166626,
          0.09103013575077057,
          0.004327163100242615,
          0.19067105650901794,
          0.3234413266181946,
          -0.19590625166893005,
          -0.6911414861679077,
          1.173685073852539,
          -1.3709750175476074,
          -1.0909008979797363,
          -0.17793965339660645,
          -0.47985389828681946,
          -0.49685293436050415,
          -0.10295894742012024,
          -0.32483941316604614,
          -0.15009763836860657,
          0.29191675782203674,
          -0.017346631735563278,
          0.10210703313350677,
          0.05335419252514839,
          0.6873824000358582,
          0.5033550262451172,
          -0.09800732880830765,
          0.09915340691804886,
          0.17474332451820374,
          -0.23330973088741302,
          1.4179033041000366,
          0.2862898111343384,
          -0.9528282880783081,
          -0.43649327754974365,
          1.347090482711792,
          -0.8314518928527832,
          0.04470990598201752,
          0.15271328389644623,
          -0.9834334850311279,
          0.05162891000509262,
          -1.7510744333267212,
          0.22575333714485168,
          -0.33927634358406067,
          -0.13490307331085205,
          -0.19219383597373962,
          0.13329002261161804,
          0.07088959217071533,
          0.40284475684165955,
          0.42043614387512207,
          -0.34614068269729614,
          -0.4115922152996063,
          -0.035939037799835205,
          -0.03428232669830322,
          -0.2898816764354706,
          -0.6816505789756775,
          -0.11284060776233673,
          -0.3089505136013031,
          0.592289924621582,
          0.5915088057518005,
          -0.4818468987941742,
          -0.8475371599197388,
          0.35266533493995667,
          -0.4296112358570099,
          -0.12677806615829468,
          0.3935043215751648,
          -1.1167279481887817,
          -0.3735401928424835,
          0.24358312785625458,
          0.3015119433403015,
          0.4164826273918152,
          0.9834502935409546,
          -0.5169036388397217,
          -0.5362943410873413,
          0.18943998217582703,
          -0.11732405424118042,
          -0.44593629240989685,
          0.253665030002594,
          -0.9488722085952759,
          -0.6222605109214783,
          1.2933471202850342,
          -0.2865421772003174,
          -0.5919924974441528,
          0.10992945730686188,
          0.5060473680496216,
          0.836090624332428,
          0.45056480169296265,
          -0.930769681930542,
          -0.5110034942626953,
          -0.3968924582004547,
          -0.8635793328285217,
          -0.1694154441356659,
          -0.5702371597290039,
          -0.3528898358345032,
          -0.493221640586853,
          -0.03056086227297783,
          0.5776892304420471,
          -0.3379126489162445,
          0.3408393859863281,
          1.3146013021469116,
          0.4445377290248871,
          -0.525827944278717,
          0.27791041135787964,
          -0.09127913415431976,
          0.282274454832077,
          -0.3909584879875183,
          -0.12265782803297043,
          -0.2457614243030548,
          0.12813544273376465,
          -0.4988931119441986,
          0.06866627931594849,
          -0.4447716474533081,
          -0.106541208922863,
          0.38786938786506653,
          0.7913634777069092,
          -0.7413010597229004,
          0.775324285030365,
          0.4037558436393738,
          -0.5712036490440369,
          -0.6102412939071655,
          -0.05573038011789322,
          -0.021903034299612045,
          -0.1462237387895584,
          0.3367842733860016,
          0.6483315825462341,
          0.1567929983139038,
          0.703822135925293,
          -0.418596476316452,
          -0.9845737218856812,
          -0.3308846652507782,
          0.9071925282478333,
          0.05028039962053299,
          -0.6639173030853271,
          0.11535808444023132,
          1.1137734651565552,
          -0.3638182580471039,
          -0.4889247417449951,
          0.6181485056877136,
          -0.02779429405927658,
          0.5992048382759094,
          -0.5238412618637085,
          0.664156973361969,
          -0.5857069492340088,
          0.3087894022464752,
          -0.04391023516654968,
          0.4980544447898865,
          -0.2649374306201935,
          0.09042789041996002,
          1.5001615285873413,
          0.660581111907959,
          -0.6484439373016357,
          0.08012375235557556,
          0.5610902309417725,
          -0.05558042228221893,
          0.16947150230407715,
          -1.435293197631836,
          0.18919359147548676,
          -0.21033211052417755,
          -0.7327558994293213,
          0.6275338530540466,
          -1.292905569076538,
          -0.5802360773086548,
          0.6846987009048462,
          0.2267981469631195,
          -0.0727679580450058,
          -0.5694261789321899,
          -0.270569384098053,
          0.15001875162124634,
          0.28637057542800903,
          -0.5935037732124329,
          -0.6720048785209656,
          1.0415982007980347,
          -0.11773726344108582,
          0.21281181275844574,
          -0.09617699682712555,
          -0.4924790561199188,
          1.0729053020477295,
          0.5639911890029907,
          -0.3418894112110138,
          -0.45607706904411316,
          -0.23179790377616882,
          -1.440958857536316,
          -0.625061571598053,
          -0.13939470052719116,
          0.4510401487350464,
          -0.14870594441890717,
          0.5254385471343994,
          0.5277076363563538,
          -0.3614584803581238,
          -0.3466988801956177,
          0.23796667158603668,
          -0.8468714952468872,
          -0.9309036135673523,
          -0.3417734205722809,
          0.6418401002883911,
          -0.22253325581550598,
          0.2049674689769745,
          -0.035577353090047836,
          0.20203594863414764,
          -0.0621543824672699,
          0.9182784557342529,
          -0.4835076630115509,
          0.31576040387153625,
          0.17590227723121643,
          0.37348121404647827,
          -0.7713009715080261,
          -0.20246313512325287,
          -0.43777233362197876,
          -0.047247182577848434,
          -0.523733913898468,
          0.11654707044363022,
          0.04062481224536896,
          0.2597143054008484,
          0.23495599627494812,
          -0.622073233127594,
          0.3934164047241211,
          -0.568568766117096,
          0.22402295470237732,
          -0.5708338022232056,
          0.26124486327171326,
          0.45421111583709717,
          -0.30458971858024597,
          0.17866866290569305,
          -1.033951997756958,
          0.9181324243545532,
          -0.05456344410777092,
          -0.8352078199386597,
          0.8615874648094177,
          -0.034518927335739136,
          0.17175529897212982,
          -0.23762130737304688,
          -0.4431626796722412,
          0.6475188136100769,
          -0.3126313090324402,
          0.743602991104126,
          -0.18286657333374023,
          0.40622517466545105,
          0.03512750566005707,
          -1.1029956340789795,
          0.010386109352111816,
          -0.8845862150192261,
          -0.19404193758964539,
          -0.7457612156867981,
          -0.42485207319259644,
          0.0519365593791008,
          -0.3685932457447052,
          -0.5548126697540283,
          0.6355205178260803,
          -0.3186395764350891,
          -1.0450465679168701,
          -0.2923884987831116,
          -0.10414649546146393,
          0.8619942665100098,
          0.5798779726028442,
          0.14356207847595215,
          0.3211731016635895,
          -0.543953001499176,
          -0.8162217140197754,
          -0.46962466835975647,
          -0.48016592860221863,
          -0.05218483507633209,
          0.6663265228271484,
          0.3802618384361267,
          0.28975075483322144,
          0.703967809677124,
          0.03932301327586174,
          0.04805632680654526,
          0.33189576864242554,
          0.6816569566726685,
          -0.04259403795003891,
          0.7217411398887634,
          0.46707257628440857,
          -0.22374603152275085,
          -0.5756751298904419,
          -1.0765427350997925,
          0.07055937498807907,
          0.7407249808311462,
          -0.2387426346540451,
          -0.6942083835601807,
          0.43676987290382385,
          -0.15834391117095947,
          0.3448452949523926,
          -0.6736925840377808,
          -0.48863285779953003,
          0.35350194573402405,
          -0.42028284072875977,
          0.25030070543289185,
          -0.32021626830101013,
          0.356039822101593,
          -0.5573790669441223,
          0.07967155426740646,
          0.7918251752853394,
          0.7860649228096008,
          -0.7983522415161133,
          0.6057566404342651,
          0.48691684007644653,
          -0.6705623269081116,
          -0.5870904922485352,
          -0.29672178626060486,
          0.623399555683136,
          -0.7504681944847107,
          0.06811656057834625,
          -0.4094310402870178,
          0.39333000779151917,
          0.42040807008743286,
          -0.08687949925661087,
          -0.2094607800245285,
          0.340623140335083,
          0.7033461332321167,
          -0.12268371880054474,
          0.31300172209739685,
          0.052735667675733566,
          1.335033893585205,
          -0.006833025254309177,
          0.4315384328365326,
          0.0790226086974144,
          0.5883747339248657,
          -0.8275479078292847,
          0.3095546364784241,
          -0.3954501152038574,
          0.9827227592468262,
          -1.714896321296692,
          -0.7310325503349304,
          0.3808196187019348,
          0.25815844535827637,
          -0.7880319356918335,
          -0.2636028528213501,
          -0.6012517213821411,
          0.8603214621543884,
          0.2902914881706238,
          -0.7453880310058594,
          0.12103156745433807,
          -0.0822831243276596,
          0.004434447735548019,
          0.32127007842063904,
          0.321548730134964,
          -0.7821998596191406,
          0.245408833026886,
          -0.01854480803012848,
          0.4277697503566742,
          -0.4730241894721985,
          0.3422299027442932,
          0.25823724269866943,
          -0.04156874865293503,
          -0.3686752915382385,
          0.6803967356681824,
          -0.5010291337966919,
          1.0667849779129028,
          0.3335834741592407,
          -0.5964741706848145,
          1.0777087211608887,
          0.3173842430114746,
          -0.5189573168754578,
          0.5736876726150513,
          -0.5587151646614075,
          -0.3127050995826721,
          -1.071533203125,
          1.0956732034683228,
          -0.7926661372184753,
          0.4204946756362915,
          0.30386653542518616,
          -0.38796359300613403,
          -0.5360329151153564,
          -0.27013254165649414,
          -0.19643647968769073,
          0.01306617259979248,
          0.24244312942028046,
          0.5219368934631348,
          0.31203195452690125,
          1.4455853700637817,
          1.3931809663772583,
          -0.2795129418373108,
          -0.5002759695053101,
          0.152633398771286,
          0.00428597629070282,
          -0.13602089881896973,
          -0.1271190345287323,
          -0.6434690356254578,
          -0.3041950464248657,
          0.01474638283252716,
          -0.9543590545654297,
          -0.7991464138031006,
          0.2915641665458679,
          0.04489129036664963,
          0.40109726786613464,
          -0.4543018639087677,
          1.2512245178222656,
          -0.08032700419425964,
          0.22869543731212616,
          -0.27270427346229553,
          0.49756014347076416,
          0.41229894757270813,
          0.48912733793258667,
          0.3454647958278656,
          -0.22440259158611298,
          0.4718988835811615,
          -1.3216580152511597,
          0.5721954107284546,
          -0.02993059903383255,
          -0.3386295437812805,
          0.0886279046535492,
          -0.1789313554763794,
          -0.48449787497520447,
          -0.8814272880554199,
          0.8491232991218567,
          -0.5717388391494751,
          -0.06985998153686523,
          -0.06450144946575165,
          -0.10472320765256882,
          0.35573506355285645,
          -0.6703779101371765,
          -0.34213748574256897,
          1.1140443086624146,
          0.732547402381897,
          -0.2872118353843689,
          0.6521491408348083,
          1.2650363445281982,
          0.8802485466003418,
          -0.030680473893880844,
          0.5073578953742981,
          -0.08175978064537048,
          0.36892732977867126,
          -0.978002667427063,
          0.7338712811470032,
          -0.28810247778892517,
          -0.0947214737534523,
          -0.9844988584518433,
          1.2178605794906616,
          0.8406937122344971,
          -0.013150777667760849,
          0.2629128396511078,
          -0.8735443949699402,
          -0.23373344540596008,
          -0.7370491027832031,
          0.4489883482456207,
          -0.41504114866256714,
          1.0085315704345703,
          -0.5365620255470276,
          -0.008806593716144562,
          0.7190882563591003,
          -0.557081937789917,
          3.546618938446045,
          1.3505271673202515,
          0.03523727506399155,
          0.3730278015136719,
          0.5461034774780273,
          1.0387763977050781,
          0.8835951089859009,
          -0.17192421853542328,
          0.7427443861961365,
          -0.4398568570613861,
          0.5249803066253662,
          -0.7895184755325317,
          0.8741750717163086,
          0.26566728949546814,
          0.05622735247015953,
          -0.257822185754776,
          -0.589774489402771,
          0.3704323172569275,
          -0.02251802384853363,
          -0.27245575189590454,
          -1.2720428705215454,
          0.36681172251701355,
          0.33050093054771423,
          -0.5826241374015808,
          0.32944533228874207,
          0.7478929162025452,
          0.19990283250808716,
          -0.18889261782169342,
          -0.010208312422037125,
          -0.049647293984889984,
          -0.09963390231132507,
          -0.755445122718811,
          -0.5080907940864563,
          -0.24698281288146973,
          0.26172032952308655,
          0.9474697709083557,
          -0.12400849163532257,
          -0.827985405921936,
          -0.3589438796043396,
          1.6173346042633057,
          0.46566855907440186,
          -0.7020752429962158,
          -0.4539545774459839,
          -0.47034651041030884,
          0.24336716532707214,
          0.7864907383918762,
          0.3944046199321747,
          0.06576148420572281,
          0.9005893468856812,
          -1.1531851291656494,
          0.22231589257717133,
          -1.3755923509597778,
          -0.11290989071130753,
          -0.2995709478855133,
          0.495760440826416,
          -0.01080633420497179,
          -0.1295289695262909,
          -0.2101012021303177,
          -1.132317066192627,
          0.31023210287094116,
          0.793005108833313,
          -0.6724430918693542,
          -0.5260054469108582,
          0.48100781440734863,
          -0.12989866733551025,
          -0.6021767258644104,
          0.9546927809715271,
          0.3049473166465759,
          -0.30643051862716675,
          -0.05894167348742485,
          0.07372990250587463,
          0.1219046488404274,
          -0.35166066884994507,
          0.3322145938873291,
          -0.07641133666038513,
          0.4298877716064453,
          -0.28851231932640076,
          0.8517731428146362,
          -0.07581955194473267,
          -0.4478563964366913,
          -0.025652721524238586,
          -0.49986857175827026,
          -0.3647233545780182,
          -0.12722724676132202,
          0.3082530200481415,
          0.7311428785324097,
          -0.27601921558380127,
          0.3119897246360779,
          -0.639182448387146,
          0.11222491413354874,
          -0.312813937664032,
          -0.19402246177196503,
          0.44843465089797974,
          -0.042652130126953125,
          0.04873228818178177
        ]
      },
      "type": "document"
    },
    {
      "id": "0223d122-2759-494c-acd3-10ad9357a5c8",
      "properties": {
        "page_content": "Question Context Answer\nWho directed the film Op-\npenheimer and who stars\nas J. Robert Oppenheimer\nin the film?\nOppenheimer is a 2023 biographical thriller film written\nand directed by Christopher Nolan. Based on the 2005\nbiography American Prometheus by Kai Bird and Mar-\ntin J. Sherwin, the film chronicles the life of J. Robert\nOppenheimer, a theoretical physicist who was pivotal in\ndeveloping the first nuclear weapons as part of the Man-\nhattan Project, and thereby ushering in the Atomic Age.\nCillian Murphy stars as Oppenheimer, with Emily Blunt\nas Oppenheimer’s wife Katherine \"Kitty\" Oppenheimer.\nHigh Faithfulness : Christopher\nNolan directed the film Oppen-\nheimer. Cillian Murphy stars as J.\nRobert Oppenheimer in the film.\nLow Faithfulness : James\nCameron directed the film Op-\npenheimer. Tom Cruise stars as J.\nRobert Oppenheimer in the film.\nTable 2: Example from WikiEval, showing answers with high and low faithfulness.\nQuestion Answer\nWhen is the scheduled\nlaunch date and time for\nthe PSLV-C56 mission,\nand where will it be\nlaunched from?\nHigh answer relevance: The PSLV-C56 mission is scheduled to be launched on Sunday, 30\nJuly 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space\nCentre, Sriharikota, Andhra Pradesh, India.\nLow answer relevance: The scheduled launch date and time for the PSLV-C56 mission have\nnot been provided.The PSLV-C56 mission is an important space mission for India. It aims to\nlaunch a satellite into orbit to study weather patterns.\nTable 3: Example from WikiEval, showing answers with high and low answer relevance.\nQuestion Context\nWhen was the Chimnabai\nClock Tower completed,\nand who was it named af-\nter?\nHigh context relevance: The Chimnabai Clock Tower, also known as the Raopura Tower, is\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\nSayajirao Gaekwad III of Baroda State.\nLow context relevance: The Chimnabai Clock Tower, also known as the Raopura Tower, is\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\nSayajirao Gaekwad III of Baroda State. It was built in Indo-Saracenic architecture style.\nHistory. Chimnabai Clock Tower was built in 1896. The tower was named after Chimnabai\nI (1864–1885), a queen and the first wife of Sayajirao Gaekwad III of Baroda State. It was\ninaugurated by Mir Kamaluddin Hussainkhan, the last Nawab of Baroda. During the rule of\nGaekwad, it was a stoppage for horse drawn trams. The clock tower was erected at the cost\nof 25,000 (equivalent to 9.2 million or USD 120,000 in 2023).\nTable 4: Example from WikiEval, showing answers with high and low context relevance.",
        "document_metadata": {
          "page_label": "8",
          "file_name": "2309.15217v1.pdf",
          "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
          "file_type": "application/pdf",
          "file_size": 329967,
          "creation_date": "2024-11-21",
          "last_modified_date": "2024-11-15"
        },
        "headlines": [
          "Main Concepts",
          "Detailed Analysis",
          "Subsection: Specialized Techniques",
          "Future Directions"
        ]
      },
      "type": "document"
    }
  ],
  "relationships": [
    {
      "id": "73846951-f35d-40ca-90c3-d35898b55f12",
      "type": "child",
      "source": {
        "id": "cebcfccc-06e1-4417-af00-157d82513ca4",
        "properties": {
          "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 Models\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 Generator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 Training\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "document_metadata": {
            "page_label": "3",
            "file_name": "2005.11401v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
            "file_type": "application/pdf",
            "file_size": 861548,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "Models",
            "Retriever: DPR",
            "Generator: BART",
            "Training"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "9e32d06e-071a-48d1-9897-24efcf6420b7",
        "properties": {
          "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 \n\nModels\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 ",
          "entities": [
            "θthat",
            "xand",
            "z",
            "y1:i−1",
            "y1:i−1",
            "pη",
            "pθ",
            "RAG-Sequence",
            "RAG-Token"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "dac6f393-9059-4c2d-af89-d3a715177a0c",
      "type": "child",
      "source": {
        "id": "cebcfccc-06e1-4417-af00-157d82513ca4",
        "properties": {
          "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 Models\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 Generator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 Training\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "document_metadata": {
            "page_label": "3",
            "file_name": "2005.11401v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
            "file_type": "application/pdf",
            "file_size": 861548,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "Models",
            "Retriever: DPR",
            "Generator: BART",
            "Training"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "91a7be85-55a2-44f0-97cd-ff13fde405b8",
        "properties": {
          "page_content": "Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 \n\nGenerator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 \n\nTraining\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "entities": [
            "Retriever: DPR",
            "DPR",
            "BERT",
            "BERTBASE",
            "BART-large",
            "TriviaQA",
            "Natural Questions"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "b0518f00-c061-44fa-8356-2e52ee6e5292",
      "type": "next",
      "source": {
        "id": "9e32d06e-071a-48d1-9897-24efcf6420b7",
        "properties": {
          "page_content": "by θthat generates a current token based on a context of the previous i−1 tokens y1:i−1, the original\ninput xand a retrieved passage z.\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.\nWe propose two models that marginalize over the latent documents in different ways to produce a\ndistribution over generated text. In one approach, RAG-Sequence, the model uses the same document\nto predict each target token. The second approach, RAG-Token, can predict each target token based\non a different document. In the following, we formally introduce both models and then describe the\npη and pθ components, as well as the training and decoding procedure.\n2.1 \n\nModels\nRAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate\nthe complete sequence. Technically, it treats the retrieved document as a single latent variable that\nis marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the\ntop K documents are retrieved using the retriever, and the generator produces the output sequence\nprobability for each document, which are then marginalized,\npRAG-Sequence(y|x) ≈\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(y|x,z) =\n∑\nz∈top-k(p(·|x))\npη(z|x)\nN∏\ni\npθ(yi|x,z,y 1:i−1)\nRAG-Token Model In the RAG-Token model we can draw a different latent document for each\ntarget token and marginalize accordingly. This allows the generator to choose content from several\ndocuments when producing an answer. Concretely, the top K documents are retrieved using the\nretriever, and then the generator produces a distribution for the next output token for each document,\nbefore marginalizing, and repeating the process with the following output token, Formally, we deﬁne:\npRAG-Token(y|x) ≈\nN∏\ni\n∑\nz∈top-k(p(·|x))\npη(z|x)pθ(yi|x,z,y 1:i−1)\nFinally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class\nas a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n2.2 ",
          "entities": [
            "θthat",
            "xand",
            "z",
            "y1:i−1",
            "y1:i−1",
            "pη",
            "pθ",
            "RAG-Sequence",
            "RAG-Token"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "91a7be85-55a2-44f0-97cd-ff13fde405b8",
        "properties": {
          "page_content": "Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 \n\nGenerator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 \n\nTraining\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "entities": [
            "Retriever: DPR",
            "DPR",
            "BERT",
            "BERTBASE",
            "BART-large",
            "TriviaQA",
            "Natural Questions"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "a348d9c9-aa10-4994-b1fa-3d128415ffa3",
      "type": "child",
      "source": {
        "id": "e697a572-289b-4477-b7ad-448cf24f0944",
        "properties": {
          "page_content": "D Further Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE Further Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG Parameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "document_metadata": {
            "page_label": "18",
            "file_name": "2005.11401v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
            "file_type": "application/pdf",
            "file_size": 861548,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "Further Details on Open-Domain QA",
            "Further Details on FEVER",
            "Null Document Probabilities",
            "Parameters"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
        "properties": {
          "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
          "entities": [
            "Open-Domain QA",
            "Natural Questions",
            "WebQuestions",
            "TriviaQA",
            "CuratedTrec",
            "DPR",
            "Wikipedia",
            "Berlin",
            "Shanghai"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "bee81156-0df0-42ca-94a1-500d1b13c44e",
      "type": "child",
      "source": {
        "id": "e697a572-289b-4477-b7ad-448cf24f0944",
        "properties": {
          "page_content": "D Further Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE Further Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG Parameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "document_metadata": {
            "page_label": "18",
            "file_name": "2005.11401v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2005.11401v4.pdf",
            "file_type": "application/pdf",
            "file_size": 861548,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "Further Details on Open-Domain QA",
            "Further Details on FEVER",
            "Null Document Probabilities",
            "Parameters"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "b6538aa9-9c99-4c2f-aa83-d8ba6759852f",
      "type": "next",
      "source": {
        "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
        "properties": {
          "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
          "entities": [
            "Open-Domain QA",
            "Natural Questions",
            "WebQuestions",
            "TriviaQA",
            "CuratedTrec",
            "DPR",
            "Wikipedia",
            "Berlin",
            "Shanghai"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "3337c391-58f5-4f7e-be50-be121270595c",
      "type": "child",
      "source": {
        "id": "c8acd236-9a3b-46fb-8fb8-d789a5e6f759",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "document_metadata": {
            "page_label": "4",
            "file_name": "2009.02252v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
            "file_type": "application/pdf",
            "file_size": 836403,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "3 Tasks",
            "3.1 Fact Checking",
            "3.2 Entity Linking"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "Wikipedia",
            "KILT",
            "EvalAI",
            "Yadav",
            "FEVER",
            "Thorne"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "85c32865-13a8-4ce6-9d52-6e1b8b6bac79",
      "type": "child",
      "source": {
        "id": "c8acd236-9a3b-46fb-8fb8-d789a5e6f759",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "document_metadata": {
            "page_label": "4",
            "file_name": "2009.02252v4.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2009.02252v4.pdf",
            "file_type": "application/pdf",
            "file_size": 836403,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-10-10"
          },
          "headlines": [
            "3 Tasks",
            "3.1 Fact Checking",
            "3.2 Entity Linking"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "80ef7bf0-018a-4a27-b41f-c36b5406013f",
        "properties": {
          "page_content": "3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "entities": [
            "Entity Linking",
            "EL",
            "KILT",
            "Wikipedia",
            "Berlin",
            "Shanghai",
            "Wu et al.",
            "AIDA CoNLL-YAGO",
            "CoNLL 2003",
            "YAGO2",
            "WNED-WIKI",
            "Guo and Barbosa"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "6c525739-ab1f-44bf-bfc3-28800e1e0e4f",
      "type": "next",
      "source": {
        "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "Wikipedia",
            "KILT",
            "EvalAI",
            "Yadav",
            "FEVER",
            "Thorne"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "80ef7bf0-018a-4a27-b41f-c36b5406013f",
        "properties": {
          "page_content": "3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "entities": [
            "Entity Linking",
            "EL",
            "KILT",
            "Wikipedia",
            "Berlin",
            "Shanghai",
            "Wu et al.",
            "AIDA CoNLL-YAGO",
            "CoNLL 2003",
            "YAGO2",
            "WNED-WIKI",
            "Guo and Barbosa"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "50da8e95-3ee3-4fc5-b106-dbbe761afda1",
      "type": "child",
      "source": {
        "id": "b09fdece-c2a0-446b-936e-9ef8b868ae29",
        "properties": {
          "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "document_metadata": {
            "page_label": "2",
            "file_name": "2309.15217v1.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
            "file_type": "application/pdf",
            "file_size": 329967,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-11-15"
          },
          "headlines": [
            "2 Related Work",
            "3 Evaluation Strategies"
          ],
          "summary": "Artificial intelligence is transforming various industries by automating tasks, analyzing data quickly and accurately. It's also driving innovations in self-driving cars and personalized recommendations.",
          "summary_embedding": [
            0.17001354694366455,
            0.7037400007247925,
            -0.5972846746444702,
            -0.6107304096221924,
            -0.09962859004735947,
            0.012287147343158722,
            0.24262061715126038,
            -0.07306702435016632,
            0.6197491884231567,
            0.5682291388511658,
            0.05057787150144577,
            0.17918753623962402,
            -0.46196144819259644,
            -1.2443815469741821,
            0.3404715955257416,
            -0.5651688575744629,
            0.08762447535991669,
            0.017658911645412445,
            0.02144092321395874,
            -0.18358242511749268,
            -0.15251317620277405,
            0.6823208332061768,
            -0.6607199311256409,
            -1.0904662609100342,
            -0.9997321367263794,
            0.6225168108940125,
            0.6563811898231506,
            -0.660983145236969,
            0.7149767279624939,
            0.5960270762443542,
            -0.19491973519325256,
            -0.1593451350927353,
            0.1737854778766632,
            -0.5283905863761902,
            -0.623901903629303,
            -0.09424623847007751,
            0.4171382188796997,
            -0.1489633172750473,
            -1.149383544921875,
            -0.5682276487350464,
            0.19610586762428284,
            -0.17803159356117249,
            0.1425337791442871,
            -1.2038860321044922,
            -0.8164084553718567,
            0.4083344340324402,
            0.5729390978813171,
            -1.2199351787567139,
            0.15247289836406708,
            -0.2304106503725052,
            -0.6340320110321045,
            0.1897246241569519,
            -0.21273764967918396,
            -0.438821405172348,
            0.05487480387091637,
            -1.0113580226898193,
            -0.40598830580711365,
            -0.21763378381729126,
            -0.7388358116149902,
            -0.026535741984844208,
            1.0041377544403076,
            -0.33603066205978394,
            0.6034368276596069,
            0.005080267786979675,
            0.25079208612442017,
            0.5439397096633911,
            0.14208808541297913,
            -0.3908669054508209,
            -0.4078671634197235,
            0.17537899315357208,
            -1.2247917652130127,
            -0.32663723826408386,
            0.20429465174674988,
            0.20743021368980408,
            -0.3620830178260803,
            0.004530645906925201,
            0.2692049443721771,
            -0.11996978521347046,
            -0.874296247959137,
            -0.07769046723842621,
            -0.5227373838424683,
            0.6978479623794556,
            -0.45599138736724854,
            1.0713742971420288,
            -0.016694139689207077,
            -0.5868815183639526,
            0.720486044883728,
            0.8622515797615051,
            -0.20124369859695435,
            -0.616811990737915,
            -0.05302967131137848,
            -0.0593307688832283,
            -0.1878845989704132,
            -0.17706695199012756,
            0.24921253323554993,
            0.7306819558143616,
            -0.6822174787521362,
            0.7657720446586609,
            0.2649552822113037,
            -0.08407216519117355,
            0.2404964566230774,
            1.0467617511749268,
            -0.04381487891077995,
            0.9058229327201843,
            -0.7524072527885437,
            0.12525521218776703,
            0.5160109996795654,
            -0.8609219193458557,
            -0.0173206627368927,
            -1.0341943502426147,
            0.6395199298858643,
            0.11479394137859344,
            -0.04732735455036163,
            0.14186322689056396,
            -0.06773766875267029,
            1.5499204397201538,
            -0.3137304484844208,
            0.2628898620605469,
            -0.38901185989379883,
            0.22014670073986053,
            -0.3750650882720947,
            -0.5553479790687561,
            0.1089082881808281,
            -0.3424307703971863,
            0.27794450521469116,
            -1.0881855487823486,
            0.09664730727672577,
            0.7481679320335388,
            -0.5601145029067993,
            0.7897307872772217,
            -0.30724218487739563,
            0.09517356753349304,
            -0.4318879246711731,
            0.7920940518379211,
            0.033566854894161224,
            -0.9695606231689453,
            -0.009823329746723175,
            0.864151656627655,
            -0.29377883672714233,
            0.6365285515785217,
            0.02301349677145481,
            0.11497770249843597,
            -0.17999710142612457,
            1.8254234790802002,
            -0.4079185426235199,
            -0.13048787415027618,
            -0.40041717886924744,
            -0.03488878905773163,
            -0.3938792943954468,
            0.9345355033874512,
            -0.971676230430603,
            0.6461847424507141,
            0.3946326673030853,
            0.058993346989154816,
            -0.6912416219711304,
            -0.694898247718811,
            -0.6673235297203064,
            -0.0035253912210464478,
            0.4665566682815552,
            0.5976436138153076,
            -0.27679160237312317,
            0.09515354037284851,
            -0.11937268078327179,
            1.1978421211242676,
            -0.4322178065776825,
            0.7163383960723877,
            -1.058738112449646,
            0.1593240648508072,
            -0.5214572548866272,
            -0.31140780448913574,
            0.29515790939331055,
            -0.4033297300338745,
            -0.6524462103843689,
            -0.19453158974647522,
            0.9488608241081238,
            1.1427854299545288,
            0.8205499053001404,
            0.22198358178138733,
            0.195535808801651,
            -0.25921016931533813,
            -1.2958908081054688,
            -0.4238226115703583,
            -0.8352176547050476,
            -0.012574121356010437,
            0.2892308831214905,
            0.54080730676651,
            0.29236042499542236,
            0.20837149024009705,
            0.34818941354751587,
            -0.48493045568466187,
            0.16334225237369537,
            0.8018690347671509,
            -1.020436406135559,
            0.013810727745294571,
            -0.06829479336738586,
            0.4744613766670227,
            -0.7049046754837036,
            0.3593010902404785,
            0.24060703814029694,
            -0.0841606929898262,
            -0.19825541973114014,
            0.612318754196167,
            -0.0248248428106308,
            -0.5237756371498108,
            -0.7225826382637024,
            0.49753671884536743,
            -0.1758880764245987,
            1.1122462749481201,
            -1.7922130823135376,
            1.2731688022613525,
            0.5327811241149902,
            0.353199303150177,
            -0.08620534092187881,
            -0.28796327114105225,
            0.8151822686195374,
            -0.10103068500757217,
            -0.3608563542366028,
            0.44243451952934265,
            0.15663601458072662,
            -0.3948861062526703,
            -0.14119377732276917,
            -0.36077097058296204,
            0.4262925386428833,
            -0.5494167804718018,
            -0.47240450978279114,
            -0.14515872299671173,
            -0.33626535534858704,
            0.9724587202072144,
            0.11287185549736023,
            0.21463297307491302,
            0.6391748189926147,
            0.6695569157600403,
            -0.34146133065223694,
            0.824224591255188,
            -0.05279159918427467,
            0.27140527963638306,
            -0.4832804799079895,
            0.40109753608703613,
            -0.25941988825798035,
            -0.2852022647857666,
            0.7792918086051941,
            0.16887053847312927,
            1.4423108100891113,
            0.4774094820022583,
            -0.7280946969985962,
            0.15461347997188568,
            -0.047271013259887695,
            0.024457715451717377,
            0.5811721086502075,
            0.6883000731468201,
            -0.5382037162780762,
            0.1655680537223816,
            0.19549331068992615,
            -0.22478577494621277,
            -0.34745144844055176,
            0.5519740581512451,
            0.6778715252876282,
            0.621571958065033,
            0.34663286805152893,
            -1.3806411027908325,
            -0.7420792579650879,
            0.916611909866333,
            0.5347574353218079,
            -0.03582051023840904,
            0.5334360599517822,
            0.439033180475235,
            -0.29742687940597534,
            -0.06089968979358673,
            -0.8731357455253601,
            -0.36906328797340393,
            -1.3391317129135132,
            -1.3571643829345703,
            -0.44515088200569153,
            -0.34963005781173706,
            -0.9001395106315613,
            -0.12250621616840363,
            0.1641312688589096,
            -0.6905884146690369,
            0.897812008857727,
            0.061345234513282776,
            -0.24086147546768188,
            -0.5424370169639587,
            -0.7769922018051147,
            0.5027157068252563,
            0.8489565849304199,
            0.5165011286735535,
            -1.2212680578231812,
            0.10286206007003784,
            -0.6299771070480347,
            0.7383338809013367,
            0.7440586686134338,
            0.5113784074783325,
            -0.1221046969294548,
            -0.5191940069198608,
            -0.09395311027765274,
            -0.314754843711853,
            0.7612513899803162,
            0.10572165995836258,
            -1.0105764865875244,
            -0.35746049880981445,
            0.009414376690983772,
            0.045240629464387894,
            -0.7688693404197693,
            -0.058514662086963654,
            0.05042830482125282,
            0.517877459526062,
            0.22862103581428528,
            0.0892048180103302,
            1.0613096952438354,
            0.0017666742205619812,
            -1.080322027206421,
            0.18166190385818481,
            -0.18859942257404327,
            0.877560555934906,
            -0.5682258009910583,
            0.6199414730072021,
            0.28334546089172363,
            -0.7195314168930054,
            0.2786213159561157,
            -1.240120768547058,
            -0.14328446984291077,
            0.23443672060966492,
            -0.6127557754516602,
            0.6155505776405334,
            0.15677830576896667,
            0.4240148663520813,
            0.07984823733568192,
            -2.0081636905670166,
            -0.0785396620631218,
            0.14704301953315735,
            -0.4844054579734802,
            -0.11410640180110931,
            0.19603168964385986,
            0.8945372700691223,
            0.8010289072990417,
            -0.47574174404144287,
            -0.05377098172903061,
            -0.01349401380866766,
            -0.31099560856819153,
            0.8452745079994202,
            0.47201094031333923,
            -0.328797310590744,
            0.3333401679992676,
            0.39465823769569397,
            -0.5335476994514465,
            0.7957864999771118,
            1.143248438835144,
            -0.38700470328330994,
            0.7955979704856873,
            -0.23907476663589478,
            -0.17071068286895752,
            -0.23980006575584412,
            -0.41667109727859497,
            -0.3437284529209137,
            0.492573618888855,
            -0.005062118172645569,
            -0.3787897527217865,
            0.42240867018699646,
            -0.1357440948486328,
            0.05385256186127663,
            0.7424731254577637,
            0.285732626914978,
            -0.39705517888069153,
            0.394060879945755,
            -0.5315396785736084,
            0.19403427839279175,
            -0.2192429006099701,
            0.32639408111572266,
            0.28066638112068176,
            -0.7122159004211426,
            0.5880001783370972,
            -0.031648751348257065,
            -0.3973133862018585,
            0.589089035987854,
            -0.7184100151062012,
            -1.0398342609405518,
            0.4490841031074524,
            -1.051051139831543,
            0.11777503788471222,
            -0.729235053062439,
            0.4005323648452759,
            -0.030979089438915253,
            0.07806631922721863,
            -0.29288747906684875,
            -0.2867293357849121,
            0.7395055890083313,
            -0.7586572170257568,
            0.6267704963684082,
            -0.24792706966400146,
            0.022784046828746796,
            0.46371448040008545,
            0.09443165361881256,
            -0.5219950079917908,
            0.19392916560173035,
            -0.6515740752220154,
            -0.7531136870384216,
            1.0470738410949707,
            -0.0744270607829094,
            0.3077602684497833,
            -0.4794044494628906,
            1.1581754684448242,
            -0.11803773045539856,
            0.08202047646045685,
            0.3491073548793793,
            0.42259082198143005,
            0.26220935583114624,
            0.29422926902770996,
            0.8511523604393005,
            0.5405593514442444,
            -0.3957494795322418,
            -0.1757473200559616,
            -0.6707167029380798,
            0.4769055247306824,
            -0.1910010129213333,
            -0.23642201721668243,
            0.24765565991401672,
            -0.08596424758434296,
            -0.033979542553424835,
            -0.8453472852706909,
            0.10397256165742874,
            -0.5907039642333984,
            -0.10156093537807465,
            -0.8092979788780212,
            0.2800861895084381,
            0.46581098437309265,
            -0.21332964301109314,
            -0.5400623083114624,
            -1.4116414785385132,
            0.8352559804916382,
            0.5236283540725708,
            -0.533128559589386,
            -0.7852641940116882,
            0.7948476076126099,
            -0.2872685492038727,
            -0.1552233099937439,
            0.19597934186458588,
            1.4522719383239746,
            -1.0497678518295288,
            0.8697558641433716,
            -0.17765170335769653,
            0.09382285177707672,
            0.7901621460914612,
            0.36114501953125,
            -0.015217822045087814,
            -0.44020381569862366,
            -0.48164623975753784,
            0.03653434291481972,
            0.40998390316963196,
            -0.5152121782302856,
            -0.6707544922828674,
            0.9459491968154907,
            -1.173895239830017,
            1.0103949308395386,
            -0.40128952264785767,
            0.49530327320098877,
            -0.1863308548927307,
            -0.40873822569847107,
            -0.04119553416967392,
            0.1952550709247589,
            0.010577404871582985,
            0.25374725461006165,
            0.22621914744377136,
            0.6641642451286316,
            -0.47020575404167175,
            -0.3554995357990265,
            0.059834063053131104,
            0.8010814189910889,
            0.36591029167175293,
            0.5428950786590576,
            0.16746950149536133,
            0.11595715582370758,
            -0.28647756576538086,
            0.14675003290176392,
            -0.6380338072776794,
            0.7459187507629395,
            -0.6545936465263367,
            0.5749554634094238,
            0.42819446325302124,
            -0.6775094866752625,
            -0.5077385306358337,
            -0.7357791662216187,
            -0.14749374985694885,
            0.45021265745162964,
            0.021158762276172638,
            -0.38448983430862427,
            -0.9372546672821045,
            0.4596109986305237,
            1.0532870292663574,
            -0.1024080365896225,
            0.5325855016708374,
            0.2941443920135498,
            0.2726539075374603,
            -0.14131250977516174,
            0.5887532234191895,
            0.0540425069630146,
            0.08028078079223633,
            0.18049952387809753,
            0.43496033549308777,
            -0.30056819319725037,
            -0.606791079044342,
            1.4120935201644897,
            -1.539868712425232,
            -1.1236213445663452,
            -0.1381358653306961,
            -0.3960403501987457,
            -0.42162036895751953,
            -0.15366025269031525,
            -0.37809696793556213,
            -0.08143360912799835,
            0.3260965645313263,
            -0.06285702437162399,
            0.07940836250782013,
            0.036577582359313965,
            0.39435407519340515,
            0.4194391071796417,
            -0.1030038446187973,
            0.06774973124265671,
            0.1838335394859314,
            -0.13735273480415344,
            1.397924780845642,
            0.3971671462059021,
            -1.165160894393921,
            -0.23002788424491882,
            1.4131200313568115,
            -0.8849786520004272,
            -0.013607487082481384,
            0.32859742641448975,
            -0.9870821833610535,
            0.04724349081516266,
            -1.651365876197815,
            0.22628116607666016,
            -0.25228849053382874,
            -0.16541975736618042,
            -0.16008374094963074,
            0.23235461115837097,
            0.180307075381279,
            0.431549996137619,
            0.5491371154785156,
            -0.4926064610481262,
            -0.5446996688842773,
            0.11665681004524231,
            -0.09422634541988373,
            -0.30947792530059814,
            -0.7230757474899292,
            -0.1223548874258995,
            -0.23080389201641083,
            0.41157492995262146,
            0.6572481989860535,
            -0.5850919485092163,
            -0.6978720426559448,
            0.3820691406726837,
            -0.5212529897689819,
            -0.06448941677808762,
            0.6063043475151062,
            -1.0989983081817627,
            -0.39392203092575073,
            0.26510363817214966,
            0.27503445744514465,
            0.48877447843551636,
            0.9942187070846558,
            -0.5441843271255493,
            -0.4457719326019287,
            0.4149174690246582,
            -0.010136399418115616,
            -0.5762455463409424,
            0.32066112756729126,
            -0.9460886120796204,
            -0.6540416479110718,
            1.1765847206115723,
            -0.4740753769874573,
            -0.6362676024436951,
            0.14861755073070526,
            0.48039260506629944,
            0.7775120735168457,
            0.4484742283821106,
            -0.9746091365814209,
            -0.5573586225509644,
            -0.3240833580493927,
            -1.040083646774292,
            -0.19513455033302307,
            -0.5238984823226929,
            -0.34710004925727844,
            -0.48671960830688477,
            0.13946281373500824,
            0.523432195186615,
            -0.3502989709377289,
            0.35093337297439575,
            1.255302906036377,
            0.5760223269462585,
            -0.5122931003570557,
            0.24288761615753174,
            -0.1372120976448059,
            0.4007200598716736,
            -0.2523748576641083,
            -0.05269220098853111,
            -0.17466726899147034,
            0.09777648746967316,
            -0.4247840642929077,
            0.2223731130361557,
            -0.3812035620212555,
            -0.015078425407409668,
            0.3727424442768097,
            0.7122883796691895,
            -0.7806264162063599,
            0.8414087295532227,
            0.4867090582847595,
            -0.5301060676574707,
            -0.6682600378990173,
            -0.18018731474876404,
            -0.025562386959791183,
            -0.27821844816207886,
            0.38584697246551514,
            0.6938211917877197,
            0.2600957751274109,
            0.6235162615776062,
            -0.3494308292865753,
            -0.9028358459472656,
            -0.4220636188983917,
            0.9436613321304321,
            0.06673064827919006,
            -0.7452048063278198,
            0.1683463752269745,
            1.0002591609954834,
            -0.3949195146560669,
            -0.3138110637664795,
            0.5160955786705017,
            -0.09094443172216415,
            0.5896313190460205,
            -0.5889685153961182,
            0.6214655041694641,
            -0.6478976607322693,
            0.34441739320755005,
            0.0017762742936611176,
            0.519878089427948,
            -0.3244141936302185,
            0.2415621280670166,
            1.4682563543319702,
            0.6422873139381409,
            -0.8613927960395813,
            0.05625161901116371,
            0.545099139213562,
            -0.11511749774217606,
            0.25268709659576416,
            -1.4956293106079102,
            0.22368770837783813,
            -0.14334438741207123,
            -0.7840650677680969,
            0.6866493225097656,
            -1.141023874282837,
            -0.47525739669799805,
            0.7224677801132202,
            0.3698676824569702,
            0.1014661192893982,
            -0.5526877641677856,
            -0.28340044617652893,
            0.2723788022994995,
            0.4167567789554596,
            -0.7093644738197327,
            -0.5773450136184692,
            1.0992814302444458,
            -0.196613147854805,
            0.28266510367393494,
            -0.14656779170036316,
            -0.43136000633239746,
            1.0052707195281982,
            0.5708770155906677,
            -0.34246253967285156,
            -0.37612420320510864,
            -0.1908121258020401,
            -1.275506615638733,
            -0.703254759311676,
            0.033887624740600586,
            0.4685025215148926,
            -0.15191856026649475,
            0.4386812746524811,
            0.4796735644340515,
            -0.35543501377105713,
            -0.4038871228694916,
            0.27127981185913086,
            -0.9501429796218872,
            -1.0727314949035645,
            -0.25700175762176514,
            0.3988332450389862,
            -0.16924560070037842,
            0.14980749785900116,
            -0.006653411313891411,
            0.11718682199716568,
            0.047420624643564224,
            0.9359047412872314,
            -0.5301834344863892,
            0.3056376576423645,
            0.1699923574924469,
            0.4255838096141815,
            -0.6619510054588318,
            -0.31164491176605225,
            -0.35329490900039673,
            -0.13582590222358704,
            -0.5112341046333313,
            0.04059603810310364,
            -0.003652714192867279,
            0.25951236486434937,
            0.2676461935043335,
            -0.6374751925468445,
            0.3035447299480438,
            -0.42165347933769226,
            0.45802199840545654,
            -0.6701480150222778,
            0.18224060535430908,
            0.5058137774467468,
            -0.2548138499259949,
            0.3355627655982971,
            -1.0425794124603271,
            1.0436476469039917,
            0.03962875157594681,
            -0.8060978055000305,
            0.9327201247215271,
            -0.06457459181547165,
            0.07619282603263855,
            -0.3150366544723511,
            -0.35759446024894714,
            0.6337752938270569,
            -0.18901996314525604,
            0.6751437783241272,
            -0.2137773036956787,
            0.3838304281234741,
            0.08684554696083069,
            -0.9672592878341675,
            0.06794177740812302,
            -1.0044156312942505,
            -0.1812874674797058,
            -0.7855228781700134,
            -0.40825703740119934,
            0.1801707148551941,
            -0.30765601992607117,
            -0.5223142504692078,
            0.7315949201583862,
            -0.21172048151493073,
            -0.9583691358566284,
            -0.2168758511543274,
            -0.18539315462112427,
            0.862801730632782,
            0.44850772619247437,
            0.09827776253223419,
            0.20500892400741577,
            -0.5893012285232544,
            -0.7761632800102234,
            -0.36789920926094055,
            -0.4591901898384094,
            -0.07052107900381088,
            0.5964833498001099,
            0.479718953371048,
            0.2891619801521301,
            0.7711735367774963,
            0.05081861466169357,
            0.09017185866832733,
            0.3816324472427368,
            0.6926770210266113,
            0.01983916014432907,
            0.6555072069168091,
            0.3903695046901703,
            -0.14761152863502502,
            -0.575197160243988,
            -0.9898099899291992,
            0.08500632643699646,
            0.8257237672805786,
            -0.2930217385292053,
            -0.6874611973762512,
            0.4775601327419281,
            -0.15995976328849792,
            0.3258691132068634,
            -0.6289264559745789,
            -0.46555328369140625,
            0.420318067073822,
            -0.2901972830295563,
            0.10389847308397293,
            -0.34914082288742065,
            0.47068512439727783,
            -0.769072949886322,
            0.05595392733812332,
            0.592705488204956,
            0.6698029041290283,
            -0.7116877436637878,
            0.5991199016571045,
            0.4397561550140381,
            -0.5263884663581848,
            -0.5824525356292725,
            -0.1977275013923645,
            0.7402856349945068,
            -0.6579052209854126,
            0.12078002840280533,
            -0.5129790902137756,
            0.41893893480300903,
            0.3594971299171448,
            -0.15906713902950287,
            -0.25405222177505493,
            0.29509878158569336,
            0.6125257611274719,
            -0.07987882196903229,
            0.1964319944381714,
            0.057425357401371,
            1.1973668336868286,
            -0.1455817073583603,
            0.47452229261398315,
            0.08990931510925293,
            0.5480901002883911,
            -0.7766255736351013,
            0.3147953152656555,
            -0.4887899160385132,
            1.0461783409118652,
            -1.7564404010772705,
            -0.6384751796722412,
            0.33399122953414917,
            0.2917623221874237,
            -0.8807685375213623,
            -0.3822582960128784,
            -0.6550198793411255,
            0.8475666046142578,
            0.25435903668403625,
            -0.7574268579483032,
            -0.0018529444932937622,
            -0.014977369457483292,
            0.03859864920377731,
            0.352078914642334,
            0.09113695472478867,
            -0.680365800857544,
            0.05272725224494934,
            -0.050849609076976776,
            0.4229072332382202,
            -0.4171856939792633,
            0.3756403923034668,
            0.08677571266889572,
            0.0173296257853508,
            -0.3013012111186981,
            0.6550720930099487,
            -0.5206359028816223,
            1.1400402784347534,
            0.2801797688007355,
            -0.7541120052337646,
            1.065847396850586,
            0.40635785460472107,
            -0.6848594546318054,
            0.4961469769477844,
            -0.5760297775268555,
            -0.3164706826210022,
            -0.979499340057373,
            1.0243557691574097,
            -0.7872797250747681,
            0.41145145893096924,
            0.3963802754878998,
            -0.38772183656692505,
            -0.4024256467819214,
            -0.17413336038589478,
            -0.2881929278373718,
            0.02224862575531006,
            0.3467528522014618,
            0.6031092405319214,
            0.17441962659358978,
            1.5294687747955322,
            1.4079548120498657,
            -0.3090057969093323,
            -0.4795108735561371,
            0.20001280307769775,
            -0.050295181572437286,
            -0.04949251562356949,
            0.029213011264801025,
            -0.8218201398849487,
            -0.2659166753292084,
            -0.016189932823181152,
            -0.901006281375885,
            -0.6852371096611023,
            0.10220614820718765,
            0.024360425770282745,
            0.5643877387046814,
            -0.45608797669410706,
            1.1881756782531738,
            -0.013729273341596127,
            0.3067585825920105,
            -0.21116375923156738,
            0.5415292978286743,
            0.3503587245941162,
            0.3404058516025543,
            0.26543930172920227,
            -0.40818291902542114,
            0.34338510036468506,
            -1.242517113685608,
            0.6535123586654663,
            -0.09536947309970856,
            -0.22092273831367493,
            0.1358795017004013,
            -0.07661644369363785,
            -0.48790687322616577,
            -0.8044420480728149,
            0.8619990944862366,
            -0.5634229183197021,
            -0.15451452136039734,
            -0.056584082543849945,
            -0.10315336287021637,
            0.2963704466819763,
            -0.6731477379798889,
            -0.2650216221809387,
            1.140690565109253,
            0.7295383810997009,
            -0.2410965859889984,
            0.8084008693695068,
            1.3607964515686035,
            0.9849858283996582,
            -0.0021980777382850647,
            0.30507537722587585,
            -0.05425456538796425,
            0.3335658013820648,
            -1.0028042793273926,
            0.7778862118721008,
            -0.21071121096611023,
            0.01591450907289982,
            -0.7356854677200317,
            1.2284009456634521,
            0.7665082812309265,
            -0.007250789552927017,
            0.2533431947231293,
            -0.8016059398651123,
            -0.23056310415267944,
            -0.6829859614372253,
            0.41483235359191895,
            -0.34258410334587097,
            1.0617529153823853,
            -0.2951352596282959,
            -0.042767491191625595,
            0.6269879341125488,
            -0.6027786135673523,
            3.558955669403076,
            1.2797582149505615,
            0.007599048316478729,
            0.3860686123371124,
            0.4726114869117737,
            0.8475812673568726,
            0.9102058410644531,
            -0.27242863178253174,
            0.6766815185546875,
            -0.5287512540817261,
            0.44011643528938293,
            -0.8467885851860046,
            0.8155112862586975,
            0.33959078788757324,
            -0.07588443160057068,
            -0.302099347114563,
            -0.6180403828620911,
            0.3061239421367645,
            0.0778491422533989,
            -0.250794380903244,
            -1.354028582572937,
            0.18711569905281067,
            0.38861584663391113,
            -0.3797015845775604,
            0.29237303137779236,
            0.6752381324768066,
            0.18495091795921326,
            -0.1203288808465004,
            -0.12374788522720337,
            -0.43279942870140076,
            -0.022384442389011383,
            -0.6906774640083313,
            -0.3512727618217468,
            -0.15720349550247192,
            0.3055146336555481,
            0.8287830352783203,
            -0.09221271425485611,
            -0.8191463351249695,
            -0.34214597940444946,
            1.540235996246338,
            0.4085407257080078,
            -0.7491922378540039,
            -0.49750491976737976,
            -0.5750055909156799,
            0.21292488276958466,
            0.7254807949066162,
            0.30850186944007874,
            0.10280518233776093,
            0.9576418399810791,
            -1.058341383934021,
            0.11174922436475754,
            -1.300818920135498,
            -0.0058571817353367805,
            -0.3538460433483124,
            0.42406314611434937,
            0.24924302101135254,
            -0.22851957380771637,
            -0.2821687161922455,
            -1.114016056060791,
            0.2703506350517273,
            0.682325005531311,
            -0.7011772394180298,
            -0.4857853055000305,
            0.6133390069007874,
            -0.20744799077510834,
            -0.5177156925201416,
            0.8633387088775635,
            0.37909919023513794,
            -0.3055003583431244,
            0.002858804538846016,
            0.07647169381380081,
            0.1047683134675026,
            -0.22133761644363403,
            0.26869189739227295,
            -0.005936175584793091,
            0.21599900722503662,
            -0.3166124224662781,
            0.8280325531959534,
            -0.008065769448876381,
            -0.38700973987579346,
            0.011715345084667206,
            -0.5531673431396484,
            -0.29621240496635437,
            -0.10843560844659805,
            0.3202867805957794,
            0.8495392203330994,
            -0.19346767663955688,
            0.20536071062088013,
            -0.5506631135940552,
            0.20396719872951508,
            -0.3247654139995575,
            -0.24715667963027954,
            0.40172138810157776,
            -0.048450928181409836,
            0.04589752107858658
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "4153fc52-5968-44e6-aed7-c938bbcf6a2c",
        "properties": {
          "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n\n\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n",
          "entities": [
            "Ji et al.",
            "Zhang et al.",
            "Li et al.",
            "Azaria and Mitchell",
            "Min et al.",
            "Yuan et al.",
            "BARTScore",
            "Kadavath et al.",
            "ChatGPT",
            "GPT-4",
            "SelfCheckGPT",
            "GPTScore",
            "Fu et al.",
            "Wang et al.",
            "BERTScore",
            "MoverScore",
            "Zhao et al."
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "090b2cbb-6979-4f5f-b35b-b1feaacda9cc",
      "type": "child",
      "source": {
        "id": "b09fdece-c2a0-446b-936e-9ef8b868ae29",
        "properties": {
          "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "document_metadata": {
            "page_label": "2",
            "file_name": "2309.15217v1.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
            "file_type": "application/pdf",
            "file_size": 329967,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-11-15"
          },
          "headlines": [
            "2 Related Work",
            "3 Evaluation Strategies"
          ],
          "summary": "Artificial intelligence is transforming various industries by automating tasks, analyzing data quickly and accurately. It's also driving innovations in self-driving cars and personalized recommendations.",
          "summary_embedding": [
            0.17001354694366455,
            0.7037400007247925,
            -0.5972846746444702,
            -0.6107304096221924,
            -0.09962859004735947,
            0.012287147343158722,
            0.24262061715126038,
            -0.07306702435016632,
            0.6197491884231567,
            0.5682291388511658,
            0.05057787150144577,
            0.17918753623962402,
            -0.46196144819259644,
            -1.2443815469741821,
            0.3404715955257416,
            -0.5651688575744629,
            0.08762447535991669,
            0.017658911645412445,
            0.02144092321395874,
            -0.18358242511749268,
            -0.15251317620277405,
            0.6823208332061768,
            -0.6607199311256409,
            -1.0904662609100342,
            -0.9997321367263794,
            0.6225168108940125,
            0.6563811898231506,
            -0.660983145236969,
            0.7149767279624939,
            0.5960270762443542,
            -0.19491973519325256,
            -0.1593451350927353,
            0.1737854778766632,
            -0.5283905863761902,
            -0.623901903629303,
            -0.09424623847007751,
            0.4171382188796997,
            -0.1489633172750473,
            -1.149383544921875,
            -0.5682276487350464,
            0.19610586762428284,
            -0.17803159356117249,
            0.1425337791442871,
            -1.2038860321044922,
            -0.8164084553718567,
            0.4083344340324402,
            0.5729390978813171,
            -1.2199351787567139,
            0.15247289836406708,
            -0.2304106503725052,
            -0.6340320110321045,
            0.1897246241569519,
            -0.21273764967918396,
            -0.438821405172348,
            0.05487480387091637,
            -1.0113580226898193,
            -0.40598830580711365,
            -0.21763378381729126,
            -0.7388358116149902,
            -0.026535741984844208,
            1.0041377544403076,
            -0.33603066205978394,
            0.6034368276596069,
            0.005080267786979675,
            0.25079208612442017,
            0.5439397096633911,
            0.14208808541297913,
            -0.3908669054508209,
            -0.4078671634197235,
            0.17537899315357208,
            -1.2247917652130127,
            -0.32663723826408386,
            0.20429465174674988,
            0.20743021368980408,
            -0.3620830178260803,
            0.004530645906925201,
            0.2692049443721771,
            -0.11996978521347046,
            -0.874296247959137,
            -0.07769046723842621,
            -0.5227373838424683,
            0.6978479623794556,
            -0.45599138736724854,
            1.0713742971420288,
            -0.016694139689207077,
            -0.5868815183639526,
            0.720486044883728,
            0.8622515797615051,
            -0.20124369859695435,
            -0.616811990737915,
            -0.05302967131137848,
            -0.0593307688832283,
            -0.1878845989704132,
            -0.17706695199012756,
            0.24921253323554993,
            0.7306819558143616,
            -0.6822174787521362,
            0.7657720446586609,
            0.2649552822113037,
            -0.08407216519117355,
            0.2404964566230774,
            1.0467617511749268,
            -0.04381487891077995,
            0.9058229327201843,
            -0.7524072527885437,
            0.12525521218776703,
            0.5160109996795654,
            -0.8609219193458557,
            -0.0173206627368927,
            -1.0341943502426147,
            0.6395199298858643,
            0.11479394137859344,
            -0.04732735455036163,
            0.14186322689056396,
            -0.06773766875267029,
            1.5499204397201538,
            -0.3137304484844208,
            0.2628898620605469,
            -0.38901185989379883,
            0.22014670073986053,
            -0.3750650882720947,
            -0.5553479790687561,
            0.1089082881808281,
            -0.3424307703971863,
            0.27794450521469116,
            -1.0881855487823486,
            0.09664730727672577,
            0.7481679320335388,
            -0.5601145029067993,
            0.7897307872772217,
            -0.30724218487739563,
            0.09517356753349304,
            -0.4318879246711731,
            0.7920940518379211,
            0.033566854894161224,
            -0.9695606231689453,
            -0.009823329746723175,
            0.864151656627655,
            -0.29377883672714233,
            0.6365285515785217,
            0.02301349677145481,
            0.11497770249843597,
            -0.17999710142612457,
            1.8254234790802002,
            -0.4079185426235199,
            -0.13048787415027618,
            -0.40041717886924744,
            -0.03488878905773163,
            -0.3938792943954468,
            0.9345355033874512,
            -0.971676230430603,
            0.6461847424507141,
            0.3946326673030853,
            0.058993346989154816,
            -0.6912416219711304,
            -0.694898247718811,
            -0.6673235297203064,
            -0.0035253912210464478,
            0.4665566682815552,
            0.5976436138153076,
            -0.27679160237312317,
            0.09515354037284851,
            -0.11937268078327179,
            1.1978421211242676,
            -0.4322178065776825,
            0.7163383960723877,
            -1.058738112449646,
            0.1593240648508072,
            -0.5214572548866272,
            -0.31140780448913574,
            0.29515790939331055,
            -0.4033297300338745,
            -0.6524462103843689,
            -0.19453158974647522,
            0.9488608241081238,
            1.1427854299545288,
            0.8205499053001404,
            0.22198358178138733,
            0.195535808801651,
            -0.25921016931533813,
            -1.2958908081054688,
            -0.4238226115703583,
            -0.8352176547050476,
            -0.012574121356010437,
            0.2892308831214905,
            0.54080730676651,
            0.29236042499542236,
            0.20837149024009705,
            0.34818941354751587,
            -0.48493045568466187,
            0.16334225237369537,
            0.8018690347671509,
            -1.020436406135559,
            0.013810727745294571,
            -0.06829479336738586,
            0.4744613766670227,
            -0.7049046754837036,
            0.3593010902404785,
            0.24060703814029694,
            -0.0841606929898262,
            -0.19825541973114014,
            0.612318754196167,
            -0.0248248428106308,
            -0.5237756371498108,
            -0.7225826382637024,
            0.49753671884536743,
            -0.1758880764245987,
            1.1122462749481201,
            -1.7922130823135376,
            1.2731688022613525,
            0.5327811241149902,
            0.353199303150177,
            -0.08620534092187881,
            -0.28796327114105225,
            0.8151822686195374,
            -0.10103068500757217,
            -0.3608563542366028,
            0.44243451952934265,
            0.15663601458072662,
            -0.3948861062526703,
            -0.14119377732276917,
            -0.36077097058296204,
            0.4262925386428833,
            -0.5494167804718018,
            -0.47240450978279114,
            -0.14515872299671173,
            -0.33626535534858704,
            0.9724587202072144,
            0.11287185549736023,
            0.21463297307491302,
            0.6391748189926147,
            0.6695569157600403,
            -0.34146133065223694,
            0.824224591255188,
            -0.05279159918427467,
            0.27140527963638306,
            -0.4832804799079895,
            0.40109753608703613,
            -0.25941988825798035,
            -0.2852022647857666,
            0.7792918086051941,
            0.16887053847312927,
            1.4423108100891113,
            0.4774094820022583,
            -0.7280946969985962,
            0.15461347997188568,
            -0.047271013259887695,
            0.024457715451717377,
            0.5811721086502075,
            0.6883000731468201,
            -0.5382037162780762,
            0.1655680537223816,
            0.19549331068992615,
            -0.22478577494621277,
            -0.34745144844055176,
            0.5519740581512451,
            0.6778715252876282,
            0.621571958065033,
            0.34663286805152893,
            -1.3806411027908325,
            -0.7420792579650879,
            0.916611909866333,
            0.5347574353218079,
            -0.03582051023840904,
            0.5334360599517822,
            0.439033180475235,
            -0.29742687940597534,
            -0.06089968979358673,
            -0.8731357455253601,
            -0.36906328797340393,
            -1.3391317129135132,
            -1.3571643829345703,
            -0.44515088200569153,
            -0.34963005781173706,
            -0.9001395106315613,
            -0.12250621616840363,
            0.1641312688589096,
            -0.6905884146690369,
            0.897812008857727,
            0.061345234513282776,
            -0.24086147546768188,
            -0.5424370169639587,
            -0.7769922018051147,
            0.5027157068252563,
            0.8489565849304199,
            0.5165011286735535,
            -1.2212680578231812,
            0.10286206007003784,
            -0.6299771070480347,
            0.7383338809013367,
            0.7440586686134338,
            0.5113784074783325,
            -0.1221046969294548,
            -0.5191940069198608,
            -0.09395311027765274,
            -0.314754843711853,
            0.7612513899803162,
            0.10572165995836258,
            -1.0105764865875244,
            -0.35746049880981445,
            0.009414376690983772,
            0.045240629464387894,
            -0.7688693404197693,
            -0.058514662086963654,
            0.05042830482125282,
            0.517877459526062,
            0.22862103581428528,
            0.0892048180103302,
            1.0613096952438354,
            0.0017666742205619812,
            -1.080322027206421,
            0.18166190385818481,
            -0.18859942257404327,
            0.877560555934906,
            -0.5682258009910583,
            0.6199414730072021,
            0.28334546089172363,
            -0.7195314168930054,
            0.2786213159561157,
            -1.240120768547058,
            -0.14328446984291077,
            0.23443672060966492,
            -0.6127557754516602,
            0.6155505776405334,
            0.15677830576896667,
            0.4240148663520813,
            0.07984823733568192,
            -2.0081636905670166,
            -0.0785396620631218,
            0.14704301953315735,
            -0.4844054579734802,
            -0.11410640180110931,
            0.19603168964385986,
            0.8945372700691223,
            0.8010289072990417,
            -0.47574174404144287,
            -0.05377098172903061,
            -0.01349401380866766,
            -0.31099560856819153,
            0.8452745079994202,
            0.47201094031333923,
            -0.328797310590744,
            0.3333401679992676,
            0.39465823769569397,
            -0.5335476994514465,
            0.7957864999771118,
            1.143248438835144,
            -0.38700470328330994,
            0.7955979704856873,
            -0.23907476663589478,
            -0.17071068286895752,
            -0.23980006575584412,
            -0.41667109727859497,
            -0.3437284529209137,
            0.492573618888855,
            -0.005062118172645569,
            -0.3787897527217865,
            0.42240867018699646,
            -0.1357440948486328,
            0.05385256186127663,
            0.7424731254577637,
            0.285732626914978,
            -0.39705517888069153,
            0.394060879945755,
            -0.5315396785736084,
            0.19403427839279175,
            -0.2192429006099701,
            0.32639408111572266,
            0.28066638112068176,
            -0.7122159004211426,
            0.5880001783370972,
            -0.031648751348257065,
            -0.3973133862018585,
            0.589089035987854,
            -0.7184100151062012,
            -1.0398342609405518,
            0.4490841031074524,
            -1.051051139831543,
            0.11777503788471222,
            -0.729235053062439,
            0.4005323648452759,
            -0.030979089438915253,
            0.07806631922721863,
            -0.29288747906684875,
            -0.2867293357849121,
            0.7395055890083313,
            -0.7586572170257568,
            0.6267704963684082,
            -0.24792706966400146,
            0.022784046828746796,
            0.46371448040008545,
            0.09443165361881256,
            -0.5219950079917908,
            0.19392916560173035,
            -0.6515740752220154,
            -0.7531136870384216,
            1.0470738410949707,
            -0.0744270607829094,
            0.3077602684497833,
            -0.4794044494628906,
            1.1581754684448242,
            -0.11803773045539856,
            0.08202047646045685,
            0.3491073548793793,
            0.42259082198143005,
            0.26220935583114624,
            0.29422926902770996,
            0.8511523604393005,
            0.5405593514442444,
            -0.3957494795322418,
            -0.1757473200559616,
            -0.6707167029380798,
            0.4769055247306824,
            -0.1910010129213333,
            -0.23642201721668243,
            0.24765565991401672,
            -0.08596424758434296,
            -0.033979542553424835,
            -0.8453472852706909,
            0.10397256165742874,
            -0.5907039642333984,
            -0.10156093537807465,
            -0.8092979788780212,
            0.2800861895084381,
            0.46581098437309265,
            -0.21332964301109314,
            -0.5400623083114624,
            -1.4116414785385132,
            0.8352559804916382,
            0.5236283540725708,
            -0.533128559589386,
            -0.7852641940116882,
            0.7948476076126099,
            -0.2872685492038727,
            -0.1552233099937439,
            0.19597934186458588,
            1.4522719383239746,
            -1.0497678518295288,
            0.8697558641433716,
            -0.17765170335769653,
            0.09382285177707672,
            0.7901621460914612,
            0.36114501953125,
            -0.015217822045087814,
            -0.44020381569862366,
            -0.48164623975753784,
            0.03653434291481972,
            0.40998390316963196,
            -0.5152121782302856,
            -0.6707544922828674,
            0.9459491968154907,
            -1.173895239830017,
            1.0103949308395386,
            -0.40128952264785767,
            0.49530327320098877,
            -0.1863308548927307,
            -0.40873822569847107,
            -0.04119553416967392,
            0.1952550709247589,
            0.010577404871582985,
            0.25374725461006165,
            0.22621914744377136,
            0.6641642451286316,
            -0.47020575404167175,
            -0.3554995357990265,
            0.059834063053131104,
            0.8010814189910889,
            0.36591029167175293,
            0.5428950786590576,
            0.16746950149536133,
            0.11595715582370758,
            -0.28647756576538086,
            0.14675003290176392,
            -0.6380338072776794,
            0.7459187507629395,
            -0.6545936465263367,
            0.5749554634094238,
            0.42819446325302124,
            -0.6775094866752625,
            -0.5077385306358337,
            -0.7357791662216187,
            -0.14749374985694885,
            0.45021265745162964,
            0.021158762276172638,
            -0.38448983430862427,
            -0.9372546672821045,
            0.4596109986305237,
            1.0532870292663574,
            -0.1024080365896225,
            0.5325855016708374,
            0.2941443920135498,
            0.2726539075374603,
            -0.14131250977516174,
            0.5887532234191895,
            0.0540425069630146,
            0.08028078079223633,
            0.18049952387809753,
            0.43496033549308777,
            -0.30056819319725037,
            -0.606791079044342,
            1.4120935201644897,
            -1.539868712425232,
            -1.1236213445663452,
            -0.1381358653306961,
            -0.3960403501987457,
            -0.42162036895751953,
            -0.15366025269031525,
            -0.37809696793556213,
            -0.08143360912799835,
            0.3260965645313263,
            -0.06285702437162399,
            0.07940836250782013,
            0.036577582359313965,
            0.39435407519340515,
            0.4194391071796417,
            -0.1030038446187973,
            0.06774973124265671,
            0.1838335394859314,
            -0.13735273480415344,
            1.397924780845642,
            0.3971671462059021,
            -1.165160894393921,
            -0.23002788424491882,
            1.4131200313568115,
            -0.8849786520004272,
            -0.013607487082481384,
            0.32859742641448975,
            -0.9870821833610535,
            0.04724349081516266,
            -1.651365876197815,
            0.22628116607666016,
            -0.25228849053382874,
            -0.16541975736618042,
            -0.16008374094963074,
            0.23235461115837097,
            0.180307075381279,
            0.431549996137619,
            0.5491371154785156,
            -0.4926064610481262,
            -0.5446996688842773,
            0.11665681004524231,
            -0.09422634541988373,
            -0.30947792530059814,
            -0.7230757474899292,
            -0.1223548874258995,
            -0.23080389201641083,
            0.41157492995262146,
            0.6572481989860535,
            -0.5850919485092163,
            -0.6978720426559448,
            0.3820691406726837,
            -0.5212529897689819,
            -0.06448941677808762,
            0.6063043475151062,
            -1.0989983081817627,
            -0.39392203092575073,
            0.26510363817214966,
            0.27503445744514465,
            0.48877447843551636,
            0.9942187070846558,
            -0.5441843271255493,
            -0.4457719326019287,
            0.4149174690246582,
            -0.010136399418115616,
            -0.5762455463409424,
            0.32066112756729126,
            -0.9460886120796204,
            -0.6540416479110718,
            1.1765847206115723,
            -0.4740753769874573,
            -0.6362676024436951,
            0.14861755073070526,
            0.48039260506629944,
            0.7775120735168457,
            0.4484742283821106,
            -0.9746091365814209,
            -0.5573586225509644,
            -0.3240833580493927,
            -1.040083646774292,
            -0.19513455033302307,
            -0.5238984823226929,
            -0.34710004925727844,
            -0.48671960830688477,
            0.13946281373500824,
            0.523432195186615,
            -0.3502989709377289,
            0.35093337297439575,
            1.255302906036377,
            0.5760223269462585,
            -0.5122931003570557,
            0.24288761615753174,
            -0.1372120976448059,
            0.4007200598716736,
            -0.2523748576641083,
            -0.05269220098853111,
            -0.17466726899147034,
            0.09777648746967316,
            -0.4247840642929077,
            0.2223731130361557,
            -0.3812035620212555,
            -0.015078425407409668,
            0.3727424442768097,
            0.7122883796691895,
            -0.7806264162063599,
            0.8414087295532227,
            0.4867090582847595,
            -0.5301060676574707,
            -0.6682600378990173,
            -0.18018731474876404,
            -0.025562386959791183,
            -0.27821844816207886,
            0.38584697246551514,
            0.6938211917877197,
            0.2600957751274109,
            0.6235162615776062,
            -0.3494308292865753,
            -0.9028358459472656,
            -0.4220636188983917,
            0.9436613321304321,
            0.06673064827919006,
            -0.7452048063278198,
            0.1683463752269745,
            1.0002591609954834,
            -0.3949195146560669,
            -0.3138110637664795,
            0.5160955786705017,
            -0.09094443172216415,
            0.5896313190460205,
            -0.5889685153961182,
            0.6214655041694641,
            -0.6478976607322693,
            0.34441739320755005,
            0.0017762742936611176,
            0.519878089427948,
            -0.3244141936302185,
            0.2415621280670166,
            1.4682563543319702,
            0.6422873139381409,
            -0.8613927960395813,
            0.05625161901116371,
            0.545099139213562,
            -0.11511749774217606,
            0.25268709659576416,
            -1.4956293106079102,
            0.22368770837783813,
            -0.14334438741207123,
            -0.7840650677680969,
            0.6866493225097656,
            -1.141023874282837,
            -0.47525739669799805,
            0.7224677801132202,
            0.3698676824569702,
            0.1014661192893982,
            -0.5526877641677856,
            -0.28340044617652893,
            0.2723788022994995,
            0.4167567789554596,
            -0.7093644738197327,
            -0.5773450136184692,
            1.0992814302444458,
            -0.196613147854805,
            0.28266510367393494,
            -0.14656779170036316,
            -0.43136000633239746,
            1.0052707195281982,
            0.5708770155906677,
            -0.34246253967285156,
            -0.37612420320510864,
            -0.1908121258020401,
            -1.275506615638733,
            -0.703254759311676,
            0.033887624740600586,
            0.4685025215148926,
            -0.15191856026649475,
            0.4386812746524811,
            0.4796735644340515,
            -0.35543501377105713,
            -0.4038871228694916,
            0.27127981185913086,
            -0.9501429796218872,
            -1.0727314949035645,
            -0.25700175762176514,
            0.3988332450389862,
            -0.16924560070037842,
            0.14980749785900116,
            -0.006653411313891411,
            0.11718682199716568,
            0.047420624643564224,
            0.9359047412872314,
            -0.5301834344863892,
            0.3056376576423645,
            0.1699923574924469,
            0.4255838096141815,
            -0.6619510054588318,
            -0.31164491176605225,
            -0.35329490900039673,
            -0.13582590222358704,
            -0.5112341046333313,
            0.04059603810310364,
            -0.003652714192867279,
            0.25951236486434937,
            0.2676461935043335,
            -0.6374751925468445,
            0.3035447299480438,
            -0.42165347933769226,
            0.45802199840545654,
            -0.6701480150222778,
            0.18224060535430908,
            0.5058137774467468,
            -0.2548138499259949,
            0.3355627655982971,
            -1.0425794124603271,
            1.0436476469039917,
            0.03962875157594681,
            -0.8060978055000305,
            0.9327201247215271,
            -0.06457459181547165,
            0.07619282603263855,
            -0.3150366544723511,
            -0.35759446024894714,
            0.6337752938270569,
            -0.18901996314525604,
            0.6751437783241272,
            -0.2137773036956787,
            0.3838304281234741,
            0.08684554696083069,
            -0.9672592878341675,
            0.06794177740812302,
            -1.0044156312942505,
            -0.1812874674797058,
            -0.7855228781700134,
            -0.40825703740119934,
            0.1801707148551941,
            -0.30765601992607117,
            -0.5223142504692078,
            0.7315949201583862,
            -0.21172048151493073,
            -0.9583691358566284,
            -0.2168758511543274,
            -0.18539315462112427,
            0.862801730632782,
            0.44850772619247437,
            0.09827776253223419,
            0.20500892400741577,
            -0.5893012285232544,
            -0.7761632800102234,
            -0.36789920926094055,
            -0.4591901898384094,
            -0.07052107900381088,
            0.5964833498001099,
            0.479718953371048,
            0.2891619801521301,
            0.7711735367774963,
            0.05081861466169357,
            0.09017185866832733,
            0.3816324472427368,
            0.6926770210266113,
            0.01983916014432907,
            0.6555072069168091,
            0.3903695046901703,
            -0.14761152863502502,
            -0.575197160243988,
            -0.9898099899291992,
            0.08500632643699646,
            0.8257237672805786,
            -0.2930217385292053,
            -0.6874611973762512,
            0.4775601327419281,
            -0.15995976328849792,
            0.3258691132068634,
            -0.6289264559745789,
            -0.46555328369140625,
            0.420318067073822,
            -0.2901972830295563,
            0.10389847308397293,
            -0.34914082288742065,
            0.47068512439727783,
            -0.769072949886322,
            0.05595392733812332,
            0.592705488204956,
            0.6698029041290283,
            -0.7116877436637878,
            0.5991199016571045,
            0.4397561550140381,
            -0.5263884663581848,
            -0.5824525356292725,
            -0.1977275013923645,
            0.7402856349945068,
            -0.6579052209854126,
            0.12078002840280533,
            -0.5129790902137756,
            0.41893893480300903,
            0.3594971299171448,
            -0.15906713902950287,
            -0.25405222177505493,
            0.29509878158569336,
            0.6125257611274719,
            -0.07987882196903229,
            0.1964319944381714,
            0.057425357401371,
            1.1973668336868286,
            -0.1455817073583603,
            0.47452229261398315,
            0.08990931510925293,
            0.5480901002883911,
            -0.7766255736351013,
            0.3147953152656555,
            -0.4887899160385132,
            1.0461783409118652,
            -1.7564404010772705,
            -0.6384751796722412,
            0.33399122953414917,
            0.2917623221874237,
            -0.8807685375213623,
            -0.3822582960128784,
            -0.6550198793411255,
            0.8475666046142578,
            0.25435903668403625,
            -0.7574268579483032,
            -0.0018529444932937622,
            -0.014977369457483292,
            0.03859864920377731,
            0.352078914642334,
            0.09113695472478867,
            -0.680365800857544,
            0.05272725224494934,
            -0.050849609076976776,
            0.4229072332382202,
            -0.4171856939792633,
            0.3756403923034668,
            0.08677571266889572,
            0.0173296257853508,
            -0.3013012111186981,
            0.6550720930099487,
            -0.5206359028816223,
            1.1400402784347534,
            0.2801797688007355,
            -0.7541120052337646,
            1.065847396850586,
            0.40635785460472107,
            -0.6848594546318054,
            0.4961469769477844,
            -0.5760297775268555,
            -0.3164706826210022,
            -0.979499340057373,
            1.0243557691574097,
            -0.7872797250747681,
            0.41145145893096924,
            0.3963802754878998,
            -0.38772183656692505,
            -0.4024256467819214,
            -0.17413336038589478,
            -0.2881929278373718,
            0.02224862575531006,
            0.3467528522014618,
            0.6031092405319214,
            0.17441962659358978,
            1.5294687747955322,
            1.4079548120498657,
            -0.3090057969093323,
            -0.4795108735561371,
            0.20001280307769775,
            -0.050295181572437286,
            -0.04949251562356949,
            0.029213011264801025,
            -0.8218201398849487,
            -0.2659166753292084,
            -0.016189932823181152,
            -0.901006281375885,
            -0.6852371096611023,
            0.10220614820718765,
            0.024360425770282745,
            0.5643877387046814,
            -0.45608797669410706,
            1.1881756782531738,
            -0.013729273341596127,
            0.3067585825920105,
            -0.21116375923156738,
            0.5415292978286743,
            0.3503587245941162,
            0.3404058516025543,
            0.26543930172920227,
            -0.40818291902542114,
            0.34338510036468506,
            -1.242517113685608,
            0.6535123586654663,
            -0.09536947309970856,
            -0.22092273831367493,
            0.1358795017004013,
            -0.07661644369363785,
            -0.48790687322616577,
            -0.8044420480728149,
            0.8619990944862366,
            -0.5634229183197021,
            -0.15451452136039734,
            -0.056584082543849945,
            -0.10315336287021637,
            0.2963704466819763,
            -0.6731477379798889,
            -0.2650216221809387,
            1.140690565109253,
            0.7295383810997009,
            -0.2410965859889984,
            0.8084008693695068,
            1.3607964515686035,
            0.9849858283996582,
            -0.0021980777382850647,
            0.30507537722587585,
            -0.05425456538796425,
            0.3335658013820648,
            -1.0028042793273926,
            0.7778862118721008,
            -0.21071121096611023,
            0.01591450907289982,
            -0.7356854677200317,
            1.2284009456634521,
            0.7665082812309265,
            -0.007250789552927017,
            0.2533431947231293,
            -0.8016059398651123,
            -0.23056310415267944,
            -0.6829859614372253,
            0.41483235359191895,
            -0.34258410334587097,
            1.0617529153823853,
            -0.2951352596282959,
            -0.042767491191625595,
            0.6269879341125488,
            -0.6027786135673523,
            3.558955669403076,
            1.2797582149505615,
            0.007599048316478729,
            0.3860686123371124,
            0.4726114869117737,
            0.8475812673568726,
            0.9102058410644531,
            -0.27242863178253174,
            0.6766815185546875,
            -0.5287512540817261,
            0.44011643528938293,
            -0.8467885851860046,
            0.8155112862586975,
            0.33959078788757324,
            -0.07588443160057068,
            -0.302099347114563,
            -0.6180403828620911,
            0.3061239421367645,
            0.0778491422533989,
            -0.250794380903244,
            -1.354028582572937,
            0.18711569905281067,
            0.38861584663391113,
            -0.3797015845775604,
            0.29237303137779236,
            0.6752381324768066,
            0.18495091795921326,
            -0.1203288808465004,
            -0.12374788522720337,
            -0.43279942870140076,
            -0.022384442389011383,
            -0.6906774640083313,
            -0.3512727618217468,
            -0.15720349550247192,
            0.3055146336555481,
            0.8287830352783203,
            -0.09221271425485611,
            -0.8191463351249695,
            -0.34214597940444946,
            1.540235996246338,
            0.4085407257080078,
            -0.7491922378540039,
            -0.49750491976737976,
            -0.5750055909156799,
            0.21292488276958466,
            0.7254807949066162,
            0.30850186944007874,
            0.10280518233776093,
            0.9576418399810791,
            -1.058341383934021,
            0.11174922436475754,
            -1.300818920135498,
            -0.0058571817353367805,
            -0.3538460433483124,
            0.42406314611434937,
            0.24924302101135254,
            -0.22851957380771637,
            -0.2821687161922455,
            -1.114016056060791,
            0.2703506350517273,
            0.682325005531311,
            -0.7011772394180298,
            -0.4857853055000305,
            0.6133390069007874,
            -0.20744799077510834,
            -0.5177156925201416,
            0.8633387088775635,
            0.37909919023513794,
            -0.3055003583431244,
            0.002858804538846016,
            0.07647169381380081,
            0.1047683134675026,
            -0.22133761644363403,
            0.26869189739227295,
            -0.005936175584793091,
            0.21599900722503662,
            -0.3166124224662781,
            0.8280325531959534,
            -0.008065769448876381,
            -0.38700973987579346,
            0.011715345084667206,
            -0.5531673431396484,
            -0.29621240496635437,
            -0.10843560844659805,
            0.3202867805957794,
            0.8495392203330994,
            -0.19346767663955688,
            0.20536071062088013,
            -0.5506631135940552,
            0.20396719872951508,
            -0.3247654139995575,
            -0.24715667963027954,
            0.40172138810157776,
            -0.048450928181409836,
            0.04589752107858658
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
        "properties": {
          "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "themes": [
            "Evaluation Strategies",
            "RAG setting",
            "Question answering",
            "Context retrieval",
            "Answer generation"
          ],
          "entities": [
            "RAG"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "a5399480-7115-4e35-9bad-91617c8bc55f",
      "type": "next",
      "source": {
        "id": "4153fc52-5968-44e6-aed7-c938bbcf6a2c",
        "properties": {
          "page_content": "ment of retrieval augmented generation systems.\nWe focus on settings where reference answers may\nnot be available, and where we want to estimate\ndifferent proxies for correctness, in addition to the\nusefulness of the retrieved passages. The RAGA S\nframework provides an integration with both llama-\nindex and Langchain, the most widely used frame-\nworks for building RAG solutions, thus enabling\ndevelopers to easily integrate RAGA S into their\nstandard workflow.\n\n\n2 Related Work\nEstimating faithfulness using LLMsThe prob-\nlem of detecting hallucinations in LLM generated\nresponses has been extensively studied (Ji et al.,\n2023). Several authors have suggested the idea\nof predicting factuality using a few-shot prompt-\ning strategy (Zhang et al., 2023). Recent analy-\nses, however, suggest that existing models struggle\nwith detecting hallucination when using standard\nprompting strategies (Li et al., 2023; Azaria and\nMitchell, 2023). Other approaches rely on linking\nthe generated responses to facts from an external\nknowledge base (Min et al., 2023), but this is not\nalways possible.\nYet another strategy is to inspect the probabili-\nties assigned to individual tokens, where we would\nexpect the model to be less confident in halluci-\nnated answers than in factual ones. For instance,\nBARTScore (Yuan et al., 2021) estimates factuality\nby looking at the conditional probability of the gen-\nerated text given the input. Kadavath et al. (2022)\nuse a variation of this idea. Starting from the ob-\nservation that LLMs provide well-calibrated proba-\nbilities when answering multiple-choice questions,\nthey essentially convert the problem of validating\nmodel generated answers into a multiple-choice\nquestion which asks whether the answer is true or\nfalse. Rather than looking at the output probabil-\nities, Azaria and Mitchell (2023) propose to train\na supervised classifier on the weights from one of\nthe hidden layers of the LLM, to predict whether a\ngiven statement is true or not. While the approach\nperforms well, the need to access the hidden states\nof the model makes it unsuitable for systems that\naccess LLMs through an API.\nFor models that do not provide access to token\nprobabilities, such as ChatGPT and GPT-4, differ-\nent methods are needed. SelfCheckGPT (Manakul\net al., 2023) addresses this problem by instead sam-\npling multiple answers. Their core idea is that\nfactual answers are more stable: when an answer is\nfactual, we can expect that different samples will\ntend to be semantically similar, whereas this is less\nlikely to be the case for hallucinated answers.\nAutomated evaluation of text generation systems\nLLMs have also been leveraged to automatically\nevaluate other aspects of generated text fragments,\nbeyond factuality. For instance, GPTScore (Fu\net al., 2023) uses a prompt that specifies the consid-\nered aspect (e.g. fluency) and then scores passages\nbased on the average probability of the generated\ntokens, according to a given autoregressive LM.\nThis idea of using prompts was previously also\nconsidered by Yuan et al. (2021), although they\nused a smaller fine-tuned LM (i.e. BART) and did\nnot observe a clear benefit from using prompts. An-\nother approach directly asks ChatGPT to evaluate\na particular aspect of the given answer by provid-\ning a score between 0 and 100, or by providing a\nrating on a 5-star scale (Wang et al., 2023a). Re-\nmarkably, strong results can be obtained in this\nway, although it comes with the limitation of being\nsensitive to the design of the prompt. Rather than\nscoring individual answers, some authors have also\nfocused on using an LLM to select the best answer\namong a number of candidates (Wang et al., 2023b),\ntypically to compare the performance of different\nLLMs. However, care is needed with this approach,\nas the order in which the answers is presented can\ninfluence the result (Wang et al., 2023b).\nIn terms of how ground truth answers or, more\ngenerally, generations, have been typically used\nin the literature, most approaches have relied on\nthe availability of one or more reference answers.\nFor instance, BERTScore (Zhang et al., 2020)\nand MoverScore (Zhao et al., 2019) use contex-\ntualised embeddings, produced by a pre-trained\nBERT model, to compare the similarity between\nthe generated answer and the reference answers.\nBARTScore (Yuan et al., 2021) similarly uses refer-\nence answers to compute aspects such as precision\n(estimated as the probability of generating the gen-\nerated answer given the reference) and recall (esti-\nmated as the probability of generating the reference\ngiven the generated answer).\n",
          "entities": [
            "Ji et al.",
            "Zhang et al.",
            "Li et al.",
            "Azaria and Mitchell",
            "Min et al.",
            "Yuan et al.",
            "BARTScore",
            "Kadavath et al.",
            "ChatGPT",
            "GPT-4",
            "SelfCheckGPT",
            "GPTScore",
            "Fu et al.",
            "Wang et al.",
            "BERTScore",
            "MoverScore",
            "Zhao et al."
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
        "properties": {
          "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "themes": [
            "Evaluation Strategies",
            "RAG setting",
            "Question answering",
            "Context retrieval",
            "Answer generation"
          ],
          "entities": [
            "RAG"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "0cf518bb-9b71-4a82-81c8-0a5564681c79",
      "type": "child",
      "source": {
        "id": "31b29608-6eb4-4705-a183-09d77f197b14",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "document_metadata": {
            "page_label": "5",
            "file_name": "2309.15217v1.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
            "file_type": "application/pdf",
            "file_size": 329967,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-11-15"
          },
          "headlines": [
            "5 Experiments",
            "6 Conclusions"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
          "entities": [
            "Faith. Ans. Rel. Cont. Rel.",
            "RAGAs",
            "GPT Score",
            "GPT Ranking",
            "Table 1",
            "WikiEval dataset",
            "accuracy",
            "ChatGPT",
            "context relevance",
            "faithfulness",
            "answer relevance",
            "context relevance"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "1e938964-e53c-48cf-b29b-6bd8e47a275d",
      "type": "child",
      "source": {
        "id": "31b29608-6eb4-4705-a183-09d77f197b14",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "document_metadata": {
            "page_label": "5",
            "file_name": "2309.15217v1.pdf",
            "file_path": "/mnt/c/Users/danie/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/ragas/data/2309.15217v1.pdf",
            "file_type": "application/pdf",
            "file_size": 329967,
            "creation_date": "2024-11-21",
            "last_modified_date": "2024-11-15"
          },
          "headlines": [
            "5 Experiments",
            "6 Conclusions"
          ]
        },
        "type": "document"
      },
      "target": {
        "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
        "properties": {
          "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "entities": [
            "RAG systems",
            "WikiEval",
            "RAGAs"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "484691da-c827-4946-87f3-2cea71e20dbc",
      "type": "next",
      "source": {
        "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
          "entities": [
            "Faith. Ans. Rel. Cont. Rel.",
            "RAGAs",
            "GPT Score",
            "GPT Ranking",
            "Table 1",
            "WikiEval dataset",
            "accuracy",
            "ChatGPT",
            "context relevance",
            "faithfulness",
            "answer relevance",
            "context relevance"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
        "properties": {
          "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "entities": [
            "RAG systems",
            "WikiEval",
            "RAGAs"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {}
    },
    {
      "id": "b1c8f1d3-29c3-447f-a40e-6d048286cb61",
      "type": "entities_overlap",
      "source": {
        "id": "91a7be85-55a2-44f0-97cd-ff13fde405b8",
        "properties": {
          "page_content": "Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 \n\nGenerator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 \n\nTraining\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "entities": [
            "Retriever: DPR",
            "DPR",
            "BERT",
            "BERTBASE",
            "BART-large",
            "TriviaQA",
            "Natural Questions"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
        "properties": {
          "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
          "entities": [
            "Open-Domain QA",
            "Natural Questions",
            "WebQuestions",
            "TriviaQA",
            "CuratedTrec",
            "DPR",
            "Wikipedia",
            "Berlin",
            "Shanghai"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.05555555555555555,
        "overlapped_items": [
          [
            "TriviaQA",
            "TriviaQA"
          ],
          [
            "Natural Questions",
            "Natural Questions"
          ]
        ]
      }
    },
    {
      "id": "18183745-3227-42c2-a73c-3fe8de472dd8",
      "type": "entities_overlap",
      "source": {
        "id": "91a7be85-55a2-44f0-97cd-ff13fde405b8",
        "properties": {
          "page_content": "Retriever: DPR\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture:\npη(z|x) ∝exp\n(\nd(z)⊤q(x)\n)\nd(z) =BERTd(z), q(x) =BERTq(x)\nwhere d(z) is a dense representation of a document produced by a BERTBASE document encoder [8],\nand q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating\ntop-k(pη(·|x)), the list of kdocuments zwith highest prior probability pη(z|x), is a Maximum Inner\nProduct Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use\na pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This\nretriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and\nNatural Questions [29]. We refer to the document index as the non-parametric memory.\n2.3 \n\nGenerator: BART\nThe generator component pθ(yi|x,z,y 1:i−1) could be modelled using any encoder-decoder. We use\nBART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input\nxwith the retrieved content zwhen generating from BART, we simply concatenate them. BART was\npre-trained using a denoising objective and a variety of different noising functions. It has obtained\nstate-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5\nmodels [32]. We refer to the BART generator parameters θas the parametric memory henceforth.\n2.4 \n\nTraining\nWe jointly train the retriever and generator components without any direct supervision on what\ndocument should be retrieved. Given a ﬁne-tuning training corpus of input/output pairs (xj,yj), we\n3",
          "entities": [
            "Retriever: DPR",
            "DPR",
            "BERT",
            "BERTBASE",
            "BART-large",
            "TriviaQA",
            "Natural Questions"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.020833333333333332,
        "overlapped_items": [
          [
            "BART-large",
            "BART-large"
          ]
        ]
      }
    },
    {
      "id": "3a317e8a-93a3-4132-8b81-1bae50477f4a",
      "type": "entities_overlap",
      "source": {
        "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
        "properties": {
          "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
          "entities": [
            "Open-Domain QA",
            "Natural Questions",
            "WebQuestions",
            "TriviaQA",
            "CuratedTrec",
            "DPR",
            "Wikipedia",
            "Berlin",
            "Shanghai"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "Wikipedia",
            "KILT",
            "EvalAI",
            "Yadav",
            "FEVER",
            "Thorne"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.015151515151515152,
        "overlapped_items": [
          [
            "Wikipedia",
            "Wikipedia"
          ]
        ]
      }
    },
    {
      "id": "6249ff82-f93e-4e7e-b2a0-c5597ae5d30c",
      "type": "entities_overlap",
      "source": {
        "id": "1cc7b231-6c18-4f1d-ba80-13b783a076ec",
        "properties": {
          "page_content": "D \n\nFurther Details on Open-Domain QA\nFor open-domain QA, multiple answer annotations are often available for a given question. These\nanswer annotations are exploited by extractive models during training as typically all the answer\nannotations are used to ﬁnd matches within documents when preparing training data. For RAG, we\nalso make use of multiple annotation examples for Natural Questions and WebQuestions by training\nthe model with each (q,a) pair separately, leading to a small increase in accuracy. For TriviaQA,\nthere are often many valid answers to a given question, some of which are not suitable training targets,\nsuch as emoji or spelling variants. For TriviaQA, we ﬁlter out answer candidates if they do not occur\nin top 1000 documents for the query.\nCuratedTrec preprocessing The answers for CuratedTrec are given in the form of regular expres-\nsions, which has been suggested as a reason why it is unsuitable for answer-generation models [20].\nTo overcome this, we use a pre-processing step where we ﬁrst retrieve the top 1000 documents for\neach query, and use the answer that most frequently matches the regex pattern as the supervision\ntarget. If no matches are found, we resort to a simple heuristic: generate all possible permutations for\neach regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\nTriviaQA Evaluation setups The open-domain QA community customarily uses public develop-\nment datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading\ncompehension purposes. We report our results using the datasets splits used in DPR [26], which are\nconsistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public\nTriviaQA Web Development split. Roberts et al.[52] used the TriviaQA ofﬁcial Wikipedia test set\ninstead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See\nappendix of [14]). We report results on both test sets to enable fair comparison to both approaches.\nWe ﬁnd that our performance is much higher using the ofﬁcial Wiki test set, rather than the more\nconventional open-domain test set, which we attribute to the ofﬁcial Wiki test set questions being\nsimpler to answer from Wikipedia.\nE \n\nFurther Details on FEVER\nFor FEVER classiﬁcation, we follow the practice from [ 32], and ﬁrst re-generate the claim, and\nthen classify using the representation of the ﬁnal hidden state, before ﬁnally marginalizing across\ndocuments to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The\nﬁrst is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task\nwe explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia\nas evidence supporting the classiﬁcation prediction. As FEVER uses a different Wikipedia dump to\nus, directly tackling this task is not straightforward. We hope to address this in future work.\nF ",
          "entities": [
            "Open-Domain QA",
            "Natural Questions",
            "WebQuestions",
            "TriviaQA",
            "CuratedTrec",
            "DPR",
            "Wikipedia",
            "Berlin",
            "Shanghai"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "80ef7bf0-018a-4a27-b41f-c36b5406013f",
        "properties": {
          "page_content": "3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "entities": [
            "Entity Linking",
            "EL",
            "KILT",
            "Wikipedia",
            "Berlin",
            "Shanghai",
            "Wu et al.",
            "AIDA CoNLL-YAGO",
            "CoNLL 2003",
            "YAGO2",
            "WNED-WIKI",
            "Guo and Barbosa"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.016666666666666666,
        "overlapped_items": [
          [
            "Wikipedia",
            "Wikipedia"
          ]
        ]
      }
    },
    {
      "id": "d5792e1b-46aa-4f1b-9fc9-39b4f16496ea",
      "type": "entities_overlap",
      "source": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "Wikipedia",
            "KILT",
            "EvalAI",
            "Yadav",
            "FEVER",
            "Thorne"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.056818181818181816,
        "overlapped_items": [
          [
            "Elon Musk",
            "Elon Musk"
          ],
          [
            "Tesla",
            "Tesla"
          ],
          [
            "SpaceX",
            "SpaceX"
          ],
          [
            "Europe",
            "Europe"
          ],
          [
            "Asia",
            "Asia"
          ]
        ]
      }
    },
    {
      "id": "deb6d93b-80b5-4930-b66c-1d592898f40e",
      "type": "entities_overlap",
      "source": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
        "properties": {
          "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "themes": [
            "Evaluation Strategies",
            "RAG setting",
            "Question answering",
            "Context retrieval",
            "Answer generation"
          ],
          "entities": [
            "RAG"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.125,
        "overlapped_items": [
          [
            "RAG",
            "RAG"
          ]
        ]
      }
    },
    {
      "id": "774ffb4c-38b9-4e58-83db-1e466b8b23b4",
      "type": "entities_overlap",
      "source": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
          "entities": [
            "Faith. Ans. Rel. Cont. Rel.",
            "RAGAs",
            "GPT Score",
            "GPT Ranking",
            "Table 1",
            "WikiEval dataset",
            "accuracy",
            "ChatGPT",
            "context relevance",
            "faithfulness",
            "answer relevance",
            "context relevance"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.010416666666666666,
        "overlapped_items": [
          [
            "RAG",
            "RAGAs"
          ]
        ]
      }
    },
    {
      "id": "1aa04905-e096-4a3d-9685-316a653c990e",
      "type": "entities_overlap",
      "source": {
        "id": "9e6032ab-2531-49c0-a50d-1f6ce9de6aa1",
        "properties": {
          "page_content": "Null Document Probabilities\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order\nto model cases where no useful information could be retrieved for a given input. Here, ifkdocuments\nwere retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null\ndocument, before marginalizing over k+ 1predictions. We explored modelling this null document\nlogit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or\n(iii) a neural network to predict the logit. We did not ﬁnd that these improved performance, so in\nthe interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents\ncannot always be retrieved, we observe that the model learns to always retrieve a particular set of\ndocuments for questions that are less likely to beneﬁt from retrieval, suggesting that null document\nmechanisms may not be necessary for RAG.\nG \n\nParameters\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of\nDPR, with 110M parameters each (although we do not train the document encoder ourselves) and\n406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable\n18",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "REALM",
            "RAG",
            "DPR",
            "BART-large"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
        "properties": {
          "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "entities": [
            "RAG systems",
            "WikiEval",
            "RAGAs"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.041666666666666664,
        "overlapped_items": [
          [
            "RAG",
            "RAGAs"
          ]
        ]
      }
    },
    {
      "id": "999e8e06-58af-4c4c-93b4-695c6f959231",
      "type": "entities_overlap",
      "source": {
        "id": "cbdcaf5b-98de-44b2-9dae-4d5fd2d63943",
        "properties": {
          "page_content": "use 0.5 as threshold) — this is meant to ensure\nhigh quality mappings in the evaluation sets — dis-\ncarding on average 18% of test and dev data (for\nall tasks except entity linking). We keep all input-\noutput pairs in the train sets (see Figure 5 in the\nappendix for more details).\n\n\n3 Tasks\nWe consider ﬁve tasks that use Wikipedia as a\nknowledge source for KILT: fact checking, open\ndomain question answering, slot ﬁlling, entity link-\ning, and dialogue. The diversity of these tasks\nchallenge models to represent knowledge ﬂexibly.\nSome tasks require a discrete prediction (e.g., an\nentity), others, such as extractive question answer-\ning, can copy the output directly from a Wikipedia\npage, while still other tasks must synthesize mul-\ntiple pieces of knowledge in an abstractive way to\nproduce an output. KILT also provides a variety of\nways to seek knowledge, from a claim to verify to a\ntext chunk to annotate, from a structured or natural\nquestion to a conversation (see Table 1 for details).\nWe are able to include the test set for all datasets\nin KILT, either because the test set is public, or\nbecause we were able to obtain the test set from\nthe authors of the original dataset. These test sets\nare not publicly released, but are used for the KILT\nchallenge on EvalAI (Yadav et al., 2019) where\nparticipants can upload their models’ predictions\nand be listed on the public leaderboard.5\nTo facilitate experimentation, we deﬁne a con-\nsistent interface for all datasets in the KILT Bench-\nmark. Each dataset is represented in JSON Line\nformat , where each record contains three ﬁelds: id,\ninput, output. The input is a natural language string\nand the output a non-empty list of equally-valid\noutputs (e.g. if multiple answers to a question are\nvalid in a question answering dataset). Each output\nis a string and it is accompanied by a non-empty list\nof complementary provenance spans (all should be\nused to acquire the knowledge needed to provide a\nvalid output). Figure 1 displays an example for all\nconsidered tasks (Figure 3 in the appendix contains\nfurther details on the common interface).\n\n\n3.1 Fact Checking\nFact checking veriﬁes a claim against a collection\nof evidence. It requires deep knowledge about the\nclaim and reasoning over multiple documents. We\n5available at https://evalai.cloudcv.org/\nweb/challenges/challenge-page/689.\nconsider the claim as input and the classiﬁcation\nlabel as output. Each label is accompanied by a\nset of provenance spans that corroborate the clas-\nsiﬁcation label. We model multiple equally-valid\nprovenance sets per label.\nFEVER (Thorne et al., 2018a) is a large dataset\nfor claim veracity that requires retrieving sentence-\nlevel evidence to support if a claim is supported or\nrefuted. Additional details are in the appendix.\n",
          "entities": [
            "Elon Musk",
            "Tesla",
            "SpaceX",
            "Europe",
            "Asia",
            "Berlin",
            "Shanghai",
            "Wikipedia",
            "KILT",
            "EvalAI",
            "Yadav",
            "FEVER",
            "Thorne"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "80ef7bf0-018a-4a27-b41f-c36b5406013f",
        "properties": {
          "page_content": "3.2 Entity Linking\nEntity Linking (EL) assigns a unique Wikipedia\npage to entities mentioned in text. Each KILT\nrecord for EL has text in the input (max 256\ntokens) where a single entity mention is tagged\nwith two special tokens (i.e., [START_ENT] and\n[END_ENT]—see Figure 1 for an example). The\noutput is the title of the Wikipedia page for the en-\ntity mention plus provenance pointing to the entire\npage (through a unique identiﬁer). Since Wikipedia\nassociates unambiguous titles to entities6, ﬁnding\nthe correct output is enough to link entity mention\nand Wikipedia page. The provenance mimics the\ncanonical approach to EL, that is to produce an\nidentiﬁer for each mention (Wu et al., 2019). To\nmap the provenance (whole Wikipedia page), we\nsimply match Wikipedia pages speciﬁed in vari-\nous datasets to the KILT knowledge source. We\nconsider three popular EL datasets in KILT, two\nof which do not contain a train set but should be\nassessed in a zero-shot fashion. Note that, in ad-\ndition to the AY2 train set, the whole knowledge\nsource can be used as training data by exploiting\nhyperlinks. To facilitate experimentation, we re-\nlease such data in KILT format (9M train instances),\nfollowing the splits of Wu et al. (2019).\nAIDA CoNLL-YAGO (Hoffart et al., 2011b)\nsupplements the CoNLL 2003 dataset (Sang and\nDe Meulder, 2003) with Wikipedia URL annota-\ntions for all entities using the Y AGO2 system (Hof-\nfart et al., 2011a). The original data is split into\nthree parts: train, testa, testb. Following Hoffart\net al. (2011b) we consider testa as dev and testb as\ntest.\nWNED-WIKI (Guo and Barbosa, 2018) is a\ndataset automatically created by sampling docu-\nment from the 2013/06/06 Wikipedia dump, and\nbalancing the difﬁculty of linking each mention\n(using a baseline as proxy). We randomly split the\ndataset into dev and test.\n6Wikipedia uses explicit text in titles to disambiguate.",
          "entities": [
            "Entity Linking",
            "EL",
            "KILT",
            "Wikipedia",
            "Berlin",
            "Shanghai",
            "Wu et al.",
            "AIDA CoNLL-YAGO",
            "CoNLL 2003",
            "YAGO2",
            "WNED-WIKI",
            "Guo and Barbosa"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.01818181818181818,
        "overlapped_items": [
          [
            "Wikipedia",
            "Wikipedia"
          ],
          [
            "KILT",
            "KILT"
          ]
        ]
      }
    },
    {
      "id": "3c2b0d2b-2407-429e-9c7f-772526720d4c",
      "type": "entities_overlap",
      "source": {
        "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
        "properties": {
          "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "themes": [
            "Evaluation Strategies",
            "RAG setting",
            "Question answering",
            "Context retrieval",
            "Answer generation"
          ],
          "entities": [
            "RAG"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
          "entities": [
            "Faith. Ans. Rel. Cont. Rel.",
            "RAGAs",
            "GPT Score",
            "GPT Ranking",
            "Table 1",
            "WikiEval dataset",
            "accuracy",
            "ChatGPT",
            "context relevance",
            "faithfulness",
            "answer relevance",
            "context relevance"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.08333333333333333,
        "overlapped_items": [
          [
            "RAG",
            "RAGAs"
          ]
        ]
      }
    },
    {
      "id": "a931c32c-6c15-42af-8af0-eb3edf4a11ce",
      "type": "entities_overlap",
      "source": {
        "id": "0ee0e375-188a-4be2-a186-fe904f1fcc23",
        "properties": {
          "page_content": "3 Evaluation Strategies\nWe consider a standard RAG setting, where given a\nquestion q, the system first retrieves some context\nc(q) and then uses the retrieved context to generate\nan answer as(q). When building a RAG system,",
          "themes": [
            "Evaluation Strategies",
            "RAG setting",
            "Question answering",
            "Context retrieval",
            "Answer generation"
          ],
          "entities": [
            "RAG"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
        "properties": {
          "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "entities": [
            "RAG systems",
            "WikiEval",
            "RAGAs"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.3333333333333333,
        "overlapped_items": [
          [
            "RAG",
            "RAGAs"
          ]
        ]
      }
    },
    {
      "id": "b910a9ae-39af-45a6-a28a-a898dcf4c605",
      "type": "entities_overlap",
      "source": {
        "id": "277364de-18c9-4520-ac8b-0dc2ed332471",
        "properties": {
          "page_content": "Faith. Ans. Rel. Cont. Rel.\nRAGAs 0.95 0.78 0.70\nGPT Score 0.72 0.52 0.63\nGPT Ranking 0.54 0.40 0.52\nTable 1: Agreement with human annotators in pairwise\ncomparisons of faithfulness, answer relevance and con-\ntext relevance, using the WikEval dataset (accuracy).\nanswering the question. For the few pages with-\nout any back-links, we instead used ChatGPT to\ncomplete the given context.\n\n\n5 Experiments\nTable 1 analyses the agreement between the met-\nrics proposed in Section 3 and the human assess-\nments from the proposed WikiEval dataset. Each\nWikiEval instance requires the model to compare\ntwo answers or two context fragments. We count\nhow often the answer/context preferred by the\nmodel (i.e. with highest estimated faithfulness, an-\nswer relevance, or context relevance) coincides\nwith the answer/context preferred by the human\nannotators. We report the results in terms of ac-\ncuracy (i.e. the fraction of instances on which the\nmodel agrees with the annotators).\nTo put the results in context, we compare our\nproposed metrics (shown asRAGAs in Table 1) with\ntwo baseline methods. For the first method, shown\nas GPT Score, we ask ChatGPT to assign a score\nbetween 0 and 10 for the three quality dimensions.\nTo this end, we use a prompt that describes the\nmeaning of the quality metric and then asks to\nscore the given answer/context in line with that\ndefinition. For instance, for evaluating faithfulness,\nwe used the following prompt:\nFaithfulness measures the information\nconsistency of the answer against the\ngiven context. Any claims that are made\nin the answer that cannot be deduced\nfrom context should be penalized.\nGiven an answer and context, assign a\nscore for faithfulness in the range 0-10.\ncontext: [context]\nanswer: [answer]\nTies, where the same score is assigned by the LLM\nto both answer candidates, were broken randomly.\nThe second baseline, shown as GPT Ranking, in-\nstead asks ChatGPT to select the preferred answer/-\ncontext. In this case, the prompt again includes\na definition of the considered quality metric. For\ninstance, for evaluating answer relevance, we used\nthe following prompt:\nAnswer Relevancy measures the degree\nto which a response directly addresses\nand is appropriate for a given question.\nIt penalizes the present of redundant in-\nformation or incomplete answers given a\nquestion. Given an question and answer,\nrank each answer based on Answer Rele-\nvancy.\nquestion: [question]\nanswer 1: [answer 1]\nanswer 2: [answer 2]\nThe results in Table 1 show that our proposed\nmetrics are much closer aligned with the human\njudgements than the predictions from the two base-\nlines. For faithfulness, the RAGAs prediction are\nin general highly accurate. For answer relevance,\nthe agreement is lower, but this is largely due to the\nfact that the differences between the two candidate\nanswers are often very subtle. We found context\nrelevance to be the hardest quality dimension to\nevaluate. In particular, we observed that ChatGPT\noften struggles with the task of selecting the sen-\ntences from the context that are crucial, especially\nfor longer contexts.\n",
          "entities": [
            "Faith. Ans. Rel. Cont. Rel.",
            "RAGAs",
            "GPT Score",
            "GPT Ranking",
            "Table 1",
            "WikiEval dataset",
            "accuracy",
            "ChatGPT",
            "context relevance",
            "faithfulness",
            "answer relevance",
            "context relevance"
          ]
        },
        "type": "chunk"
      },
      "target": {
        "id": "50dc0663-7e04-41d4-b343-0d14a923566b",
        "properties": {
          "page_content": "6 Conclusions\nWe have highlighted the need for automated\nreference-free evaluation of RAG systems. In par-\nticular, we have argued the need for an evaluation\nframework that can assess faithfulness (i.e. is the\nanswer grounded in the retrieved context), answer\nrelevance (i.e. does the answer address the ques-\ntion) and context relevance (i.e. is the retrieved\ncontext sufficiently focused). To support the devel-\nopment of such a framework, we have introduced\nWikiEval, a dataset which human judgements of\nthese three different aspects. Finally, we have also\ndescribed RAGAs, our implementation of the three\nconsidered quality aspects. This framework is easy\nto use and can provide deverlopers of RAG sys-\ntems with valuable insights, even in the absence\nof any ground truth. Our evaluation on WikiEval\nhas shown that the predictions from RAGAs are\nclosely aligned with human predictions, especially\nfor faithfulness and answer relevance.",
          "entities": [
            "RAG systems",
            "WikiEval",
            "RAGAs"
          ]
        },
        "type": "chunk"
      },
      "bidirectional": false,
      "properties": {
        "entities_overlap_score": 0.05555555555555555,
        "overlapped_items": [
          [
            "RAGAs",
            "RAGAs"
          ],
          [
            "WikiEval dataset",
            "WikiEval"
          ]
        ]
      }
    }
  ]
}