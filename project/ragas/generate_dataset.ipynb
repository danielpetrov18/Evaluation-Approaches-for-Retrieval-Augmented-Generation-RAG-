{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Retrieve data (Optional - can use your own dataset / files instead)\n",
    "\n",
    "!git clone https://huggingface.co/datasets/explodinggradients/Sample_Docs_Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load data\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"Sample_Docs_Markdown/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\", exclude=\"README.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 3. Construct objects\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.cache import DiskCacheBackend\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=7200, # 2 hours (Note since llama3.1:8b is not particularly strong you may need more time)\n",
    "    max_retries=15,\n",
    "    max_wait=60,\n",
    "    log_tenacity=True\n",
    ")\n",
    "\n",
    "cacher = DiskCacheBackend(cache_dir=\".cache\")\n",
    "\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.1,\n",
    "    num_ctx=24000,\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(\n",
    "    langchain_llm=ollama_llm,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(\n",
    "    embeddings=ollama_embeddings,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "query_distribution = default_query_distribution(langchain_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlineSplitter:   0%|          | 0/11 [00:00<?, ?it/s] unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:   0%|          | 0/6 [00:00<?, ?it/s] Property 'summary' already exists in node '89424a'. Skipping!\n",
      "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "unable to apply transformation: Invalid json output: After analyzing the input, I would give a score of 4. The content of the node is highly relevant and accurate, reflecting the main themes of the document summary with minor gaps. It covers all important details and adds depth to the understanding of the document's topics.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "unable to apply transformation: The output parser failed to parse the output including retries.\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/30 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node '89424a'. Skipping!\n",
      "Generating personas: 100%|██████████| 3/3 [00:00<00:00, 172.93it/s]                                 \n",
      "Generating Scenarios: 100%|██████████| 3/3 [09:30<00:00, 190.30s/it]\n",
      "Generating Samples: 100%|██████████| 52/52 [22:47<00:00, 26.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "# 4. Generate the synthetic test dataset\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=langchain_llm,\n",
    "    embedding_model=langchain_embeddings\n",
    ")\n",
    "\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs,\n",
    "    testset_size=50,\n",
    "    query_distribution=query_distribution,\n",
    "    run_config=run_config,\n",
    "    with_debugging_logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'What does it mean to be an ally in the context of diversity, inclusion and belonging?',\n",
       " 'retrieved_contexts': None,\n",
       " 'reference_contexts': ['What is an ally? A diversity, inclusion and belonging \"ally\" is someone who is willing to take action in support of another person, in order to remove barriers that impede that person from contributing their skills and talents in the workplace or community. Being an ally is a verb, this means that you proactively and purposefully take action and is not something forced upon you. How to be an ally It is not required to be an ally to work at GitLab. At GitLab it is required to be inclusive. Being an ally goes a step beyond being inclusive to taking action to support marginalized groups. The first step in being an ally is self-educating. This ally lab will provide you with some of the tools, resources and learning activities to help you grow as an ally. Skills and Behaviors of allies To be an effective ally it is important to understand some of the skills and behaviors great allies exhibit. Active listening Neutral and nonjudgmental. Patient (periods of silence are not \"filled\") Verbal and nonverbal feedback to show signs of listening (e.g., smiling, eye contact, leaning in, mirroring) Asking questions. Reflecting back what is said. Asking for clarification. Summarizing. Empathy & Emotional Intelligence An example of this could be: A colleague comes to you and tells you that their pronouns are being misused often at work and it is making them feel uncomfortable and they are avoiding social calls and interactions. Whilst you haven’t experienced this yourself and unlikely you would experience this, you allow yourself to think of situations where you have felt uncomfortable at work before. You also put yourself consciously into the shoes of your colleague and think of a way you can practically help. You offer to your colleague that in the next 5 calls they participate in you will be on the call and actively point out misuse of their pronouns to other colleagues to take away some of the emotional burden. Active learning about other experiences You go beyond performative actions for example black squares on Instagram for Black Lives Matter, but actively does the work to understand the pain, struggle and experience of those burdened. This could look like: You are managing black team members, an incident has occurred externally that could affect the mental health of those team members. You actively research the experience and historical context of the trauma associated with the incident. You use this to ensure you are informed and able to appropriately apply empathy if a team member approaches you to ask for assistance. Humility Non-defensive Willingness to take on feedback You aren’t going to get it right all the time and you have to be ok with that. Be willing to take feedback on and not let it deter you from continuing to be an ally. Example of this could be: You are in a safe space with an underrepresented group acting as an ally and absorbing information. A point comes up that you are passionate about and you talk over someone in the group and take over the conversation. After the meeting someone from the group jumps on a Zoom meeting with you and explains that it felt you took away the viewpoints of a number of people from the URG because you took over the conversation and interrupted an individual. You apologize, take on the feedback, ask for any tips on how to make sure it doesn’t happen again and take the necessary steps. --- One of the mistakes that often happens here is being defensive or justifying the action. The group will already know you are operating with good intent but generally are wanting to help you level up in their lived experience. Courage Comfortable getting uncomfortable Speak up where others don\\'t or can\\'t The empathy example is also a good example of this. Self-awareness Own and use your privilege This could look like: You are in a product meeting and the meeting will be making critical decisions about the product roadmap for the next three months and you notice that everyone in the meeting is of the same gender and race. You use your privileged situation in the meeting to point this out and ask the people in the meeting. Who should be invited to ensure we are getting a diverse perspective and viewpoint on the agenda items for the meeting? Action orientated You see something, you say something The example above is a good example of this: Ensure decisions and conversations have diverse voices. I.E. you are in a meeting and everyone looks the same, insist on other perspectives. In a group setting when a discussion or comment is verbalized that could be controversial use language similar to this to course correct the conversation: \"I would like us all to be aware of our language and/or acknowledgements and ensure we are being respectful to all individuals. Thank you.\" \"I am practicing being an ally and as a reminder I would like to ensure we are all using inclusive language\" What it means to be an ally Take on the struggle as your own Stand up, even when you feel uncomfortable Transfer the benefits of your privilege to those who lack it Acknowledge that while you, too, feel pain, the conversation is not about you Concepts & Terms Privilege: an unearned advantage given to some people but not all Oppression: systemic inequality present throughout society that benefits people with more privilege and is a disadvantage to those with fewer privileges Ally: a member of a social group that has some privilege, that is working to end oppression and understands their own privilege Power: The ability to control circumstances or access to resources and/or privileges Marginalized groups: a person or group that are treated as unimportant, insignificant or of lower status. In a workplace setting, employees could be treated as invisible, as if they aren\\'t there or their skills or talents are unwelcome or unnecessary Performative allyship: referring to allyship that is done'],\n",
       " 'response': None,\n",
       " 'multi_responses': None,\n",
       " 'reference': 'A diversity, inclusion and belonging \"ally\" is someone who is willing to take action in support of another person, in order to remove barriers that impede that person from contributing their skills and talents in the workplace or community. Being an ally is a verb, this means that you proactively and purposefully take action and is not something forced upon you.',\n",
       " 'rubrics': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Inspect the synthetic testset (Optional)\n",
    "\n",
    "dataset.samples[0].eval_sample.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Ingest documents in R2R if not already done (Optional)\n",
    "\n",
    "from pathlib import Path\n",
    "from r2r import R2RClient, R2RException\n",
    "\n",
    "client = R2RClient(\n",
    "    base_url=\"http://localhost:7272\",\n",
    "    timeout=600\n",
    ")\n",
    "\n",
    "dir_path = Path(\"Sample_Docs_Markdown\")\n",
    "for item in dir_path.iterdir():\n",
    "    if item.is_file() and item.suffix == '.md' and item.name != \"README.md\":\n",
    "        try:\n",
    "            client.documents.create(\n",
    "                file_path=str(item),\n",
    "                ingestion_mode=\"custom\",\n",
    "                run_with_orchestration=True   \n",
    "            )\n",
    "            print(f\"Ingested file: {item.name}\")\n",
    "        except R2RException as r2re:\n",
    "            print(f\"Couldn't ingest file: {item.name} due to {str(r2re)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't ingest file: {item.name} due to {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to sample: 1 out of 52\n",
      "Added data to sample: 2 out of 52\n",
      "Added data to sample: 3 out of 52\n",
      "Added data to sample: 4 out of 52\n",
      "Added data to sample: 5 out of 52\n",
      "Added data to sample: 6 out of 52\n",
      "Added data to sample: 7 out of 52\n",
      "Added data to sample: 8 out of 52\n",
      "Added data to sample: 9 out of 52\n",
      "Added data to sample: 10 out of 52\n",
      "Added data to sample: 11 out of 52\n",
      "Added data to sample: 12 out of 52\n",
      "Added data to sample: 13 out of 52\n",
      "Added data to sample: 14 out of 52\n",
      "Added data to sample: 15 out of 52\n",
      "Added data to sample: 16 out of 52\n",
      "Added data to sample: 17 out of 52\n",
      "Added data to sample: 18 out of 52\n",
      "Added data to sample: 19 out of 52\n",
      "Added data to sample: 20 out of 52\n",
      "Added data to sample: 21 out of 52\n",
      "Added data to sample: 22 out of 52\n",
      "Added data to sample: 23 out of 52\n",
      "Added data to sample: 24 out of 52\n",
      "Added data to sample: 25 out of 52\n",
      "Added data to sample: 26 out of 52\n",
      "Added data to sample: 27 out of 52\n",
      "Added data to sample: 28 out of 52\n",
      "Added data to sample: 29 out of 52\n",
      "Added data to sample: 30 out of 52\n",
      "Added data to sample: 31 out of 52\n",
      "Added data to sample: 32 out of 52\n",
      "Added data to sample: 33 out of 52\n",
      "Added data to sample: 34 out of 52\n",
      "Added data to sample: 35 out of 52\n",
      "Added data to sample: 36 out of 52\n",
      "Added data to sample: 37 out of 52\n",
      "Added data to sample: 38 out of 52\n",
      "Added data to sample: 39 out of 52\n",
      "Added data to sample: 40 out of 52\n",
      "Added data to sample: 41 out of 52\n",
      "Added data to sample: 42 out of 52\n",
      "Added data to sample: 43 out of 52\n",
      "Added data to sample: 44 out of 52\n",
      "Added data to sample: 45 out of 52\n",
      "Added data to sample: 46 out of 52\n",
      "Added data to sample: 47 out of 52\n",
      "Added data to sample: 48 out of 52\n",
      "Added data to sample: 49 out of 52\n",
      "Added data to sample: 50 out of 52\n",
      "Added data to sample: 51 out of 52\n",
      "Added data to sample: 52 out of 52\n"
     ]
    }
   ],
   "source": [
    "# 7. Fill out the retrieved_contexts and response fields\n",
    "\n",
    "import re\n",
    "import ollama\n",
    "import nest_asyncio\n",
    "from r2r import R2RClient, R2RException\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "client = R2RClient(\n",
    "    base_url=\"http://localhost:7272\",\n",
    "    timeout=600\n",
    ")\n",
    "\n",
    "search_settings = {\n",
    "    \"use_semantic_search\": True,\n",
    "    \"limit\": 5,\n",
    "    \"offset\": 0,\n",
    "    \"include_metadatas\": False,\n",
    "    \"include_scores\": True,\n",
    "    \"search_strategy\": \"vanilla\",\n",
    "}\n",
    "    \n",
    "rag_generation_config = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens_to_sample\": 512\n",
    "}\n",
    "\n",
    "template = \"\"\"\n",
    "## Task:\n",
    " \n",
    "Answer the query given below using the provided context. Keep your answer very short and concise!\n",
    "     \n",
    " - Aim to answer in 2-3 sentences whenever possible.\n",
    " - If a longer answer is needed, make it as concise as possible, focusing only on the relevant details.\n",
    " - If there are multiple points, lists, or enumerations (e.g., \"*\", \"-\", \"1.\", \"2.\"), merge them into a single sentence using commas or conjunctions instead of listing them separately.\n",
    " - DO NOT use line item references for the context.\n",
    " - If there is no context available locally to answer, inform the user of insufficient information.\n",
    " - NEVER provide an answer if there's no context that discusses it.\n",
    " - NEVER reason about a possible answer! If no context can answer the query, there should be NO answer.\n",
    " - Do NOT rely on your own knowledge for answering a question, but only use retrieved information.\n",
    " \n",
    "### Query:\n",
    " \n",
    "{query}\n",
    " \n",
    "### Context:\n",
    " \n",
    "{context}\n",
    " \n",
    "### Query:\n",
    " \n",
    "{query}\n",
    " \n",
    "# Reminder: Provide short and concise answers. NEVER answer something that is not in the provided context!\n",
    "\n",
    "## Response:\n",
    "\"\"\"\n",
    "    \n",
    "def summarize_ctx_template(context: str) -> str:\n",
    "    summarize_prompt = f\"\"\"\n",
    "    Summarize the following context while preserving all key information:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Provide a concise summary that includes all essential facts, data points, and information.\n",
    "    Try to stay under 4 sentences. Only provide the summary and no further explanation or details.\n",
    "    Don't mention things like: Here is a concise summary of the key information.\n",
    "    \"\"\"\n",
    "    return summarize_prompt\n",
    "    \n",
    "# Make sure to use a different variable if something goes wrong\n",
    "final_dataset = dataset\n",
    "for i, sample in enumerate(final_dataset.samples):\n",
    "    try:\n",
    "        # Submit a query\n",
    "        response = client.retrieval.rag(\n",
    "            query=sample.eval_sample.user_input,\n",
    "            search_mode=\"custom\",\n",
    "            search_settings=search_settings,\n",
    "            rag_generation_config=rag_generation_config,\n",
    "            task_prompt_override=template\n",
    "        ).results\n",
    "\n",
    "        # After getting the response summarize the context\n",
    "        full_ctx = \"\\n\".join([re.sub(r\"\\n+\", \"\\n\", chunk.text) for chunk in response.search_results.chunk_search_results])\n",
    "        \n",
    "        # Generate the summary by using the LLM\n",
    "        summary_ctx = ollama.generate(\n",
    "            model=\"llama3.1\",\n",
    "            prompt = summarize_ctx_template(full_ctx),\n",
    "            options = {\n",
    "                \"temperature\": 0.1,\n",
    "                \"num_predict\": 512\n",
    "            }\n",
    "        )['response']\n",
    "        \n",
    "        llm_response = response.completion # Response in RAGAs dataset\n",
    "        retrieved_context = summary_ctx    # Retrieved contexts \n",
    "\n",
    "        final_dataset.samples[i].eval_sample.response = llm_response\n",
    "        final_dataset.samples[i].eval_sample.retrieved_contexts = [retrieved_context]\n",
    "\n",
    "        print(f\"Added data to sample: {i + 1} out of {len(final_dataset.samples)}\")\n",
    "        \n",
    "    except ollama.RequestError | ollama.ResponseError as oe:\n",
    "        print(f\"Something went wrong when submitting query: {sample.eval_sample.user_input} due to {str(oe)}\")\n",
    "    except R2RException as r2re:\n",
    "        print(f\"Something went wrong when submitting query: {sample.eval_sample.user_input} due to {str(r2re)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Something went wrong when submitting query: {sample.eval_sample.user_input} due to {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the dataset\n",
    "\n",
    "final_dataset.to_jsonl(\"dataset.jsonl\")\n",
    "final_dataset.to_csv(\"dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
