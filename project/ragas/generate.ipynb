{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sample_Docs_Markdown'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 31 (delta 4), reused 0 (delta 0), pack-reused 10 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (31/31), 132.02 KiB | 6.00 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# 1. Retrieve data (Optional - can use your own dataset / files instead)\n",
    "\n",
    "!git clone https://huggingface.co/datasets/explodinggradients/Sample_Docs_Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load data into document objects\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"Sample_Docs_Markdown/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\", exclude=\"README.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 3. Construct knowledge graph\n",
    "\n",
    "\"\"\"\n",
    "The knowledge graph in RAGAs consists of Node objects which hold information.\n",
    "They have a type and a set of properties.\n",
    "Additionally, a knowledge graph could contain relationships.\n",
    "The graph is crucial when it comes to generation of synthetic test data, since \n",
    "it serves as a context for the generation of personas and scenarios.\n",
    "\"\"\"\n",
    "\n",
    "from ragas.testset.graph import (\n",
    "    Node,\n",
    "    NodeType,\n",
    "    KnowledgeGraph,\n",
    ")\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.add(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Instantiate required objects\n",
    "\n",
    "# Objects we will use to interact with our running instance of Ollama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Configuration where one can set a timeout and additional parameters\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "# A cache which saves data for future re-runs on disk\n",
    "from ragas.cache import DiskCacheBackend\n",
    "\n",
    "# Wrappers around Langchain objects required by prompts when generating \n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=14400, # 4 hours (Note since llama3.1:8b is not particularly strong you may need more time)\n",
    "    max_retries=15,\n",
    "    max_wait=60,\n",
    "    log_tenacity=True\n",
    ")\n",
    "\n",
    "# Caching which makes the applying of transformations much faster and \n",
    "# saves output for future re-runs.\n",
    "cacher = DiskCacheBackend(cache_dir=\".cache\")\n",
    "\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.1,\n",
    "    num_ctx=24000,\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(\n",
    "    langchain_llm=ollama_llm,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(\n",
    "    embeddings=ollama_embeddings,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create the transformation pipeline\n",
    "\n",
    "from ragas.testset.transforms.engine import Parallel\n",
    "from ragas.testset.transforms import default_transforms\n",
    "from ragas.testset.transforms.extractors.llm_based import (\n",
    "    KeyphrasesExtractor,\n",
    "    TopicDescriptionExtractor\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "default_transforms()\n",
    "\n",
    "This function defines a default set of transformations for processing a knowledge graph.  \n",
    "It extracts key information from documents, splits them into smaller chunks if necessary,  \n",
    "and computes relationships between these chunks.\n",
    "\n",
    "The sequence of transformations works as follows:\n",
    "\n",
    "1. Document Length Analysis\n",
    "    - Documents are categorized into three bins based on token length:\n",
    "    - (0-100 tokens): Too short → raises an error.\n",
    "    - (101-500 tokens): Medium-length processing.\n",
    "    - (501+ tokens): Long documents undergo additional processing.\n",
    "\n",
    "2. Headline Extraction & Splitting (for long documents, 501+ tokens)  \n",
    "    - Extracts headlines from large documents to create logical sections.  \n",
    "    - Splits long documents into smaller chunks at headline boundaries.\n",
    "\n",
    "3. Summary Extraction  \n",
    "    - Generates a concise summary for each document to facilitate quick understanding.\n",
    "\n",
    "4. Named Entity Recognition (NER) & Theme Extraction  \n",
    "    - NERExtractor identifies and extracts named entities (e.g., people, organizations, locations).  \n",
    "    - ThemesExtractor detects overarching topics/themes in each chunk.\n",
    "\n",
    "5. Embedding Generation\n",
    "    - Uses an embedding model to convert summaries into vector representations for similarity-based retrieval.\n",
    "\n",
    "6. Cosine Similarity Computation  \n",
    "    - Measures semantic similarity between documents based on their summary embeddings.  \n",
    "    - Creates relationships between similar documents using a threshold (0.7 for long docs, 0.5 for medium docs).\n",
    "\n",
    "7. NER-Based Overlap Score Computation\n",
    "    - Computes overlap scores between extracted named entities in different chunks.  \n",
    "    - Helps detect if two chunks talk about similar entities.\n",
    "\n",
    "8. Custom Node Filtering \n",
    "    - Filters nodes to keep only relevant chunks for processing.\n",
    "\n",
    "9. Parallel Processing for Efficiency\n",
    "    - Certain transformations run in parallel to improve performance:\n",
    "      - Summary embeddings, theme extraction, and NER run together.\n",
    "      - Cosine similarity and entity overlap scoring run together.\n",
    "\n",
    "-> Final Outcome:\n",
    "    - A structured set of document transformations that extracts headlines, summaries, key entities, themes, embeddings, \n",
    "        and relationships between different chunks/documents\n",
    "    - Used to construct a knowledge graph for downstream retrieval-augmented generation (RAG) tasks.\n",
    "\"\"\"\n",
    "transforms = default_transforms(\n",
    "    docs,\n",
    "    langchain_llm,\n",
    "    langchain_embeddings\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Using 2 additional extractors for keyphrases and topic description.\n",
    "Both of those extractors are going to be performed in parallel.\n",
    "Finally, we extend the default transformation by 2 additional ones\n",
    "    by adding them before the cosine distance similarity transformation.\n",
    "\"\"\"\n",
    "keyphrase_extractor = KeyphrasesExtractor(\n",
    "    llm=langchain_llm,\n",
    "    max_num=15\n",
    ")\n",
    "\n",
    "topic_description_extractor = TopicDescriptionExtractor(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "parallel_transforms = Parallel(\n",
    "    keyphrase_extractor,\n",
    "    topic_description_extractor\n",
    ")\n",
    "\n",
    "transforms.insert(-1, parallel_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/6 [00:00<?, ?it/s]Property 'headlines' already exists in node 'cf944d'. Skipping!\n",
      "Property 'headlines' already exists in node '872d4b'. Skipping!\n",
      "Property 'headlines' already exists in node '45230e'. Skipping!\n",
      "Property 'headlines' already exists in node 'd41106'. Skipping!\n",
      "Property 'headlines' already exists in node 'fb8933'. Skipping!\n",
      "Property 'headlines' already exists in node 'cf944d'. Skipping!\n",
      "Applying HeadlineSplitter:   0%|          | 0/24 [00:00<?, ?it/s] unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:   0%|          | 0/8 [00:00<?, ?it/s] Property 'summary' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary' already exists in node '872d4b'. Skipping!\n",
      "Property 'summary' already exists in node '45230e'. Skipping!\n",
      "Property 'summary' already exists in node 'd41106'. Skipping!\n",
      "Property 'summary' already exists in node 'fb8933'. Skipping!\n",
      "Property 'summary' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary' already exists in node 'cf944d'. Skipping!\n",
      "Applying CustomNodeFilter:   0%|          | 0/24 [00:00<?, ?it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "unable to apply transformation: Invalid json output: After analyzing the input, I would give a score of 4. The content of the node is highly relevant and accurate, reflecting the main themes of the document summary with minor gaps. It covers all important details and adds depth to the understanding of the document's topics.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Applying CustomNodeFilter:   4%|▍         | 1/24 [00:00<00:08,  2.68it/s]unable to apply transformation: The output parser failed to parse the output including retries.\n",
      "unable to apply transformation: Invalid json output: After analyzing the input, I would give a score of 4. The content of the node is highly relevant and accurate, reflecting the main themes of the document summary with minor gaps. It covers all important details and adds depth to the understanding of the document's topics.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "unable to apply transformation: The output parser failed to parse the output including retries.\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/56 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '872d4b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '45230e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd41106'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fb8933'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'cf944d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'cf944d'. Skipping!\n",
      "Property 'themes' already exists in node 'a204c8'. Skipping!\n",
      "Property 'themes' already exists in node 'ef87f5'. Skipping!\n",
      "Property 'themes' already exists in node 'fcf74e'. Skipping!\n",
      "Property 'themes' already exists in node '8ac1c7'. Skipping!\n",
      "Property 'themes' already exists in node '87f41f'. Skipping!\n",
      "Property 'themes' already exists in node 'b9df0c'. Skipping!\n",
      "Property 'themes' already exists in node 'a9a825'. Skipping!\n",
      "Property 'themes' already exists in node 'fa71ee'. Skipping!\n",
      "Property 'themes' already exists in node 'cb962d'. Skipping!\n",
      "Property 'themes' already exists in node 'fd4f77'. Skipping!\n",
      "Property 'themes' already exists in node '05774c'. Skipping!\n",
      "Property 'themes' already exists in node 'f7c1f0'. Skipping!\n",
      "Property 'entities' already exists in node 'a204c8'. Skipping!\n",
      "Property 'entities' already exists in node 'ef87f5'. Skipping!\n",
      "Property 'entities' already exists in node 'fcf74e'. Skipping!\n",
      "Property 'entities' already exists in node '8ac1c7'. Skipping!\n",
      "Property 'entities' already exists in node '87f41f'. Skipping!\n",
      "Property 'entities' already exists in node 'b9df0c'. Skipping!\n",
      "Property 'entities' already exists in node 'a9a825'. Skipping!\n",
      "Property 'entities' already exists in node 'fa71ee'. Skipping!\n",
      "Property 'entities' already exists in node 'cb962d'. Skipping!\n",
      "Property 'entities' already exists in node 'fd4f77'. Skipping!\n",
      "Property 'entities' already exists in node '05774c'. Skipping!\n",
      "Property 'entities' already exists in node 'f7c1f0'. Skipping!\n",
      "Applying [KeyphrasesExtractor, TopicDescriptionExtractor]:   0%|          | 0/76 [00:00<?, ?it/s]           Property 'keyphrases' already exists in node '1943e0'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'cf944d'. Skipping!\n",
      "Property 'keyphrases' already exists in node '872d4b'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'f3b5c3'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'e0af21'. Skipping!\n",
      "Property 'keyphrases' already exists in node '52b77f'. Skipping!\n",
      "Property 'keyphrases' already exists in node '45230e'. Skipping!\n",
      "Property 'keyphrases' already exists in node '075d2c'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'd41106'. Skipping!\n",
      "Property 'keyphrases' already exists in node '83e26f'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'fb8933'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'cf944d'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'a204c8'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'ef87f5'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'fcf74e'. Skipping!\n",
      "Property 'keyphrases' already exists in node '8ac1c7'. Skipping!\n",
      "Property 'keyphrases' already exists in node '87f41f'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'b9df0c'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'a9a825'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'fa71ee'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'cb962d'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'fd4f77'. Skipping!\n",
      "Property 'keyphrases' already exists in node '05774c'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'f7c1f0'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'cf944d'. Skipping!\n",
      "Property 'keyphrases' already exists in node 'cf944d'. Skipping!\n",
      "Property 'topic_description' already exists in node '1943e0'. Skipping!\n",
      "Property 'topic_description' already exists in node 'cf944d'. Skipping!\n",
      "Property 'topic_description' already exists in node '872d4b'. Skipping!\n",
      "Property 'topic_description' already exists in node 'f3b5c3'. Skipping!\n",
      "Property 'topic_description' already exists in node 'e0af21'. Skipping!\n",
      "Property 'topic_description' already exists in node '52b77f'. Skipping!\n",
      "Property 'topic_description' already exists in node '45230e'. Skipping!\n",
      "Property 'topic_description' already exists in node '075d2c'. Skipping!\n",
      "Property 'topic_description' already exists in node 'd41106'. Skipping!\n",
      "Property 'topic_description' already exists in node '83e26f'. Skipping!\n",
      "Property 'topic_description' already exists in node 'fb8933'. Skipping!\n",
      "Property 'topic_description' already exists in node 'cf944d'. Skipping!\n",
      "Property 'topic_description' already exists in node 'a204c8'. Skipping!\n",
      "Property 'topic_description' already exists in node 'ef87f5'. Skipping!\n",
      "Property 'topic_description' already exists in node 'fcf74e'. Skipping!\n",
      "Property 'topic_description' already exists in node '8ac1c7'. Skipping!\n",
      "Property 'topic_description' already exists in node '87f41f'. Skipping!\n",
      "Property 'topic_description' already exists in node 'b9df0c'. Skipping!\n",
      "Property 'topic_description' already exists in node 'a9a825'. Skipping!\n",
      "Property 'topic_description' already exists in node 'fa71ee'. Skipping!\n",
      "Property 'topic_description' already exists in node 'cb962d'. Skipping!\n",
      "Property 'topic_description' already exists in node 'fd4f77'. Skipping!\n",
      "Property 'topic_description' already exists in node '05774c'. Skipping!\n",
      "Property 'topic_description' already exists in node 'f7c1f0'. Skipping!\n",
      "Property 'topic_description' already exists in node 'cf944d'. Skipping!\n",
      "Property 'topic_description' already exists in node 'cf944d'. Skipping!\n",
      "                                                                                                         \r"
     ]
    }
   ],
   "source": [
    "# 6. Apply the transformations to the knowledge graph\n",
    "\n",
    "from ragas.testset.transforms import apply_transforms\n",
    "\n",
    "apply_transforms(kg, transforms, run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 10/10 [01:38<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# 7. Generate personas\n",
    "\n",
    "from persona import generate_personas_from_kg\n",
    "\n",
    "\"\"\"\n",
    "A persona is an entity/role which interacts with the system.\n",
    "It groups people together under a common theme and goals.\n",
    "Example: a Senior DevOps engineer, a Junior Data Scientist, a Marketing Manager in the context of an IT company \n",
    "\n",
    "Persona object consists of a name and a description.\n",
    "The name is used to identify the persona and the description is used to describe the role of the persona.\n",
    "\"\"\"\n",
    "\n",
    "personas = generate_personas_from_kg(\n",
    "    kg=kg,\n",
    "    llm=langchain_llm,\n",
    "    num_personas=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(name='Human Resources Manager', role_description='Oversees diversity, inclusion, and equality initiatives within the organization.'),\n",
       " Persona(name='DIB Team Lead', role_description='Oversees diversity, inclusion, and belonging initiatives, ensuring effective communication and team member engagement.'),\n",
       " Persona(name='Diversity and Inclusion Program Manager', role_description='Focuses on creating an equitable work environment by promoting allyship, diversity, and inclusion strategies.'),\n",
       " Persona(name='Diana Rodriguez', role_description='Serves as a member of the Advisory Group to foster diversity and promote inclusive practices within an organization.'),\n",
       " Persona(name='Liam McNally', role_description='Curates and promotes programs of events that celebrate diversity, inclusion, and belonging within the workplace.'),\n",
       " Persona(name='Global Diversity and Inclusion Director', role_description='Oversees initiatives to promote diversity, equity, and inclusion across various regions and employee groups, while tracking key performance indicators for success.'),\n",
       " Persona(name='Diversity and Inclusion Lead', role_description='Develops initiatives to increase diversity, equity, and inclusion in the workplace, while also identifying opportunities for team members from underrepresented groups to advance their careers.'),\n",
       " Persona(name='Diversity and Inclusion Officer', role_description='Works to create an inclusive environment where diversity is valued and all team members feel heard.'),\n",
       " Persona(name='DIB Team Facilitator', role_description='Works with the Diversity, Inclusion & Belonging (DIB) team to organize and facilitate quarterly roundtables for teams at GitLab, fostering safe spaces for discussing DIB-related issues and building connections among team members.'),\n",
       " Persona(name='Diversity Ambassador', role_description='Develops and implements strategies for fostering a culture of inclusion within the organization.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.'),\n",
       " Persona(name='DIB Team Member', role_description='Participates in quarterly roundtables organized by the Diversity, Inclusion & Belonging (DIB) Team to discuss and build connections related to diversity, inclusion, and belonging issues within teams.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.specific import MultiHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.abstract import MultiHopAbstractQuerySynthesizer\n",
    "\n",
    "\"\"\" \n",
    "There are two main types of queries in RAGAs:\n",
    "    -> SingleHopQuery where the context relevant for answering a question lies in a single document/chunk\n",
    "    -> MultiHopQuery where the context relevant for answering a question lies in multiple documents/chunks\n",
    "Additionally, for each of those queries there's a Specific or Abstract query variant:\n",
    "    -> Specific one which pertains to a fact. \n",
    "        Example: When did WW1 break out? (Can be precisely answered, there's no room for guessing/interpretation)\n",
    "    -> Abstract one which is more about testing the reasoning capabilities of the LLM. \n",
    "        Example: Why did WW1 break out? (There's room for interpretation in this case)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "What `SingleHopSpecificQuerySynthesizer` provides:\n",
    "    -> Can filter out all nodes which match/contain the selected property\n",
    "    -> Generate a scenorio (hidden function, marked with underscore)\n",
    "        If no nodes have been found with the specified entity a ValueError is thrown\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "single_hop_specific_entities = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"entities\"\n",
    ")\n",
    "\n",
    "single_hop_specific_keyphrases = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"keyphrases\"\n",
    ")\n",
    "\n",
    "single_hop_specific_headlines = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"headlines\"\n",
    ")\n",
    "\n",
    "single_hop_specific_themes = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"themes\"\n",
    ")\n",
    "\n",
    "multi_hop_specific_entities = MultiHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "multi_hop_abstract_entities = MultiHopAbstractQuerySynthesizer(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (single_hop_specific_entities, 0.125),\n",
    "    (single_hop_specific_keyphrases, 0.125),\n",
    "    (single_hop_specific_headlines, 0.125),\n",
    "    (single_hop_specific_themes, 0.125),\n",
    "    (multi_hop_specific_entities, 0.25),\n",
    "    (multi_hop_abstract_entities, 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   0%|          | 0/14 [00:00<?, ?it/s] Property 'summary' already exists in node 'd09b23'. Skipping!\n",
      "Property 'summary' already exists in node 'ba784b'. Skipping!\n",
      "Property 'summary' already exists in node 'e76f93'. Skipping!\n",
      "Property 'summary' already exists in node '506bfd'. Skipping!\n",
      "Property 'summary' already exists in node '818e1a'. Skipping!\n",
      "Property 'summary' already exists in node '11314d'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/22 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node 'd09b23'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ba784b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e76f93'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '506bfd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '818e1a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '11314d'. Skipping!\n",
      "Generating personas: 100%|██████████| 3/3 [00:00<00:00, 436.57it/s]                                 \n",
      "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No clusters found in the knowledge graph. Try changing the relationship condition.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m load_dotenv()\n\u001b[32m      6\u001b[39m generator = TestsetGenerator(\n\u001b[32m      7\u001b[39m     llm=langchain_llm,\n\u001b[32m      8\u001b[39m     embedding_model=langchain_embeddings,\n\u001b[32m      9\u001b[39m     knowledge_graph=kg\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m dataset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:188\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    185\u001b[39m apply_transforms(kg, transforms)\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.knowledge_graph = kg\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:413\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    415\u001b[39m     scenario_generation_rm.on_chain_end(\n\u001b[32m    416\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33mscenario_sample_list\u001b[39m\u001b[33m\"\u001b[39m: scenario_sample_list}\n\u001b[32m    417\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:410\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    401\u001b[39m     exec.submit(\n\u001b[32m    402\u001b[39m         scenario.generate_scenarios,\n\u001b[32m    403\u001b[39m         n=splits[i],\n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m         callbacks=scenario_generation_grp,\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     scenario_sample_list: t.List[t.List[BaseScenario]] = \u001b[43mexec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/asyncio/futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:141\u001b[39m, in \u001b[36mExecutor._process_jobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    137\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jobs),\n\u001b[32m    138\u001b[39m         desc=\u001b[38;5;28mself\u001b[39m.desc,\n\u001b[32m    139\u001b[39m         disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    140\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m internal_pbar:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    142\u001b[39m             \u001b[38;5;28mself\u001b[39m.jobs, internal_pbar, results, max_workers\n\u001b[32m    143\u001b[39m         )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    146\u001b[39m         \u001b[38;5;28mself\u001b[39m.jobs, \u001b[38;5;28mself\u001b[39m.pbar, results, max_workers\n\u001b[32m    147\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:191\u001b[39m, in \u001b[36mExecutor._process_coroutines\u001b[39m\u001b[34m(self, jobs, pbar, results, max_workers)\u001b[39m\n\u001b[32m    189\u001b[39m coroutines = [afunc(*args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m afunc, args, kwargs, _ \u001b[38;5;129;01min\u001b[39;00m jobs]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m as_completed(coroutines, max_workers):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    192\u001b[39m     results.append(result)\n\u001b[32m    193\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/asyncio/tasks.py:631\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/asyncio/futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:48\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:100\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_exceptions:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m         exec_name = \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/executor.py:96\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(\n\u001b[32m     93\u001b[39m     *args, **kwargs\n\u001b[32m     94\u001b[39m ) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Callable | \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/testset/synthesizers/base.py:94\u001b[39m, in \u001b[36mBaseSynthesizer.generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m     88\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m     89\u001b[39m scenario_generation_rm, scenario_generation_group = new_group(\n\u001b[32m     90\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m     91\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n, \u001b[33m\"\u001b[39m\u001b[33mknowledge_graph\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(knowledge_graph)},\n\u001b[32m     92\u001b[39m     callbacks=callbacks,\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m scenarios = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_scenarios(\n\u001b[32m     95\u001b[39m     n, knowledge_graph, persona_list, scenario_generation_group\n\u001b[32m     96\u001b[39m )\n\u001b[32m     97\u001b[39m scenario_generation_rm.on_chain_end(outputs={\u001b[33m\"\u001b[39m\u001b[33mscenarios\u001b[39m\u001b[33m\"\u001b[39m: scenarios})\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scenarios\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/ragas/testset/synthesizers/multi_hop/specific.py:79\u001b[39m, in \u001b[36mMultiHopSpecificQuerySynthesizer._generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m     76\u001b[39m triplets = \u001b[38;5;28mself\u001b[39m.get_node_clusters(knowledge_graph)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(triplets) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo clusters found in the knowledge graph. Try changing the relationship condition.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     83\u001b[39m num_sample_per_cluster = \u001b[38;5;28mint\u001b[39m(np.ceil(n / \u001b[38;5;28mlen\u001b[39m(triplets)))\n\u001b[32m     84\u001b[39m scenarios = []\n",
      "\u001b[31mValueError\u001b[39m: No clusters found in the knowledge graph. Try changing the relationship condition."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=langchain_llm,\n",
    "    embedding_model=langchain_embeddings,\n",
    "    knowledge_graph=kg\n",
    ")\n",
    "\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs,\n",
    "    testset_size=50,\n",
    "    query_distribution=query_distribution,\n",
    "    run_config=run_config,\n",
    "    with_debugging_logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n",
      "dict_keys(['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding', 'keyphrases', 'topic_description'])\n"
     ]
    }
   ],
   "source": [
    "for node in kg.nodes:\n",
    "    if node.type == NodeType.DOCUMENT:\n",
    "        print(node.properties.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "['Ally', 'Diversity and inclusion', 'Belonging', 'Self-education', 'Active listening', 'Empathy and emotional intelligence', 'Humility', 'Non-defensive', 'Willingness to take feedback', 'Courage', 'Self-awareness', 'Privilege', 'Oppression', 'Power', 'Marginalized groups', 'Performative allyship']\n",
      "['Allyship', 'Empathy', 'Privilege', 'Oppression', 'Social capital', 'Marginalized groups', 'Power dynamics', 'Authority', 'Education', 'Personal growth']\n",
      "['Diversity on teams', 'Allyship', 'Recruiting and hiring', 'Sourcing', 'Interviewing', 'Compensation', 'Guidance and support', 'Mentorship', 'Difficult conversations', 'Performance conversations']\n",
      "['Allyship', 'Diversity', 'Inclusion', 'Belonging', 'Equality', 'Empathy', 'Effective Listening', 'Building Trust', 'Anti-racism', ' Ally Training']\n",
      "['Sales Sponsorship Pilot Program', 'Mentorship', 'Sponsorship', 'GitLab', 'Career advancement', 'Leadership development', 'Communication skills', 'Influence and power', 'Senior leadership', 'Diversity and inclusion']\n",
      "['Sponsorship Program', 'Open and honest communication', 'Active listening', 'Learning and growth mindset', 'Risk-taking and discomfort', 'Advocacy and influence', 'Feedback and accountability', 'Career development and advancement', 'Leadership and senior IC roles', 'Individual Growth Plan (IGP)']\n",
      "['Sponsorship', 'Relationship building', 'Career development', 'Diversity and inclusion', 'Equity', 'Inclusion', 'Leadership', 'Mentorship', 'Talent management', 'Succession planning']\n",
      "['Diversity, Inclusion & Belonging', 'Roundtables', 'Team Building', 'Safe Spaces', 'Discussion', 'Feedback', 'Privilege for Sale', 'Privilege Backpack', 'Agenda', 'Facilitation']\n",
      "['Diversity', 'Inclusion', 'Belonging', 'Privilege', 'Social privilege', 'Financial privilege', 'Legal privilege', 'Roundtable discussion', 'Empowerment', 'Vulnerability']\n",
      "['Diversity, Inclusion & Belonging', 'Inclusive language and pronouns', 'Parental leave', 'Asynchronous communication and workflows', 'Tips for Companies', 'Defining Diversity, Inclusion & Belonging', 'Company values', 'Family and Friends first', 'Work second', 'DIB Advisory group guidelines']\n",
      "['Inclusive Remote Culture', 'Remote Working', 'Diversity and Inclusion', 'Belonging', 'Team Member Resource Groups', 'DIB Events', 'DIB Advisory Group', 'TMRGs', 'GitLab', 'Work Environment']\n",
      "['Inclusive language', 'Pronouns', 'Identity', 'Respect', 'Welcoming environment', 'Safe space', 'Supportive environment', 'Diversity and inclusion', 'Team accountability', 'Unconscious bias']\n"
     ]
    }
   ],
   "source": [
    "for node in kg.nodes:\n",
    "    print(node.properties.get(\"themes\", None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
