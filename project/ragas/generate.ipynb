{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic test data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of High-Quality Test Sets for RAG Systems\n",
    "\n",
    "### Purpose\n",
    "Test sets are critical for:\n",
    "- Accurately measuring RAG system performance\n",
    "- Identifying system strengths and weaknesses\n",
    "- Guiding continuous improvement\n",
    "\n",
    "### Key Evaluation Dimensions\n",
    "1. **Retrieval Effectiveness**: Assess how well relevant context is retrieved\n",
    "2. **Generation Quality**: Evaluate the accuracy and coherence of generated responses\n",
    "3. **Contextual Relevance**: Measure how well the system understands and integrates retrieved information\n",
    "\n",
    "### Evaluation Goals\n",
    "- Benchmark system performance\n",
    "- Detect hallucinations\n",
    "- Validate generalization capabilities\n",
    "- Simulate real-world query complexity\n",
    "\n",
    "### Best Practices\n",
    "- Use diverse query types\n",
    "- Cover multiple domains\n",
    "- Include edge cases\n",
    "- Create reproducible test scenarios\n",
    "- Contains enough number of samples to be derive statistically significant conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve data:\n",
    "* The data can be a dataset from `huggingface` or any other platform.\n",
    "\n",
    "* Alternatively, files available on disk - pdf, md, etc.\n",
    "\n",
    "* One can also use `AsyncHtmlLoader` from `langchain` to scrape from the internet.\n",
    "    - **Careful when performing web scraping to not violate any terms and conditions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 31 (delta 4), reused 0 (delta 0), pack-reused 10 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (31/31), 132.02 KiB | 8.80 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/datasets/explodinggradients/Sample_Docs_Markdown data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data into document objects\n",
    "\n",
    "I prefer to use `langchain`, however `llama-index` is also a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\", exclude=\"README.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct knowledge graph\n",
    "\n",
    "- A **knowledge graph** is a fundamental concept when it comes to **RAGAs** and using its capabilities for **automatic data generation**.\n",
    "\n",
    "- A **knowledge graph** consists of **Node** objects at first, which represent **documents** - their content and additional metadata.\n",
    "\n",
    "- Thereafter, one can enrich the graph by **apply various transformations** to it and **relationships get built**, which express some kind of connection between Node objects. The transformations can be applied only through the use of **Extractors**. They serve as a way to gather relevant data from the documents depending on the type of extractor and this way to logically connect 2 or more nodes together.\n",
    "\n",
    "- This graph then is used to generate so called **scenarios** and can also be used to generate **personas** to arrive at the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3tr0vv/Desktop/Evaluation-Approaches-for-Retrieval-Augmented-Generation-RAG-/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.graph import (\n",
    "    Node,\n",
    "    NodeType,\n",
    "    KnowledgeGraph,\n",
    ")\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.add(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate required objects\n",
    "\n",
    "- **RAGAs** would require a **Large-Language-Model** and an **Embedding** one to able to apply the **transformations** to the **knowledge graph**. For that purpose one must create **wrapper** objects for both of the models. `Langchain` and `llama-index` are both supported. \n",
    "\n",
    "- Additionally, a **configuration** can be used to modify the default behaviour of the framework. For example timeout values can be modified, maximum retries for failed operations and so on can be configured from the **RunConfig**.\n",
    "    - **NOTE**: since llama3.1:8b is not particularly efficient you may need to modify the `timeout` value.\n",
    "\n",
    "- Lastly, there's a single implementation in **RAGAs** for caching saving steps onto disk. To use it the **DiskCacheBackend** class can come in play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "from ragas import (\n",
    "    RunConfig,\n",
    "    DiskCacheBackend\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=14400,\n",
    "    max_retries=15,\n",
    "    max_wait=30\n",
    ")\n",
    "\n",
    "cacher = DiskCacheBackend(cache_dir=\".cache\")\n",
    "\n",
    "ollama_llm = OllamaLLM(\n",
    "    cache=InMemoryCache(),\n",
    "    model=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.1,\n",
    "    num_ctx=24000,\n",
    "    format=\"json\"\n",
    ")\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(\n",
    "    langchain_llm=ollama_llm,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")\n",
    "\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(\n",
    "    embeddings=ollama_embeddings,\n",
    "    run_config=run_config,\n",
    "    cache=cacher\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the transformation pipeline\n",
    "\n",
    "The sequence of transformations:\n",
    "\n",
    "1. Headline Extraction & Splitting (for long documents, 501+ tokens up to 1500)  \n",
    "    - Extracts headlines from large documents to create logical sections.  \n",
    "    - Splits long documents into smaller chunks at headline boundaries.\n",
    "\n",
    "2. Summary Extraction  \n",
    "    - Generates a concise summary for each document to facilitate quick understanding.\n",
    "\n",
    "3. Named Entity Recognition (NER) & Theme Extraction  \n",
    "    - NERExtractor identifies and extracts named entities (e.g., people, organizations, locations).  \n",
    "    - ThemesExtractor detects overarching topics/themes in each chunk.\n",
    "\n",
    "4. Embedding Generation\n",
    "    - Uses an embedding model to convert summaries into vector representations for similarity-based retrieval.\n",
    "\n",
    "5. Cosine Similarity Computation  \n",
    "    - Measures semantic similarity between documents based on their summary embeddings.  \n",
    "    - Creates relationships between similar documents using a threshold of `0.75`.\n",
    "\n",
    "6. NER-Based Overlap Score Computation\n",
    "    - Computes overlap scores between extracted named entities in different chunks.  \n",
    "    - Helps detect if two chunks talk about similar entities.\n",
    "\n",
    "7. Extraction of key phrases and topics\n",
    "    - Relevant for generating personas in my case\n",
    "    - Gain additional insights into documents\n",
    "\n",
    "8. Custom Node Filtering \n",
    "    - Filters nodes to keep only relevant chunks for processing.\n",
    "\n",
    "9. Parallel Processing for Efficiency\n",
    "    - Certain transformations run in parallel to improve performance:\n",
    "      - Summary embeddings, theme extraction, and NER run together.\n",
    "      - Cosine similarity and entity overlap scoring run together.\n",
    "\n",
    "-> Final Outcome:\n",
    "    - A structured set of document transformations that extracts headlines, summaries, key entities, themes, embeddings, \n",
    "        and relationships between different chunks/documents\n",
    "    - Used to construct a knowledge graph for downstream retrieval-augmented generation (RAG) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import (\n",
    "    HeadlinesExtractor,\n",
    "    SummaryExtractor,\n",
    "    ThemesExtractor,\n",
    "    NERExtractor,\n",
    "    KeyphrasesExtractor,\n",
    "    TopicDescriptionExtractor,\n",
    ")\n",
    "from ragas.testset.transforms.relationship_builders import (\n",
    "    OverlapScoreBuilder,\n",
    "    CosineSimilarityBuilder\n",
    "    \n",
    ")\n",
    "from ragas.testset.transforms.engine import Parallel\n",
    "from ragas.testset.transforms.filters import CustomNodeFilter\n",
    "from ragas.testset.transforms.splitters import HeadlineSplitter\n",
    "from ragas.testset.transforms.extractors.embeddings import EmbeddingExtractor\n",
    "\n",
    "from ragas.utils import num_tokens_from_string\n",
    "\n",
    "# Taken from the default_transforms\n",
    "def filter_doc_with_num_tokens(node, min_num_tokens=500):\n",
    "    return (\n",
    "        node.type == NodeType.DOCUMENT\n",
    "        and num_tokens_from_string(node.properties[\"page_content\"]) > min_num_tokens\n",
    "    )\n",
    "\n",
    "headline_extractor = HeadlinesExtractor(\n",
    "    llm=langchain_llm,\n",
    "    max_num=10,\n",
    "    filter_nodes=lambda node: filter_doc_with_num_tokens(node)\n",
    ")\n",
    "\n",
    "splitter = HeadlineSplitter(\n",
    "    min_tokens=500,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "summary_extractor = SummaryExtractor(\n",
    "    llm=langchain_llm,\n",
    "    filter_nodes=lambda node: filter_doc_with_num_tokens(node)\n",
    ")\n",
    "\n",
    "theme_extractor = ThemesExtractor(\n",
    "    llm=langchain_llm,\n",
    "    max_num_themes=10\n",
    ")\n",
    "\n",
    "ner_extractor = NERExtractor(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "summary_emb_extractor = EmbeddingExtractor(\n",
    "    embedding_model=langchain_embeddings,\n",
    "    property_name=\"summary_embedding\",\n",
    "    embed_property_name=\"summary\",\n",
    "    filter_nodes=lambda node: filter_doc_with_num_tokens(node),\n",
    ")\n",
    "\n",
    "keyphrase_extractor = KeyphrasesExtractor(\n",
    "    llm=langchain_llm,\n",
    "    max_num=15\n",
    ")\n",
    "\n",
    "topic_description_extractor = TopicDescriptionExtractor(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "cosine_sim_builder = CosineSimilarityBuilder(\n",
    "    property_name=\"summary_embedding\",\n",
    "    new_property_name=\"summary_similarity\",\n",
    "    threshold=0.75,\n",
    "    filter_nodes=lambda node: filter_doc_with_num_tokens(node),\n",
    ")\n",
    "\n",
    "ner_overlap_sim = OverlapScoreBuilder(\n",
    "    threshold=0.01, filter_nodes=lambda node: node.type == NodeType.CHUNK\n",
    ")\n",
    "\n",
    "node_filter = CustomNodeFilter(\n",
    "    llm=langchain_llm,\n",
    "    filter_nodes=lambda node: node.type == NodeType.CHUNK\n",
    ")\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    splitter,\n",
    "    summary_extractor,\n",
    "    node_filter,\n",
    "    Parallel(summary_emb_extractor, theme_extractor, ner_extractor, keyphrase_extractor, topic_description_extractor),\n",
    "    Parallel(cosine_sim_builder, ner_overlap_sim)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply the transformations to the knowledge graph\n",
    "\n",
    "In the section below the `apply_transforms` is going to apply all the previously defined transformations enriching the `knowledge graph` in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlineSplitter:   0%|          | 0/11 [00:00<?, ?it/s]         unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:   0%|          | 0/6 [00:00<?, ?it/s] Property 'summary' already exists in node '8d10ac'. Skipping!\n",
      "Applying CustomNodeFilter:   0%|          | 0/11 [00:00<?, ?it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "unable to apply transformation: The output parser failed to parse the output including retries.\n",
      "Applying CustomNodeFilter:  91%|█████████ | 10/11 [01:43<00:13, 13.92s/it]unable to apply transformation: Invalid json output: The output string did not satisfy the constraints given in the prompt. Fix the output string and return it.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"score\": {\"description\": \"1 to 5 score\", \"title\": \"Score\", \"type\": \"integer\"}}, \"required\": [\"score\"], \"title\": \"QuestionPotentialOutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes, properly escaped with a backslash.\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"document_summary\": \"The Sponsorship Program at GitLab aims to provide team members from underrepresented groups opportunities for career advancement and visibility. The program consists of four phases, including training materials development, sponsorship matching, and quarterly check-ins. The goals of the program are to increase diversity, equity, and inclusion in the workplace, while also providing benefits to sponsors, sponsees, and GitLab as a whole.\",\n",
      "    \"node_content\": \"What does a successful sponsorship look like? Build Take the time to build a solid relationship with each other. This will be particularly important if you have no previous direct working relationship and can often take some time to cultivate. It is very important to build the relationship first before moving into authentic sponsorship. Suggested Actions: Commit to regular 1-1s Understand the sponsees career development plan Set goals and expectations early Develop You have taken the time to build a relationship with each other, the next step is to develop that relationship by becoming action & capability focussed. In this step the sponsor will help guide the sponsee on areas of improvement in skills & capabilities. The sponsee is responsible for acting on feedback and being intentional about displaying these improvements to the sponsor. Suggested Actions: Find and seek opportunities for the sponsor to observe the sponsees improvement areas Sponsee invites Sponsor to a team meeting where they are presenting Sponsor invites sponsee to a working group Commit This is where both parties agree to move forward with the next step, which is sponsorship and advocating for the sponsee. This can take many forms, such as; a formal discussion, the sponsor outlining actions to the sponsee or at the sponsees request. This is an opportunity to provide feedback, any uncertainties and to reestablish career development goals. Suggested Actions: Participate in feedback session with sponsee Advocate Now that a commitment has been made and the sponsor is satisfied that the sponsee is ready for the next step. The sponsor actively and intentionally advocates for sponsees continued career development and advancement at GitLab. Goals & Benefits of Sponsorship Program Goals: The goal of this program is to provide team members from underrepresented groups opportunities to have more visibility at GitLab. We are starting with the Black team member population in sales as they are very underrepresented in all areas of leadership. The goal is that programs like this will help redress the imbalance and ensure we are moving towards a more diverse, equitable and inclusive workplace. Benefits: Sponsor: Exposure to a diverse set of team members at GitLab, increasing their ability to lead diverse teams Exposure to new ideas and be challenged on the status quo Intentional talent management & succession planning Better understanding of the challenges of team members from underrepresented groups Sponsee: Increased exposure to GitLab and visibility to senior leaders at GitLab Access to feedback from a senior leader Ability to develop skills and capabilities Increased control over your career development plan GitLab: A more diverse team at leadership team Increased retention of team members Attraction of underrepresented groups to GitLab Team members more motivated to maintain performance levels Measurables Start, Mid and End of the program - Satisfaction score from both Sponsor and Sponsee Career Advancement Rate within twelve months of the program Pilot Project Plan Phase 1: Develop training materials for Sponsors & Sponsees => 0% Develop program materials => 0% Sponsorship 1-1 guide => 0% Next Steps Doc - for End of Program => 0% Identify first cohort of sponsees amongst Team Members in Sales => 0% What criteria they have for a sponsor => 0% Identify first cohort of sponsors with the Sales Org => 0% What expertise they are willing to provide and opportunities they can provide => 0% Matchmaking of Sponsors & Sponsee => 0% Complete => => 0%\n",
      "    \"rubrics\": {\n",
      "        \"score1_description\": \"The page content is irrelevant or does not align with the main themes or topics of the document summary.\",\n",
      "        \"score2_description\": \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\",\n",
      "        \"score3_description\": \"The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.\",\n",
      "        \"score4_description\": \"The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.\",\n",
      "        \"score5_description\": \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"\n",
      "    }\n",
      "}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor, KeyphrasesExtractor, TopicDescriptionExtractor]:   0%|          | 0/94 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node '8d10ac'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor, KeyphrasesExtractor, TopicDescriptionExtractor]:  21%|██▏       | 20/94 [03:03<20:06, 16.31s/it]Property 'themes' already exists in node '8d10ac'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor, KeyphrasesExtractor, TopicDescriptionExtractor]:  37%|███▋      | 35/94 [06:24<09:48,  9.97s/it]Property 'keyphrases' already exists in node '8d10ac'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor, KeyphrasesExtractor, TopicDescriptionExtractor]:  61%|██████    | 57/94 [07:07<02:12,  3.58s/it]Property 'topic_description' already exists in node '8d10ac'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor, KeyphrasesExtractor, TopicDescriptionExtractor]:  76%|███████▌  | 71/94 [07:24<00:47,  2.08s/it]Property 'entities' already exists in node '8d10ac'. Skipping!\n",
      "                                                                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "from ragas.testset.transforms import apply_transforms\n",
    "\n",
    "apply_transforms(kg, transforms, run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generating personas\n",
    "\n",
    "- A **Persona** is an entity/role which interacts with the system. **Personas** provide context and perspective, ensuring that **generated queries are natural, user-specific, and diverse**.\n",
    "\n",
    "- `Example: a Senior DevOps engineer, a Junior Data Scientist, a Marketing Manager in the context of an IT company `\n",
    "\n",
    "- **Persona** object consists of a **name** and a **description**.\n",
    "    \n",
    "    - The name is used to identify the persona and the description is used to describe the role of the persona.\n",
    "\n",
    "I've decided to diviate a little bit from **RAGAs** and created my own custom function for generating personas, which doesn't differ quite alot. Instead of just using the **summary** property I also make use of the **keyphrases** and **themes** with the hopes of getting more diverse and creative persona objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 10/10 [00:00<00:00, 595.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from persona import generate_personas_from_kg\n",
    "\n",
    "personas = generate_personas_from_kg(\n",
    "    kg,\n",
    "    langchain_llm,\n",
    "    num_personas=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(name='Diversity and Inclusion Manager', role_description='Works to create inclusive workplaces and promote diversity through events and initiatives.'),\n",
       " Persona(name='Diversity and Inclusion Manager', role_description='Oversees and implements strategies to promote diversity, inclusion, and belonging within the organization.'),\n",
       " Persona(name='Diversity and Inclusion Coordinator', role_description='Develops and implements strategies to promote diversity, equity, and inclusion within the organization.'),\n",
       " Persona(name='Diversity and Inclusion Advisor', role_description='Works to promote diversity, equity, and inclusion within an organization.'),\n",
       " Persona(name='Program Coordinator', role_description='Develops and implements programs to promote diversity, inclusion, and belonging within an organization.'),\n",
       " Persona(name='Global Diversity Officer', role_description='Develops strategies to promote diversity, equity, and inclusion in a predominantly US-based organization, focusing on geographic diversity, leadership representation, and hiring practices.'),\n",
       " Persona(name='Diversity and Inclusion Lead', role_description='Focuses on implementing programs that promote diversity, equity, and inclusion in the workplace while fostering career growth and development.'),\n",
       " Persona(name='Inclusion Specialist', role_description='Works to foster an inclusive environment within their organization, promoting diversity and ensuring all voices are heard.'),\n",
       " Persona(name='Diversity, Inclusion & Belonging Coordinator', role_description='Focuses on creating safe spaces for discussion and building deeper connections among team members while promoting empathy and vulnerability.'),\n",
       " Persona(name='Diversity and Inclusion Specialist', role_description='Works on promoting an inclusive culture within a global company and developing initiatives for diverse team members.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate query types \n",
    "\n",
    "- There are two main types of queries in **RAGAs**:\n",
    "    \n",
    "    - **SingleHopQuery** where the **context** relevant for answering a question lies in a **single document/chunk**\n",
    "\n",
    "    - **MultiHopQuery** where the **context** relevant for answering a question lies in **multiple documents/chunks**\n",
    "\n",
    "- Additionally, for each of those queries there's a **Specific** or **Abstract** query variant:\n",
    "    \n",
    "    - **Specific** one which pertains to a **fact**. \n",
    "\n",
    "        - `Example: When did WW1 break out? (Can be precisely answered, there's no room for guessing/interpretation)`\n",
    "    \n",
    "    - **Abstract** one which is more about testing the **reasoning** capabilities of the LLM. \n",
    "\n",
    "        - `Example: Why did WW1 break out? (There's room for interpretation in this case)`\n",
    "\n",
    "**Synthesizers** are responsible for **converting enriched nodes and personas into queries**. They achieve this by **selecting a node property (e.g., \"entities\" or \"keyphrases\"), pairing it with a persona, style, and query length**, and then using a LLM to generate a query-answer pair based on the content of the node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.multi_hop.specific import MultiHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.multi_hop.abstract import MultiHopAbstractQuerySynthesizer\n",
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "\n",
    "single_hop_specific_entities = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"entities\"\n",
    ")\n",
    "\n",
    "single_hop_specific_keyphrases = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"keyphrases\"\n",
    ")\n",
    "\n",
    "single_hop_specific_headlines = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"headlines\"\n",
    ")\n",
    "\n",
    "single_hop_specific_themes = SingleHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm,\n",
    "    property_name=\"themes\"\n",
    ")\n",
    "\n",
    "multi_hop_specific_entities = MultiHopSpecificQuerySynthesizer(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "multi_hop_abstract_entities = MultiHopAbstractQuerySynthesizer(\n",
    "    llm=langchain_llm\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (single_hop_specific_entities, 0.25),\n",
    "    (single_hop_specific_keyphrases, 0.25),\n",
    "    (single_hop_specific_headlines, 0.125),\n",
    "    (single_hop_specific_themes, 0.125),\n",
    "    (multi_hop_specific_entities, 0.125),\n",
    "    (multi_hop_abstract_entities, 0.125),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlineSplitter:   0%|          | 0/11 [00:00<?, ?it/s] unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:   0%|          | 0/6 [00:00<?, ?it/s] Property 'summary' already exists in node '6b5c2e'. Skipping!\n",
      "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "unable to apply transformation: Invalid json output: After analyzing the input, I would give a score of 4. The content of the node is highly relevant and accurate, reflecting the main themes of the document summary with minor gaps. It covers all important details and adds depth to the understanding of the document's topics.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "unable to apply transformation: The output parser failed to parse the output including retries.\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/30 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node '6b5c2e'. Skipping!\n",
      "Generating Scenarios: 100%|██████████| 6/6 [25:50<00:00, 258.36s/it]                                \n",
      "Generating Samples: 100%|██████████| 42/42 [13:22<00:00, 19.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    langchain_llm,\n",
    "    langchain_embeddings,\n",
    "    kg,\n",
    "    personas\n",
    ")\n",
    "\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs,\n",
    "    testset_size=50,\n",
    "    query_distribution=query_distribution,\n",
    "    run_config=run_config,\n",
    "    with_debugging_logs=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
